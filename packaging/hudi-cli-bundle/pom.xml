<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>hudi</artifactId>
        <groupId>org.apache.hudi</groupId>
        <version>0.13.0-SNAPSHOT</version>
        <relativePath>../../pom.xml</relativePath>
    </parent>
    <modelVersion>4.0.0</modelVersion>
    <artifactId>hudi-cli-bundle</artifactId>
    <packaging>jar</packaging>

    <properties>
        <checkstyle.skip>true</checkstyle.skip>
        <main.basedir>${project.parent.basedir}</main.basedir>
        <skipTests>true</skipTests>
        <javax.servlet.version>3.1.0</javax.servlet.version>
    </properties>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.rat</groupId>
                <artifactId>apache-rat-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>${maven-shade-plugin.version}</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <createSourcesJar>${shadeSources}</createSourcesJar>
                            <dependencyReducedPomLocation>${project.build.directory}/dependency-reduced-pom.xml
                            </dependencyReducedPomLocation>
                            <transformers>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ApacheLicenseResourceTransformer" />
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ApacheNoticeResourceTransformer">
                                    <addHeader>true</addHeader>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
                                    <resource>META-INF/LICENSE</resource>
                                    <file>target/classes/META-INF/LICENSE</file>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                                    <resource>META-INF/services/org.apache.spark.sql.sources.DataSourceRegister</resource>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                                    <resource>META-INF/spring.handlers</resource>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                                    <resource>META-INF/spring.schemas</resource>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                                    <resource>META-INF/spring.factories</resource>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                    <mainClass>org.apache.hudi.cli.Main</mainClass>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                                    <resource>META-INF/spring/org.springframework.boot.actuate.autoconfigure.web.ManagementContextConfiguration.imports</resource>
                                </transformer>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                                    <resource>META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports</resource>
                                </transformer>
                            </transformers>
                            <artifactSet>
                                <includes combine.children="append">
                                    <include>org.apache.hudi:hudi-common</include>
                                    <include>org.apache.hudi:hudi-cli</include>
                                    <include>org.apache.hudi:hudi-client-common</include>
                                    <include>org.apache.hudi:hudi-spark-client</include>
                                    <include>org.apache.hudi:hudi-spark-common_${scala.binary.version}</include>
                                    <include>org.apache.hudi:hudi-spark_${scala.binary.version}</include>
                                    <include>org.apache.hudi:${hudi.spark.module}_${scala.binary.version}</include>
                                    <include>org.apache.hudi:${hudi.spark.common.modules.1}</include>
                                    <include>org.apache.hudi:${hudi.spark.common.modules.2}</include>
                                    <include>org.apache.hudi:hudi-hive-sync</include>
                                    <include>org.apache.hudi:hudi-sync-common</include>
                                    <include>org.apache.hudi:hudi-hadoop-mr</include>
                                    <include>org.apache.hudi:hudi-timeline-service</include>
                                    <include>org.apache.hudi:hudi-utilities_${scala.binary.version}</include>

                                    <include>org.apache.logging.log4j:*</include>
                                    <include>org.scala-lang:scala-library</include>
                                    <include>org.apache.parquet:parquet-hadoop</include>

                                    <include>javax.servlet:javax.servlet-api</include>
                                    <include>com.beust:jcommander</include>
                                    <include>io.javalin:javalin</include>
                                    <!-- Spark only has mortbay jetty -->
                                    <include>org.eclipse.jetty:*</include>
                                    <include>org.eclipse.jetty.websocket:*</include>
                                    <include>org.jetbrains.kotlin:*</include>
                                    <include>org.rocksdb:rocksdbjni</include>
                                    <include>org.apache.httpcomponents:httpclient</include>
                                    <include>org.apache.httpcomponents:httpcore</include>
                                    <include>org.apache.httpcomponents:fluent-hc</include>
                                    <include>org.antlr:stringtemplate</include>
                                    <include>org.apache.parquet:parquet-avro</include>

                                    <include>com.github.davidmoten:guava-mini</include>
                                    <include>com.github.davidmoten:hilbert-curve</include>
                                    <include>com.github.ben-manes.caffeine:caffeine</include>
                                    <include>com.twitter:bijection-avro_${scala.binary.version}</include>
                                    <include>com.twitter:bijection-core_${scala.binary.version}</include>
                                    <include>io.dropwizard.metrics:metrics-core</include>
                                    <include>io.dropwizard.metrics:metrics-graphite</include>
                                    <include>io.dropwizard.metrics:metrics-jmx</include>
                                    <include>io.prometheus:simpleclient</include>
                                    <include>io.prometheus:simpleclient_httpserver</include>
                                    <include>io.prometheus:simpleclient_dropwizard</include>
                                    <include>io.prometheus:simpleclient_pushgateway</include>
                                    <include>io.prometheus:simpleclient_common</include>
                                    <include>com.yammer.metrics:metrics-core</include>
                                    <include>com.google.guava:guava</include>

                                    <include>org.apache.hive:hive-common</include>
                                    <include>org.apache.hive:hive-service</include>
                                    <include>org.apache.hive:hive-service-rpc</include>
                                    <include>org.apache.hive:hive-metastore</include>
                                    <include>org.apache.hive:hive-jdbc</include>

                                    <include>org.apache.hbase:hbase-client</include>
                                    <include>org.apache.hbase:hbase-common</include>
                                    <include>org.apache.hbase:hbase-hadoop-compat</include>
                                    <include>org.apache.hbase:hbase-hadoop2-compat</include>
                                    <include>org.apache.hbase:hbase-metrics</include>
                                    <include>org.apache.hbase:hbase-metrics-api</include>
                                    <include>org.apache.hbase:hbase-protocol</include>
                                    <include>org.apache.hbase:hbase-protocol-shaded</include>
                                    <include>org.apache.hbase:hbase-server</include>
                                    <include>org.apache.hbase.thirdparty:hbase-shaded-miscellaneous</include>
                                    <include>org.apache.hbase.thirdparty:hbase-shaded-netty</include>
                                    <include>org.apache.hbase.thirdparty:hbase-shaded-protobuf</include>
                                    <include>org.apache.htrace:htrace-core4</include>
                                    <include>org.apache.curator:curator-framework</include>
                                    <include>org.apache.curator:curator-client</include>
                                    <include>org.apache.curator:curator-recipes</include>
                                    <include>commons-codec:commons-codec</include>
                                    <include>commons-io:commons-io</include>
                                    <include>org.springframework*:*</include>
                                    <include>org.springframework.boot:*</include>
                                    <include>org.jline:*</include>
                                    <include>org.slf4j:slf4j-api</include>
                                    <include>org.yaml:*</include>
                                    <include>commons-logging:*</include>
                                    <include>org.apache.avro:avro</include>
                                    <include>org.hibernate.validator:hibernate-validator</include>
                                    <include>javax.validation:validation-api</include>
                                    <include>jakarta.validation:jakarta.validation-api</include>
                                    <include>org.jboss.logging:jboss-logging</include>
                                    <include>com.fasterxml:classmate</include>
                                    <include>org.glassfish:jakarta.el</include>
                                    <include>com.fasterxml.woodstox:woodstox-core</include>
                                    <include>org.codehaus.woodstox:stax2-api</include>
                                    <include>commons-collections:commons-collections</include>
                                    <include>commons-configuration:*</include>
                                    <include>commons-lang:*</include>
                                    <include>com.google.code.gson:gson</include>
                                    <include>org.fusesource.jansi:jansi</include>
                                    <include>net.java.dev.jna:jna</include>
                                    <include>com.jakewharton.fliptables:fliptables</include>
                                    <include>com.google.re2j:re2j</include>
                                    <include>org.openjdk.jol:jol-core</include>
                                </includes>
                            </artifactSet>
                            <relocations>
                                <!-- NOTE: We have to relocate all classes w/in org.apache.spark.sql.avro to avoid
                                           potential classpath collisions in case users would like to also use "spark-avro" w/in
                                           their runtime, since Hudi carries some of the same classes as "spark-avro" -->
                                <relocation combine.children="append">
                                    <pattern>org.apache.parquet.avro.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.parquet.avro.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.avro.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.avro.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>javax.servlet.</pattern>
                                    <shadedPattern>org.apache.hudi.javax.servlet.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.spark.sql.avro.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.spark.sql.avro.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>com.yammer.metrics.</pattern>
                                    <shadedPattern>org.apache.hudi.com.yammer.metrics.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>com.beust.jcommander.</pattern>
                                    <shadedPattern>org.apache.hudi.com.beust.jcommander.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.commons.io.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.commons.io.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.hbase.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.hbase.</shadedPattern>
                                    <excludes>
                                        <exclude>org.apache.hadoop.hbase.KeyValue$KeyComparator</exclude>
                                    </excludes>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hbase.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hbase.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.htrace.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.htrace.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hive.jdbc.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hive.jdbc.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.hive.metastore.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hadoop.hive.metastore.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hive.common.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hive.common.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.hive.common.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hadoop.hive.common.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.hive.conf.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hadoop.hive.conf.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hive.service.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hive.service.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.hive.service.</pattern>
                                    <shadedPattern>${spark.bundle.hive.shade.prefix}org.apache.hadoop.hive.service.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>com.codahale.metrics.</pattern>
                                    <shadedPattern>org.apache.hudi.com.codahale.metrics.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.commons.codec.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.commons.codec.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.eclipse.jetty.</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.jetty.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>com.google.common.</pattern>
                                    <shadedPattern>org.apache.hudi.com.google.common.</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.openjdk.jol.</pattern>
                                    <shadedPattern>org.apache.hudi.org.openjdk.jol.</shadedPattern>
                                </relocation>
                                <!-- TODO: Revisit GH ISSUE #533 & PR#633-->
                                <!-- The classes below in org.apache.hadoop.metrics2 package come from
                                hbase-hadoop-compat and hbase-hadoop2-compat, which have to be shaded one by one,
                                instead of shading all classes under org.apache.hadoop.metrics2 including ones
                                from hadoop. -->
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.MetricHistogram</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.MetricHistogram
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.MetricsExecutor</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.MetricsExecutor
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.impl.JmxCacheBuster</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.impl.JmxCacheBuster</shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.DefaultMetricsSystemHelper</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.DefaultMetricsSystemHelper
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.DynamicMetricsRegistry
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.MetricsExecutorImpl</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.MetricsExecutorImpl
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.MutableFastCounter</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.MutableFastCounter
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.MutableHistogram</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.MutableHistogram
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.MutableRangeHistogram</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.MutableRangeHistogram
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.MutableSizeHistogram</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.MutableSizeHistogram
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.lib.MutableTimeHistogram</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.lib.MutableTimeHistogram
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.util.MetricQuantile</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.util.MetricQuantile
                                    </shadedPattern>
                                </relocation>
                                <relocation>
                                    <pattern>org.apache.hadoop.metrics2.util.MetricSampleQuantiles</pattern>
                                    <shadedPattern>org.apache.hudi.org.apache.hadoop.metrics2.util.MetricSampleQuantiles
                                    </shadedPattern>
                                </relocation>
                            </relocations>
                            <filters>
                                <filter>
                                    <artifact>*:*</artifact>
                                    <excludes>
                                        <exclude>META-INF/*.SF</exclude>
                                        <exclude>META-INF/*.DSA</exclude>
                                        <exclude>META-INF/*.RSA</exclude>
                                        <exclude>**/*.proto</exclude>
                                        <exclude>hbase-webapps/**</exclude>
                                        <!-- hbase-default.xml comes from hbase-common, hbase related classes used in hudi are in shaded
                                        pattern, the default classes in hbase-default.xml can cause ClassNotFoundException. -->
                                        <exclude>hbase-default.xml</exclude>
                                    </excludes>
                                </filter>
                            </filters>
                            <finalName>${project.artifactId}-${project.version}</finalName>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
        <resources>
            <resource>
                <directory>src/main/resources</directory>
            </resource>
        </resources>
    </build>

    <dependencies>
        <!-- Hoodie -->
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-common</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-cli</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-client-common</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-spark-client</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-hadoop-mr</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-hive-sync</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-spark-common_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-spark_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>${hudi.spark.module}_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-timeline-service</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hudi</groupId>
            <artifactId>hudi-utilities-bundle_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
        </dependency>

        <!-- Parquet -->
        <dependency>
            <groupId>org.apache.parquet</groupId>
            <artifactId>parquet-avro</artifactId>
            <scope>compile</scope>
        </dependency>

        <!-- Hive -->
        <dependency>
            <groupId>${hive.groupid}</groupId>
            <artifactId>hive-service</artifactId>
            <version>${hive.version}</version>
            <scope>${spark.bundle.hive.scope}</scope>
            <exclusions>
                <exclusion>
                    <artifactId>servlet-api</artifactId>
                    <groupId>javax.servlet</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>${hive.groupid}</groupId>
            <artifactId>hive-service-rpc</artifactId>
            <version>${hive.version}</version>
            <scope>${spark.bundle.hive.scope}</scope>
        </dependency>

        <dependency>
            <groupId>${hive.groupid}</groupId>
            <artifactId>hive-jdbc</artifactId>
            <version>${hive.version}</version>
            <scope>${spark.bundle.hive.scope}</scope>
        </dependency>

        <dependency>
            <groupId>${hive.groupid}</groupId>
            <artifactId>hive-metastore</artifactId>
            <version>${hive.version}</version>
            <scope>${spark.bundle.hive.scope}</scope>
        </dependency>

        <dependency>
            <groupId>${hive.groupid}</groupId>
            <artifactId>hive-common</artifactId>
            <version>${hive.version}</version>
            <scope>${spark.bundle.hive.scope}</scope>
        </dependency>

        <!-- zookeeper -->
        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-framework</artifactId>
            <version>${zk-curator.version}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-client</artifactId>
            <version>${zk-curator.version}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.curator</groupId>
            <artifactId>curator-recipes</artifactId>
            <version>${zk-curator.version}</version>
        </dependency>

        <dependency>
            <groupId>javax.servlet</groupId>
            <artifactId>javax.servlet-api</artifactId>
            <version>${javax.servlet.version}</version>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-validation</artifactId>
            <version>${springboot.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <groupId>org.springframework.boot</groupId>
                    <artifactId>spring-boot-starter-logging</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.google.guava</groupId>
                    <artifactId>guava</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>ch.qos.logback</groupId>
                    <artifactId>logback-classic</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.springframework.shell</groupId>
            <artifactId>spring-shell-starter</artifactId>
            <version>${spring.shell.version}</version>
            <scope>compile</scope>
            <exclusions>
                <exclusion>
                    <groupId>com.google.guava</groupId>
                    <artifactId>guava</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>ch.qos.logback</groupId>
                    <artifactId>logback-classic</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!-- Avro -->
        <dependency>
            <groupId>org.apache.avro</groupId>
            <artifactId>avro</artifactId>
            <scope>compile</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-auth</artifactId>
            <version>${hadoop.version}</version>
            <scope>compile</scope>
        </dependency>
        <!-- Logging -->
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-1.2-api</artifactId>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-core</artifactId>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-api</artifactId>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>${slf4j.version}</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>javax.validation</groupId>
            <artifactId>validation-api</artifactId>
            <version>1.1.0.Final</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.glassfish</groupId>
            <artifactId>jakarta.el</artifactId>
            <version>3.0.3</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.woodstox</groupId>
            <artifactId>woodstox-core</artifactId>
            <scope>compile</scope>
            <version>5.0.3</version>
        </dependency>
        <dependency>
            <groupId>org.codehaus.woodstox</groupId>
            <artifactId>stax2-api</artifactId>
            <scope>compile</scope>
            <version>3.1.4</version>
        </dependency>
        <dependency>
            <groupId>org.jline</groupId>
            <artifactId>jline</artifactId>
            <version>3.21.0</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.jline</groupId>
            <artifactId>jline-terminal-jna</artifactId>
            <version>3.21.0</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.fusesource.jansi</groupId>
            <artifactId>jansi</artifactId>
            <version>2.4.0</version>
            <scope>compile</scope>
        </dependency>

        <!-- TODO: Reinvestigate PR 633 -->
    </dependencies>

    <profiles>
        <profile>
            <id>spark-bundle-shade-hive</id>
            <properties>
                <spark.bundle.hive.scope>compile</spark.bundle.hive.scope>
                <spark.bundle.hive.shade.prefix>org.apache.hudi.</spark.bundle.hive.shade.prefix>
            </properties>
        </profile>
    </profiles>
</project>

# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
dag_name: spark-non-core-operations.yaml
dag_rounds: 1
dag_intermittent_delay_mins: 1
dag_content:
  first_insert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10000
    type: SparkInsertNode
    deps: none
  first_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      num_records_insert: 1000
      repeat_count: 1
      num_records_upsert: 8000
      num_partitions_upsert: 10
    type: SparkUpsertNode
    deps: first_insert
  second_insert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10000
    type: SparkInsertNode
    deps: first_upsert
  second_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      num_records_insert: 1000
      repeat_count: 1
      num_records_upsert: 8000
      num_partitions_upsert: 10
    type: SparkUpsertNode
    deps: second_insert
  first_insert_overwrite:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10
    type: SparkInsertOverwriteNode
    deps: second_upsert
  delete_all_input_except_last:
    config:
      delete_input_data_except_latest: true
    type: DeleteInputDatasetNode
    deps: first_insert_overwrite
  third_insert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10000
    type: SparkInsertNode
    deps: delete_all_input_except_last
  third_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      num_records_insert: 1000
      repeat_count: 1
      num_records_upsert: 8000
      num_partitions_upsert: 10
    type: SparkUpsertNode
    deps: third_insert
  second_validate:
    config:
      validate_full_data : true
      validate_hive: false
      delete_input_data: false
    type: ValidateDatasetNode
    deps: third_upsert
  fourth_insert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10000
    type: SparkInsertNode
    deps: second_validate
  fourth_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      num_records_insert: 1000
      repeat_count: 1
      num_records_upsert: 8000
      num_partitions_upsert: 10
    type: SparkUpsertNode
    deps: fourth_insert
  fifth_insert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10000
    type: SparkInsertNode
    deps: fourth_upsert
  fifth_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      num_records_insert: 1000
      repeat_count: 1
      num_records_upsert: 8000
      num_partitions_upsert: 10
    type: SparkUpsertNode
    deps: fifth_insert
  first_insert_overwrite_table:
    config:
      record_size: 1000
      repeat_count: 1
      num_records_insert: 10
    type: SparkInsertOverwriteTableNode
    deps: fifth_upsert
  second_delete_all_input_except_last:
    config:
      delete_input_data_except_latest: true
    type: DeleteInputDatasetNode
    deps: first_insert_overwrite_table
  sixth_insert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      repeat_count: 1
      num_records_insert: 10000
    type: SparkInsertNode
    deps: second_delete_all_input_except_last
  sixth_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 10
      num_records_insert: 1000
      repeat_count: 1
      num_records_upsert: 8000
      num_partitions_upsert: 10
    type: SparkUpsertNode
    deps: sixth_insert
  third_validate:
    config:
      validate_full_data : true
      validate_hive: false
      delete_input_data: false
    type: ValidateDatasetNode
    deps: sixth_upsert
  seventh_insert:
    config:
      record_size: 1000
      num_partitions_insert: 5
      repeat_count: 1
      num_records_insert: 10
    type: SparkInsertNode
    deps: third_validate
  first_delete_partition:
    config:
      partitions_to_delete: "1970/01/01"
    type: SparkDeletePartitionNode
    deps: seventh_insert
  fourth_validate:
    config:
      validate_full_data : true
      input_partitions_to_skip_validate : "0"
      validate_hive: false
      delete_input_data: false
    type: ValidateDatasetNode
    deps: first_delete_partition
  eigth_insert:
    config:
      record_size: 1000
      num_partitions_insert: 5
      repeat_count: 1
      num_records_insert: 10
      start_partition: 2
    type: SparkInsertNode
    deps: fourth_validate
  fifth_validate:
    config:
      validate_full_data : true
      input_partitions_to_skip_validate : "0"
      validate_hive: false
      delete_input_data: false
    type: ValidateDatasetNode
    deps: eigth_insert
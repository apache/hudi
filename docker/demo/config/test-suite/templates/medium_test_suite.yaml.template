# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Long running test suite which validates entire input after every dag. Input accumulates and so validation
# happens for entire dataset.
dag_name: NAME-long-running-multi-partitions.yaml
dag_rounds: medium_num_iterations
dag_intermittent_delay_mins: delay_in_mins
dag_content:
  first_insert:
    config:
      record_size: 1000
      num_partitions_insert: 5
      repeat_count: 1
      num_records_insert: 1000
    type: InsertNode
    deps: none
  second_insert:
    config:
      record_size: 1000
      num_partitions_insert: 50
      repeat_count: 1
      num_records_insert: 10000
    deps: first_insert
    type: InsertNode
  third_insert:
    config:
      record_size: 1000
      num_partitions_insert: 2
      repeat_count: 1
      num_records_insert: 300
    deps: second_insert
    type: InsertNode
  first_hive_sync:
    config:
      queue_name: "adhoc"
      engine: "mr"
    type: HiveSyncNode
    deps: third_insert
  first_validate:
    config:
      validate_hive: true
    type: ValidateDatasetNode
    deps: first_hive_sync
  first_upsert:
    config:
      record_size: 1000
      num_partitions_insert: 2
      num_records_insert: 300
      repeat_count: 1
      num_records_upsert: 100
      num_partitions_upsert: 1
    type: UpsertNode
    deps: first_validate
  first_delete:
    config:
      num_partitions_delete: 50
      num_records_delete: 8000
    type: DeleteNode
    deps: first_upsert
  second_hive_sync:
    config:
      queue_name: "adhoc"
      engine: "mr"
    type: HiveSyncNode
    deps: first_delete
  second_validate:
    config:
      validate_hive: true
      delete_input_data: false
    type: ValidateDatasetNode
    deps: second_hive_sync
  last_validate:
    config:
      execute_itr_count: medium_num_iterations
      validate_clean: true
      validate_archival: true
    type: ValidateAsyncOperations
    deps: second_validate

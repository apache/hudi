{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bbcda9-7b8a-4415-8915-acadcfa07660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44b9eca-63e2-468a-ba86-8113533b4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUDI_JAR = os.environ.get(\"HUDI_SPARK_BUNDLE\")\n",
    "if not HUDI_JAR:\n",
    "        raise EnvironmentError(\"HUDI_SPARK_BUNDLE environment variable not set\")\n",
    "\n",
    "HADOOP_S3_JAR = \"/opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.734.jar\"\n",
    "\n",
    "ALL_JARS = f\"{HUDI_JAR},{HADOOP_S3_JAR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f104543-3374-4c78-b666-bf44f3be962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session(app_name=\"Hudi-Notebooks\"):\n",
    "    \"\"\"\n",
    "    Initialize a SparkSession with Hudi extensions.\n",
    "    \n",
    "    Parameters:\n",
    "    - app_name (str): Optional name for the Spark application.\n",
    "    \n",
    "    Returns:\n",
    "    - SparkSession object\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .config(\"spark.jars\", ALL_JARS) \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n",
    "        .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9090\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", \"s3a://warehouse\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    print(f\"SparkSession started with app name: {app_name}\")\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f676ddc-ec63-470e-ad25-98bc589e69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Utility Function\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "def ls(path):\n",
    "    \"\"\"\n",
    "    List files or directories at the given MinIO S3 path.\n",
    "    \n",
    "    Example: ls(\"s3a://warehouse/hudi_table/\")\n",
    "    \"\"\"\n",
    "    hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "    fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(hadoop_conf)\n",
    "    p = spark._jvm.org.apache.hadoop.fs.Path(path)\n",
    "\n",
    "    if not fs.exists(p):\n",
    "        print(f\"Path does not exist: {path}\")\n",
    "        return []\n",
    "\n",
    "    status = fs.listStatus(p)\n",
    "    files = [str(file.getPath()) for file in status]\n",
    "    for f in files:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992498d3-fa60-4614-a08e-256a9f5fd88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Utility Function\n",
    "\n",
    "from IPython.display import display as display_html, HTML\n",
    "\n",
    "def display(df, num_rows=100, truncate=False):\n",
    "    \"\"\"\n",
    "    Displays a PySpark DataFrame in a formatted HTML table.\n",
    "\n",
    "    This function is designed to mimic the Databricks 'display' function by\n",
    "    presenting a sample of the DataFrame in a clean, readable table format\n",
    "    using HTML and Tailwind CSS for styling.\n",
    "\n",
    "    Args:\n",
    "        df (pyspark.sql.DataFrame): The PySpark DataFrame to display.\n",
    "        num_rows (int): The number of rows to show. Defaults to 100.\n",
    "        truncate (bool): Whether to truncate the output of long strings.\n",
    "                         This argument is not currently used for simplicity\n",
    "                         but can be added for more advanced functionality.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Collect a limited number of rows to the driver as a Pandas DataFrame\n",
    "    try:\n",
    "        pandas_df = df.limit(num_rows).toPandas()\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting DataFrame to Pandas: {e}\")\n",
    "        return\n",
    "\n",
    "    # Use pandas to_html to get a clean table, then add custom styling.\n",
    "    # The styling uses Tailwind CSS classes for a clean, modern look.\n",
    "    html_table = pandas_df.to_html(index=False, classes=[\n",
    "        \"w-full\", \"border-collapse\", \"text-sm\", \"text-gray-900\", \"dark:text-white\"\n",
    "    ])\n",
    "\n",
    "    # We are adding custom styling here to make it look like a well-formatted blog post table.\n",
    "    custom_css = \"\"\"\n",
    "    <style>\n",
    "        .dataframe {\n",
    "            border-radius: 0.5rem;\n",
    "            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n",
    "            overflow-x: auto;\n",
    "            border: 1px solid #e2e8f0;\n",
    "        }\n",
    "        .dataframe th {\n",
    "            background-color: #f1f5f9;\n",
    "            color: #1f2937;\n",
    "            font-weight: 600;\n",
    "            padding: 0.75rem 1.5rem;\n",
    "            text-align: left;\n",
    "            border-bottom: 2px solid #e2e8f0;\n",
    "        }\n",
    "        .dataframe td {\n",
    "            padding: 0.75rem 1.5rem;\n",
    "            border-bottom: 1px solid #e2e8f0;\n",
    "        }\n",
    "        .dataframe tr:nth-child(even) {\n",
    "            background-color: #f8fafc;\n",
    "        }\n",
    "        .dataframe tr:hover {\n",
    "            background-color: #e2e8f0;\n",
    "            transition: background-color 0.2s ease-in-out;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Display the final HTML\n",
    "    display_html(HTML(custom_css + html_table))\n",
    "\n",
    "# Example usage with your data\n",
    "# display(inputDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

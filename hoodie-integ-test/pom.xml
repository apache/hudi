<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright (c) 2016 Uber Technologies, Inc. (hoodie-dev-group@uber.com)
  ~
  ~ Licensed under the Apache License, Version 2.0 (the "License");
  ~ you may not use this file except in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~           http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <parent>
    <artifactId>hoodie</artifactId>
    <groupId>com.uber.hoodie</groupId>
    <version>0.4.6-SNAPSHOT</version>
    <relativePath>../pom.xml</relativePath>
  </parent>
  <modelVersion>4.0.0</modelVersion>

  <artifactId>hoodie-integ-test</artifactId>

  <dependencies>
    <!-- Hoodie -->
    <dependency>
      <groupId>com.uber.hoodie</groupId>
      <artifactId>hoodie-spark</artifactId>
      <version>${project.version}</version>
    </dependency>

    <!-- Logging -->
    <dependency>
      <groupId>org.slf4j</groupId>
      <artifactId>slf4j-api</artifactId>
    </dependency>
    <dependency>
      <groupId>org.slf4j</groupId>
      <artifactId>slf4j-log4j12</artifactId>
    </dependency>

    <!-- Glassfish -->
    <dependency>
      <groupId>org.glassfish.jersey.core</groupId>
      <artifactId>jersey-server</artifactId>
    </dependency>
    <dependency>
      <groupId>org.glassfish.jersey.connectors</groupId>
      <artifactId>jersey-apache-connector</artifactId>
    </dependency>
    <dependency>
      <groupId>org.glassfish.jersey.containers</groupId>
      <artifactId>jersey-container-servlet-core</artifactId>
    </dependency>

    <!-- Hoodie - Test -->
    <dependency>
      <groupId>com.uber.hoodie</groupId>
      <artifactId>hoodie-common</artifactId>
      <version>${project.version}</version>
      <classifier>tests</classifier>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>com.uber.hoodie</groupId>
      <artifactId>hoodie-spark</artifactId>
      <version>${project.version}</version>
      <classifier>tests</classifier>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>com.uber.hoodie</groupId>
      <artifactId>hoodie-hadoop-sparkworker-docker</artifactId>
      <version>${project.version}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>

    <!-- Fasterxml - Test-->
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-annotations</artifactId>
      <version>${fasterxml.version}</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>${fasterxml.version}</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.datatype</groupId>
      <artifactId>jackson-datatype-guava</artifactId>
      <version>${fasterxml.version}</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>org.awaitility</groupId>
      <artifactId>awaitility</artifactId>
      <version>3.1.2</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>com.google.guava</groupId>
      <artifactId>guava</artifactId>
      <version>20.0</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>${junit.version}</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>com.github.docker-java</groupId>
      <artifactId>docker-java</artifactId>
      <version>3.1.2</version>
      <scope>test</scope>
    </dependency>
  </dependencies>

  <properties>
    <dockerCompose.envFile>${project.basedir}/compose_env</dockerCompose.envFile>
    <dockerCompose.file>${project.basedir}/../docker/compose/docker-compose_hadoop284_hive233_spark240.yml</dockerCompose.file>
    <skipITs>false</skipITs>
    <docker.compose.skip>${skipITs}</docker.compose.skip>
    <checkstyle.skip>true</checkstyle.skip>
  </properties>

  <build>
    <plugins>
      <plugin>
        <artifactId>exec-maven-plugin</artifactId>
        <version>1.6.0</version>
        <groupId>org.codehaus.mojo</groupId>
        <executions>
          <execution><!-- setup HUDI_WS variable in docker compose env file -->
            <id>Setup HUDI_WS</id>
            <phase>generate-sources</phase>
            <goals>
              <goal>exec</goal>
            </goals>
            <configuration>
              <executable>/bin/bash</executable>
              <arguments>
                <argument> -c </argument>
                <argument>echo HUDI_WS=`dirname ${project.basedir}`</argument>
              </arguments>
              <outputFile>${dockerCompose.envFile}</outputFile>
            </configuration>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-failsafe-plugin</artifactId>
        <version>2.22.0</version>
        <executions>
          <execution>
            <goals>
              <goal>integration-test</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>com.dkanejs.maven.plugins</groupId>
        <artifactId>docker-compose-maven-plugin</artifactId>
        <version>2.4.0</version>
        <executions>
          <execution>
            <id>up</id>
            <phase>pre-integration-test</phase>
            <goals>
              <goal>up</goal>
            </goals>
            <configuration>
              <skip>${docker.compose.skip}</skip>
              <host>unix:///var/run/docker.sock</host>
              <composeFile>${project.basedir}/../docker/compose/docker-compose_hadoop284_hive233_spark240.yml</composeFile>
              <detachedMode>true</detachedMode>
              <envFile>${dockerCompose.envFile}</envFile>
            </configuration>
          </execution>
          <execution>
            <id>down</id>
            <phase>integration-test</phase>
            <goals>
              <goal>down</goal>
            </goals>
            <configuration>
              <skip>${docker.compose.skip}</skip>
              <composeFile>${project.basedir}/../docker/compose/docker-compose_hadoop284_hive233_spark240.yml</composeFile>
              <removeVolumes>true</removeVolumes>
            </configuration>
          </execution>
        </executions>
      </plugin>
    </plugins>
  </build>
</project>

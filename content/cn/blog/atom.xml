<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://hudi.apache.org/cn/blog</id>
    <title>Apache Hudi: User-Facing Analytics</title>
    <updated>2025-04-14T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://hudi.apache.org/cn/blog"/>
    <subtitle>Apache Hudi Blog</subtitle>
    <icon>https://hudi.apache.org/cn/assets/images/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[How Doris + Hudi Turned the Impossible Into the Everyday]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/04/14/doris-hudi-making-impossible-possible</id>
        <link href="https://hudi.apache.org/cn/blog/2025/04/14/doris-hudi-making-impossible-possible"/>
        <updated>2025-04-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://dzone.com/articles/doris-hudi-making-impossible-possible">here</a></span>]]></content>
        <author>
            <name>Zen Hua</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Doris" term="Apache Doris"/>
        <category label="use-case" term="use-case"/>
        <category label="federated querying" term="federated querying"/>
        <category label="dzone" term="dzone"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why Walmart Chose Apache Hudi for Their Lakehouse]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/04/09/why-walmart-chose-apache-hudi-for-their-lakehouse</id>
        <link href="https://hudi.apache.org/cn/blog/2025/04/09/why-walmart-chose-apache-hudi-for-their-lakehouse"/>
        <updated>2025-04-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://blog.det.life/why-walmart-chose-apache-hudi-for-their-lakehouse-c0a3574db0ba">here</a></span>]]></content>
        <author>
            <name>Vu Trinh</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="use-case" term="use-case"/>
        <category label="det" term="det"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[ From Swamp to Stream: How Apache Hudi Transforms the Modern Data Lake]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/04/06/from-swamp-to-stream-how-apache-hudi-transforms-the-modern-data-lake</id>
        <link href="https://hudi.apache.org/cn/blog/2025/04/06/from-swamp-to-stream-how-apache-hudi-transforms-the-modern-data-lake"/>
        <updated>2025-04-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/aimonks/from-swamp-to-stream-how-apache-hudi-transforms-the-modern-data-lake-8a938f517ea1">here</a></span>]]></content>
        <author>
            <name>Everton Gomede</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="real-time datalake" term="real-time datalake"/>
        <category label="incremental processing" term="incremental processing"/>
        <category label="upserts" term="upserts"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Integrating Apache Doris and Hudi for Data Querying and Migration]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/04/03/integrate-apache-doris-hudi-data-querying-migration</id>
        <link href="https://hudi.apache.org/cn/blog/2025/04/03/integrate-apache-doris-hudi-data-querying-migration"/>
        <updated>2025-04-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://dzone.com/articles/integrate-apache-doris-hudi-data-querying-migration">here</a></span>]]></content>
        <author>
            <name>li yy</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Doris" term="Apache Doris"/>
        <category label="real-time query" term="real-time query"/>
        <category label="how-to" term="how-to"/>
        <category label="dzone" term="dzone"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing Secondary Index in Apache Hudi Lakehouse Platform]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/04/02/secondary-index</id>
        <link href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index"/>
        <updated>2025-04-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache Hudi 1.0 introduces Secondary Indexes, enabling faster queries on non-primary key fields. This improves data retrieval in Lakehouse architectures by reducing data scans. Hudi also offers asynchronous indexing for scalability and efficient index maintenance without disrupting data ingestion. By the end of this blog, you'll understand how these features enhance Hudi's capabilities as a high-performance lakehouse platform.]]></summary>
        <content type="html"><![CDATA[<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>TL;DR</div><div class="admonitionContent_BuS1"><p>Apache Hudi 1.0 introduces Secondary Indexes, enabling faster queries on non-primary key fields. This improves data retrieval in Lakehouse architectures by reducing data scans. Hudi also offers asynchronous indexing for scalability and efficient index maintenance without disrupting data ingestion. By the end of this blog, you'll understand how these features enhance Hudi's capabilities as a high-performance lakehouse platform.</p></div></div>
<p>Indexes are a fundamental data structure that enables efficient data retrieval by eliminating the need to scan the entire dataset for every query. In the context of a Lakehouse, where records are written as immutable data files (such as Parquet) at scale, indexing becomes crucial in reducing lookup times. Otherwise, a lot of time will be spent by the compute engine on finding out where exactly a particular record exists amongst thousands of files in the data lake storage, which is computationally expensive at scale. Indexing is not only important for <em>reads</em> in a lakehouse architecture, but also for <em>writes</em>, such as upserts and deletes, as you need to know where the record is to update it.</p>
<p>One of the standout design choices in Apache Hudi that separates it from other lakehouse formats is its <a href="https://hudi.apache.org/docs/next/indexes/" target="_blank" rel="noopener noreferrer">indexing</a> capability, which has been central to its architecture from the beginning. Hudi is heavily optimized to handle mutable change streams with varying write patterns, and indexing plays a pivotal role in making upserts and deletes efficient.</p>
<p>Hudi's indexing mechanism is designed to efficiently manage record lookups and updates by maintaining a structured mapping between records and file groups. Here's how it works:</p>
<ul>
<li>
<p>The first time a record is ingested into Hudi, it is assigned to a <a href="https://hudi.apache.org/tech-specs/#file-layout-hierarchy" target="_blank" rel="noopener noreferrer">File Group</a> - a logical grouping of files. This assignment typically remains unchanged throughout the record's lifecycle. However, in cases such as clustering or cross-partition updates, the record may be remapped to a different file group. Even in such scenarios, Hudi ensures that a given record key is associated with exactly one file group at any completed instant on the timeline</p>
</li>
<li>
<p>Hudi maintains a mapping between the incoming <a href="https://hudi.apache.org/docs/key_generation" target="_blank" rel="noopener noreferrer">record’s key</a> (unique identifier) and the File Group where it resides.</p>
</li>
<li>
<p>The index is responsible for quickly locating records based on this File Group mapping, eliminating the need for full dataset scans.</p>
</li>
</ul>
<p>This strategy allows Hudi to determine whether a record exists and pinpoint its exact location, enabling faster upserts and deletes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="apache-hudis-multi-modal-indexing-system">Apache Hudi's Multi-Modal Indexing System<a href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index#apache-hudis-multi-modal-indexing-system" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>While Hudi’s indexes have set a benchmark for fast writes, bringing those advantages to queries was equally important. This led to the design of a generalized indexing subsystem that enhances performance in the lakehouse. Hudi’s <a href="https://www.onehouse.ai/blog/introducing-multi-modal-index-for-the-lakehouse-in-apache-hudi" target="_blank" rel="noopener noreferrer">multi-modal indexing</a> redefines indexing in data lakes by employing multiple index types, each optimized for different workloads and query patterns. It is built on scalable metadata that supports multiple index types without extra overhead, ACID-compliant updates to keep indexes in sync with the data table, and optimized lookups that minimize full scans for low-latency queries on large datasets.</p>
<p>At the core of Hudi’s indexing design is its <a href="https://hudi.apache.org/docs/metadata" target="_blank" rel="noopener noreferrer">metadata table</a>, a specialized Merge-on-Read table that houses multiple index types as separate partitions. These indexes serve various purposes, improving the efficiency of reads, writes, and upserts.</p>
<img src="https://hudi.apache.org/assets/images/blog/hudi-stack-indexes.png" alt="index" width="800" align="middle">
<p>Some key indexes within Hudi’s metadata table include:</p>
<ul>
<li>File Index - Stores a compact listing of files, reducing the overhead of expensive file system operations.</li>
<li>Column Stats Index - Tracks min/max statistics for each column, enabling more effective data pruning.</li>
<li>Bloom Filter Index - Stores precomputed bloom filters for all data files, optimizing record lookups.</li>
<li>Partition Stats Index - Stores aggregated partition-related information which helps in efficient partition pruning by skipping entire folders very quickly.</li>
<li>Record-Level Index - Maintains direct mappings to individual records, facilitating faster upserts and deletes.</li>
<li>Secondary Index - Allow users to create indexes on columns that are not part of record key columns in Hudi tables.</li>
</ul>
<p>By structuring these indexes as individual partitions within the metadata table, Hudi ensures efficient retrieval, quick lookups, and scalability, even as the data volume grows. In this blog, we will focus on secondary indexes and understand how it can help accelerate query performance in a lakehouse.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introducing-secondary-index">Introducing Secondary Index<a href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index#introducing-secondary-index" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>A secondary index is an indexing mechanism commonly used in database systems to provide efficient access to records based on non-primary key attributes. Unlike primary indexes, which enforce uniqueness and define the main data layout, secondary indexes serve as auxiliary data structures that accelerate lookups on fields that are frequently queried but are not the primary key.</p>
<p>For example, in an OLTP (Online Transaction Processing) database, a primary index might be defined on a unique <code>order_id</code>, whereas a secondary index could be created on <code>customer_id</code> to quickly fetch all orders placed by a specific customer. Secondary indexes enhance query performance by reducing the need for full table scans, especially in analytical workloads that involve complex filtering or joins.</p>
<p>With <a href="https://hudi.apache.org/blog/2024/12/16/announcing-hudi-1-0-0/" target="_blank" rel="noopener noreferrer">Hudi 1.0</a>, Apache Hudi introduces <a href="https://hudi.apache.org/docs/next/indexes#secondary-index" target="_blank" rel="noopener noreferrer">secondary indexes</a>, bringing database-style indexing capabilities to the Lakehouse. Secondary indexes allow queries to scan significantly fewer files, reducing query latency and compute costs. This is especially beneficial for cloud-based query engines (such as AWS Athena), where pricing is based on the amount of data scanned. A secondary index in Hudi allows users to index any column beyond the record key (primary key), making queries on non-primary key fields much faster. This extends Hudi’s existing <a href="https://hudi.apache.org/blog/2023/11/01/record-level-index/" target="_blank" rel="noopener noreferrer">record-level index</a>, which optimizes writes and reads based on the record key.</p>
<img src="https://hudi.apache.org/assets/images/blog/secondary_index.png" alt="sec_index" width="800" align="middle">
<p>Here is how the secondary index works in Hudi.</p>
<ul>
<li>Indexes Non-Primary Key Columns: Unlike the record-level index, which tracks record keys, secondary indexes help accelerate queries on fields outside the primary key.</li>
<li>Stores Mappings Between Secondary and Primary Keys: Hudi maintains a mapping between secondary keys (e.g., city, driver) and record keys, enabling fast lookups for non-primary key queries.</li>
<li>Minimizes Data Scans via Index-Aware Query Execution: During query execution, the secondary index enables data skipping, allowing Hudi to prune unnecessary files before scanning.</li>
<li>SQL-Based Index Management: Users can create, drop, and manage indexes using SQL, making secondary indexes easily accessible.</li>
</ul>
<p>Hudi supports hash-based secondary indexes, which are horizontally scalable by distributing keys across shards for fast writes and lookups.</p>
<p>If you are interested in the implementation details of secondary indexes, you can read more <a href="https://hudi.apache.org/tech-specs-1point0/#secondary-index" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="creating-a-secondary-index-in-hudi">Creating a Secondary Index in Hudi<a href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index#creating-a-secondary-index-in-hudi" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>In Hudi 1.0, secondary indexes are supported currently in Apache Spark, with future support planned for Flink, Presto, and Trino in Hudi 1.1.</p>
<p>Let’s see an example of creating a Hudi table with a secondary index.</p>
<p>First, let’s create a table with a record index enabled. The record index maintains mappings of record keys (<code>id</code>) to file groups, enabling fast updates, deletes, and lookups.</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DROP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> hudi_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    id STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rider STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    driver STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    fare </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DOUBLE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    city STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    state STRING</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">USING</span><span class="token plain"> hudi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">OPTIONS </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    primaryKey </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'id'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">metadata</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">record</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">index</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">enable</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)">-- Enable record index</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">write</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">record</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">merge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">mode</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"COMMIT_TIME_ORDERING"</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)">-- Only Required for 1.0.0 version</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PARTITIONED </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">city</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">LOCATION </span><span class="token string" style="color:rgb(255, 121, 198)">'file:///tmp/hudi_test_table'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now we can create a secondary index on the <code>city</code> field to optimize queries filtering on this column.</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INDEX</span><span class="token plain"> idx_city </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> hudi_table </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">USING</span><span class="token plain"> secondary_index</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">city</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now, when executing a query such as:</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"> rider </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> hudi_table </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WHERE</span><span class="token plain"> city </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'SFO'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>✅ Hudi first checks the secondary index to determine which records match the filter condition.<br>
<!-- -->✅ It then uses the record index to locate the exact file group for retrieval.<br>
<!-- -->✅ Data skipping is applied, reducing the number of files read from cloud storage.</p>
<p>Users can also create secondary indexes using the Spark DataSource API by setting the following configurations:</p>
<table><thead><tr><th style="text-align:left">Config Name</th><th style="text-align:left">Default</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left"><code>hoodie.metadata.index.secondary.enable</code></td><td style="text-align:left">true</td><td style="text-align:left">Enables secondary index maintenance. When true, Hudi writers automatically maintain all secondary indexes within the metadata table. When disabled, secondary indexes must be created manually using SQL.</td></tr><tr><td style="text-align:left"><code>hoodie.datasource.write.secondarykey.column</code></td><td style="text-align:left">(N/A)</td><td style="text-align:left">Specifies the columns to be used as secondary keys. Supports dot notation for nested fields (e.g., <code>customer.region</code>).</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="asynchronous-indexing-in-hudi">Asynchronous Indexing in Hudi<a href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index#asynchronous-indexing-in-hudi" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>A notable thing about Hudi’s indexing system is that it offers <a href="https://www.onehouse.ai/blog/asynchronous-indexing-using-hudi" target="_blank" rel="noopener noreferrer">asynchronous indexing</a> as a service. Traditional indexing approaches often introduce performance bottlenecks, as index maintenance needs to be performed synchronously with writes. Hudi’s asynchronous indexing service eliminates the performance bottlenecks of traditional indexing by decoupling index maintenance from ingestion. Instead of requiring synchronous updates that slow down writes, Hudi builds indexes in the background, ensuring ingestion remains uninterrupted.</p>
<p>A key aspect of this design is timeline-consistent indexing, where a new indexing action is introduced in Hudi’s transactional <a href="https://hudi.apache.org/docs/timeline" target="_blank" rel="noopener noreferrer">timeline</a>. The indexer service schedules indexing by adding an <code>indexing.requested</code> instant, moves it to <code>inflight</code> during execution, and finally marks it <code>completed</code> once indexing is done, without locking index file writes. This enables a scalable indexing framework, allowing indexes to be dynamically added or removed without downtime as datasets grow. Async indexing also supports multiple index types, including secondary indexes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarking">Benchmarking<a href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index#benchmarking" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>We ran a simple benchmark using the TPCDS 1TB dataset, created the index on one of the fact table <code>web_sales</code> and ran a complex join query with lookup on customer id.</p>
<p><strong>Setup:</strong></p>
<ul>
<li>Uses 1TB TPCDS public dataset.</li>
<li>Apache Spark version -  3.5.5 installed on EMR cluster</li>
<li>Apache Hudi version - 1.0.1</li>
<li>Table on which secondary index is created - <code>web_sales</code></li>
<li>Column on which Secondary Index is created - <code>ws_ship_customer_sk</code></li>
<li>Cluster Configurations<!-- -->
<ul>
<li>Nodes: m5.xlarge (10 executors)</li>
</ul>
</li>
</ul>
<p>To evaluate performance, we executed the same query multiple times within the same Spark session. The table below demonstrates an approximately <strong>33%</strong> improvement in the first run and a <strong>58%</strong> improvement in the second run. Additionally, the amount of data scanned was reduced by <strong>90%</strong> when using the secondary index.</p>
<table><thead><tr><th style="text-align:left"></th><th style="text-align:left">Run 1</th><th style="text-align:left">Run 2</th><th style="text-align:left">Files Read</th><th style="text-align:left">File Size Read</th><th style="text-align:left">Rows Scanned</th></tr></thead><tbody><tr><td style="text-align:left">Without Secondary index</td><td style="text-align:left">32 sec</td><td style="text-align:left">14 sec</td><td style="text-align:left">5000</td><td style="text-align:left">67 GB</td><td style="text-align:left">719 M</td></tr><tr><td style="text-align:left">With Secondary Index</td><td style="text-align:left">22 sec</td><td style="text-align:left">6 sec</td><td style="text-align:left">521</td><td style="text-align:left">7 GB</td><td style="text-align:left">75 M</td></tr></tbody></table>
<p><strong>Read Query used for Benchmarking:</strong></p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_order_number</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_item_sk</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_quantity</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_sales_price</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   c</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">c_customer_id</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   c</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">c_first_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   c</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">c_last_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   d</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">d_date</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   wp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">wp_web_page_id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   web_sales ws</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">JOIN</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   tpcds_hudi_1tb</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">customer c </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_ship_customer_sk </span><span class="token operator">=</span><span class="token plain"> c</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">c_customer_sk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">JOIN</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   tpcds_hudi_1tb</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">date_dim d </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_ship_date_sk </span><span class="token operator">=</span><span class="token plain"> d</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">d_date_sk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">JOIN</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   tpcds_hudi_1tb</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">web_page wp </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_web_page_sk </span><span class="token operator">=</span><span class="token plain"> wp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">wp_web_page_sk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WHERE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_ship_customer_sk </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'647632'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ORDER</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BY</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ws_order_number</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>As shown in the DAG below, there is a significant difference in the amount of data scanned and other metrics (see the highlighted part) for the websales table, both with and without the secondary index.</p>
<p><strong>Spark SQL Stats  with Secondary index</strong></p>
<img src="https://hudi.apache.org/assets/images/blog/sec_index_spark1.png" alt="orch" width="600" align="middle">
<p><strong>Spark SQL Stats  without Secondary index</strong></p>
<img src="https://hudi.apache.org/assets/images/blog/sec_index_spark2.png" alt="orch" width="600" align="middle">
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://hudi.apache.org/cn/blog/2025/04/02/secondary-index#conclusion" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Indexing has been a core component of Apache Hudi since its inception, enabling efficient upserts and deletes at scale. With Hudi 1.0, the introduction of secondary indexing expands these capabilities by allowing queries to efficiently filter and retrieve records based on <em>non-primary key</em> fields, significantly reducing data scans and improving query performance. Looking ahead, secondary indexing in Hudi opens new possibilities for further optimizations, such as accelerating complex joins and MERGE INTO operations.</p>
<p>Additionally, to ensure that index maintenance does not introduce bottlenecks, Hudi’s <em>asynchronous indexing</em> service decouples index updates from ingestion, enabling seamless scaling while keeping indexes timeline-consistent and ACID-compliant. These advancements further solidify Hudi’s role as a high-performance lakehouse platform, making data structures such as secondary indexes more accessible.</p>
<hr>]]></content>
        <author>
            <name>Dipankar Mazumdar, Aditya Goenka</name>
        </author>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Indexing" term="Indexing"/>
        <category label="Performance" term="Performance"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Powering Amazon Unit Economics at Scale Using Apache Hudi]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi"/>
        <updated>2025-03-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Amazon’s Profit Intelligence team built Nexus, a configuration-driven platform powered by Apache Hudi, to scale unit economics across thousands of retail use cases. Nexus manages over 1,200 tables, processes hundreds of billions of rows daily, and handles ~1 petabyte of data churn each month. This blog dives into their data lakehouse journey, Nexus architecture, Hudi integration, and key operational learnings.]]></summary>
        <content type="html"><![CDATA[<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>TL;DR</div><div class="admonitionContent_BuS1"><p>Amazon’s Profit Intelligence team built Nexus, a configuration-driven platform powered by Apache Hudi, to scale unit economics across thousands of retail use cases. Nexus manages over 1,200 tables, processes hundreds of billions of rows daily, and handles ~1 petabyte of data churn each month. This blog dives into their data lakehouse journey, Nexus architecture, Hudi integration, and key operational learnings.</p></div></div>
<p>Understanding and improving unit-level profitability at Amazon's scale is a massive challenge - one that requires flexibility, precision, and operational efficiency. In this blog, we walk through how Amazon’s Profit Intelligence team built a scalable, configuration-driven platform called Nexus, and how Apache Hudi became the cornerstone of its data lake architecture.</p>
<p>By combining declarative configuration with Hudi's advanced table management capabilities, the team has enabled thousands of retail business use cases to run seamlessly, allowing finance and pricing teams to self-serve insights on cost and profitability, without constantly relying on engineering intervention.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-business-need-profit-intelligence-and-unit-economics">The Business Need: Profit Intelligence and Unit Economics<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#the-business-need-profit-intelligence-and-unit-economics" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Within Amazon’s Worldwide Stores, the Selling Partner Services (SPS) team supports seller-facing operations. A key part of this effort is computing <strong>Contribution Profit</strong> - a granular metric that captures revenue, costs, and profitability at the unit level, such as <em>a shipped item to the customer</em>.</p>
<p>Contribution Profit powers decision-making for a range of downstream teams including:</p>
<ul>
<li>Pricing</li>
<li>Forecasting</li>
<li>Finance</li>
</ul>
<p>The challenge? Supporting the scale and diversity of retail use cases across Amazon's global business, while maintaining a data platform that's both extensible and maintainable.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="amazons-data-lakehouse-journey">Amazon’s Data Lakehouse Journey<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#amazons-data-lakehouse-journey" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Over the past decade, the architecture behind Contribution Profit has gone through several phases of evolution, driven by the need to better support Amazon’s growing and diverse retail business use cases.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="early-phase">Early Phase<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#early-phase" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<img src="https://hudi.apache.org/assets/images/blog/fig1_amz.png" alt="redshift" width="800" align="middle">
<p>Initial implementations relied on ETL pipelines that published data to Redshift, often with unstructured job flows. Business logic could exist at various layers of the ETL and was written entirely in SQL, making it difficult to track, maintain, or modify. These pipelines lacked systematic enforcement of patterns, which led to fragmentation and technical debt.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="intermediate-phase">Intermediate Phase<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#intermediate-phase" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<img src="https://hudi.apache.org/assets/images/blog/fig2_amz.png" alt="flink" width="800" align="middle">
<p>To improve scalability and support streaming workloads, the team transitioned to a setup involving Apache Flink and a custom-built data lake. Although this introduced broader data processing flexibility, it still had major drawbacks:</p>
<ul>
<li>Redshift-based ETLs remained in use.</li>
<li>Business logic and schema changes required engineering involvement.</li>
<li>There were ongoing scalability and maintainability issues with the custom data lake.</li>
<li>Flink introduced operational challenges of its own, such as handling version upgrades through AWS Managed Flink and providing done signal in batch operation.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="current-state-nexus--apache-hudi">Current State: Nexus + Apache Hudi<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#current-state-nexus--apache-hudi" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>Each of the prior approaches came with tradeoffs, especially around business logic being tightly coupled with code, making it hard for non-engineers to simulate or change metrics for a specific retail business.</p>
<p>Recognizing the need for better abstraction and operational maturity, the team built Nexus - a configuration-driven platform for defining and orchestrating data pipelines. All lake interactions including ingestion, transformation, schema evolution, and table management now go through Nexus. Nexus is powered by <a href="https://hudi.apache.org/" target="_blank" rel="noopener noreferrer"><strong>Apache Hudi</strong></a>, which provides the foundation for scalable ingestion, efficient upserts, schema evolution, and transactional guarantees on Amazon S3.</p>
<p>This new architecture enabled the team to decouple business logic from engineering code, allowing business teams to define logic declaratively. It also introduced standardization across workloads, eliminated redundant pipelines, and laid the groundwork for scaling unit economics calculations across thousands of use cases.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="key-modules-of-nexus">Key Modules of Nexus<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#key-modules-of-nexus" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<img src="https://hudi.apache.org/assets/images/blog/fig3_amz.png" alt="nexus" width="800" align="middle">
<p>Nexus consists of four core components:</p>
<p><strong>Configuration Layer</strong></p>
<p>The topmost layer where users define their business logic in a declarative format. These configurations are typically generated and enriched with metadata by internal systems.</p>
<p><strong>NexusFlow (Orchestration)</strong></p>
<img src="https://hudi.apache.org/assets/images/blog/fig4_amz.png" alt="orch" width="1000" align="middle">
<p align="center"><em>Figure: Sample NexusFlow Config</em></p>
<p>Responsible for generating and executing workflows. It operates on two levels:</p>
<ul>
<li>Logical Layer: Comprising NexusETL jobs and other tasks.</li>
<li>Physical Layer: Implemented via AWS Step Functions to orchestrate EMR jobs and related dependencies. NexusFlow supports extensibility through a federated model and can execute diverse task types like Spark jobs, Redshift queries, wait conditions, and legacy ETLs.</li>
</ul>
<p><strong>NexusETL (Execution)</strong></p>
<img src="https://hudi.apache.org/assets/images/blog/fig5_amz.png" alt="etl" width="1000" align="middle">
<p align="center"><em>Figure: Sample NexusETL Config</em></p>
<p>Executes Spark-based data transformation jobs. Jobs are defined entirely in configuration, with support for:</p>
<ul>
<li>Built-in transforms like joins and filters</li>
<li>Custom UDFs</li>
<li>Source/Sink/Transform operators: It operates at the job abstraction level and is typically invoked by NexusFlow during orchestration.</li>
</ul>
<p><strong>NexusDataLake (Storage)</strong></p>
<img src="https://hudi.apache.org/assets/images/blog/fig5_amz.png" alt="datalake" width="1000" align="middle">
<p align="center"><em>Figure: Sample NexusDataLake Config</em></p>
<p>A storage abstraction layer built on Apache Hudi. NexusDataLake manages:</p>
<ul>
<li>Table creation</li>
<li>Schema inference and evolution</li>
<li>Catalog integration: All interactions with Hudi, such as inserts, upserts, table schema changes, and metadata syncs are funneled through NexusETL and NexusFlow, maintaining consistency across the platform.</li>
</ul>
<p>By standardizing how data is defined, processed, and stored, Nexus has enabled a scalable, maintainable, and extensible architecture. Every data lake interaction - from ingestion to table maintenance, is performed through this configuration-first model, which now powers hundreds of use cases across Amazon retail.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-apache-hudi">Why Apache Hudi?<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#why-apache-hudi" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Apache Hudi has been central to Nexus’ success, providing the core data lake storage layer for scalable ingestion, updates, and metadata management. It enables fast, incremental updates at massive scale while maintaining transactional guarantees on top of Amazon S3.</p>
<p>In Amazon’s current architecture:</p>
<ul>
<li>Copy-on-Write (COW) table type is used for all Hudi tables.</li>
<li>Workloads generate hundreds of billions of row updates daily, with write patterns spanning concentrated single-partition updates and wide-range backfills across up to 90 partitions.</li>
<li>All Hudi interactions, including inserts, schema changes, and metadata syncs, are managed through Nexus.</li>
</ul>
<p><strong>Key Capabilities used with Apache Hudi</strong></p>
<ul>
<li>
<p><strong>Efficient Upserts</strong><br>
<!-- -->Hudi’s design primitives such as <a href="https://hudi.apache.org/docs/indexes" target="_blank" rel="noopener noreferrer">indexes</a> for Copy-on-Write (CoW) tables enable high-throughput update patterns by avoiding the need to join against the entire dataset to determine which files to rewrite, which is particularly critical for our daily workloads.</p>
</li>
<li>
<p><strong>Incremental Processing</strong><br>
<!-- -->By using Hudi’s native <a href="https://www.onehouse.ai/blog/getting-started-incrementally-process-data-with-apache-hudi" target="_blank" rel="noopener noreferrer">incremental pull</a> capabilities, downstream systems are able to consume only the changes between commits. This is essential for efficiently updating Contribution Profit metrics that power business decision-making.</p>
</li>
<li>
<p><strong>Metadata Table</strong><br>
<!-- -->Enabling the <a href="https://hudi.apache.org/docs/metadata" target="_blank" rel="noopener noreferrer">metadata table</a> (<code>hoodie.metadata.enable=true</code>) significantly reduced job runtimes by avoiding expensive file listings on S3. This is an important optimization given the scale at which we process updates across more than 1200 Hudi tables.</p>
</li>
<li>
<p><strong>Schema Evolution</strong><br>
<!-- -->Table creation and evolution are fully managed through configuration in Nexus. Hudi’s built-in support for <a href="https://hudi.apache.org/docs/schema_evolution" target="_blank" rel="noopener noreferrer">schema evolution</a> has allowed the team to onboard new use cases and adapt to changing schemas without requiring expensive rewrites or manual interventions.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-learnings-from-operating-hudi-at-amazon-scale">Key Learnings from Operating Hudi at Amazon Scale<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#key-learnings-from-operating-hudi-at-amazon-scale" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Operating Apache Hudi at the scale and velocity required by Amazon’s Profit Intelligence workloads surfaced a set of hard-earned lessons, especially around concurrency, metadata handling, and cost optimization. These learnings reflect both architectural refinements and operational trade-offs that others adopting Hudi at large scale may find useful.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-concurrency-control">1. Concurrency Control<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#1-concurrency-control" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>At Amazon’s ingestion scale - hundreds of billions of rows per day and thousands of concurrent table updates, multi-writer concurrency is a reality, not an edge case.</p>
<p>The team initially used Optimistic Concurrency Control (OCC), which works well in environments with low write conflicts. OCC assumes that concurrent writers rarely overlap, and when they do, the job retries after detecting a conflict. However, in high-contention scenarios, like multiple jobs writing to the same partition within a short time window, this led to frequent retries and job failures.</p>
<p>To resolve this, the team pivoted to a new table structure designed to minimize concurrent insertions. This change helped reduce contention by lowering the likelihood of multiple writers operating on overlapping partitions simultaneously. The updated design enabled using OCC while avoiding the excessive retries and failures we had initially encountered.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-metadata-table-management-async-vs-sync-trade-offs">2. Metadata Table Management: Async vs Sync Trade-Offs<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#2-metadata-table-management-async-vs-sync-trade-offs" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>Apache Hudi’s metadata table dramatically improves performance by avoiding expensive file listings on cloud object stores like S3. It maintains a persistent <em>index</em> <em>of files</em>, enabling faster operations such as file pruning, and data skipping.</p>
<p>The team enabled Hudi’s metadata table early (<code>hoodie.metadata.enable=true</code>) and started off with synchronous cleaning but switched to asynchronous cleaning to reduce job runtime. However, we ran into an issue when experimenting with asynchronous cleaning. Due to a <a href="https://github.com/apache/hudi/issues/11535" target="_blank" rel="noopener noreferrer">known issue (#11535)</a>, async cleaning wasn’t properly cleaning up metadata entries.</p>
<p>To ensure the metadata tables were properly cleaned, we switched all of  our Hudi workloads back to synchronous cleaning.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-cost-management">3. Cost Management<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#3-cost-management" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>While Apache Hudi helped Amazon reduce data duplication and improve ingestion efficiency, we quickly realized that operational costs were not driven by storage - but by the API interaction patterns with S3.</p>
<p>Breakdown of the cost profile:</p>
<ul>
<li><strong>70% of total cost</strong> came from <code>PUT</code> requests (writes)</li>
<li>Combined <code>PUT + GET</code> operations accounted for <strong>80%</strong> of the bill</li>
<li>Storage cost remained a small fraction, even with 3+ PB of total data under management</li>
</ul>
<p>Their data ingestion patterns contributed to this:</p>
<ul>
<li>Daily workloads: Heavy concentration (99%) of updates into a single partition</li>
<li>Backfill workloads: Spread evenly across 30–90 partitions</li>
</ul>
<p>To manage this:</p>
<ul>
<li>We moved to <strong>S3 Intelligent-Tiering</strong> to reduce unused data storage costs</li>
<li>Enabled <strong>EMR cluster auto-scaling</strong> to dynamically adjust compute resources</li>
<li>Batched writes and carefully tuned Hudi configurations (e.g., <code>write.batch.size</code>, <code>compaction.small.file.limit</code>) to reduce unnecessary file churn</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="operational-scale-nexus-by-the-numbers">Operational Scale: Nexus by the Numbers<a href="https://hudi.apache.org/cn/blog/2025/03/31/amazon-hudi#operational-scale-nexus-by-the-numbers" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<table><thead><tr><th style="text-align:left">Metric</th><th style="text-align:left">Value</th></tr></thead><tbody><tr><td style="text-align:left">Tables Managed</td><td style="text-align:left">1200+ (5–15 updates/day per table)</td></tr><tr><td style="text-align:left">Legacy SQL Deprecated</td><td style="text-align:left">300,000+ lines</td></tr><tr><td style="text-align:left">Total Data Managed</td><td style="text-align:left">~3 Petabytes</td></tr><tr><td style="text-align:left">Monthly Data Changes</td><td style="text-align:left">~1 Petabyte added/deleted</td></tr><tr><td style="text-align:left">Daily Record Updates</td><td style="text-align:left">Hundreds of billions</td></tr><tr><td style="text-align:left">Developer Time Saved</td><td style="text-align:left">300+ days</td></tr></tbody></table>
<p>Nexus with Apache Hudi as the foundation has significantly improved the scale, modularity, and maintainability of the data lake operations at Amazon. As the business use cases scale, the team is also focused on managing the increasing complexity of the data lake, while ensuring that both technical and non-technical stakeholders can interact with Nexus effectively.</p>
<p>This blog is based on Amazon’s presentation at the Hudi Community Sync. If you are interested in watching the recorded version of the video, you can find it <a href="https://www.youtube.com/watch?v=rMXhlb7Uci8" target="_blank" rel="noopener noreferrer">here</a>.</p>
<hr>]]></content>
        <author>
            <name>Jason, Abhishek, Sethu in collaboration with Dipankar</name>
        </author>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Amazon" term="Amazon"/>
        <category label="Community" term="Community"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[ACID Transactions in an Open Data Lakehouse]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/26/acid-transactions</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/26/acid-transactions"/>
        <updated>2025-03-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.onehouse.ai/blog/acid-transactions-in-an-open-data-lakehouse">here</a></span>]]></content>
        <author>
            <name>Dipankar Mazumdar</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="ACID" term="ACID"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is Clustering in an Open Data Lakehouse?]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/26/clustering</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/26/clustering"/>
        <updated>2025-03-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.onehouse.ai/blog/what-is-clustering-in-an-open-data-lakehouse">here</a></span>]]></content>
        <author>
            <name>Dipankar Mazumdar</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="Clustering" term="Clustering"/>
        <category label="Z-order" term="Z-order"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Deduplication Strategies in an Open Lakehouse Architecture]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/26/dedupe</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/26/dedupe"/>
        <updated>2025-03-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.onehouse.ai/blog/data-deduplication-strategies-in-an-open-lakehouse-architecture">here</a></span>]]></content>
        <author>
            <name>Dipankar Mazumdar, Aditya Goenka</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="Deduplication" term="Deduplication"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Transactional Bottlenecks to Lightning-Fast Analytics]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/26/uptycs</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/26/uptycs"/>
        <updated>2025-03-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/allthatscales/from-transactional-bottlenecks-to-lightning-fast-analytics-74e0d3fff1c0">here</a></span>]]></content>
        <author>
            <name>Akash, Anudeep, Rohan</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="CDC" term="CDC"/>
        <category label="Debezium" term="Debezium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building an Amazon Sales Analytics Pipeline with Apache Hudi on Databricks]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/13/hudi-on-dbr</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/13/hudi-on-dbr"/>
        <updated>2025-03-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.linkedin.com/pulse/building-amazon-sales-analytics-pipeline-apache-hudi-databricks-ruotf/">here</a></span>]]></content>
        <author>
            <name>Sameer Shaik</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="aws" term="aws"/>
        <category label="databricks" term="databricks"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Transactional Bottlenecks to Lightning-Fast Analytics]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/13/lightning-fast-analytics</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/13/lightning-fast-analytics"/>
        <updated>2025-03-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://aakashsankritya.medium.com/from-transactional-bottlenecks-to-lightning-fast-analytics-74e0d3fff1c0">here</a></span>]]></content>
        <author>
            <name>Akash Sankritya</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="kafka" term="kafka"/>
        <category label="debezium" term="debezium"/>
        <category label="S3" term="S3"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[21 Unique Reasons Why Apache Hudi Should Be Your Next Data Lakehouse]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/05/hudi-21-unique-differentiators</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/05/hudi-21-unique-differentiators"/>
        <updated>2025-03-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Apache Hudi is continuously redefining the data lakehouse, pushing the technical boundaries and offering cutting-edge features to handle data quickly and efficiently. If you have ever wondered how Apache Hudi has sustained its position over the years as the most comprehensive, open, high-performance data lakehouse project, this blog aims to give you some concise answers. Below, we shine a light on some unique capabilities in Hudi, that go beyond the lowest-common-denominator across the different projects in the space.]]></summary>
        <content type="html"><![CDATA[<p>Apache Hudi is continuously <a href="https://hudi.apache.org/blog/2024/12/16/announcing-hudi-1-0-0" target="_blank" rel="noopener noreferrer">redefining</a> the data lakehouse, pushing the technical boundaries and offering cutting-edge features to handle data quickly and efficiently. If you have ever wondered how Apache Hudi has sustained its position over the years as the most comprehensive, open, high-performance data lakehouse project, this blog aims to give you some concise answers. Below, we shine a light on some unique capabilities in Hudi, that go beyond the lowest-common-denominator across the different projects in the space.</p>
<p><strong>1. Well-Balanced Storage Format</strong></p>
<p>Hudi’s <a href="https://hudi.apache.org/docs/storage_layouts" target="_blank" rel="noopener noreferrer">storage format</a> <em>perfectly balances write speed</em> (record-level changes) and <em>query performance</em> (scan+lookup optimized), at the cost of additional storage space to track indexes. In contrast, Apache Iceberg/Delta Lake formats produce storage layouts aimed at vanilla scans, focus more on metadata to help scale/prune the scans. Recent effots that adopt LSM tree structures to improve write performance, inevitably sacrifice query performance. See <a href="https://www.codementor.io/@arpitbhayani/the-rum-conjecture-16z2ckqte9" target="_blank" rel="noopener noreferrer">RUM conjecture</a>.</p>
<p><strong>2. Database-like Secondary Indexes</strong></p>
<p>In a long line of unique technical contributions to the lakehouse tech, Hudi recently added <a href="https://hudi.apache.org/docs/indexes#multi-modal-indexing" target="_blank" rel="noopener noreferrer">secondary indexes</a> (record level, bloom filters, …), with support for even creating indexes on expressions on columns. Features heavily inspired by relational databases like Postgres, that can <em>unlock completely new use-cases</em> on the data lakehouse like <a href="https://en.wikipedia.org/wiki/Hybrid_transactional/analytical_processing" target="_blank" rel="noopener noreferrer">HTAP</a> or <a href="https://planetscale.com/learn/courses/mysql-for-developers/queries/indexing-joins" target="_blank" rel="noopener noreferrer">index-joins</a>.</p>
<p><strong>3. Efficient Merge-on-Read (MoR) Design</strong></p>
<p>Hudi’s <a href="https://hudi.apache.org/docs/table_types#merge-on-read-table" target="_blank" rel="noopener noreferrer">optimized MoR design</a> <em>minimizes read/write amplification</em>, by a range of techniques like file grouping and partial updates. Grouping helps cut down the amount of update blocks/deletion blocks/vectors to be scanned to serve snapshot queries. It also helps <em>preserve temporal locality</em> of data that dramatically improves time-based access for e.g building dashboards based on time - last hour, last day, last week, … - that are table stakes for warehouse/lakehouse users.</p>
<p><strong>4. Scalable Metadata for Large-Scale Datasets</strong></p>
<p>Hudi’s <a href="https://hudi.apache.org/docs/metadata" target="_blank" rel="noopener noreferrer">metadata table</a> efficiently handles <em>millions of files</em>, by storing them <em>efficiently</em> in an indexed <a href="https://www.scylladb.com/glossary/sstable" target="_blank" rel="noopener noreferrer">SSTable</a> based file format. Similarly, Hudi also indexes other metadata like column statistics, such that query planning scales linearly with <em>O(number_of_columns_in_query)</em>, as opposed to flat-file storage like avro that scales poorly with size of tables, large number of files or wide-columns.</p>
<p><strong>5. Built-In Table Services</strong></p>
<p>Hudi comes <em>loaded with automated <a href="https://hudi.apache.org/docs/write_operations#write-path" target="_blank" rel="noopener noreferrer">table services</a></em> like compaction, clustering, indexer, de-duplication, archiver, TTL enforcement and cleaning, that are scheduled, executed, retried, automatically with every write without requiring any external orchestration or manual SQL commands for table maintenance. Hudi’s <a href="https://hudi.apache.org/docs/markers/" target="_blank" rel="noopener noreferrer">marker mechanism</a> efficiently cleans up uncomitted/orphaned files during writes without requiring full-listing of cloud storage to identify such files (can take hours or even timeout forever).</p>
<p><strong>6. Data Management Smarts</strong></p>
<p>Stepping in level deeper, Hudi fully manages everything around storage : <a href="https://hudi.apache.org/docs/overview" target="_blank" rel="noopener noreferrer">file sizes, partitions and metadata maintenance</a> automatically on each write, to provide consistent, dependable read/write performance. Further more,  Hudi provides <em>advanced <a href="https://hudi.apache.org/docs/clustering" target="_blank" rel="noopener noreferrer">sorting/clustering</a> capabilities</em>, that can be <em>incrementally</em> run with new writes, to keep tables optimized.</p>
<p><strong>7. Concurrency Control Purpose-built For the Lake</strong></p>
<p>Hudi’s <a href="https://hudi.apache.org/blog/2025/01/28/concurrency-control" target="_blank" rel="noopener noreferrer">concurrency control</a> is carefully designed to deliver high throughput for data lakehouse workloads, without blindly rehashing approaches that work for OLTP databases. Hudi brings novel MVCC based approaches and <a href="https://hudi.apache.org/docs/concurrency_control#non-blocking-concurrency-control" target="_blank" rel="noopener noreferrer">non-blocking concurrency control</a>. Data pipelines/SQL ETLs and table services won’t fail/livelock each other eliminating wastage of compute cycles, improving data freshness and reducing cloud bills. Even on optimistic concurrency control model (L.C.D across projects), Hudi provides <em>early conflict detection</em> to pre-emptively abort writes that will eventually fail due to conflicts, saving countless compute hours.</p>
<p><strong>8. Performance at Scale</strong></p>
<p>Hudi stands out on the <em>toughest workloads</em> you should be testing first before deciding your lakehouse stack : CDC ingest, expensive SQL merges or TB-PB scale streaming data. Hudi provides about <a href="https://hudi.apache.org/docs/indexes#additional-writer-side-indexes" target="_blank" rel="noopener noreferrer">half a dozen writer side indexes</a> including advanced record level indexes, range indexes built on interval trees or consistent-hashed bucket indexes to scale writes for such workloads. Hudi is the <em>only lakehouse project</em>, that can rapidly ingest/write and handle small-file compaction without blocking those writes.</p>
<p><strong>9. Out-of-box CDC/Streaming Ingestion</strong></p>
<p>Hudi provides <em>powerful, fully-production ready  ingestion</em> <a href="https://hudi.apache.org/docs/hoodie_streaming_ingestion" target="_blank" rel="noopener noreferrer">tools</a> for both Spark/Flink/Kafka users, that help users build data lakehouses from their data, with a single-command. In fact, many many Hudi users blissfully use these tools, unaware of all the underlying machinery balancing write/read performance or table maintenance. This way, Hudi provides a self-managing runtime environment, for your data lakehouse pipelines, without having to pay for closed-services from vendors. Hudi ingest tools natively support popular CDC formats like Debezium/AWS DMS/Mongo and sources like S3, GCS, Kafka, Pulsar and the like.</p>
<p><strong>10. First-Class Support for Keys</strong></p>
<p>Hudi treats record <a href="https://hudi.apache.org/docs/key_generation" target="_blank" rel="noopener noreferrer">keys</a> as first-class citizen, used everywhere from indexing, de-duplication, clustering, compaction to consistently track/control movement of records within a table, across files. Additionally, Hudi also tracks <a href="https://www.onehouse.ai/blog/hudi-metafields-demystified" target="_blank" rel="noopener noreferrer">necessary record-level metadata</a> that help implement powerful features like incremental queries, in conjunction with queries. Ingest tools seamlessly map source primary keys to Hudi primary keys or auto-generate <em>highly-compressible</em> keys to aid these capabilities.</p>
<p><strong>11. Streaming-First Design</strong></p>
<p>Hudi was born out of a need to bridge the gap between batch processing and stream processing models. Thus, naturally, Hudi offers <em>best-in-class and unique capabilities</em> around handling streaming data. Hudi supports <a href="https://hudi.apache.org/docs/record_merger#event_time_ordering" target="_blank" rel="noopener noreferrer">event time ordering</a> and late data handling natively in storage where MoR is employed heavily. RecordPayload/RecordMerger APIs let you merge updates in the database LSN order compared to other approaches, avoiding cases like tables going back in (event) time, if the input is out-of-order/late-arriving (which is more the norm/nor an exception).</p>
<p><strong>12. Efficient Incremental Processing</strong></p>
<p>All roads in Hudi, lead to efficiency in storage and compute. Storage by <em>reducing</em> the amount of <em>data stored/accessed</em>, compute by reducing the <em>time needed write/read</em>. Hudi supports unique <a href="https://www.onehouse.ai/blog/getting-started-incrementally-process-data-with-apache-hudi" target="_blank" rel="noopener noreferrer">incremental queries</a>, along with CDC queries to allow downstream data consumers to quickly obtain changes to a table, between two time intervals. Owing to scalable metadata design, a LSM-tree backed timeline history and record-level change tracking, Hudi is able to support near infinite retention for such streams, provide very useful when dealing with transactional data/logs.</p>
<p><strong>13. Powerful Apache Spark Implementation</strong></p>
<p>Hudi comes with a very feature-rich, advanced integration with Apache Spark - across SQL, DataSource, RDD APIs, Structured Streaming and Spark Streaming. When combined together, <em>Hudi + Spark</em> almost gives users a <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-69/rfc-69.md" target="_blank" rel="noopener noreferrer">database</a> - with built-in data management, ingestion, streaming/batch APIs, ANSI SQL and programmatic access from Python/JVM. Much like a database, the write/read implementation paths automatically pick the right storage layout to optimize storage at rest or do necessary index pruning to speed up queries.</p>
<p><strong>14. Next-Gen Flink Writer for Streaming Pipelines</strong></p>
<p><a href="https://www.onehouse.ai/blog/intro-to-hudi-and-flink" target="_blank" rel="noopener noreferrer">Hudi and Flink</a> have the best impedance match when it comes to handling streaming data. Hudi Flink sink is built on a <em>deep integration</em> between the two project capabilities, by leveraging Flink’s state backends as an writer side index in Hudi. With the combination of non-blocking concurrency and partial updates, Hudi is the only lakehouse storage sink for Flink, that can allow <em>multiple streaming writers</em> concurrently write a table (without having to fail one). Just like Spark, Flink writer comes with built-in table services, akin to a “streaming database” for the lakehouse.</p>
<p><strong>15. Avoid Compute Lockins</strong></p>
<p>Don’t let the noise fool you. Hudi is <a href="https://hudi.apache.org/ecosystem" target="_blank" rel="noopener noreferrer"><em>widely supported</em></a> across cloud warehouses (Redshift, BigQuery), open-source query/processing engines (Spark, Presto, Trino, Flink, Hive, Clickhouse, Starrocks, Doris) and also hosted offering of those open-source engines (AWS Athena, EMR, DataProc, Databricks). This means, you have the power to fully control <em>not just the open format</em> you store data in, but also the end-end ingestion, transformation and optimizations of your tables, avoiding any “compute lockin” with these engines.</p>
<p><strong>16. Seamless Interop Iceberg/Delta Lake and Catalog Syncs</strong></p>
<p>To make the point above really easy, Hudi also ships with a <a href="https://hudi.apache.org/docs/syncing_aws_glue_data_catalog" target="_blank" rel="noopener noreferrer">catalog sync</a> mechanism, that supports about <em>6 different data catalogs</em> to keep your table definitions in sync over time. Hudi tables can be readily queried as external tables on cloud data warehouses. And, with the <a href="https://github.com/apache/xtable" target="_blank" rel="noopener noreferrer">Apache XTable</a> (Incubating) catalog sync, Hudi enables interoperability with Iceberg and Delta Lake table format, without the need to duplicate data storage or processing. Thus, Hudi offers the most open way to manage your data on the cloud.</p>
<p><strong>17. Truly Open and Community-Driven</strong></p>
<p>Apache Hudi is an <a href="https://hudi.apache.org/community" target="_blank" rel="noopener noreferrer">open-source project</a>, actively developed by a diverse global <a href="https://ossinsight.io/analyze/apache/hudi#contributors" target="_blank" rel="noopener noreferrer">community</a>. In fact, the grass-roots nature of the project and its community have been the crucial reason for the lasting success Hudi has had in the industry, inspite 100-1000x bigger vendor teams marketing/selling users in other directions. Project has an established track record of truly, collaborative way of software development, the <a href="https://www.apache.org/theapacheway/" target="_blank" rel="noopener noreferrer">apache way</a>.</p>
<p><strong>18. Massive Adoption Across Industries</strong></p>
<p>For system/infrastructure software like Hudi, it’s very important to gain/prove maturity by clocking massive amounts of server hours. Hudi is used at massive scale at much of the Fortune 100s and large organizations like  <a href="https://hudi.apache.org/powered-by" target="_blank" rel="noopener noreferrer">Uber, AWS, ByteDance, Peloton, Huawei, Alibaba, and more</a>, adding immense value in terms of a steady stream of  high-quality bug reports and feature asks shaping the projects roadmap. This way, Hudi users get highly capable lakehouse software, that can address a diverse range of use-cases.</p>
<p><strong>19. Proven Reliability in High-Pressure Workloads</strong></p>
<p>Hudi has been pressure-tested at some of the most demanding worloads there is, on the data lakehouse. From <a href="https://www.uber.com/blog/uber-big-data-platform/" target="_blank" rel="noopener noreferrer">minute-level latency</a> on petabytes to storing ingesting &gt; 100GB/s or just very <a href="https://aws.amazon.com/blogs/big-data/how-amazon-transportation-service-enabled-near-real-time-event-analytics-at-petabyte-scale-using-aws-glue-with-apache-hudi/" target="_blank" rel="noopener noreferrer">tough random write</a> workloads, that test even the best OLTP databases out there. Hudi has been deployed industry-wide for very critical data processing needs like financial clearing jobs, ride-sharing payments or transactional reconciliation.</p>
<p><strong>20. Cloud-Native and Lakehouse-Ready</strong></p>
<p>Don’t let the origins from a Hadoop mislead you either. Hudi has long evolved past HDFS and works seamlessly with <a href="https://hudi.apache.org/docs/cloud" target="_blank" rel="noopener noreferrer">S3, GCS, Azure, Alibaba, Huawei and many other cloud storage</a> systems. Together with the <a href="https://www.onehouse.ai/blog/apache-hudi-native-aws-integrations" target="_blank" rel="noopener noreferrer">cloud-native</a> integrations or just via <a href="https://www.onehouse.ai/blog/apache-hudi-on-microsoft-azure" target="_blank" rel="noopener noreferrer">easy integrations</a> outside of Cloud-native services, Hudi provides a very portable (cross-engine, format, cloud) way for building cloud data lakehouses.</p>
<p><strong>21. Future-Proof and Actively Evolving</strong></p>
<p>Hudi’s community boasts about 40-50 monthly active developers, which is growing even more with efforts like <a href="https://github.com/apache/hudi-rs" target="_blank" rel="noopener noreferrer">hudi-rs</a>. Hudi’s <a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer">rapid development</a> ensures constant improvements and cutting-edge features on one hand, while the openness of the community to truly work across the entire cloud data ecosystem on the other, ensure your data stays as open as possible.</p>
<p>In summary, there is no secret sauce. The answer to the original question is simply how these design and implementation differences have compounded over time into unmatched technical capabilities that data engineers across the industry widely recognize. These have resulted from 6+ years of evolution, hardening and iteration from an OSS community. And, it's always a moving target, given the amount of innovation that is still ahead of us, in the data lakehouse space. By the time some of these differences make it to other projects, the community might have innovated 21 more reasons.</p>
<p>Apache Hudi is the <strong>best-in-class open-source data lakehouse platform</strong> —powerful, efficient, and future-proof. Start exploring it today! 🚀</p>]]></content>
        <author>
            <name>Vinoth Chandar</name>
        </author>
        <category label="Data Lake" term="Data Lake"/>
        <category label="Data Lakehouse" term="Data Lakehouse"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="Table Format" term="Table Format"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Record Mergers in Apache Hudi]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi</id>
        <link href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi"/>
        <updated>2025-03-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Challenge of Unordered Streams of Events]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-challenge-of-unordered-streams-of-events">The Challenge of Unordered Streams of Events<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#the-challenge-of-unordered-streams-of-events" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>One of the primary challenges associated with streaming workloads is the unordered nature of incoming events. In a typical streaming scenario, events can arrive out of sequence due to network latency, processing delays, or other factors. With the increasing volume and velocity of data being ingested from various sources—especially in mobile applications and IoT platforms—data processing frameworks must be equipped to handle mutations (i.e., changes to records) and out-of-order events.
Traditional data storage systems and file formats, such as those optimized for batch processing, often struggle to manage these scenarios effectively. Hudi steps in with features specifically designed to handle such challenges.
When events or changes to a record arrive at different times, they may not be in the same order in which they were originally generated. For example, in a smart city traffic monitoring system, sensors may report vehicle speeds at various intersections in real-time. However, due to network issues or delays, some sensor data might arrive later than others, possibly out of order. To handle this, the system needs to merge the new incoming data with existing records efficiently. Just like how Hudi’s merge modes control the merging of records with the same key in a storage system, ensuring consistency and accuracy, it ensures that the final traffic data reflects the correct event times, even when some data arrives with a delay. These merge modes help maintain a consistent, deterministic result under heavy load, making sure that late data updates the right records without causing inconsistencies.
This can lead to several issues:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="data-integrity">Data Integrity<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#data-integrity" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>When events are processed out of order, it can result in incorrect or inconsistent data states. For example, if an event representing a transaction is processed before the event that indicates the account balance, the resulting data may not accurately reflect the true state of the system.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="complexity-in-processing">Complexity in Processing<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#complexity-in-processing" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>Handling unordered events often requires additional logic to ensure that data is processed in the correct sequence. This can complicate the data pipeline and increase the likelihood of errors.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-record-mergers">What are Record Mergers<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#what-are-record-mergers" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>With the new api introduced with version 1.0.0, Hudi supports three primary merge modes, each suited to different stages of data processing: writing, compaction, and querying.
4 places/points of data processing [Subheader]</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-merging-input-data-before-writing--combining-change-records-during-writes">1. Merging input data before writing : Combining Change Records During Writes<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#1-merging-input-data-before-writing--combining-change-records-during-writes" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>When new data arrives for an existing record, Hudi performs deduplication on the input dataset. This process involves combining multiple change records for the same record key before the write phase. This is an optimization that also helps reduce the number of records written to the log files (in case of MOR). By merging changes upfront, Hudi reduces unnecessary records, improving the efficiency of both query and write operations.
This step is crucial for handling stream data in real-time, where changes may arrive rapidly, and ensuring that only the final version of the record is written into the system. Normally these out of order events come together commonly in the same batch,  With processing engines like spark, which deals with micro-batches, merging the input changes helps in reduces the number of records which needs to be written.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-merging-final-change-record-in-cow-copy-on-write-tables-applying-changes-to-existing-records">2. Merging Final Change Record in CoW (Copy-on-Write) Tables: Applying Changes to Existing Records<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#2-merging-final-change-record-in-cow-copy-on-write-tables-applying-changes-to-existing-records" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>In Copy-on-Write (CoW) tables, changes are applied by creating new file versions for the records. When an update, partial update, or delete operation occurs, Hudi will merge this final change with the existing record in the storage. The merge mode controls how these updates are applied, ensuring that only the most recent changes are reflected and the table’s data remains consistent.
This is especially important in CoW tables, as they preserve immutability of historical data by writing new versions of the records instead of overwriting the existing data. The merge mode ensures that the new version of the record is consistent with all previous changes.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-compaction-merge-in-mor-merge-on-read-tables--merging-log-files-with-base-files">3. Compaction Merge in MoR (Merge-on-Read) Tables : Merging Log Files with Base Files<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#3-compaction-merge-in-mor-merge-on-read-tables--merging-log-files-with-base-files" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>Hudi uses a concept of log files (delta logs) and base files (original data). As changes to records accumulate over time, Hudi’s compaction service merges the change records stored in the log files with the base files to keep the data consistent and query-optimized. The merge mode defines how these log records are merged with base files during the compaction process.
Compaction helps maintain storage efficiency and ensures that queries run faster by reducing the number of small log files that might need to be read.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-query-time-merge-merging-log-files-with-base-files-in-mor-merge-on-read-tables">4. Query-Time Merge: Merging Log Files with Base Files in MoR (Merge-on-Read) Tables<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#4-query-time-merge-merging-log-files-with-base-files-in-mor-merge-on-read-tables" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>In Merge-on-Read (MoR) tables, the data is stored in both log files and base files. When a query is executed, Hudi merges the change records in the log files with the base files based on the merge mode. The merge operation occurs at query time to provide the final, consistent view of the data.
By merging records at query time, Hudi ensures that queries reflect the most recent changes while maintaining query performance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementation">Implementation<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#implementation" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>In common scenarios, the input data contains a field that can be used to identify the latest record. Typically, tables have fields like updated_at or other ordering columns. If no such column is present in the input, we are limited to relying on the incoming order.</p>
<p>After the release of Hudi 1.0.0, a new configuration, <a href="https://hudi.apache.org/docs/configurations/#hoodierecordmergemode" target="_blank" rel="noopener noreferrer">hoodie.record.merge.mode</a> was introduced to define the merge modes responsible for handling record updates. These merge modes dictate how records with the same key are processed at different stages of the pipeline, from data ingestion to query results.
It can have the following three values:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-commit_time_ordering">1. COMMIT_TIME_ORDERING<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#1-commit_time_ordering" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>This merge mode is used when no field is available in the input data to explicitly determine which record is the latest. The system will rely on the order of ingestion (commit time) to determine the order of records. Hudi expects records to arrive in strict order of their commits. So, the most recent record (in terms of ingestion time) is assumed to be the latest version of the record. This mode is typically used when there is no dedicated column like updated_at, timestamp, or versioning field that can indicate the order of the records.
The merging logic here simply picks the latest write based on the ingestion order (commit time). In a way, it's equivalent to overwriting semantics where only the most recent record is considered.
Example -</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">sql</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">insert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">into</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">operation</span><span class="token operator">=</span><span class="token plain">upsert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> hudi_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    uuid STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rider STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    driver STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    fare </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DOUBLE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    city STRING</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">USING</span><span class="token plain"> HUDI TBLPROPERTIES </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">primaryKey </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'uuid'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">record</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">merge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">mode</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'COMMIT_TIME_ORDERING'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> hudi_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">VALUES</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-A'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-K'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">19.10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-C'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-M'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">27.70</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Result - 20250106162911278	20250106162911278_0_0	334e26e9-8355-45cc-97c6-c31daf0df330		08218473-f72a-480d-90e6-c6764f062e5c-0_0-43-47_20250106162911278.parquet	1695091554788	334e26e9-8355-45cc-97c6-c31daf0df330	rider-C	driver-M	27.7	san_francisco</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> hudi_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">VALUES</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-D'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-K'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">19.10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Result - 20250106163449812	20250106163449812_0_0	334e26e9-8355-45cc-97c6-c31daf0df330		08218473-f72a-480d-90e6-c6764f062e5c-0_0-71-68_20250106163449812.parquet	1	334e26e9-8355-45cc-97c6-c31daf0df330	rider-D	driver-K	19.1	san_francisco</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the example above, we created the table using the COMMIT_TIME_ORDERING merge mode. When using this mode, there is no need to specify a precombine or ordering field.
During the first insert, two records with the same record key are provided. The system will deduplicate them and keep the record that is processed later.
In the second insert, a new record with the same record key is inserted. As expected, the table is updated with the new record because it is committed later, regardless of the values in any of the fields.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-event_time_ordering-default">2. EVENT_TIME_ORDERING (DEFAULT)<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#2-event_time_ordering-default" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>This merge mode is used when you do have a field in the input data that can be used to determine the order of events (such as a timestamp field like updated_at or a version number). If your records contain a field that can be used to track when the record was last updated (e.g., updated_at, last_modified, or a sequence number), Hudi will use this field to determine which record is the latest.
In this case, Hudi does not rely on the ingestion order but instead uses the value of the ordering field (updated_at, for example) to decide the correct record.
This approach is ideal when you have temporal or event-driven data, and you want to maintain the "latest" record according to an event timestamp.
Example -</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DROP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">sql</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">insert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">into</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">operation</span><span class="token operator">=</span><span class="token plain">upsert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> hudi_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    uuid STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rider STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    driver STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    fare </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DOUBLE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    city STRING</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">USING</span><span class="token plain"> HUDI TBLPROPERTIES </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">primaryKey </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'uuid'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">preCombineField </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ts'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">record</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">merge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">mode</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'EVENT_TIME_ORDERING'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> hudi_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">VALUES</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-A'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-K'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">19.10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-C'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-M'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">27.70</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Result - 20250106165902806	20250106165902806_0_0	334e26e9-8355-45cc-97c6-c31daf0df330		568ce7bc-9b71-4e15-b557-cbaeb5b4d2ea-0_0-56-57_20250106165902806.parquet	3	334e26e9-8355-45cc-97c6-c31daf0df330	rider-A	driver-K	19.1	san_francisco</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> hudi_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">VALUES</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-D'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-K'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">18.00</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Result - 20250106165902806	20250106165902806_0_0	334e26e9-8355-45cc-97c6-c31daf0df330		568ce7bc-9b71-4e15-b557-cbaeb5b4d2ea-0_0-84-78_20250106165918731.parquet	3	334e26e9-8355-45cc-97c6-c31daf0df330	rider-A	driver-K	19.1	san_francisco</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the example above, we created the table using the EVENT_TIME_ORDERING merge mode. When using this mode, we need to specify the precombineField. In this case we are specifying ts as the precombineField.
During the first insert, two records with the same record key are provided. The system will deduplicate them and keep the record that is processed later.
In the second insert, a new record with the same record key is inserted. As expected, the table is updated with the new record because it is committed later, regardless of the values in any of the fields.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-custom">3. CUSTOM<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#3-custom" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>For more complex use-case sometimes prior discussed merging modes won’t work. We may need to implement a use-case specific merging logic.
The details for the implementation is provided here  - <a href="https://hudi.apache.org/docs/record_merger/#custom" target="_blank" rel="noopener noreferrer">https://hudi.apache.org/docs/record_merger/#custom</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="record-payloads">Record Payloads<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#record-payloads" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Pre 1.0.0, Hudi uses the legacy Record Payload API, Please refer to the <a href="https://hudi.apache.org/docs/record_merger/#record-payloads" target="_blank" rel="noopener noreferrer">Record Payloads</a> section to know about the implementation and some of the existing record payloads.</p>
<p>Along with the existing payloads, Hudi provides flexibility to implement the custom record payload by implementing the <a href="https://github.com/apache/hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java" target="_blank" rel="noopener noreferrer">HoodieRecordPayload</a> interface</p>
<p>The following example demonstrates the use of Record Payload, which achieves a similar outcome to what EVENT_TIME_ORDERING does. We’ve used the same example as above to illustrate how this functionality works.</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DROP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">sql</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">insert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">into</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">operation</span><span class="token operator">=</span><span class="token plain">upsert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> hudi_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    uuid STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rider STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    driver STRING</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    fare </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DOUBLE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    city STRING</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">USING</span><span class="token plain"> HUDI TBLPROPERTIES </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">primaryKey </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'uuid'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">preCombineField </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ts'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hoodie</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">datasource</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">write</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">payload</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">class</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'org.apache.hudi.common.model.DefaultHoodieRecordPayload'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> hudi_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">VALUES</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-A'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-K'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">19.10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-C'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-M'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">27.70</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Result - 20250203164444124	20250203164444124_0_0	334e26e9-8355-45cc-97c6-c31daf0df330		4549ed8e-0346-4d59-8878-9e047fb6c651-0_0-14-17_20250203164444124.parquet	3	334e26e9-8355-45cc-97c6-c31daf0df330	rider-A	driver-K	19.1	san_francisco</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> hudi_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">VALUES</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'334e26e9-8355-45cc-97c6-c31daf0df330'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'rider-D'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'driver-K'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">18.00</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token string" style="color:rgb(255, 121, 198)">'san_francisco'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">select</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> hudi_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Result - 20250203164444124	20250203164444124_0_0	334e26e9-8355-45cc-97c6-c31daf0df330		4549ed8e-0346-4d59-8878-9e047fb6c651-0_0-53-51_20250203164537068.parquet	3	334e26e9-8355-45cc-97c6-c31daf0df330	rider-A	driver-K	19.1	san_francisco</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://hudi.apache.org/cn/blog/2025/03/03/record-mergers-in-hudi#conclusion" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>In conclusion, managing late-arriving and out-of-order data is a critical challenge in modern data processing systems, especially when dealing with large-scale, real-time data pipelines. Tools like Hudi provide powerful merge modes that ensure data consistency, accuracy, and efficiency by handling record updates intelligently across different stages of the pipeline. Whether you're working with streaming data, IoT sensors, or social media posts, understanding how to configure and use these merge modes can greatly improve the performance and reliability of your data storage and query processes. By leveraging the right merge strategy, you can ensure that your system remains robust, even under heavy load and with delayed data, ultimately enabling better decision-making and insights from your data.</p>]]></content>
        <author>
            <name>Aditya Goenka</name>
        </author>
        <category label="Data Lake" term="Data Lake"/>
        <category label="Data Lakehouse" term="Data Lakehouse"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Record Mergers" term="Record Mergers"/>
        <category label="Record payloads" term="Record payloads"/>
        <category label="Late Arriving Data" term="Late Arriving Data"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Curious Engineering Facts ( Trace Agents | Hudi| Daft : 1) : March Release 18 : 25]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/02/25/curious-engineering-facts-trace-agents-hudi-daft-1</id>
        <link href="https://hudi.apache.org/cn/blog/2025/02/25/curious-engineering-facts-trace-agents-hudi-daft-1"/>
        <updated>2025-02-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/@kkgsanjeewac77/curious-engineering-facts-trace-agents-hudi-daft-1-march-release-18-25-bedc00e05ecd">here</a></span>]]></content>
        <author>
            <name>Gayan Sanjeewa</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="daft" term="daft"/>
        <category label="trace agents" term="trace agents"/>
        <category label="openai" term="openai"/>
        <category label="llm" term="llm"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a Lakehouse Architecture on AWS with Terraform]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/02/24/building-a-lakehouse-architecture-on-aws-with-terraform</id>
        <link href="https://hudi.apache.org/cn/blog/2025/02/24/building-a-lakehouse-architecture-on-aws-with-terraform"/>
        <updated>2025-02-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/@juanfelipear97/building-a-lakehouse-architecture-on-aws-with-terraform-139c079ec385">here</a></span>]]></content>
        <author>
            <name>Juanfelipear</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="aws" term="aws"/>
        <category label="terraform" term="terraform"/>
        <category label="lakehouse" term="lakehouse"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Curious Engineering Facts (Lakehouse | Apache Hudi | Daft |Positional argument|) : March Release 19 : 25]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/02/23/curious-engineering-facts-lakehouse-apache-hudi-daft-positional-argument</id>
        <link href="https://hudi.apache.org/cn/blog/2025/02/23/curious-engineering-facts-lakehouse-apache-hudi-daft-positional-argument"/>
        <updated>2025-02-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://medium.com/@kkgsanjeewac77/curious-engineering-facts-lakehouse-apache-hudi-daft-positional-argument-march-release-d0fee8151736">here</a></span>]]></content>
        <author>
            <name>Gayan Sanjeewa</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="daft" term="daft"/>
        <category label="streamlit" term="streamlit"/>
        <category label="cow" term="cow"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[An intro to Hudi with MinIO]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/01/30/an-intro-to-hudi-with-minio</id>
        <link href="https://hudi.apache.org/cn/blog/2025/01/30/an-intro-to-hudi-with-minio"/>
        <updated>2025-01-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://dataxplorer.medium.com/an-intro-to-hudi-with-minio-i-75536fe75b4c">here</a></span>]]></content>
        <author>
            <name>Simbu</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="minio" term="minio"/>
        <category label="medium" term="medium"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Concurrency Control in Open Data Lakehouse]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control</id>
        <link href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control"/>
        <updated>2025-01-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introduction]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#introduction" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Concurrency control is critical in database management systems to ensure consistent and safe access to shared data by multiple users. Relational databases (RDBMS) such as <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-transaction-model.html" target="_blank" rel="noopener noreferrer">MySQL (InnoDB)</a> and analytical databases (such as data warehouses) have been offering robust concurrency control mechanisms to effectively deal with this. As data grows in scale and complexity, managing concurrent access becomes more challenging, especially in large distributed systems like Data Lakes or <a href="https://hudi.apache.org/blog/2024/07/11/what-is-a-data-lakehouse/" target="_blank" rel="noopener noreferrer">Lakehouses</a>, which are expected to handle different types of workloads in the analytics realm. While data lakes have traditionally struggled with concurrent operations due to the lack of a <a href="https://hudi.apache.org/docs/hudi_stack#storage-engine" target="_blank" rel="noopener noreferrer">storage engine</a> and ACID guarantees, lakehouse architectures with open table formats like Apache Hudi, Apache Iceberg, and Delta Lake take inspiration from some of the widely used concurrency control methods to support high concurrent workloads.</p>
<p>This blog goes into the fundamentals of concurrency control, explores why it is essential for lakehouses, and examines how open table formats such as Apache Hudi enable strong concurrency control mechanisms to uphold the ACID properties and deal with varied workloads.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="concurrency-control-foundations">Concurrency Control Foundations<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#concurrency-control-foundations" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>At the core of concurrency control are the concepts of Isolation and Serializability, which define the expected behavior for concurrent transactions and ensure the <strong>"I"</strong> in ACID properties. Let’s quickly go over these concepts from a general database system perspective.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="isolation-and-serializability">Isolation and Serializability<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#isolation-and-serializability" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>In transactional systems, Isolation ensures that each transaction operates independently of others, as if it were executed in a single-user environment. This means a transaction should be "all by itself," free from interference by other concurrent operations, preventing concurrency anomalies like dirty reads or lost updates. This isolation allows end users (such as developers or analysts) to understand the impact of a transaction without worrying about conflicts from other simultaneous operations.</p>
<p>Serializability takes this idea further by defining the correct execution order for concurrent transactions. It guarantees that the outcome of executing transactions concurrently will be the same as if they had been executed serially, one after the other. In other words, even if transactions are interleaved, their combined effect should appear as though there were no parallel execution at all. Serializability is thus a rigorous correctness criterion that concurrency control models in databases strive to enforce, providing a predictable environment for transactional workloads.</p>
<p>For example, imagine an online concert ticketing system where multiple customers are attempting to purchase tickets for the same concert at the same time. Suppose there are only 5 tickets left, and two customers - Customer A and Customer B try to buy 3 tickets each simultaneously. Without proper concurrency control, these transactions might interfere with each other, leading to scenarios where more tickets are "sold" than available in inventory, resulting in inconsistencies. To maintain serializability, the system must ensure that the outcome of processing these transactions concurrently is the same as if they were processed one at a time (serially), i.e. no more than 5 tickets are sold, ensuring inventory consistency.</p>
<p>Concurrency control methods can be broadly classified into three approaches: Pessimistic Concurrency Control, Optimistic Concurrency Control, and Multi-Version Concurrency Control (MVCC).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pessimistic-concurrency-control-2pl">Pessimistic Concurrency Control (2PL)<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#pessimistic-concurrency-control-2pl" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>Pessimistic Concurrency Control assumes that conflicts between transactions can happen often and avoids having ‘problems’ in the first place. The most commonly used method, Strict Two-Phase Locking (2PL), works in this way:</p>
<ul>
<li>Transactions acquire a shared lock before reading data and an exclusive lock before writing.</li>
<li>Locks are held until the transaction commits or aborts but releases immediately after the commit command executes, ensuring serializability.</li>
</ul>
<img src="https://hudi.apache.org/assets/images/blog/concurrency_control/2PL.png" alt="2PL" width="1000" align="middle">
<p>If we take our online concert ticketing system example, where we have 5 tickets left and Customer A and Customer B both attempt to buy 3 tickets simultaneously. With Strict Two-Phase Locking (2PL), Transaction T1 (Customer A’s purchase) acquires an exclusive lock on the inventory, preventing Transaction T2 (Customer B’s purchase) from accessing it until T1 completes. T1 checks the inventory, deducts 3 tickets for Customer A, reducing the count to 2, and then releases the lock. Only then can T2 proceed, locking the inventory, seeing the updated 2 tickets, and completing the purchase for Customer B. This ensures serializability by isolating transactions through locking, yielding the same result as if the transactions had run one after the other.</p>
<p>While Strict 2PL guarantees correctness, it comes with some downsides:</p>
<ul>
<li>Transactions waiting to acquire locks may be blocked for long durations, especially in high-contention scenarios, leading to reduced throughput.</li>
<li>If two transactions hold locks on different resources and wait for each other to release them, a deadlock occurs, requiring intervention (e.g., by aborting one transaction).</li>
<li>The strict correctness requirements can lead to long transaction times, making it less suitable for high-concurrency workloads.</li>
</ul>
<p>Strict 2PL is present in relational database systems such as PostgreSQL, and Oracle Database.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="optimistic-concurrency-control-occ">Optimistic Concurrency Control (OCC)<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#optimistic-concurrency-control-occ" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>Optimistic concurrency control takes the opposite approach - it assumes that conflicts happen rarely, and if there are such scenarios, then it would deal with it at the time of the conflict. OCC works this way:</p>
<ul>
<li>Transactions track read and write operations and, upon completion, validate these changes to check for conflicts.</li>
<li>If conflicts are detected, one or more conflicting transactions are rolled back and can be retried if needed be.</li>
</ul>
<p>OCC is particularly effective in low-contention environments, where conflicts between transactions are infrequent. However, in scenarios with frequent conflicts, such as multiple transactions attempting to modify the same data, OCC may result in a high number of rollbacks, reducing its efficiency. Its ability to allow multiple transactions to proceed without locking makes it a good choice for workloads where contention is low and throughput is prioritized over strict blocking mechanisms.</p>
<img src="https://hudi.apache.org/assets/images/blog/concurrency_control/OCC.png" alt="OCC" align="middle">
<p>For our example, with OCC, both transactions will proceed, each reading the initial count of 5 tickets and preparing to deduct 3. When they try to commit, a conflict check (history) will reveal that reducing by 3 tickets would oversell the inventory. As a result, one transaction (e.g., Customer B’s) is rolled back, allowing Customer A to complete their purchase, reducing the inventory to 2. Customer B then retries, sees only 2 tickets left, and adjusts accordingly.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="multi-version-concurrency-control-mvcc">Multi-Version Concurrency Control (MVCC)<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#multi-version-concurrency-control-mvcc" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>MVCC enables concurrent transactions by maintaining multiple versions of each data item, allowing transactions to read data as it appeared at a specific point in time. Here’s how MVCC works at a high-level:</p>
<ul>
<li>Each transaction is split into a "read set" and a "write set." This separation of read and write sets enhances concurrency by reducing conflicts.</li>
<li>All reads in a transaction operate as if they are accessing a single, consistent ‘snapshot’ of the data at a particular moment.</li>
<li>Writes are applied as if they are part of a ‘later snapshot’, ensuring that any changes made by the transaction are isolated from other concurrent transactions until the transaction completes.</li>
</ul>
<img src="https://hudi.apache.org/assets/images/blog/concurrency_control/MVCC.png" alt="MVCC" align="middle">
<p>In our example, with MVCC, each customer sees a consistent snapshot of 5 tickets when they start. Customer A completes their purchase first, reducing the inventory to 2 tickets. When Customer B finishes, they commit their transaction based on the latest snapshot, seeing only 2 tickets left and adjusting their purchase accordingly.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="concurrency-control-in-open-table-formats">Concurrency Control in Open Table Formats<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#concurrency-control-in-open-table-formats" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Data lakes were built for scalable storage, cheaper cost, and to address some of the limitations of data warehouses (such as handling varied data types), but they lack the transactional storage engine needed to enforce ACID guarantees. We learnt in our previous section how isolation (the "I" in ACID) plays a critical role in managing concurrency by ensuring that each transaction operates independently without unintended interference from others. This level of isolation is essential for preventing concurrency anomalies like dirty reads, lost updates, and other issues that can compromise data integrity. Data lakehouse architecture with open table formats such as Apache Hudi, Apache Iceberg, and Delta Lake as the foundation for the storage layer addresses this problem by applying some of the concurrency control methods available in the database systems.</p>
<p>Let’s take a look at what type of concurrency control methods are available within these formats with a focus on <strong>Apache Hudi</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-hudi">Apache Hudi<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#apache-hudi" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>Most of the concurrency control implementations today in lakehouse table formats focus on optimistically handling conflicts. OCC relies on the assumption that conflicts are rare, making it suitable for simple, append-only jobs but inadequate for scenarios that require frequent updates or deletes. In OCC, each job typically takes a table-level lock to check for conflicts by determining if there are overlapping files that multiple jobs have impacted. If a conflict is detected, the job will abort its operation <em>entirely</em>. This could be a problem with certain types of workloads. For example, an ingest job writing data every 30 minutes and a deletion job running every two hours may often conflict, causing the deletion job to fail. In such cases especially with long-running transactions, OCC is problematic because the chance of conflicts increases over time.</p>
<img src="https://hudi.apache.org/assets/images/blog/concurrency_control/concur_blog.png" alt="Hudi concurrency control methods" width="900" align="middle">
<p>Apache Hudi’s uniqueness lies in the fact that it clearly distinguishes the different actors interacting with the format, i.e. writer processes (that issue user’s upserts/deletes), table services (such as clustering, compaction) and readers (that execute queries and read data). Hudi provides <a href="https://en.wikipedia.org/wiki/Snapshot_isolation" target="_blank" rel="noopener noreferrer">Snapshot Isolation</a> between all three types of processes, meaning they all operate on a consistent snapshot of the table. For writers, Hudi implements a variant of Serializable <a href="https://distributed-computing-musings.com/2022/02/transactions-serializable-snapshot-isolation/" target="_blank" rel="noopener noreferrer">Snapshot Isolation (SSI)</a>. Here’s how Hudi supports different types of concurrency control methods, offering fine-grained control over concurrent data access and updates.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="occ-multi-writers">OCC (Multi Writers)<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#occ-multi-writers" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>OCC is primarily used to manage concurrent writer processes in Hudi. For example, two different Spark jobs interacting with the same Hudi table to perform updates. Hudi’s OCC workflow involves a series of checks to detect and handle conflicts, ensuring that only one writer can successfully commit changes to a particular file group at any given time. Here’s a quick summary of what file groups and slices mean in Hudi.</p>
<p><em>File group: Groups multiple versions of a base file (e.g. Parquet). The file group is uniquely identified by a File id. Each version corresponds to the commit's timestamp recording updates to records in the file.</em></p>
<p><em>File slice: A File group can further be split into multiple slices. Each file slice within the file-group is uniquely identified by the commit's timestamp that created it.</em></p>
<p>OCC works in three phases - read, validate and write. When a writer begins a transaction, it first makes the changes, i.e. commits in isolation. During the validation phase, writers compare their proposed changes against existing file groups in the timeline to detect conflicts. Finally, in the write phase, the changes are either committed if no conflicts are found or rolled back if conflicts are detected.</p>
<p>For multi-writing scenarios, when a writer begins the commit process, it acquires a short-duration lock from the lock provider, typically implemented with an external service such as Zookeeper, Hive Metastore, or DynamoDB. Once the lock is secured, the writer loads the <a href="https://hudi.apache.org/docs/next/timeline" target="_blank" rel="noopener noreferrer">current timeline</a> to check for previously <code>completed</code> actions on the targeted file group. After that, it scans for any instances marked as completed with a timestamp greater than the target file slice's timestamp. If any such completed instances are found, it indicates that another writer has already modified the target file group, leading to a conflict. In this case, Hudi’s OCC logic prevents the current transaction from proceeding by aborting the writer’s operation, ensuring that only one writer’s updates are committed. If no conflicting instant exists, the transaction is allowed to proceed, and the writer completes the write operation, adding a new file slice to the timeline. Finally, Hudi updates the timeline with the location of the new file slice and releases the table lock, allowing other transactions to proceed. This approach adheres to the ACID principles providing consistency guarantees.</p>
<p>It is important to note that Hudi acquires locks <strong>only</strong> at critical points, such as during the commit or while scheduling table services, rather than across the entire transaction. This approach significantly improves concurrency by allowing writers to work in parallel without contention.</p>
<p>Additionally, Hudi’s OCC operates at the file level, meaning conflicts are detected and resolved based on the files being modified. For instance, when two writers work on non-overlapping files, both writes are allowed to succeed. However, if their operations overlap and modify the same set of files, only one transaction will succeed, and the other will be rolled back. This file-level granularity is a significant advantage in many real-world scenarios, as it enables multiple writers to proceed without issues as long as they are working on different files, improving concurrency and overall throughput.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mvcc-writer-table-service-and-table-service-table-service">MVCC (Writer-Table Service and Table Service-Table Service)<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#mvcc-writer-table-service-and-table-service-table-service" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>Apache Hudi provides support for Multiversion Concurrency Control (MVCC) between writers and table-services (for example, an update Spark job and <a href="https://hudi.apache.org/docs/clustering" target="_blank" rel="noopener noreferrer">clustering</a>) and between different table services (such as <a href="https://hudi.apache.org/docs/compaction" target="_blank" rel="noopener noreferrer">compaction</a> and clustering). Similar to OCC, the Hudi timeline is instrumental in Hudi’s MVCC implementation, which keeps a track of all the events (instants) happening in a particular Hudi table. Every writer and reader relies on the file system’s state to decide where to carry out the operations, thereby providing read-write isolation.</p>
<p>When a write operation begins, Hudi marks the action as either <code>requested</code> or <code>inflight</code> on the timeline, making all processes aware of the ongoing operation. This ensures that table management operations such as compaction and clustering are aware of active writes and do not include the file slices currently being modified. With Hudi 1.0's new <a href="https://hudi.apache.org/docs/timeline/" target="_blank" rel="noopener noreferrer">timeline</a> design, compaction and clustering operations are now based on both the requested and completion times of actions, treating these timestamps as <em>intervals</em> to dynamically determine file slices. This means a service like compaction no longer needs to block ongoing writes and can be scheduled at any instant without interfering with active operations.</p>
<p>Under the new design, file slicing includes only those file slices whose completion times precede the start of the compaction or clustering process. This intelligent slicing mechanism ensures that these table management services work only on finalized data while new writes seamlessly continue without impacting the base files being compacted. By decoupling the scheduling of table services from active writes, Hudi 1.0 eliminates the need for strict scheduling sequences or blocking behaviors.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="non-blocking-concurrency-control-multi-writers">Non-Blocking Concurrency Control (Multi Writers)<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#non-blocking-concurrency-control-multi-writers" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>In a generic sense, Non-Blocking Concurrency Control (NBCC) allows multiple transactions to proceed simultaneously without locking, reducing delays and improving throughput in high-concurrency environments. <a href="https://hudi.apache.org/blog/2024/12/16/announcing-hudi-1-0-0" target="_blank" rel="noopener noreferrer">Hudi 1.0</a> introduces a new concurrency mode, <code>NON_BLOCKING_CONCURRENCY_CONTROL</code>, where, unlike OCC, multiple writers can operate on the same table simultaneously with non-blocking conflict resolution. This approach eliminates the need for explicit locks to serialize writes, enabling higher concurrency. Instead of requiring each writer to wait, NBCC allows concurrent writes to proceed, making it ideal for real-time applications that demand faster data ingestion.</p>
<p>In NBCC, the only lock required is for writing the commit metadata to the Hudi timeline, which ensures that the order and state of completed transactions is tracked accurately. With the release of version 1.0, Hudi introduces <a href="https://hudi.apache.org/docs/timeline#truetime-generation" target="_blank" rel="noopener noreferrer">TrueTime</a> semantics for instant times on the timeline, ensuring unique and monotonically increasing instant values. Each action on the Hudi timeline now includes both a <em>requested time</em> and a <em>completion time</em>, enabling these actions to be treated as intervals. This allows for more precise conflict detection by reasoning about overlapping actions within these time intervals.  The final serialization of writes in NBCC is determined by the <em>completion</em> times. This means multiple writers can modify the same file group, with conflicts resolved automatically by query readers and the compactor. NBCC is available with the new Hudi 1.0 release, thereby providing more controls to balance speed with data consistency, even under heavy concurrent workloads.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="concurrency-control-deployment-modes-in-hudi">Concurrency Control Deployment Modes in Hudi<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#concurrency-control-deployment-modes-in-hudi" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>Hudi offers several deployment models to handle different concurrency needs, allowing users to optimize for performance, simplicity, or high-concurrency scenarios depending on the requirements.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="single-writer-with-inline-table-services">Single Writer with Inline Table Services<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#single-writer-with-inline-table-services" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>In this model, only one writer handles data ingestion or updates, with table services (such as cleaning, compaction, and clustering) running inline sequentially after every write. This approach <em>eliminates</em> the need for concurrency control as all operations occur in a single process. MVCC in Hudi guarantees that readers see consistent snapshots, isolating them from ongoing writes and table services. This model is ideal for straightforward use cases where the focus is on getting data into the lakehouse without the complexity of managing multiple writers.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="single-writer-with-async-table-services">Single Writer with Async Table Services<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#single-writer-with-async-table-services" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>For workloads that require higher throughput without blocking writers, Hudi supports asynchronous table services. In this model, a single writer continuously ingests data, while table services such as compaction and clustering run asynchronously in the same process. MVCC allows these background jobs to operate concurrently with ingestion without creating conflicts, as they coordinate to avoid race conditions. This model suits applications where ingestion speed is essential, as async services help optimize the table in the background, reducing operational complexity without the need for external orchestration.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="multi-writer-configuration">Multi-Writer Configuration<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#multi-writer-configuration" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h4>
<p>In cases where multiple writer jobs need to access the same table, Hudi supports multi-writer setups. This model allows disparate processes, such as multiple ingestion writers or a mix of ingestion and separate table service jobs to write concurrently. To manage conflicts, Hudi uses OCC with file-level conflict resolution, allowing non-overlapping writes to proceed while conflicting writes are resolved by allowing only one to succeed. For these types of multi-writer setups, <a href="https://hudi.apache.org/docs/concurrency_control#external-locking-and-lock-providers" target="_blank" rel="noopener noreferrer"><em>external</em></a> lock providers like Amazon DynamoDB, Zookeeper, or Hive Metastore are required to coordinate concurrent access. This setup is ideal for production-level, high-concurrency environments where different processes need to modify the table simultaneously.</p>
<p>Note that while Hudi provides OCC to deal with multiple writers, table services can still run asynchronously and without locks if they operate in the same process as the writer. This is because Hudi intelligently differentiates between the different types of actors (writers, table services) that interact with the table.</p>
<p>You will need to set the following properties to activate OCC with locks.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.write.concurrency.mode=optimistic_concurrency_control</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.write.lock.provider=&lt;lock-provider-classname&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.cleaner.policy.failed.writes=LAZY</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><code>Hoodie.write.lock.provider</code> defines the lock provider class that manages locks for concurrent writes. Default is <code>org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider</code></p>
<p>The <code>LAZY</code> mode cleans failed writes only after a heartbeat timeout when the cleaning service runs and is recommended when using multiple writers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-occ-with-apache-hudi-and-apache-spark">How to use OCC with Apache Hudi and Apache Spark<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#how-to-use-occ-with-apache-hudi-and-apache-spark" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>This is a simple example where we configure OCC by setting the <code>hoodie.write.concurrency.mode</code> to <code>optimistic_concurrency_control</code>. We also specify a lock provider (in this case, Zookeeper) to manage concurrent access, along with essential table options like the precombine field, record key, and partition path.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> pyspark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">sql </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> SparkSession</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Initialize Spark session</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark </span><span class="token operator">=</span><span class="token plain"> SparkSession</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">builder \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">appName</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"Hudi Example with OCC"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"spark.serializer"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"org.apache.spark.serializer.KryoSerializer"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">getOrCreate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Sample DataFrame</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inputDF </span><span class="token operator">=</span><span class="token plain"> spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">createDataFrame</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"2024-11-19 10:00:00"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"A"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"partition1"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"2024-11-19 10:05:00"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"B"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"partition1"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"uuid"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"ts"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"value"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"partitionpath"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tableName </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"my_hudi_table"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">basePath </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"s3://path-to-your-hudi-table"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Write DataFrame to Hudi with OCC and Zookeeper lock provider</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inputDF</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">write</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hudi"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.datasource.write.precombine.field"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"ts"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.cleaner.policy.failed.writes"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"LAZY"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.write.concurrency.mode"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"optimistic_concurrency_control"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.write.lock.provider"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.write.lock.zookeeper.url"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"zk-cs.hudi-infra.svc.cluster.local"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.write.lock.zookeeper.port"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"2181"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.write.lock.zookeeper.base_path"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"/test"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.datasource.write.recordkey.field"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"uuid"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.datasource.write.partitionpath.field"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"partitionpath"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">option</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"hoodie.table.name"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> tableName</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">mode</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"overwrite"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">save</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">basePath</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">stop</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache-iceberg">Apache Iceberg<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#apache-iceberg" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>Apache Iceberg supports multiple concurrent writes through Optimistic Concurrency Control (OCC). The most important part to note here is that Iceberg needs a <em>catalog</em> component to adhere to the ACID guarantees. Each writer assumes it is the only one making changes, generating new table metadata for its operation. When a writer completes its updates, it attempts to commit the changes by performing an <em>atomic swap</em> of the latest <code>metadata.json</code> file in the catalog, replacing the existing metadata file with the new one.</p>
<p>If this atomic swap fails (due to another writer committing changes in the meantime), the writer’s commit is rejected. The writer then retries the entire process by creating a new metadata tree based on the latest state of the table and attempting the atomic swap again.</p>
<p>When it comes to table maintenance tasks, such as optimizations (e.g., compaction) or large delete jobs, Iceberg treats these as regular writes. These operations can overlap with ingestion jobs, but they follow the same OCC principles - conflicts are resolved by retrying based on the latest table state. Users are recommended to schedule such jobs during official maintenance periods to avoid contention, as frequent retries due to conflicts can impact performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="delta-lake">Delta Lake<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#delta-lake" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h3>
<p>Delta Lake provides concurrency control through Optimistic Concurrency Control (OCC) for transactional guarantees between writes. OCC allows multiple writers to attempt changes independently, assuming conflicts are infrequent. When a writer tries to commit, it checks for any conflicting updates from other transactions in the <a href="https://www.databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html" target="_blank" rel="noopener noreferrer">transaction log</a>. If a conflict is found, the transaction is rolled back, and the writer retries based on the latest version of the data.</p>
<p>Additionally, Delta Lake employs Multi-Version Concurrency Control (MVCC) within the file system to separate reads from writes. By keeping data objects and the transaction log immutable, MVCC allows readers to access a consistent snapshot of the data, even as new writes are added. This not only protects existing data from modification during concurrent transactions but also enables time-travel queries, allowing users to query historical snapshots.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://hudi.apache.org/cn/blog/2025/01/28/concurrency-control#conclusion" class="hash-link" aria-label="Direct link to heading" title="Direct link to heading">​</a></h2>
<p>Concurrency control is critical for Open lakehouse architectures, especially when your architecture has multiple concurrent pipelines interacting with the same table. Open table formats such as Apache Hudi bring well-established concurrency control methods from traditional database systems into the Lakehouse architecture to handle these operations while maintaining data consistency and scalability. Apache Hudi’s unique design to distinguish between writers, table services, and readers ensures snapshot isolation across all three processes. By supporting multiple concurrency control methods, such as OCC for managing writer conflicts, MVCC for isolating background table services and writers, and a novel NBCC for non-blocking, real-time ingestion, Hudi offers greater flexibility with complex workloads.</p>
<hr>]]></content>
        <author>
            <name>Dipankar Mazumdar</name>
        </author>
        <category label="multi-writer" term="multi-writer"/>
        <category label="concurrency" term="concurrency"/>
        <category label="concurrency-control" term="concurrency-control"/>
        <category label="non-blocking concurrency-control" term="non-blocking concurrency-control"/>
        <category label="Apache Hudi" term="Apache Hudi"/>
        <category label="Apache Iceberg" term="Apache Iceberg"/>
        <category label="Delta Lake" term="Delta Lake"/>
        <category label="blog" term="blog"/>
        <category label="design" term="design"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apache Hudi 1.0 Now Generally Available]]></title>
        <id>https://hudi.apache.org/cn/blog/2025/01/18/apache-hudi-1-0-now-generally-available</id>
        <link href="https://hudi.apache.org/cn/blog/2025/01/18/apache-hudi-1-0-now-generally-available"/>
        <updated>2025-01-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Redirecting... please wait!!]]></summary>
        <content type="html"><![CDATA[<span>Redirecting... please wait!! <!-- -->or click <a href="https://www.infoq.com/news/2025/01/apache-hudi/">here</a></span>]]></content>
        <author>
            <name>Renato Losio</name>
        </author>
        <category label="blog" term="blog"/>
        <category label="apache hudi" term="apache hudi"/>
        <category label="hudi 1.0.0" term="hudi 1.0.0"/>
        <category label="infoq" term="infoq"/>
    </entry>
</feed>
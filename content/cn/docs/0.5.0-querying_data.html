<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>查询 Hudi 数据集 - Apache Hudi</title>
<meta name="description" content="从概念上讲，Hudi物理存储一次数据到DFS上，同时在其上提供三个逻辑视图，如之前所述。数据集同步到Hive Metastore后，它将提供由Hudi的自定义输入格式支持的Hive外部表。一旦提供了适当的Hudi捆绑包，就可以通过Hive、Spark和Presto之类的常用查询引擎来查询数据集。">

<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="">
<meta property="og:title" content="查询 Hudi 数据集">
<meta property="og:url" content="https://hudi.apache.org/cn/docs/0.5.0-querying_data.html">


  <meta property="og:description" content="从概念上讲，Hudi物理存储一次数据到DFS上，同时在其上提供三个逻辑视图，如之前所述。数据集同步到Hive Metastore后，它将提供由Hudi的自定义输入格式支持的Hive外部表。一旦提供了适当的Hudi捆绑包，就可以通过Hive、Spark和Presto之类的常用查询引擎来查询数据集。">





  <meta property="article:modified_time" content="2019-12-30T14:59:57-05:00">







<!-- end _includes/seo.html -->


<!--<link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">-->

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



<link rel="icon" type="image/x-icon" href="/assets/images/favicon.ico">
<link rel="stylesheet" href="/assets/css/font-awesome.min.css">

  </head>

  <body class="layout--single">
    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap" id="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/">
              <div style="width: 150px; height: 40px">
              </div>
          </a>
        
        <a class="site-title" href="/">
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/cn/docs/quick-start-guide.html" target="_self" >文档</a>
            </li><li class="masthead__menu-item">
              <a href="/cn/community.html" target="_self" >社区</a>
            </li><li class="masthead__menu-item">
              <a href="/cn/activity.html" target="_self" >动态</a>
            </li><li class="masthead__menu-item">
              <a href="https://cwiki.apache.org/confluence/display/HUDI/FAQ" target="_blank" >FAQ</a>
            </li><li class="masthead__menu-item">
              <a href="/cn/releases.html" target="_self" >发布</a>
            </li></ul>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>
<!--
<p class="notice--warning" style="margin: 0 !important; text-align: center !important;"><strong>Note:</strong> This site is work in progress, if you notice any issues, please <a target="_blank" href="https://github.com/apache/incubator-hudi/issues">Report on Issue</a>.
  Click <a href="/"> here</a> back to old site.</p>
-->

    <div class="initial-content">
      <div id="main" role="main">
  

  <div class="sidebar sticky">

  

  

    
      







<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">文档菜单</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">入门指南</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-quick-start-guide.html" class="">快速开始</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-use_cases.html" class="">使用案例</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-powered_by.html" class="">演讲 & hudi 用户</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-comparison.html" class="">对比</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-docker_demo.html" class="">Docker 示例</a></li>
            

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">帮助文档</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-concepts.html" class="">概念</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-writing_data.html" class="">写入数据</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-querying_data.html" class="active">查询数据</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-configurations.html" class="">配置</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-performance.html" class="">性能</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-admin_guide.html" class="">管理</a></li>
            

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">其他信息</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-docs-versions.html" class="">文档版本</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-privacy.html" class="">版权信息</a></li>
            

          
        </ul>
        
      </li>
    
  </ul>
</nav>
    

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">查询 Hudi 数据集
</h1>
        </header>
      

      <section class="page__content" itemprop="text">
        
        <aside class="sidebar__right sticky">
          <nav class="toc">
            <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> IN THIS PAGE</h4></header>
            <ul class="toc__menu">
  <li><a href="#hive">Hive</a>
    <ul>
      <li><a href="#hive-ro-view">读优化表</a></li>
      <li><a href="#hive-rt-view">实时表</a></li>
      <li><a href="#hive-incr-pull">增量拉取</a></li>
    </ul>
  </li>
  <li><a href="#spark">Spark</a>
    <ul>
      <li><a href="#spark-ro-view">读优化表</a></li>
      <li><a href="#spark-rt-view">实时表</a></li>
      <li><a href="#spark-incr-pull">增量拉取</a></li>
    </ul>
  </li>
  <li><a href="#presto">Presto</a></li>
</ul>
          </nav>
        </aside>
        
        <p>从概念上讲，Hudi物理存储一次数据到DFS上，同时在其上提供三个逻辑视图，如<a href="/cn/docs/0.5.0-concepts.html#views">之前</a>所述。
数据集同步到Hive Metastore后，它将提供由Hudi的自定义输入格式支持的Hive外部表。一旦提供了适当的Hudi捆绑包，
就可以通过Hive、Spark和Presto之类的常用查询引擎来查询数据集。</p>

<p>具体来说，在写入过程中传递了两个由<a href="/cn/docs/0.5.0-configurations.html#TABLE_NAME_OPT_KEY">table name</a>命名的Hive表。
例如，如果<code class="highlighter-rouge">table name = hudi_tbl</code>，我们得到</p>

<ul>
  <li><code class="highlighter-rouge">hudi_tbl</code> 实现了由 <code class="highlighter-rouge">HoodieParquetInputFormat</code> 支持的数据集的读优化视图，从而提供了纯列式数据。</li>
  <li><code class="highlighter-rouge">hudi_tbl_rt</code> 实现了由 <code class="highlighter-rouge">HoodieParquetRealtimeInputFormat</code> 支持的数据集的实时视图，从而提供了基础数据和日志数据的合并视图。</li>
</ul>

<p>如概念部分所述，<a href="https://www.oreilly.com/ideas/ubers-case-for-incremental-processing-on-hadoop">增量处理</a>所需要的
一个关键原语是<code class="highlighter-rouge">增量拉取</code>（以从数据集中获取更改流/日志）。您可以增量提取Hudi数据集，这意味着自指定的即时时间起，
您可以只获得全部更新和新行。 这与插入更新一起使用，对于构建某些数据管道尤其有用，包括将1个或多个源Hudi表（数据流/事实）以增量方式拉出（流/事实）
并与其他表（数据集/维度）结合以<a href="/cn/docs/0.5.0-writing_data.html">写出增量</a>到目标Hudi数据集。增量视图是通过查询上表之一实现的，并具有特殊配置，
该特殊配置指示查询计划仅需要从数据集中获取增量数据。</p>

<p>接下来，我们将详细讨论在每个查询引擎上如何访问所有三个视图。</p>

<h2 id="hive">Hive</h2>

<p>为了使Hive能够识别Hudi数据集并正确查询，
HiveServer2需要在其<a href="https://www.cloudera.com/documentation/enterprise/5-6-x/topics/cm_mc_hive_udf.html#concept_nc3_mms_lr">辅助jars路径</a>中提供<code class="highlighter-rouge">hudi-hadoop-mr-bundle-x.y.z-SNAPSHOT.jar</code>。 
这将确保输入格式类及其依赖项可用于查询计划和执行。</p>

<h3 id="hive-ro-view">读优化表</h3>
<p>除了上述设置之外，对于beeline cli访问，还需要将<code class="highlighter-rouge">hive.input.format</code>变量设置为<code class="highlighter-rouge">org.apache.hudi.hadoop.HoodieParquetInputFormat</code>输入格式的完全限定路径名。
对于Tez，还需要将<code class="highlighter-rouge">hive.tez.input.format</code>设置为<code class="highlighter-rouge">org.apache.hadoop.hive.ql.io.HiveInputFormat</code>。</p>

<h3 id="hive-rt-view">实时表</h3>
<p>除了在HiveServer2上安装Hive捆绑jars之外，还需要将其放在整个集群的hadoop/hive安装中，这样查询也可以使用自定义RecordReader。</p>

<h3 id="hive-incr-pull">增量拉取</h3>

<p><code class="highlighter-rouge">HiveIncrementalPuller</code>允许通过HiveQL从大型事实/维表中增量提取更改，
结合了Hive（可靠地处理复杂的SQL查询）和增量原语的好处（通过增量拉取而不是完全扫描来加快查询速度）。
该工具使用Hive JDBC运行hive查询并将其结果保存在临时表中，这个表可以被插入更新。
Upsert实用程序（<code class="highlighter-rouge">HoodieDeltaStreamer</code>）具有目录结构所需的所有状态，以了解目标表上的提交时间应为多少。
例如：<code class="highlighter-rouge">/app/incremental-hql/intermediate/{source_table_name}_temp/{last_commit_included}</code>。
已注册的Delta Hive表的格式为<code class="highlighter-rouge">{tmpdb}.{source_table}_{last_commit_included}</code>。</p>

<p>以下是HiveIncrementalPuller的配置选项</p>

<table>
  <thead>
    <tr>
      <th><strong>配置</strong></th>
      <th><strong>描述</strong></th>
      <th><strong>默认值</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>hiveUrl</td>
      <td>要连接的Hive Server 2的URL</td>
      <td> </td>
    </tr>
    <tr>
      <td>hiveUser</td>
      <td>Hive Server 2 用户名</td>
      <td> </td>
    </tr>
    <tr>
      <td>hivePass</td>
      <td>Hive Server 2 密码</td>
      <td> </td>
    </tr>
    <tr>
      <td>queue</td>
      <td>YARN 队列名称</td>
      <td> </td>
    </tr>
    <tr>
      <td>tmp</td>
      <td>DFS中存储临时增量数据的目录。目录结构将遵循约定。请参阅以下部分。</td>
      <td> </td>
    </tr>
    <tr>
      <td>extractSQLFile</td>
      <td>在源表上要执行的提取数据的SQL。提取的数据将是自特定时间点以来已更改的所有行。</td>
      <td> </td>
    </tr>
    <tr>
      <td>sourceTable</td>
      <td>源表名称。在Hive环境属性中需要设置。</td>
      <td> </td>
    </tr>
    <tr>
      <td>targetTable</td>
      <td>目标表名称。中间存储目录结构需要。</td>
      <td> </td>
    </tr>
    <tr>
      <td>sourceDataPath</td>
      <td>源DFS基本路径。这是读取Hudi元数据的地方。</td>
      <td> </td>
    </tr>
    <tr>
      <td>targetDataPath</td>
      <td>目标DFS基本路径。 这是计算fromCommitTime所必需的。 如果显式指定了fromCommitTime，则不需要设置这个参数。</td>
      <td> </td>
    </tr>
    <tr>
      <td>tmpdb</td>
      <td>用来创建中间临时增量表的数据库</td>
      <td>hoodie_temp</td>
    </tr>
    <tr>
      <td>fromCommitTime</td>
      <td>这是最重要的参数。 这是从中提取更改的记录的时间点。</td>
      <td> </td>
    </tr>
    <tr>
      <td>maxCommits</td>
      <td>要包含在拉取中的提交数。将此设置为-1将包括从fromCommitTime开始的所有提交。将此设置为大于0的值，将包括在fromCommitTime之后仅更改指定提交次数的记录。如果您需要一次赶上两次提交，则可能需要这样做。</td>
      <td>3</td>
    </tr>
    <tr>
      <td>help</td>
      <td>实用程序帮助</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>设置fromCommitTime=0和maxCommits=-1将提取整个源数据集，可用于启动Backfill。
如果目标数据集是Hudi数据集，则该实用程序可以确定目标数据集是否没有提交或延迟超过24小时（这是可配置的），
它将自动使用Backfill配置，因为增量应用最近24小时的更改会比Backfill花费更多的时间。
该工具当前的局限性在于缺乏在混合模式（正常模式和增量模式）下自联接同一表的支持。</p>

<p><strong>关于使用Fetch任务执行的Hive查询的说明：</strong>
由于Fetch任务为每个分区调用InputFormat.listStatus()，每个listStatus()调用都会列出Hoodie元数据。
为了避免这种情况，如下操作可能是有用的，即使用Hive session属性对增量查询禁用Fetch任务：
<code class="highlighter-rouge">set hive.fetch.task.conversion = none;</code>。这将确保Hive查询使用Map Reduce执行，
合并分区（用逗号分隔），并且对所有这些分区仅调用一次InputFormat.listStatus()。</p>

<h2 id="spark">Spark</h2>

<p>Spark可将Hudi jars和捆绑包轻松部署和管理到作业/笔记本中。简而言之，通过Spark有两种方法可以访问Hudi数据集。</p>

<ul>
  <li><strong>Hudi DataSource</strong>：支持读取优化和增量拉取，类似于标准数据源（例如：<code class="highlighter-rouge">spark.read.parquet</code>）的工作方式。</li>
  <li><strong>以Hive表读取</strong>：支持所有三个视图，包括实时视图，依赖于自定义的Hudi输入格式（再次类似Hive）。</li>
</ul>

<p>通常，您的spark作业需要依赖<code class="highlighter-rouge">hudi-spark</code>或<code class="highlighter-rouge">hudi-spark-bundle-x.y.z.jar</code>，
它们必须位于驱动程序和执行程序的类路径上（提示：使用<code class="highlighter-rouge">--jars</code>参数）。</p>

<h3 id="spark-ro-view">读优化表</h3>

<p>要使用SparkSQL将RO表读取为Hive表，只需按如下所示将路径过滤器推入sparkContext。
对于Hudi表，该方法保留了Spark内置的读取Parquet文件的优化功能，例如进行矢量化读取。</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">setClass</span><span class="o">(</span><span class="s">"mapreduce.input.pathFilter.class"</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">org.apache.hudi.hadoop.HoodieROTablePathFilter</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">org.apache.hadoop.fs.PathFilter</span><span class="o">]);</span>
</code></pre></div></div>

<p>如果您希望通过数据源在DFS上使用全局路径，则只需执行以下类似操作即可得到Spark DataFrame。</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">hoodieROViewDF</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">().</span><span class="py">format</span><span class="o">(</span><span class="s">"org.apache.hudi"</span><span class="o">)</span>
<span class="c1">// pass any path glob, can include hudi &amp; non-hudi datasets
</span><span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"/glob/path/pattern"</span><span class="o">);</span>
</code></pre></div></div>

<h3 id="spark-rt-view">实时表</h3>
<p>当前，实时表只能在Spark中作为Hive表进行查询。为了做到这一点，设置<code class="highlighter-rouge">spark.sql.hive.convertMetastoreParquet = false</code>，
迫使Spark回退到使用Hive Serde读取数据（计划/执行仍然是Spark）。</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">$</span> <span class="n">spark</span><span class="o">-</span><span class="n">shell</span> <span class="o">--</span><span class="n">jars</span> <span class="n">hudi</span><span class="o">-</span><span class="n">spark</span><span class="o">-</span><span class="n">bundle</span><span class="o">-</span><span class="nv">x</span><span class="o">.</span><span class="py">y</span><span class="o">.</span><span class="py">z</span><span class="o">-</span><span class="nv">SNAPSHOT</span><span class="o">.</span><span class="py">jar</span> <span class="o">--</span><span class="n">driver</span><span class="o">-</span><span class="n">class</span><span class="o">-</span><span class="n">path</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">hive</span><span class="o">/</span><span class="n">conf</span>  <span class="o">--</span><span class="n">packages</span> <span class="nv">com</span><span class="o">.</span><span class="py">databricks</span><span class="k">:</span><span class="kt">spark-avro_2.</span><span class="err">11</span><span class="kt">:</span><span class="err">4</span><span class="kt">.</span><span class="err">0</span><span class="kt">.</span><span class="err">0</span> <span class="kt">--conf</span> <span class="kt">spark.sql.hive.convertMetastoreParquet</span><span class="o">=</span><span class="kc">false</span> <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">executors</span> <span class="mi">10</span> <span class="o">--</span><span class="n">driver</span><span class="o">-</span><span class="n">memory</span> <span class="mi">7</span><span class="n">g</span> <span class="o">--</span><span class="n">executor</span><span class="o">-</span><span class="n">memory</span> <span class="mi">2</span><span class="n">g</span>  <span class="o">--</span><span class="n">master</span> <span class="n">yarn</span><span class="o">-</span><span class="n">client</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">sqlContext</span><span class="o">.</span><span class="py">sql</span><span class="o">(</span><span class="s">"select count(*) from hudi_rt where datestr = '2016-10-02'"</span><span class="o">).</span><span class="py">show</span><span class="o">()</span>
</code></pre></div></div>

<h3 id="spark-incr-pull">增量拉取</h3>
<p><code class="highlighter-rouge">hudi-spark</code>模块提供了DataSource API，这是一种从Hudi数据集中提取数据并通过Spark处理数据的更优雅的方法。
如下所示是一个示例增量拉取，它将获取自<code class="highlighter-rouge">beginInstantTime</code>以来写入的所有记录。</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">hoodieIncViewDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">()</span>
     <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"org.apache.hudi"</span><span class="o">)</span>
     <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceReadOptions</span><span class="o">.</span><span class="na">VIEW_TYPE_OPT_KEY</span><span class="o">(),</span>
             <span class="nc">DataSourceReadOptions</span><span class="o">.</span><span class="na">VIEW_TYPE_INCREMENTAL_OPT_VAL</span><span class="o">())</span>
     <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceReadOptions</span><span class="o">.</span><span class="na">BEGIN_INSTANTTIME_OPT_KEY</span><span class="o">(),</span>
            <span class="o">&lt;</span><span class="n">beginInstantTime</span><span class="o">&gt;)</span>
     <span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="n">tablePath</span><span class="o">);</span> <span class="c1">// For incremental view, pass in the root/base path of dataset</span>
</code></pre></div></div>

<p>请参阅<a href="/cn/docs/0.5.0-configurations.html#spark-datasource">设置</a>部分，以查看所有数据源选项。</p>

<p>另外，<code class="highlighter-rouge">HoodieReadClient</code>通过Hudi的隐式索引提供了以下功能。</p>

<table>
  <thead>
    <tr>
      <th><strong>API</strong></th>
      <th><strong>描述</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>read(keys)</td>
      <td>使用Hudi自己的索通过快速查找将与键对应的数据作为DataFrame读出</td>
    </tr>
    <tr>
      <td>filterExists()</td>
      <td>从提供的RDD[HoodieRecord]中过滤出已经存在的记录。对删除重复数据有用</td>
    </tr>
    <tr>
      <td>checkExists(keys)</td>
      <td>检查提供的键是否存在于Hudi数据集中</td>
    </tr>
  </tbody>
</table>

<h2 id="presto">Presto</h2>

<p>Presto是一种常用的查询引擎，可提供交互式查询性能。 Hudi RO表可以在Presto中无缝查询。
这需要在整个安装过程中将<code class="highlighter-rouge">hudi-presto-bundle</code> jar放入<code class="highlighter-rouge">&lt;presto_install&gt;/plugin/hive-hadoop2/</code>中。</p>

      </section>

      <a href="#masthead__inner-wrap" class="back-to-top">Back to top &uarr;</a>


      

    </div>

  </article>

</div>

    </div>

    <div class="page__footer">
      <footer>
        
<div class="row">
  <div class="col-lg-12 footer">
    <p>
      <a class="footer-link-img" href="https://apache.org">
        <img width="250px" src="/assets/images/asf_logo.svg" alt="The Apache Software Foundation">
      </a>
    </p>
    <p>
      Copyright &copy; <span id="copyright-year">2019</span> <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0.
      Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation. <a href="/docs/privacy">Privacy Policy</a>
      <br>
      Apache Hudi is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the <a href="http://incubator.apache.org/">Apache Incubator</a>.
      Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have
      stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a
      reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
    </p>
  </div>
</div>
      </footer>
    </div>

    
<script src="/assets/js/main.min.js"></script>


  </body>
</html>
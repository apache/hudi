<!doctype html>
<html lang="cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.3">
<link rel="alternate" type="application/rss+xml" href="/cn/blog/rss.xml" title="Apache Hudi! Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/cn/blog/atom.xml" title="Apache Hudi! Blog Atom Feed">
<link rel="search" type="application/opensearchdescription+xml" title="Apache Hudi!" href="/cn/opensearch.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Comfortaa|Ubuntu|Roboto|Source+Code+Pro">
<link rel="stylesheet" href="https://at-ui.github.io/feather-font/css/iconfont.css"><title data-react-helmet="true">Docker Demo | Apache Hudi!</title><meta data-react-helmet="true" property="og:url" content="https://hudi.apache.org/cn/docs/next/docker_demo"><meta data-react-helmet="true" name="docsearch:language" content="cn"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Docker Demo | Apache Hudi!"><meta data-react-helmet="true" name="description" content="一个使用 Docker 容器的 Demo"><meta data-react-helmet="true" property="og:description" content="一个使用 Docker 容器的 Demo"><meta data-react-helmet="true" name="keywords" content="hudi,docker,demo"><link data-react-helmet="true" rel="shortcut icon" href="/cn/assets/images/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://hudi.apache.org/cn/docs/next/docker_demo"><link data-react-helmet="true" rel="alternate" href="https://hudi.apache.org/docs/next/docker_demo" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://hudi.apache.org/cn/docs/next/docker_demo" hreflang="cn"><link data-react-helmet="true" rel="alternate" href="https://hudi.apache.org/docs/next/docker_demo" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/cn/assets/css/styles.067d5900.css">
<link rel="preload" href="/cn/assets/js/runtime~main.62aa2619.js" as="script">
<link rel="preload" href="/cn/assets/js/main.107e672b.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><div class="announcementBar_3WsW" role="banner"><div class="announcementBarContent_3EUC announcementBarCloseable_3myR">⭐️ If you like Apache Hudi, give it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/apache/hudi">GitHub</a>! ⭐</div><button type="button" class="announcementBarClose_38nx clean-btn" aria-label="Close"><span aria-hidden="true">×</span></button></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/cn/"><img src="/cn/assets/images/hudi.png" alt="Apache Hudi" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/cn/assets/images/hudi.png" alt="Apache Hudi" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"></a><a class="navbar__item navbar__link" href="/cn/docs/quick-start-guide">Docs</a><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link">Learn</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/cn/blog">Blog</a></li><li><a class="dropdown__link" href="/cn/talks-articles">Talks &amp; Articles</a></li><li><a class="dropdown__link" href="/cn/learn/faq">FAQ</a></li><li><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Technical Wiki<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--left"><a class="navbar__item navbar__link">Contribute</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/cn/contribute/get-involved">Get Involved</a></li><li><a class="dropdown__link" href="/cn/contribute/team">Team</a></li><li><a class="dropdown__link" href="/cn/contribute/how-to-contribute">How to Contribute</a></li><li><a class="dropdown__link" href="/cn/contribute/developer-setup">Developer Setup</a></li><li><a class="dropdown__link" href="/cn/contribute/rfc-process">RFC Process</a></li><li><a class="dropdown__link" href="/cn/contribute/report-security-issues">Report Security Issues</a></li><li><a href="https://issues.apache.org/jira/projects/HUDI/summary" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Report Issues<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><a class="navbar__item navbar__link" href="/cn/powered-by">Who&#x27;s Using</a><a class="navbar__item navbar__link" href="/cn/releases/download">Download</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__item navbar__link" href="/cn/docs/next/overview">Next</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/cn/docs/next/docker_demo">Next</a></li><li><a class="dropdown__link" href="/cn/docs/docker_demo">0.9.0</a></li><li><a class="dropdown__link" href="/cn/docs/0.8.0/docker_demo">0.8.0</a></li><li><a class="dropdown__link" href="/cn/docs/0.7.0/docker_demo">0.7.0</a></li><li><a class="dropdown__link" href="/cn/docs/0.6.0/docker_demo">0.6.0</a></li><li><a class="dropdown__link" href="/cn/docs/0.5.3/docker_demo">0.5.3</a></li><li><a class="dropdown__link" href="/cn/docs/0.5.2/docker_demo">0.5.2</a></li><li><a class="dropdown__link" href="/cn/docs/0.5.1/docker_demo">0.5.1</a></li><li><a class="dropdown__link" href="/cn/docs/0.5.0/docker_demo">0.5.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__item navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" style="vertical-align:text-bottom;margin-right:5px"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>Chinese</span></span></a><ul class="dropdown__menu"><li><a href="/docs/next/docker_demo" target="_self" rel="noopener noreferrer" class="dropdown__link" style="text-transform:capitalize">English</a></li><li><a href="/cn/docs/next/docker_demo" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" style="text-transform:capitalize">Chinese</a></li></ul></div><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-twitter-link" aria-label="Hudi Twitter Handle"></a><a href="https://join.slack.com/t/apache-hudi/shared_invite/enQtODYyNDAxNzc5MTg2LTE5OTBlYmVhYjM0N2ZhOTJjOWM4YzBmMWU2MjZjMGE4NDc5ZDFiOGQ2N2VkYTVkNzU3ZDQ4OTI1NmFmYWQ0NzE" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-slack-link" aria-label="Hudi Slack Channel"></a><div class="searchBox_xXbB"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/cn/"><img src="/cn/assets/images/hudi.png" alt="Apache Hudi" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/cn/assets/images/hudi.png" alt="Apache Hudi" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/cn/docs/quick-start-guide">Docs</a></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="menu__link menu__link--sublist">Learn</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/cn/blog">Blog</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/talks-articles">Talks &amp; Articles</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/learn/faq">FAQ</a></li><li class="menu__list-item"><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank" rel="noopener noreferrer" class="menu__link"><span>Technical Wiki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="menu__link menu__link--sublist">Contribute</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/cn/contribute/get-involved">Get Involved</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/contribute/team">Team</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/contribute/how-to-contribute">How to Contribute</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/contribute/developer-setup">Developer Setup</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/contribute/rfc-process">RFC Process</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/contribute/report-security-issues">Report Security Issues</a></li><li class="menu__list-item"><a href="https://issues.apache.org/jira/projects/HUDI/summary" target="_blank" rel="noopener noreferrer" class="menu__link"><span>Report Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/cn/powered-by">Who&#x27;s Using</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/releases/download">Download</a></li><li class="menu__list-item"><a role="button" class="menu__link menu__link--sublist">Versions</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active" href="/cn/docs/next/docker_demo">Next</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/docker_demo">0.9.0</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.8.0/docker_demo">0.8.0</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.7.0/docker_demo">0.7.0</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.6.0/docker_demo">0.6.0</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.5.3/docker_demo">0.5.3</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.5.2/docker_demo">0.5.2</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.5.1/docker_demo">0.5.1</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/0.5.0/docker_demo">0.5.0</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a href="#" role="button" class="menu__link menu__link--sublist"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" style="vertical-align:text-bottom;margin-right:5px"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>Languages</span></span></a><ul class="menu__list"><li class="menu__list-item"><a href="/docs/next/docker_demo" target="_self" rel="noopener noreferrer" class="menu__link" style="text-transform:capitalize">English</a></li><li class="menu__list-item"><a href="/cn/docs/next/docker_demo" target="_self" rel="noopener noreferrer" class="menu__link dropdown__link--active" style="text-transform:capitalize">Chinese</a></li></ul></li><li class="menu__list-item"><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="menu__link header-github-link" aria-label="GitHub repository"></a></li><li class="menu__list-item"><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="menu__link header-twitter-link" aria-label="Hudi Twitter Handle"></a></li><li class="menu__list-item"><a href="https://join.slack.com/t/apache-hudi/shared_invite/enQtODYyNDAxNzc5MTg2LTE5OTBlYmVhYjM0N2ZhOTJjOWM4YzBmMWU2MjZjMGE4NDc5ZDFiOGQ2N2VkYTVkNzU3ZDQ4OTI1NmFmYWQ0NzE" target="_blank" rel="noopener noreferrer" class="menu__link header-slack-link" aria-label="Hudi Slack Channel"></a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu menu--responsive thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA" aria-label="Sidebar navigation"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/overview">Overview</a></li><li class="menu__list-item"><a class="menu__link menu__link--sublist" href="#">Quick Start</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/cn/docs/next/quick-start-guide">Spark Guide</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/cn/docs/next/flink-quick-start-guide">Flink 指南</a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/use_cases">使用案例</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/writing_data">写入 Hudi 数据集</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/schema_evolution">Schema Evolution</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/concurrency_control">Concurrency Control</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/querying_data">查询 Hudi 数据集</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/configurations">配置</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/performance">性能</a></li><li class="menu__list-item"><a class="menu__link" href="/cn/docs/next/deployment">管理 Hudi Pipelines</a></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Storage Configurations</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/cloud">云储存</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/s3_hoodie">S3 Filesystem</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/gcs_hoodie">GCS Filesystem</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/oss_hoodie">OSS Filesystem</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/azure_hoodie">Azure 文件系统</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/cos_hoodie">COS Filesystem</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/ibm_cos_hoodie">IBM Cloud Object Storage Filesystem</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/bos_hoodie">BOS Filesystem</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/cn/docs/next/jfs_hoodie">JuiceFS</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Resources</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/cn/docs/next/docker_demo">Docker Demo</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/cn/docs/next/metrics">Metrics</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/cn/docs/next/privacy">Privacy Policy</a></li></ul></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_3FnS"><div class="alert alert--warning margin-bottom--md" role="alert"><div>This is unreleased documentation for Apache Hudi! <b>Next</b> version.</div><div class="margin-top--md">For up-to-date documentation, see the <b><a href="/cn/docs/docker_demo">latest version</a></b> (0.9.0).</div></div><div class="docItemContainer_33ec"><article><span class="badge badge--secondary">Version: Next</span><div class="markdown"><header><h1 class="h1Heading_27L5">Docker Demo</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="一个使用-docker-容器的-demo"></a>一个使用 Docker 容器的 Demo<a class="hash-link" href="#一个使用-docker-容器的-demo" title="Direct link to heading">#</a></h2><p>我们来使用一个真实世界的案例，来看看 Hudi 是如何闭环运转的。 为了这个目的，在你的计算机中的本地 Docker 集群中组建了一个自包含的数据基础设施。</p><p>以下步骤已经在一台 Mac 笔记本电脑上测试过了。</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="前提条件"></a>前提条件<a class="hash-link" href="#前提条件" title="Direct link to heading">#</a></h3><ul><li>Docker 安装 :  对于 Mac ，请依照 [https://docs.docker.com/v17.12/docker-for-mac/install/] 当中定义的步骤。 为了运行 Spark-SQL 查询，请确保至少分配给 Docker 6 GB 和 4 个 CPU 。（参见 Docker -&gt; Preferences -&gt; Advanced）。否则，Spark-SQL 查询可能被因为内存问题而被杀停。</li><li>kafkacat : 一个用于发布/消费 Kafka Topic 的命令行工具集。使用 <code>brew install kafkacat</code> 来安装 kafkacat 。</li><li>/etc/hosts : Demo 通过主机名引用了多个运行在容器中的服务。将下列设置添加到 /etc/hosts ：</li></ul><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 adhoc-1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 adhoc-2</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 namenode</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 datanode1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 hiveserver</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 hivemetastore</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 kafkabroker</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 sparkmaster</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   127.0.0.1 zookeeper</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>此外，这未在其它一些环境中进行测试，例如 Windows 上的 Docker 。</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="设置-docker-集群"></a>设置 Docker 集群<a class="hash-link" href="#设置-docker-集群" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="构建-hudi"></a>构建 Hudi<a class="hash-link" href="#构建-hudi" title="Direct link to heading">#</a></h3><p>构建 Hudi 的第一步：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd &lt;HUDI_WORKSPACE&gt;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mvn package -DskipTests</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="组建-demo-集群"></a>组建 Demo 集群<a class="hash-link" href="#组建-demo-集群" title="Direct link to heading">#</a></h3><p>下一步是运行 Docker 安装脚本并设置配置项以便组建集群。
这需要从 Docker 镜像库拉取 Docker 镜像，并设置 Docker 集群。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd docker</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">./setup_demo.sh</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Stopping spark-worker-1            ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Stopping hiveserver                ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Stopping hivemetastore             ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Stopping historyserver             ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">.......</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">......</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating network &quot;hudi_demo&quot; with the default driver</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating hive-metastore-postgresql ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating namenode                  ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating zookeeper                 ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating kafkabroker               ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating hivemetastore             ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating historyserver             ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating hiveserver                ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating datanode1                 ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating presto-coordinator-1      ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating sparkmaster               ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating presto-worker-1           ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating adhoc-1                   ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating adhoc-2                   ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Creating spark-worker-1            ... done</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Copying spark default config and setting up configs</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Copying spark default config and setting up configs</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Copying spark default config and setting up configs</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ docker ps</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>至此， Docker 集群将会启动并运行。 Demo 集群提供了下列服务：</p><ul><li>HDFS 服务（ NameNode, DataNode ）</li><li>Spark Master 和 Worker</li><li>Hive 服务（ Metastore, HiveServer2 以及 PostgresDB ）</li><li>Kafka Broker 和一个 Zookeeper Node （ Kafka 将被用来当做 Demo 的上游数据源 ）</li><li>用来运行 Hudi/Hive CLI 命令的 Adhoc 容器</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="demo"></a>Demo<a class="hash-link" href="#demo" title="Direct link to heading">#</a></h2><p>Stock Tracker 数据将用来展示不同的 Hudi 视图以及压缩带来的影响。</p><p>看一下 <code>docker/demo/data</code> 目录。那里有 2 批股票数据——都是 1 分钟粒度的。
第 1 批数据包含一些股票代码在交易窗口（9:30 a.m 至 10:30 a.m）的第一个小时里的行情数据数据。第 2 批包含接下来 30 分钟（10:30 - 11 a.m）的交易数据。 Hudi 将被用来将两个批次的数据采集到一个数据集中，这个数据集将会包含最新的小时级股票行情数据。
两个批次被有意地按窗口切分，这样在第 2 批数据中包含了一些针对第 1 批数据条目的更新数据。</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-1--将第-1-批数据发布到-kafka"></a>Step 1 : 将第 1 批数据发布到 Kafka<a class="hash-link" href="#step-1--将第-1-批数据发布到-kafka" title="Direct link to heading">#</a></h3><p>将第 1 批数据上传到 Kafka 的 Topic “stock ticks” 中 <code>cat docker/demo/data/batch_1.json | kafkacat -b kafkabroker -t stock_ticks -P</code></p><p>为了检查新的 Topic 是否出现，使用</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kafkacat -b kafkabroker -L -J | jq .</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;originating_broker&quot;: {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;id&quot;: 1001,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;name&quot;: &quot;kafkabroker:9092/1001&quot;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  },</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;query&quot;: {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;topic&quot;: &quot;*&quot;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  },</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;brokers&quot;: [</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;id&quot;: 1001,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;name&quot;: &quot;kafkabroker:9092&quot;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ],</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;topics&quot;: [</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;topic&quot;: &quot;stock_ticks&quot;,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;partitions&quot;: [</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;partition&quot;: 0,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;leader&quot;: 1001,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;replicas&quot;: [</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              &quot;id&quot;: 1001</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          ],</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;isrs&quot;: [</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              &quot;id&quot;: 1001</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          ]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-2-从-kafka-topic-中增量采集数据"></a>Step 2: 从 Kafka Topic 中增量采集数据<a class="hash-link" href="#step-2-从-kafka-topic-中增量采集数据" title="Direct link to heading">#</a></h3><p>Hudi 自带一个名为 DeltaStreamer 的工具。 这个工具能连接多种数据源（包括 Kafka），以便拉取变更，并通过 upsert/insert 操作应用到 Hudi 数据集。此处，我们将使用这个工具从 Kafka Topic 下载 JSON 数据，并采集到前面步骤中初始化的 COW 和 MOR 表中。如果数据集不存在，这个工具将自动初始化数据集到文件系统中。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run the following spark-submit command to execute the delta-streamer and ingest to stock_ticks_cow dataset in HDFS</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark-submit --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer $HUDI_UTILITIES_BUNDLE --storage-type COPY_ON_WRITE --source-class org.apache.hudi.utilities.sources.JsonKafkaSource --source-ordering-field ts  --target-base-path /user/hive/warehouse/stock_ticks_cow --target-table stock_ticks_cow --props /var/demo/config/kafka-source.properties --schemaprovider-class org.apache.hudi.utilities.schema.FilebasedSchemaProvider</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run the following spark-submit command to execute the delta-streamer and ingest to stock_ticks_mor dataset in HDFS</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark-submit --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer $HUDI_UTILITIES_BUNDLE --storage-type MERGE_ON_READ --source-class org.apache.hudi.utilities.sources.JsonKafkaSource --source-ordering-field ts  --target-base-path /user/hive/warehouse/stock_ticks_mor --target-table stock_ticks_mor --props /var/demo/config/kafka-source.properties --schemaprovider-class org.apache.hudi.utilities.schema.FilebasedSchemaProvider --disable-compaction</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># As part of the setup (Look at setup_demo.sh), the configs needed for DeltaStreamer is uploaded to HDFS. The configs</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># contain mostly Kafa connectivity settings, the avro-schema to be used for ingesting along with key and partitioning fields.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>你可以使用 HDFS 的 Web 浏览器来查看数据集
<code>http://namenode:50070/explorer#/user/hive/warehouse/stock_ticks_cow</code>.</p><p>你可以浏览在数据集中新创建的分区文件夹，同时还有一个在 .hoodie 目录下的 deltacommit 文件。</p><p>在 MOR 数据集中也有类似的设置
<code>http://namenode:50070/explorer#/user/hive/warehouse/stock_ticks_mor</code></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-3-与-hive-同步"></a>Step 3: 与 Hive 同步<a class="hash-link" href="#step-3-与-hive-同步" title="Direct link to heading">#</a></h3><p>到了这一步，数据集在 HDFS 中可用。我们需要与 Hive 同步来创建新 Hive 表并添加分区，以便在那些数据集上执行 Hive 查询。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># THis command takes in HIveServer URL and COW Hudi Dataset location in HDFS and sync the HDFS state to Hive</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">/var/hoodie/ws/hudi-sync/hudi-hive-sync/run_sync_tool.sh  --jdbc-url jdbc:hive2://hiveserver:10000 --user hive --pass hive --partitioned-by dt --base-path /user/hive/warehouse/stock_ticks_cow --database default --table stock_ticks_cow</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">.....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2018-09-24 22:22:45,568 INFO  [main] hive.HiveSyncTool (HiveSyncTool.java:syncHoodieTable(112)) - Sync complete for stock_ticks_cow</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">.....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Now run hive-sync for the second data-set in HDFS using Merge-On-Read (MOR storage)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">/var/hoodie/ws/hudi-sync/hudi-hive-sync/run_sync_tool.sh  --jdbc-url jdbc:hive2://hiveserver:10000 --user hive --pass hive --partitioned-by dt --base-path /user/hive/warehouse/stock_ticks_mor --database default --table stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2018-09-24 22:23:09,171 INFO  [main] hive.HiveSyncTool (HiveSyncTool.java:syncHoodieTable(112)) - Sync complete for stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2018-09-24 22:23:09,559 INFO  [main] hive.HiveSyncTool (HiveSyncTool.java:syncHoodieTable(112)) - Sync complete for stock_ticks_mor_rt</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>执行了以上命令后，你会发现：</p><ol><li>一个名为 <code>stock_ticks_cow</code> 的 Hive 表被创建，它为写时复制数据集提供了读优化视图。</li><li>两个新表 <code>stock_ticks_mor</code> 和 <code>stock_ticks_mor_rt</code> 被创建用于读时合并数据集。 前者为 Hudi 数据集提供了读优化视图，而后者为数据集提供了实时视图。</li></ol><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-4-a-运行-hive-查询"></a>Step 4 (a): 运行 Hive 查询<a class="hash-link" href="#step-4-a-运行-hive-查询" title="Direct link to heading">#</a></h3><p>执行一个 Hive 查询来为股票 GOOG 找到采集到的最新时间戳。你会注意到读优化视图（ COW 和 MOR 数据集都是如此）和实时视图（仅对 MOR 数据集）给出了相同的值 “10:29 a.m”，这是因为 Hudi 为每个批次的数据创建了一个 Parquet 文件。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beeline -u jdbc:hive2://hiveserver:10000 --hiveconf hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat --hiveconf hive.stats.autogather=false</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># List Tables</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; show tables;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|      tab_name       |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| stock_ticks_cow     |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| stock_ticks_mor     |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| stock_ticks_mor_rt  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2 rows selected (0.801 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Look at partitions that were added</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; show partitions stock_ticks_mor_rt;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|   partition    |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| dt=2018-08-31  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (0.24 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># COPY-ON-WRITE Queries:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">=========================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_cow group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:29:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Now, run a projection query:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924221953       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924221953       | GOOG    | 2018-08-31 10:29:00  | 3391    | 1230.1899  | 1230.085  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Merge-On-Read Queries:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">==========================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Lets run similar queries against M-O-R dataset. Lets look at both</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ReadOptimized and Realtime views supported by M-O-R dataset</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run against ReadOptimized View. Notice that the latest timestamp is 10:29</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:29:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (6.326 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run against Realtime View. Notice that the latest timestamp is again 10:29</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:29:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (1.606 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run projection query against Read Optimized and Realtime tables</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 10:29:00  | 3391    | 1230.1899  | 1230.085  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor_rt where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 10:29:00  | 3391    | 1230.1899  | 1230.085  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-4-b-执行-spark-sql-查询"></a>Step 4 (b): 执行 Spark-SQL 查询<a class="hash-link" href="#step-4-b-执行-spark-sql-查询" title="Direct link to heading">#</a></h3><p>Hudi 支持以 Spark 作为类似 Hive 的查询引擎。这是在 Spartk-SQL 中执行与 Hive 相同的查询</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-1 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$SPARK_INSTALL/bin/spark-shell --jars $HUDI_SPARK_BUNDLE --master local[2] --driver-class-path $HADOOP_CONF_DIR --conf spark.sql.hive.convertMetastoreParquet=false --deploy-mode client  --driver-memory 1G --executor-memory 3G --num-executors 1  --packages com.databricks:spark-avro_2.11:4.0.0</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Welcome to</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ____              __</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     / __/__  ___ _____/ /__</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   /___/ .__/\_,_/_/ /_/\_\   version 2.3.1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      /_/</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_181)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Type in expressions to have them evaluated.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Type :help for more information.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;show tables&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+------------------+-----------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|database|tableName         |isTemporary|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+------------------+-----------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|default |stock_ticks_cow   |false      |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|default |stock_ticks_mor   |false      |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|default |stock_ticks_mor_rt|false      |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+------------------+-----------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Copy-On-Write Table</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Run max timestamp query against COW table</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_cow group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[Stage 0:&gt;                                                          (0 + 1) / 1]SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SLF4J: Defaulting to no-operation (NOP) logger implementation</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SLF4J: See http://www.slf4j.org/codes#StaticLoggerBinder for further details.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|symbol|max(ts)            |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|GOOG  |2018-08-31 10:29:00|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Projection Query</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|_hoodie_commit_time|symbol|ts                 |volume|open     |close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|20180924221953     |GOOG  |2018-08-31 09:59:00|6330  |1230.5   |1230.02 |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|20180924221953     |GOOG  |2018-08-31 10:29:00|3391  |1230.1899|1230.085|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Merge-On-Read Queries:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">==========================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Lets run similar queries against M-O-R dataset. Lets look at both</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ReadOptimized and Realtime views supported by M-O-R dataset</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run against ReadOptimized View. Notice that the latest timestamp is 10:29</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|symbol|max(ts)            |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|GOOG  |2018-08-31 10:29:00|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run against Realtime View. Notice that the latest timestamp is again 10:29</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|symbol|max(ts)            |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|GOOG  |2018-08-31 10:29:00|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run projection query against Read Optimized and Realtime tables</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|_hoodie_commit_time|symbol|ts                 |volume|open     |close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|20180924222155     |GOOG  |2018-08-31 09:59:00|6330  |1230.5   |1230.02 |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|20180924222155     |GOOG  |2018-08-31 10:29:00|3391  |1230.1899|1230.085|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor_rt where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|_hoodie_commit_time|symbol|ts                 |volume|open     |close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|20180924222155     |GOOG  |2018-08-31 09:59:00|6330  |1230.5   |1230.02 |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|20180924222155     |GOOG  |2018-08-31 10:29:00|3391  |1230.1899|1230.085|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-------------------+------+-------------------+------+---------+--------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-4-c-执行-presto-查询"></a>Step 4 (c): 执行 Presto 查询<a class="hash-link" href="#step-4-c-执行-presto-查询" title="Direct link to heading">#</a></h3><p>这是 Presto 查询，它们与 Hive 和 Spark 的查询类似。目前 Hudi 的实时视图不支持 Presto 。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it presto-worker-1 presto --server presto-coordinator-1:8090</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto&gt; show catalogs;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  Catalog</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-----------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> hive</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> jmx</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> localfile</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> system</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(4 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190817_134851_00000_j8rcz, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 19 total, 19 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:04 [0 rows, 0B] [0 rows/s, 0B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto&gt; use hive.default;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">USE</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; show tables;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">       Table</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> stock_ticks_cow</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> stock_ticks_mor_rt</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(3 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181000_00001_segyw, FINISHED, 2 nodes</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 19 total, 19 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:05 [3 rows, 99B] [0 rows/s, 18B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># COPY-ON-WRITE Queries:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">=========================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; select symbol, max(ts) from stock_ticks_cow group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> symbol |        _col1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--------+---------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> GOOG   | 2018-08-31 10:29:00</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(1 row)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181011_00002_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 49 total, 49 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:12 [197 rows, 613B] [16 rows/s, 50B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; select &quot;_hoodie_commit_time&quot;, symbol, ts, volume, open, close from stock_ticks_cow where symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> _hoodie_commit_time | symbol |         ts          | volume |   open    |  close</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">---------------------+--------+---------------------+--------+-----------+----------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180221      | GOOG   | 2018-08-31 09:59:00 |   6330 |    1230.5 |  1230.02</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180221      | GOOG   | 2018-08-31 10:29:00 |   3391 | 1230.1899 | 1230.085</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(2 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181141_00003_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 17 total, 17 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:02 [197 rows, 613B] [109 rows/s, 341B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Merge-On-Read Queries:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">==========================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Lets run similar queries against M-O-R dataset. </span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run against ReadOptimized View. Notice that the latest timestamp is 10:29</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> symbol |        _col1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--------+---------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> GOOG   | 2018-08-31 10:29:00</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(1 row)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181158_00004_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 49 total, 49 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:02 [197 rows, 613B] [110 rows/s, 343B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt;  select &quot;_hoodie_commit_time&quot;, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> _hoodie_commit_time | symbol |         ts          | volume |   open    |  close</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">---------------------+--------+---------------------+--------+-----------+----------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180250      | GOOG   | 2018-08-31 09:59:00 |   6330 |    1230.5 |  1230.02</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180250      | GOOG   | 2018-08-31 10:29:00 |   3391 | 1230.1899 | 1230.085</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(2 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181256_00006_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 17 total, 17 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:02 [197 rows, 613B] [92 rows/s, 286B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-5-将第-2-批次上传到-kafka-并运行-deltastreamer-进行采集"></a>Step 5: 将第 2 批次上传到 Kafka 并运行 DeltaStreamer 进行采集<a class="hash-link" href="#step-5-将第-2-批次上传到-kafka-并运行-deltastreamer-进行采集" title="Direct link to heading">#</a></h3><p>上传第 2 批次数据，并使用 DeltaStreamer 采集。由于这个批次不会引入任何新分区，因此不需要执行 Hive 同步。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cat docker/demo/data/batch_2.json | kafkacat -b kafkabroker -t stock_ticks -P</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Within Docker container, run the ingestion command</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run the following spark-submit command to execute the delta-streamer and ingest to stock_ticks_cow dataset in HDFS</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark-submit --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer $HUDI_UTILITIES_BUNDLE --storage-type COPY_ON_WRITE --source-class org.apache.hudi.utilities.sources.JsonKafkaSource --source-ordering-field ts  --target-base-path /user/hive/warehouse/stock_ticks_cow --target-table stock_ticks_cow --props /var/demo/config/kafka-source.properties --schemaprovider-class org.apache.hudi.utilities.schema.FilebasedSchemaProvider</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Run the following spark-submit command to execute the delta-streamer and ingest to stock_ticks_mor dataset in HDFS</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark-submit --class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer $HUDI_UTILITIES_BUNDLE --storage-type MERGE_ON_READ --source-class org.apache.hudi.utilities.sources.JsonKafkaSource --source-ordering-field ts  --target-base-path /user/hive/warehouse/stock_ticks_mor --target-table stock_ticks_mor --props /var/demo/config/kafka-source.properties --schemaprovider-class org.apache.hudi.utilities.schema.FilebasedSchemaProvider --disable-compaction</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>使用写时复制表， DeltaStreamer 的第 2 批数据采集将导致 Parquet 文件创建一个新版本。
参考： <code>http://namenode:50070/explorer#/user/hive/warehouse/stock_ticks_cow/2018/08/31</code></p><p>使用读时合并表, 第 2 批数据采集仅仅将数据追加到没有合并的 delta （日志） 文件中。看一下 HDFS 文件系统来了解这一点： <code>http://namenode:50070/explorer#/user/hive/warehouse/stock_ticks_mor/2018/08/31</code></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-6-a-执行-hive-查询"></a>Step 6 (a): 执行 Hive 查询<a class="hash-link" href="#step-6-a-执行-hive-查询" title="Direct link to heading">#</a></h3><p>使用写时复制表，在每一个批次被提交采集并创建新版本的 Parquet 文件时，读优化视图会立即发现变更，这些变更被当第 2 批次的一部分。</p><p>使用读时合并表，第 2 批数据采集仅仅将数据追加到没有合并的 delta （日志） 文件中。
此时，读优化视图和实时视图将提供不同的结果。读优化视图仍会返回“10:29 am”，因为它会只会从 Parquet 文件中读取。实时视图会做即时合并并返回最新提交的数据，即“10:59 a.m”。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beeline -u jdbc:hive2://hiveserver:10000 --hiveconf hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat --hiveconf hive.stats.autogather=false</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Copy On Write Table:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_cow group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (1.932 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924221953       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924224524       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">As you can notice, the above queries now reflect the changes that came as part of ingesting second batch.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Merge On Read Table:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Read Optimized View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:29:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (1.6 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 10:29:00  | 3391    | 1230.1899  | 1230.085  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Realtime View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor_rt where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924224537       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-6-b-执行-spark-sql-查询"></a>Step 6 (b): 执行 Spark SQL 查询<a class="hash-link" href="#step-6-b-执行-spark-sql-查询" title="Direct link to heading">#</a></h3><p>以 Spark SQL 执行类似的查询：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-1 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">bash-4.4# $SPARK_INSTALL/bin/spark-shell --jars $HUDI_SPARK_BUNDLE --driver-class-path $HADOOP_CONF_DIR --conf spark.sql.hive.convertMetastoreParquet=false --deploy-mode client  --driver-memory 1G --master local[2] --executor-memory 3G --num-executors 1  --packages com.databricks:spark-avro_2.11:4.0.0</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Copy On Write Table:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_cow group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|symbol|max(ts)            |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|GOOG  |2018-08-31 10:59:00|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------+-------------------+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924221953       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924224524       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">As you can notice, the above queries now reflect the changes that came as part of ingesting second batch.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Merge On Read Table:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Read Optimized View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:29:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (1.6 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 10:29:00  | 3391    | 1230.1899  | 1230.085  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Realtime View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor_rt where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924222155       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924224537       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-6-c-执行-presto-查询"></a>Step 6 (c): 执行 Presto 查询<a class="hash-link" href="#step-6-c-执行-presto-查询" title="Direct link to heading">#</a></h3><p>在 Presto 中为读优化视图执行类似的查询：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it presto-worker-1 presto --server presto-coordinator-1:8090</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto&gt; use hive.default;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">USE</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Copy On Write Table:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt;select symbol, max(ts) from stock_ticks_cow group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> symbol |        _col1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--------+---------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> GOOG   | 2018-08-31 10:59:00</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(1 row)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181530_00007_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 49 total, 49 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:02 [197 rows, 613B] [125 rows/s, 389B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt;select &quot;_hoodie_commit_time&quot;, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> _hoodie_commit_time | symbol |         ts          | volume |   open    |  close</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">---------------------+--------+---------------------+--------+-----------+----------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180221      | GOOG   | 2018-08-31 09:59:00 |   6330 |    1230.5 |  1230.02</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822181433      | GOOG   | 2018-08-31 10:59:00 |   9021 | 1227.1993 | 1227.215</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(2 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181545_00008_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 17 total, 17 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:02 [197 rows, 613B] [106 rows/s, 332B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">As you can notice, the above queries now reflect the changes that came as part of ingesting second batch.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Merge On Read Table:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Read Optimized View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> symbol |        _col1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--------+---------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> GOOG   | 2018-08-31 10:29:00</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(1 row)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181602_00009_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 49 total, 49 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:01 [197 rows, 613B] [139 rows/s, 435B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt;select &quot;_hoodie_commit_time&quot;, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> _hoodie_commit_time | symbol |         ts          | volume |   open    |  close</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">---------------------+--------+---------------------+--------+-----------+----------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180250      | GOOG   | 2018-08-31 09:59:00 |   6330 |    1230.5 |  1230.02</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180250      | GOOG   | 2018-08-31 10:29:00 |   3391 | 1230.1899 | 1230.085</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(2 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_181615_00010_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 17 total, 17 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:01 [197 rows, 613B] [154 rows/s, 480B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-7--写时复制表的增量查询"></a>Step 7 : 写时复制表的增量查询<a class="hash-link" href="#step-7--写时复制表的增量查询" title="Direct link to heading">#</a></h3><p>使用采集的两个批次的数据，我们展示 Hudi 写时复制数据集中支持的增量查询。</p><p>我们使用类似的工程查询样例：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beeline -u jdbc:hive2://hiveserver:10000 --hiveconf hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat --hiveconf hive.stats.autogather=false</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924064621       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924065039       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>正如你在上面的查询中看到的，有两个提交——按时间线排列是 20180924064621 和 20180924065039 。
当你按照这些步骤执行后，你的提交会得到不同的时间戳。将它们替换到上面时间戳的位置。</p><p>为了展示增量查询的影响，我们假设有一位读者已经在第 1 批数据中一部分看到了变化。那么，为了让读者看到第 2 批数据的影响，他/她需要保留第 1 批次提交时间中的开始时间（ 20180924064621 ）并执行增量查询：</p><p>Hudi 的增量模式为增量查询提供了高效的扫描，通过 Hudi 管理的元数据，过滤掉了那些不包含候选记录的文件。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beeline -u jdbc:hive2://hiveserver:10000 --hiveconf hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat --hiveconf hive.stats.autogather=false</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; set hoodie.stock_ticks_cow.consume.mode=INCREMENTAL;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">No rows affected (0.009 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt;  set hoodie.stock_ticks_cow.consume.max.commits=3;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">No rows affected (0.009 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; set hoodie.stock_ticks_cow.consume.start.timestamp=20180924064621;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>使用上面的设置，那些在提交 20180924065039 之后没有任何更新的文件ID将被过滤掉，不进行扫描。
以下是增量查询：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow where  symbol = &#x27;GOOG&#x27; and `_hoodie_commit_time` &gt; &#x27;20180924064621&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924065039       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (0.83 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="使用-spark-sql-做增量查询"></a>使用 Spark SQL 做增量查询<a class="hash-link" href="#使用-spark-sql-做增量查询" title="Direct link to heading">#</a></h3><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-1 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">bash-4.4# $SPARK_INSTALL/bin/spark-shell --jars $HUDI_SPARK_BUNDLE --driver-class-path $HADOOP_CONF_DIR --conf spark.sql.hive.convertMetastoreParquet=false --deploy-mode client  --driver-memory 1G --master local[2] --executor-memory 3G --num-executors 1  --packages com.databricks:spark-avro_2.11:4.0.0</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Welcome to</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ____              __</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     / __/__  ___ _____/ /__</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   /___/ .__/\_,_/_/ /_/\_\   version 2.3.1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      /_/</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_181)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Type in expressions to have them evaluated.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Type :help for more information.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; import org.apache.hudi.DataSourceReadOptions</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import org.apache.hudi.DataSourceReadOptions</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># In the below query, 20180925045257 is the first commit&#x27;s timestamp</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; val hoodieIncViewDF =  spark.read.format(&quot;org.apache.hudi&quot;).option(DataSourceReadOptions.VIEW_TYPE_OPT_KEY, DataSourceReadOptions.VIEW_TYPE_INCREMENTAL_OPT_VAL).option(DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY, &quot;20180924064621&quot;).load(&quot;/user/hive/warehouse/stock_ticks_cow&quot;)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SLF4J: Defaulting to no-operation (NOP) logger implementation</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SLF4J: See http://www.slf4j.org/codes#StaticLoggerBinder for further details.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodieIncViewDF: org.apache.spark.sql.DataFrame = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 15 more fields]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; hoodieIncViewDF.registerTempTable(&quot;stock_ticks_cow_incr_tmp1&quot;)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">warning: there was one deprecation warning; re-run with -deprecation for details</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_cow_incr_tmp1 where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false);</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924065039       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-8-为读时合并数据集的调度并执行压缩"></a>Step 8: 为读时合并数据集的调度并执行压缩<a class="hash-link" href="#step-8-为读时合并数据集的调度并执行压缩" title="Direct link to heading">#</a></h3><p>我们来调度并运行一个压缩来创建一个新版本的列式文件，以便读优化读取器能看到新数据。
再次强调，你可以使用 Hudi CLI 来人工调度并执行压缩。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-1 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">root@adhoc-1:/opt#   /var/hoodie/ws/hudi-cli/hudi-cli.sh</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">============================================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*                                          *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*     _    _           _   _               *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*    | |  | |         | | (_)              *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*    | |__| |       __| |  -               *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*    |  __  ||   | / _` | ||               *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*    | |  | ||   || (_| | ||               *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*    |_|  |_|\___/ \____/ ||               *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">*                                          *</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">============================================</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Welcome to Hoodie CLI. Please type help if you are looking for help.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hudi-&gt;connect --path /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:59:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:59:35 INFO table.HoodieTableMetaClient: Loading HoodieTableMetaClient from /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:59:35 INFO util.FSUtils: Hadoop Configuration: fs.defaultFS: [hdfs://namenode:8020], Config:[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml], FileSystem: [DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1261652683_11, ugi=root (auth:SIMPLE)]]]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:59:35 INFO table.HoodieTableConfig: Loading dataset properties from /user/hive/warehouse/stock_ticks_mor/.hoodie/hoodie.properties</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:59:36 INFO table.HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ from /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Metadata for table stock_ticks_mor loaded</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Ensure no compactions are present</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks_mor-&gt;compactions show all</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:59:54 INFO timeline.HoodieActiveTimeline: Loaded instants [[20180924064636__clean__COMPLETED], [20180924064636__deltacommit__COMPLETED], [20180924065057__clean__COMPLETED], [20180924065057__deltacommit__COMPLETED]]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ___________________________________________________________________</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    | Compaction Instant Time| State    | Total FileIds to be Compacted|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    |==================================================================|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Schedule a compaction. This will use Spark Launcher to schedule compaction</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks_mor-&gt;compaction schedule</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Compaction successfully completed for 20180924070031</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Now refresh and check again. You will see that there is a new compaction requested</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks-&gt;connect --path /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:01:16 INFO table.HoodieTableMetaClient: Loading HoodieTableMetaClient from /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:01:16 INFO util.FSUtils: Hadoop Configuration: fs.defaultFS: [hdfs://namenode:8020], Config:[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml], FileSystem: [DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1261652683_11, ugi=root (auth:SIMPLE)]]]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:01:16 INFO table.HoodieTableConfig: Loading dataset properties from /user/hive/warehouse/stock_ticks_mor/.hoodie/hoodie.properties</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:01:16 INFO table.HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ from /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Metadata for table stock_ticks_mor loaded</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks_mor-&gt;compactions show all</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 06:34:12 INFO timeline.HoodieActiveTimeline: Loaded instants [[20180924041125__clean__COMPLETED], [20180924041125__deltacommit__COMPLETED], [20180924042735__clean__COMPLETED], [20180924042735__deltacommit__COMPLETED], [==&gt;20180924063245__compaction__REQUESTED]]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ___________________________________________________________________</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    | Compaction Instant Time| State    | Total FileIds to be Compacted|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    |==================================================================|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    | 20180924070031         | REQUESTED| 1                            |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Execute the compaction. The compaction instant value passed below must be the one displayed in the above &quot;compactions show all&quot; query</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks_mor-&gt;compaction run --compactionInstant  20180924070031 --parallelism 2 --sparkMemory 1G  --schemaFilePath /var/demo/config/schema.avsc --retry 1  </span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Compaction successfully completed for 20180924070031</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Now check if compaction is completed</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks_mor-&gt;connect --path /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:03:00 INFO table.HoodieTableMetaClient: Loading HoodieTableMetaClient from /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:03:00 INFO util.FSUtils: Hadoop Configuration: fs.defaultFS: [hdfs://namenode:8020], Config:[Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml], FileSystem: [DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1261652683_11, ugi=root (auth:SIMPLE)]]]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:03:00 INFO table.HoodieTableConfig: Loading dataset properties from /user/hive/warehouse/stock_ticks_mor/.hoodie/hoodie.properties</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:03:00 INFO table.HoodieTableMetaClient: Finished Loading Table of type MERGE_ON_READ from /user/hive/warehouse/stock_ticks_mor</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Metadata for table stock_ticks_mor loaded</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie:stock_ticks-&gt;compactions show all</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">18/09/24 07:03:15 INFO timeline.HoodieActiveTimeline: Loaded instants [[20180924064636__clean__COMPLETED], [20180924064636__deltacommit__COMPLETED], [20180924065057__clean__COMPLETED], [20180924065057__deltacommit__COMPLETED], [20180924070031__commit__COMPLETED]]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ___________________________________________________________________</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    | Compaction Instant Time| State    | Total FileIds to be Compacted|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    |==================================================================|</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    | 20180924070031         | COMPLETED| 1                            |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-9-执行包含增量查询的-hive-查询"></a>Step 9: 执行包含增量查询的 Hive 查询<a class="hash-link" href="#step-9-执行包含增量查询的-hive-查询" title="Direct link to heading">#</a></h3><p>你将看到读优化视图和实时视图都会展示最新提交的数据。
让我们也对 MOR 表执行增量查询。
通过查看下方的查询输出，能够明确 MOR 表的第一次提交时间是 20180924064636 而第二次提交时间是 20180924070031 。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-2 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beeline -u jdbc:hive2://hiveserver:10000 --hiveconf hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat --hiveconf hive.stats.autogather=false</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Read Optimized View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (1.6 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924064636       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924070031       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Realtime View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor_rt where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924064636       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924070031       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Incremental View:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; set hoodie.stock_ticks_mor.consume.mode=INCREMENTAL;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">No rows affected (0.008 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Max-Commits covers both second batch and compaction commit</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; set hoodie.stock_ticks_mor.consume.max.commits=3;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">No rows affected (0.007 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; set hoodie.stock_ticks_mor.consume.start.timestamp=20180924064636;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">No rows affected (0.013 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Query:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0: jdbc:hive2://hiveserver:10000&gt; select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27; and `_hoodie_commit_time` &gt; &#x27;20180924064636&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924070031       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exit</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-10-压缩后在-mor-的读优化视图与实时视图上使用-spark-sql"></a>Step 10: 压缩后在 MOR 的读优化视图与实时视图上使用 Spark-SQL<a class="hash-link" href="#step-10-压缩后在-mor-的读优化视图与实时视图上使用-spark-sql" title="Direct link to heading">#</a></h3><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it adhoc-1 /bin/bash</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">bash-4.4# $SPARK_INSTALL/bin/spark-shell --jars $HUDI_SPARK_BUNDLE --driver-class-path $HADOOP_CONF_DIR --conf spark.sql.hive.convertMetastoreParquet=false --deploy-mode client  --driver-memory 1G --master local[2] --executor-memory 3G --num-executors 1  --packages com.databricks:spark-avro_2.11:4.0.0</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Read Optimized View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1 row selected (1.6 seconds)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924064636       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924070031       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Realtime View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select symbol, max(ts) from stock_ticks_mor_rt group by symbol HAVING symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| symbol  |         _c1          |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| GOOG    | 2018-08-31 10:59:00  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+---------+----------------------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; spark.sql(&quot;select `_hoodie_commit_time`, symbol, ts, volume, open, close  from stock_ticks_mor_rt where  symbol = &#x27;GOOG&#x27;&quot;).show(100, false)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| _hoodie_commit_time  | symbol  |          ts          | volume  |    open    |   close   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924064636       | GOOG    | 2018-08-31 09:59:00  | 6330    | 1230.5     | 1230.02   |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 20180924070031       | GOOG    | 2018-08-31 10:59:00  | 9021    | 1227.1993  | 1227.215  |</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+----------------------+---------+----------------------+---------+------------+-----------+--+</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="step-11--压缩后在-mor-数据集的读优化视图上进行-presto-查询"></a>Step 11:  压缩后在 MOR 数据集的读优化视图上进行 Presto 查询<a class="hash-link" href="#step-11--压缩后在-mor-数据集的读优化视图上进行-presto-查询" title="Direct link to heading">#</a></h3><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker exec -it presto-worker-1 presto --server presto-coordinator-1:8090</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto&gt; use hive.default;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">USE</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Read Optimized View</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">resto:default&gt; select symbol, max(ts) from stock_ticks_mor group by symbol HAVING symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  symbol |        _col1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--------+---------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> GOOG   | 2018-08-31 10:59:00</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(1 row)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_182319_00011_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 49 total, 49 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:01 [197 rows, 613B] [133 rows/s, 414B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt; select &quot;_hoodie_commit_time&quot;, symbol, ts, volume, open, close  from stock_ticks_mor where  symbol = &#x27;GOOG&#x27;;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> _hoodie_commit_time | symbol |         ts          | volume |   open    |  close</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">---------------------+--------+---------------------+--------+-----------+----------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822180250      | GOOG   | 2018-08-31 09:59:00 |   6330 |    1230.5 |  1230.02</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> 20190822181944      | GOOG   | 2018-08-31 10:59:00 |   9021 | 1227.1993 | 1227.215</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(2 rows)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Query 20190822_182333_00012_segyw, FINISHED, 1 node</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Splits: 17 total, 17 done (100.00%)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">0:02 [197 rows, 613B] [98 rows/s, 307B/s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">presto:default&gt;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Demo 到此结束。</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="在本地-docker-环境中测试-hudi"></a>在本地 Docker 环境中测试 Hudi<a class="hash-link" href="#在本地-docker-环境中测试-hudi" title="Direct link to heading">#</a></h2><p>你可以组建一个包含 Hadoop 、 Hive 和 Spark 服务的 Hadoop Docker 环境，并支持 Hudi 。</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ mvn pre-integration-test -DskipTests</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>上面的命令为所有的服务构建了 Docker 镜像，它带有当前安装在 /var/hoodie/ws 的 Hudi 源，并使用一个部署文件引入了这些服务。我们当前在 Docker 镜像中使用 Hadoop （v2.8.4）、 Hive （v2.3.3）和 Spark （v2.3.1）。</p><p>要销毁容器：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ cd hudi-integ-test</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ mvn docker-compose:down</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>如果你想要组建 Docker 容器，使用：</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ cd hudi-integ-test</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">$  mvn docker-compose:up -DdetachedMode=true</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Hudi 是一个在包含 Hadoop 、 Hive 和 Spark 的海量数据分析/采集环境中使用的库。与这些系统的互用性是我们的一个关键目标。 我们在积极地向 <strong>hudi-integ-test/src/test/java</strong> 添加集成测试，这些测试利用了这个 Docker 环境（参考： <strong>hudi-integ-test/src/test/java/org/apache/hudi/integ/ITTestHoodieSanity.java</strong> ）。</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="构建本地-docker-容器"></a>构建本地 Docker 容器:<a class="hash-link" href="#构建本地-docker-容器" title="Direct link to heading">#</a></h3><p>Demo 和执行集成测试所需要的 Docker 镜像已经在 Docker 源中。 Docker 镜像和部署脚本经过了谨慎的实现以便服务与多种目的：</p><ol><li>Docker 镜像有内建的 Hudi jar 包，它包含一些指向其他 jar 包的环境变量（ HUDI_HADOOP_BUNDLE 等）</li><li>为了执行集成测试，我们需要使用本地生成的 jar 包在 Docker 中运行服务。 Docker 部署脚本（参考 <code>docker/compose/docker-compose_hadoop284_hive233_spark231.yml</code>）能确保本地 jar 包通过挂载 Docker 地址上挂载本地 Hudi 工作空间，从而覆盖了内建的 jar 包。</li><li>当这些 Docker 容器挂载到本地 Hudi 工作空间之后，任何发生在工作空间中的变更将会自动反映到容器中。这对于开发者来说是一种开发和验证 Hudi 的简便方法，这些开发者没有分布式的环境。要注意的是，这是集成测试的执行方式。</li></ol><p>这避免了维护分离的 Docker 镜像，也避免了本地构建 Docker 镜像的各个步骤的消耗。
但是如果用户想要在有更低网络带宽的地方测试 Hudi ，他们仍可以构建本地镜像。
在执行 <code>docker/setup_demo.sh</code> 之前执行脚本 <code>docker/build_local_docker_images.sh</code> 来构建本地 Docker 镜像。</p><p>以下是执行的命令:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly java"><pre tabindex="0" class="prism-code language-java codeBlock_23N8 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd docker</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">./build_local_docker_images.sh</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">.....</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] Reactor Summary:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hoodie ............................................. SUCCESS [  1.709 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-common ...................................... SUCCESS [  9.015 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-mr ................................... SUCCESS [  1.108 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-client ...................................... SUCCESS [  4.409 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hive ........................................ SUCCESS [  0.976 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-spark ....................................... SUCCESS [ 26.522 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-utilities ................................... SUCCESS [ 16.256 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-cli ......................................... SUCCESS [ 11.341 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-mr-bundle ............................ SUCCESS [  1.893 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hive-bundle ................................. SUCCESS [ 14.099 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-spark-bundle ................................ SUCCESS [ 58.252 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-docker ............................... SUCCESS [  0.612 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-base-docker .......................... SUCCESS [04:04 min]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-namenode-docker ...................... SUCCESS [  6.142 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-datanode-docker ...................... SUCCESS [  7.763 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-history-docker ....................... SUCCESS [  5.922 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-hive-docker .......................... SUCCESS [ 56.152 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-sparkbase-docker ..................... SUCCESS [01:18 min]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-sparkmaster-docker ................... SUCCESS [  2.964 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-sparkworker-docker ................... SUCCESS [  3.032 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-hadoop-sparkadhoc-docker .................... SUCCESS [  2.764 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] hudi-integ-test .................................. SUCCESS [  1.785 s]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] ------------------------------------------------------------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] BUILD SUCCESS</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] ------------------------------------------------------------------------</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] Total time: 09:15 min</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] Finished at: 2018-09-10T17:47:37-07:00</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] Final Memory: 236M/1848M</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] ------------------------------------------------------------------------</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></div><footer class="row docusaurus-mt-lg"><div class="col"><a href="https://github.com/apache/hudi/edit/asf-site/website/docs/docs/docker_demo.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_3DPF"></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/cn/docs/next/jfs_hoodie"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« JuiceFS</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/cn/docs/next/metrics"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Metrics »</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#一个使用-docker-容器的-demo" class="table-of-contents__link">一个使用 Docker 容器的 Demo</a><ul><li><a href="#前提条件" class="table-of-contents__link">前提条件</a></li></ul></li><li><a href="#设置-docker-集群" class="table-of-contents__link">设置 Docker 集群</a><ul><li><a href="#构建-hudi" class="table-of-contents__link">构建 Hudi</a></li><li><a href="#组建-demo-集群" class="table-of-contents__link">组建 Demo 集群</a></li></ul></li><li><a href="#demo" class="table-of-contents__link">Demo</a><ul><li><a href="#step-1--将第-1-批数据发布到-kafka" class="table-of-contents__link">Step 1 : 将第 1 批数据发布到 Kafka</a></li><li><a href="#step-2-从-kafka-topic-中增量采集数据" class="table-of-contents__link">Step 2: 从 Kafka Topic 中增量采集数据</a></li><li><a href="#step-3-与-hive-同步" class="table-of-contents__link">Step 3: 与 Hive 同步</a></li><li><a href="#step-4-a-运行-hive-查询" class="table-of-contents__link">Step 4 (a): 运行 Hive 查询</a></li><li><a href="#step-4-b-执行-spark-sql-查询" class="table-of-contents__link">Step 4 (b): 执行 Spark-SQL 查询</a></li><li><a href="#step-4-c-执行-presto-查询" class="table-of-contents__link">Step 4 (c): 执行 Presto 查询</a></li><li><a href="#step-5-将第-2-批次上传到-kafka-并运行-deltastreamer-进行采集" class="table-of-contents__link">Step 5: 将第 2 批次上传到 Kafka 并运行 DeltaStreamer 进行采集</a></li><li><a href="#step-6-a-执行-hive-查询" class="table-of-contents__link">Step 6 (a): 执行 Hive 查询</a></li><li><a href="#step-6-b-执行-spark-sql-查询" class="table-of-contents__link">Step 6 (b): 执行 Spark SQL 查询</a></li><li><a href="#step-6-c-执行-presto-查询" class="table-of-contents__link">Step 6 (c): 执行 Presto 查询</a></li><li><a href="#step-7--写时复制表的增量查询" class="table-of-contents__link">Step 7 : 写时复制表的增量查询</a></li><li><a href="#使用-spark-sql-做增量查询" class="table-of-contents__link">使用 Spark SQL 做增量查询</a></li><li><a href="#step-8-为读时合并数据集的调度并执行压缩" class="table-of-contents__link">Step 8: 为读时合并数据集的调度并执行压缩</a></li><li><a href="#step-9-执行包含增量查询的-hive-查询" class="table-of-contents__link">Step 9: 执行包含增量查询的 Hive 查询</a></li><li><a href="#step-10-压缩后在-mor-的读优化视图与实时视图上使用-spark-sql" class="table-of-contents__link">Step 10: 压缩后在 MOR 的读优化视图与实时视图上使用 Spark-SQL</a></li><li><a href="#step-11--压缩后在-mor-数据集的读优化视图上进行-presto-查询" class="table-of-contents__link">Step 11:  压缩后在 MOR 数据集的读优化视图上进行 Presto 查询</a></li></ul></li><li><a href="#在本地-docker-环境中测试-hudi" class="table-of-contents__link">在本地 Docker 环境中测试 Hudi</a><ul><li><a href="#构建本地-docker-容器" class="table-of-contents__link">构建本地 Docker 容器:</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/cn/blog/2021/07/21/streaming-data-lake-platform">Our Vision</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/concepts">Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/contribute/team">Team</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/releases/release-0.9.0">Releases</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/releases/download">Download</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/powered-by">Who&#x27;s Using</a></li></ul></div><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/cn/docs/quick-start-guide">Quick Start</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/docker_demo">Docker Demo</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/talks-articles">Talks &amp; Articles</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/learn/faq">FAQ</a></li><li class="footer__item"><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Technical Wiki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Hudi On Cloud</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/cn/docs/s3_hoodie">AWS</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/gcs_hoodie">Google Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/oss_hoodie">Alibaba Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/azure_hoodie">Microsoft Azure</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/cos_hoodie">Tencent Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/cn/docs/ibm_cos_hoodie">IBM Cloud</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/cn/contribute/get-involved">Get Involved</a></li><li class="footer__item"><a href="https://join.slack.com/t/apache-hudi/shared_invite/enQtODYyNDAxNzc5MTg2LTE5OTBlYmVhYjM0N2ZhOTJjOWM4YzBmMWU2MjZjMGE4NDc5ZDFiOGQ2N2VkYTVkNzU3ZDQ4OTI1NmFmYWQ0NzE" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="mailto:dev-subscribe@hudi.apache.org?Subject=SubscribeToHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">Mailing List</a></li></ul></div><div class="col footer__col"><div class="footer__title">Apache</div><ul class="footer__items"><li class="footer__item"><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="footer__link-item">Events</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Thanks</a></li><li class="footer__item"><a href="https://www.apache.org/licenses" target="_blank" rel="noopener noreferrer" class="footer__link-item">License</a></li><li class="footer__item"><a href="https://www.apache.org/security" target="_blank" rel="noopener noreferrer" class="footer__link-item">Security</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Sponsorship</a></li><li class="footer__item"><a href="https://www.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Foundation</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://hudi.apache.org/" target="_blank" rel="noopener noreferrer" class="footerLogoLink_MyFc"><img src="/cn/assets/images/logo-big.png" alt="Apache Hudi™" class="themedImage_1VuW themedImage--light_3UqQ footer__logo"><img src="/cn/assets/images/logo-big.png" alt="Apache Hudi™" class="themedImage_1VuW themedImage--dark_hz6m footer__logo"></a></div><div class="footer__copyright">Copyright © 2021 <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0"> Apache License, Version 2.0</a>.
      Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation. <a href="/docs/privacy">Privacy Policy</a></div></div></div></footer></div>
<script src="/cn/assets/js/runtime~main.62aa2619.js"></script>
<script src="/cn/assets/js/main.107e672b.js"></script>
</body>
</html>
<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>写入 Hudi 数据集 - Apache Hudi</title>
<meta name="description" content="这一节我们将介绍使用DeltaStreamer工具从外部源甚至其他Hudi数据集摄取新更改的方法，以及通过使用Hudi数据源的upserts加快大型Spark作业的方法。对于此类数据集，我们可以使用各种查询引擎查询它们。">

<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="">
<meta property="og:title" content="写入 Hudi 数据集">
<meta property="og:url" content="https://hudi.apache.org/cn/docs/0.5.0-writing_data.html">


  <meta property="og:description" content="这一节我们将介绍使用DeltaStreamer工具从外部源甚至其他Hudi数据集摄取新更改的方法，以及通过使用Hudi数据源的upserts加快大型Spark作业的方法。对于此类数据集，我们可以使用各种查询引擎查询它们。">





  <meta property="article:modified_time" content="2019-12-30T14:59:57-05:00">







<!-- end _includes/seo.html -->


<!--<link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">-->

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



<link rel="icon" type="image/x-icon" href="/assets/images/favicon.ico">
<link rel="stylesheet" href="/assets/css/font-awesome.min.css">

  </head>

  <body class="layout--single">
    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap" id="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/">
              <div style="width: 150px; height: 40px">
              </div>
          </a>
        
        <a class="site-title" href="/">
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/cn/docs/quick-start-guide.html" target="_self" >文档</a>
            </li><li class="masthead__menu-item">
              <a href="/cn/community.html" target="_self" >社区</a>
            </li><li class="masthead__menu-item">
              <a href="/cn/activity.html" target="_self" >动态</a>
            </li><li class="masthead__menu-item">
              <a href="https://cwiki.apache.org/confluence/display/HUDI/FAQ" target="_blank" >FAQ</a>
            </li><li class="masthead__menu-item">
              <a href="/cn/releases.html" target="_self" >发布</a>
            </li></ul>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>
<!--
<p class="notice--warning" style="margin: 0 !important; text-align: center !important;"><strong>Note:</strong> This site is work in progress, if you notice any issues, please <a target="_blank" href="https://github.com/apache/incubator-hudi/issues">Report on Issue</a>.
  Click <a href="/"> here</a> back to old site.</p>
-->

    <div class="initial-content">
      <div id="main" role="main">
  

  <div class="sidebar sticky">

  

  

    
      







<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">文档菜单</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">入门指南</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-quick-start-guide.html" class="">快速开始</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-use_cases.html" class="">使用案例</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-powered_by.html" class="">演讲 & hudi 用户</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-comparison.html" class="">对比</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-docker_demo.html" class="">Docker 示例</a></li>
            

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">帮助文档</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-concepts.html" class="">概念</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-writing_data.html" class="active">写入数据</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-querying_data.html" class="">查询数据</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-configurations.html" class="">配置</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-performance.html" class="">性能</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-admin_guide.html" class="">管理</a></li>
            

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">其他信息</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-docs-versions.html" class="">文档版本</a></li>
            

          
            
            

            
            

            
              <li><a href="/cn/docs/0.5.0-privacy.html" class="">版权信息</a></li>
            

          
        </ul>
        
      </li>
    
  </ul>
</nav>
    

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">写入 Hudi 数据集
</h1>
        </header>
      

      <section class="page__content" itemprop="text">
        
        <aside class="sidebar__right sticky">
          <nav class="toc">
            <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> IN THIS PAGE</h4></header>
            <ul class="toc__menu">
  <li><a href="#写操作">写操作</a></li>
  <li><a href="#deltastreamer">DeltaStreamer</a></li>
  <li><a href="#datasource-writer">Datasource Writer</a></li>
  <li><a href="#与hive同步">与Hive同步</a></li>
  <li><a href="#删除数据">删除数据</a></li>
  <li><a href="#存储管理">存储管理</a></li>
</ul>
          </nav>
        </aside>
        
        <p>这一节我们将介绍使用<a href="#deltastreamer">DeltaStreamer</a>工具从外部源甚至其他Hudi数据集摄取新更改的方法，
以及通过使用<a href="#datasource-writer">Hudi数据源</a>的upserts加快大型Spark作业的方法。
对于此类数据集，我们可以使用各种查询引擎<a href="/cn/docs/0.5.0-querying_data.html">查询</a>它们。</p>

<h2 id="写操作">写操作</h2>

<p>在此之前，了解Hudi数据源及delta streamer工具提供的三种不同的写操作以及如何最佳利用它们可能会有所帮助。
这些操作可以在针对数据集发出的每个提交/增量提交中进行选择/更改。</p>

<ul>
  <li><strong>UPSERT（插入更新）</strong> ：这是默认操作，在该操作中，通过查找索引，首先将输入记录标记为插入或更新。
 在运行启发式方法以确定如何最好地将这些记录放到存储上，如优化文件大小之类后，这些记录最终会被写入。
 对于诸如数据库更改捕获之类的用例，建议该操作，因为输入几乎肯定包含更新。</li>
  <li><strong>INSERT（插入）</strong> ：就使用启发式方法确定文件大小而言，此操作与插入更新（UPSERT）非常相似，但此操作完全跳过了索引查找步骤。
 因此，对于日志重复数据删除等用例（结合下面提到的过滤重复项的选项），它可以比插入更新快得多。
 插入也适用于这种用例，这种情况数据集可以允许重复项，但只需要Hudi的事务写/增量提取/存储管理功能。</li>
  <li><strong>BULK_INSERT（批插入）</strong> ：插入更新和插入操作都将输入记录保存在内存中，以加快存储优化启发式计算的速度（以及其它未提及的方面）。
 所以对Hudi数据集进行初始加载/引导时这两种操作会很低效。批量插入提供与插入相同的语义，但同时实现了基于排序的数据写入算法，
 该算法可以很好地扩展数百TB的初始负载。但是，相比于插入和插入更新能保证文件大小，批插入在调整文件大小上只能尽力而为。</li>
</ul>

<h2 id="deltastreamer">DeltaStreamer</h2>

<p><code class="highlighter-rouge">HoodieDeltaStreamer</code>实用工具 (hudi-utilities-bundle中的一部分) 提供了从DFS或Kafka等不同来源进行摄取的方式，并具有以下功能。</p>

<ul>
  <li>从Kafka单次摄取新事件，从Sqoop、HiveIncrementalPuller输出或DFS文件夹中的多个文件
 <a href="https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_incremental_imports">增量导入</a></li>
  <li>支持json、avro或自定义记录类型的传入数据</li>
  <li>管理检查点，回滚和恢复</li>
  <li>利用DFS或Confluent <a href="https://github.com/confluentinc/schema-registry">schema注册表</a>的Avro模式。</li>
  <li>支持自定义转换操作</li>
</ul>

<p>命令行选项更详细地描述了这些功能：</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">hoodie</span><span class="o">]</span><span class="err">$</span> <span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">HoodieDeltaStreamer</span> <span class="err">`</span><span class="n">ls</span> <span class="n">packaging</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">/</span><span class="n">target</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">-*.</span><span class="na">jar</span><span class="err">`</span> <span class="o">--</span><span class="n">help</span>
<span class="nl">Usage:</span> <span class="o">&lt;</span><span class="n">main</span> <span class="kd">class</span><span class="err">&gt;</span> <span class="err">[</span><span class="nc">options</span><span class="o">]</span>
  <span class="nl">Options:</span>
    <span class="o">--</span><span class="n">commit</span><span class="o">-</span><span class="n">on</span><span class="o">-</span><span class="n">errors</span>
        <span class="nc">Commit</span> <span class="n">even</span> <span class="n">when</span> <span class="n">some</span> <span class="n">records</span> <span class="n">failed</span> <span class="n">to</span> <span class="n">be</span> <span class="n">written</span>
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">enable</span><span class="o">-</span><span class="n">hive</span><span class="o">-</span><span class="n">sync</span>
          <span class="nc">Enable</span> <span class="n">syncing</span> <span class="n">to</span> <span class="n">hive</span>
       <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">filter</span><span class="o">-</span><span class="n">dupes</span>
          <span class="nc">Should</span> <span class="n">duplicate</span> <span class="n">records</span> <span class="n">from</span> <span class="n">source</span> <span class="n">be</span> <span class="n">dropped</span><span class="o">/</span><span class="n">filtered</span> <span class="n">outbefore</span> 
          <span class="n">insert</span><span class="o">/</span><span class="n">bulk</span><span class="o">-</span><span class="n">insert</span> 
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">help</span><span class="o">,</span> <span class="o">-</span><span class="n">h</span>
    <span class="o">--</span><span class="n">hudi</span><span class="o">-</span><span class="n">conf</span>
          <span class="nc">Any</span> <span class="n">configuration</span> <span class="n">that</span> <span class="n">can</span> <span class="n">be</span> <span class="n">set</span> <span class="n">in</span> <span class="n">the</span> <span class="n">properties</span> <span class="nf">file</span> <span class="o">(</span><span class="n">using</span> <span class="n">the</span> <span class="no">CLI</span> 
          <span class="n">parameter</span> <span class="s">"--propsFilePath"</span><span class="o">)</span> <span class="n">can</span> <span class="n">also</span> <span class="n">be</span> <span class="n">passed</span> <span class="n">command</span> <span class="n">line</span> <span class="n">using</span> <span class="k">this</span> 
          <span class="n">parameter</span> 
          <span class="nl">Default:</span> <span class="o">[]</span>
    <span class="o">--</span><span class="n">op</span>
      <span class="nc">Takes</span> <span class="n">one</span> <span class="n">of</span> <span class="n">these</span> <span class="n">values</span> <span class="o">:</span> <span class="no">UPSERT</span> <span class="o">(</span><span class="k">default</span><span class="o">),</span> <span class="no">INSERT</span> <span class="o">(</span><span class="n">use</span> <span class="n">when</span> <span class="n">input</span> <span class="n">is</span>
      <span class="n">purely</span> <span class="k">new</span> <span class="n">data</span><span class="o">/</span><span class="n">inserts</span> <span class="n">to</span> <span class="n">gain</span> <span class="n">speed</span><span class="o">)</span>
      <span class="nl">Default:</span> <span class="no">UPSERT</span>
      <span class="nc">Possible</span> <span class="nl">Values:</span> <span class="o">[</span><span class="no">UPSERT</span><span class="o">,</span> <span class="no">INSERT</span><span class="o">,</span> <span class="no">BULK_INSERT</span><span class="o">]</span>
    <span class="o">--</span><span class="n">payload</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">subclass</span> <span class="n">of</span> <span class="nc">HoodieRecordPayload</span><span class="o">,</span> <span class="n">that</span> <span class="n">works</span> <span class="n">off</span> <span class="n">a</span> <span class="nc">GenericRecord</span><span class="o">.</span>
      <span class="nc">Implement</span> <span class="n">your</span> <span class="n">own</span><span class="o">,</span> <span class="k">if</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="k">do</span> <span class="n">something</span> <span class="n">other</span> <span class="n">than</span> <span class="n">overwriting</span>
      <span class="n">existing</span> <span class="n">value</span>
      <span class="nl">Default:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">OverwriteWithLatestAvroPayload</span>
    <span class="o">--</span><span class="n">props</span>
      <span class="n">path</span> <span class="n">to</span> <span class="n">properties</span> <span class="n">file</span> <span class="n">on</span> <span class="n">localfs</span> <span class="n">or</span> <span class="n">dfs</span><span class="o">,</span> <span class="n">with</span> <span class="n">configurations</span> <span class="k">for</span>
      <span class="nc">Hudi</span> <span class="n">client</span><span class="o">,</span> <span class="n">schema</span> <span class="n">provider</span><span class="o">,</span> <span class="n">key</span> <span class="n">generator</span> <span class="n">and</span> <span class="n">data</span> <span class="n">source</span><span class="o">.</span> <span class="nc">For</span>
      <span class="nc">Hudi</span> <span class="n">client</span> <span class="n">props</span><span class="o">,</span> <span class="n">sane</span> <span class="n">defaults</span> <span class="n">are</span> <span class="n">used</span><span class="o">,</span> <span class="n">but</span> <span class="n">recommend</span> <span class="n">use</span> <span class="n">to</span>
      <span class="n">provide</span> <span class="n">basic</span> <span class="n">things</span> <span class="n">like</span> <span class="n">metrics</span> <span class="n">endpoints</span><span class="o">,</span> <span class="n">hive</span> <span class="n">configs</span> <span class="n">etc</span><span class="o">.</span> <span class="nc">For</span>
      <span class="n">sources</span><span class="o">,</span> <span class="n">referto</span> <span class="n">individual</span> <span class="n">classes</span><span class="o">,</span> <span class="k">for</span> <span class="n">supported</span> <span class="n">properties</span><span class="o">.</span>
      <span class="nl">Default:</span> <span class="nl">file:</span><span class="c1">///Users/vinoth/bin/hoodie/src/test/resources/delta-streamer-config/dfs-source.properties</span>
    <span class="o">--</span><span class="n">schemaprovider</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">subclass</span> <span class="n">of</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">SchemaProvider</span> <span class="n">to</span> <span class="n">attach</span>
      <span class="n">schemas</span> <span class="n">to</span> <span class="n">input</span> <span class="o">&amp;</span> <span class="n">target</span> <span class="n">table</span> <span class="n">data</span><span class="o">,</span> <span class="n">built</span> <span class="n">in</span> <span class="nl">options:</span>
      <span class="nc">FilebasedSchemaProvider</span>
      <span class="nl">Default:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">FilebasedSchemaProvider</span>
    <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">Subclass</span> <span class="n">of</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span> <span class="n">to</span> <span class="n">read</span> <span class="n">data</span><span class="o">.</span> <span class="nc">Built</span><span class="o">-</span><span class="n">in</span>
      <span class="nl">options:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.{</span><span class="nc">JsonDFSSource</span> <span class="o">(</span><span class="k">default</span><span class="o">),</span>
      <span class="nc">AvroDFSSource</span><span class="o">,</span> <span class="nc">JsonKafkaSource</span><span class="o">,</span> <span class="nc">AvroKafkaSource</span><span class="o">,</span> <span class="nc">HiveIncrPullSource</span><span class="o">}</span>
      <span class="nl">Default:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.</span><span class="na">JsonDFSSource</span>
    <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">limit</span>
      <span class="nc">Maximum</span> <span class="n">amount</span> <span class="n">of</span> <span class="n">data</span> <span class="n">to</span> <span class="n">read</span> <span class="n">from</span> <span class="n">source</span><span class="o">.</span> <span class="nl">Default:</span> <span class="nc">No</span> <span class="n">limit</span> <span class="nc">For</span> <span class="n">e</span><span class="o">.</span><span class="na">g</span><span class="o">:</span>
      <span class="nc">DFSSource</span> <span class="o">=&gt;</span> <span class="n">max</span> <span class="n">bytes</span> <span class="n">to</span> <span class="n">read</span><span class="o">,</span> <span class="nc">KafkaSource</span> <span class="o">=&gt;</span> <span class="n">max</span> <span class="n">events</span> <span class="n">to</span> <span class="n">read</span>
      <span class="nl">Default:</span> <span class="mi">9223372036854775807</span>
    <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">ordering</span><span class="o">-</span><span class="n">field</span>
      <span class="nc">Field</span> <span class="n">within</span> <span class="n">source</span> <span class="n">record</span> <span class="n">to</span> <span class="n">decide</span> <span class="n">how</span> <span class="n">to</span> <span class="k">break</span> <span class="n">ties</span> <span class="n">between</span> <span class="n">records</span>
      <span class="n">with</span> <span class="n">same</span> <span class="n">key</span> <span class="n">in</span> <span class="n">input</span> <span class="n">data</span><span class="o">.</span> <span class="nl">Default:</span> <span class="err">'</span><span class="n">ts</span><span class="err">'</span> <span class="n">holding</span> <span class="n">unix</span> <span class="n">timestamp</span> <span class="n">of</span>
      <span class="n">record</span>
      <span class="nl">Default:</span> <span class="n">ts</span>
    <span class="o">--</span><span class="n">spark</span><span class="o">-</span><span class="n">master</span>
      <span class="n">spark</span> <span class="n">master</span> <span class="n">to</span> <span class="n">use</span><span class="o">.</span>
      <span class="nl">Default:</span> <span class="n">local</span><span class="o">[</span><span class="mi">2</span><span class="o">]</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">path</span>
      <span class="n">base</span> <span class="n">path</span> <span class="k">for</span> <span class="n">the</span> <span class="n">target</span> <span class="nc">Hudi</span> <span class="n">dataset</span><span class="o">.</span> <span class="o">(</span><span class="nc">Will</span> <span class="n">be</span> <span class="n">created</span> <span class="k">if</span> <span class="n">did</span> <span class="n">not</span>
      <span class="n">exist</span> <span class="n">first</span> <span class="n">time</span> <span class="n">around</span><span class="o">.</span> <span class="nc">If</span> <span class="n">exists</span><span class="o">,</span> <span class="n">expected</span> <span class="n">to</span> <span class="n">be</span> <span class="n">a</span> <span class="nc">Hudi</span> <span class="n">dataset</span><span class="o">)</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">table</span>
      <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">target</span> <span class="n">table</span> <span class="n">in</span> <span class="nc">Hive</span>
    <span class="o">--</span><span class="n">transformer</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">subclass</span> <span class="n">of</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">transform</span><span class="o">.</span><span class="na">Transformer</span><span class="o">.</span> <span class="no">UDF</span> <span class="n">to</span>
      <span class="n">transform</span> <span class="n">raw</span> <span class="n">source</span> <span class="n">dataset</span> <span class="n">to</span> <span class="n">a</span> <span class="n">target</span> <span class="nf">dataset</span> <span class="o">(</span><span class="n">conforming</span> <span class="n">to</span> <span class="n">target</span>
      <span class="n">schema</span><span class="o">)</span> <span class="n">before</span> <span class="n">writing</span><span class="o">.</span> <span class="nc">Default</span> <span class="o">:</span> <span class="nc">Not</span> <span class="n">set</span><span class="o">.</span> <span class="nl">E:</span><span class="n">g</span> <span class="o">-</span>
      <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">transform</span><span class="o">.</span><span class="na">SqlQueryBasedTransformer</span> <span class="o">(</span><span class="n">which</span>
      <span class="n">allows</span> <span class="n">a</span> <span class="no">SQL</span> <span class="n">query</span> <span class="n">template</span> <span class="n">to</span> <span class="n">be</span> <span class="n">passed</span> <span class="n">as</span> <span class="n">a</span> <span class="n">transformation</span> <span class="n">function</span><span class="o">)</span>
</code></pre></div></div>

<p>该工具采用层次结构组成的属性文件，并具有可插拔的接口，用于提取数据、生成密钥和提供模式。
从Kafka和DFS摄取数据的示例配置在这里：<code class="highlighter-rouge">hudi-utilities/src/test/resources/delta-streamer-config</code>。</p>

<p>例如：当您让Confluent Kafka、Schema注册表启动并运行后，可以用这个命令产生一些测试数据
（<a href="https://docs.confluent.io/current/ksql/docs/tutorials/generate-custom-test-data.html">impressions.avro</a>，
由schema-registry代码库提供）</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">confluent</span><span class="o">-</span><span class="mf">5.0</span><span class="o">.</span><span class="mi">0</span><span class="o">]</span><span class="err">$</span> <span class="n">bin</span><span class="o">/</span><span class="n">ksql</span><span class="o">-</span><span class="n">datagen</span> <span class="n">schema</span><span class="o">=../</span><span class="n">impressions</span><span class="o">.</span><span class="na">avro</span> <span class="n">format</span><span class="o">=</span><span class="n">avro</span> <span class="n">topic</span><span class="o">=</span><span class="n">impressions</span> <span class="n">key</span><span class="o">=</span><span class="n">impressionid</span>
</code></pre></div></div>

<p>然后用如下命令摄取这些数据。</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">hoodie</span><span class="o">]</span><span class="err">$</span> <span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">HoodieDeltaStreamer</span> <span class="err">`</span><span class="n">ls</span> <span class="n">packaging</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">/</span><span class="n">target</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">-*.</span><span class="na">jar</span><span class="err">`</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">props</span> <span class="nl">file:</span><span class="c1">//${PWD}/hudi-utilities/src/test/resources/delta-streamer-config/kafka-source.properties \</span>
  <span class="o">--</span><span class="n">schemaprovider</span><span class="o">-</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">SchemaRegistryProvider</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.</span><span class="na">AvroKafkaSource</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">ordering</span><span class="o">-</span><span class="n">field</span> <span class="n">impresssiontime</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">path</span> <span class="nl">file:</span><span class="c1">///tmp/hudi-deltastreamer-op --target-table uber.impressions \</span>
  <span class="o">--</span><span class="n">op</span> <span class="no">BULK_INSERT</span>
</code></pre></div></div>

<p>在某些情况下，您可能需要预先将现有数据集迁移到Hudi。 请参考<a href="/cn/docs/0.5.0-migration_guide.html">迁移指南</a>。</p>

<h2 id="datasource-writer">Datasource Writer</h2>

<p><code class="highlighter-rouge">hudi-spark</code>模块提供了DataSource API，可以将任何DataFrame写入（也可以读取）到Hudi数据集中。
以下是在指定需要使用的字段名称的之后，如何插入更新DataFrame的方法，这些字段包括
<code class="highlighter-rouge">recordKey =&gt; _row_key</code>、<code class="highlighter-rouge">partitionPath =&gt; partition</code>和<code class="highlighter-rouge">precombineKey =&gt; timestamp</code></p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputDF</span><span class="o">.</span><span class="na">write</span><span class="o">()</span>
       <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"org.apache.hudi"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">options</span><span class="o">(</span><span class="n">clientOpts</span><span class="o">)</span> <span class="c1">// 可以传入任何Hudi客户端参数</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">RECORDKEY_FIELD_OPT_KEY</span><span class="o">(),</span> <span class="s">"_row_key"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">PARTITIONPATH_FIELD_OPT_KEY</span><span class="o">(),</span> <span class="s">"partition"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">PRECOMBINE_FIELD_OPT_KEY</span><span class="o">(),</span> <span class="s">"timestamp"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">HoodieWriteConfig</span><span class="o">.</span><span class="na">TABLE_NAME</span><span class="o">,</span> <span class="n">tableName</span><span class="o">)</span>
       <span class="o">.</span><span class="na">mode</span><span class="o">(</span><span class="nc">SaveMode</span><span class="o">.</span><span class="na">Append</span><span class="o">)</span>
       <span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">basePath</span><span class="o">);</span>
</code></pre></div></div>

<h2 id="与hive同步">与Hive同步</h2>

<p>上面的两个工具都支持将数据集的最新模式同步到Hive Metastore，以便查询新的列和分区。
如果需要从命令行或在独立的JVM中运行它，Hudi提供了一个<code class="highlighter-rouge">HiveSyncTool</code>，
在构建了hudi-hive模块之后，可以按以下方式调用它。</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cd</span> <span class="n">hudi</span><span class="o">-</span><span class="n">hive</span>
<span class="o">./</span><span class="n">run_sync_tool</span><span class="o">.</span><span class="na">sh</span>
 <span class="o">[</span><span class="n">hudi</span><span class="o">-</span><span class="n">hive</span><span class="o">]</span><span class="err">$</span> <span class="o">./</span><span class="n">run_sync_tool</span><span class="o">.</span><span class="na">sh</span> <span class="o">--</span><span class="n">help</span>
<span class="nl">Usage:</span> <span class="o">&lt;</span><span class="n">main</span> <span class="kd">class</span><span class="err">&gt;</span> <span class="err">[</span><span class="nc">options</span><span class="o">]</span>
  <span class="nl">Options:</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">base</span><span class="o">-</span><span class="n">path</span>
       <span class="nc">Basepath</span> <span class="n">of</span> <span class="nc">Hudi</span> <span class="n">dataset</span> <span class="n">to</span> <span class="n">sync</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">database</span>
       <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">target</span> <span class="n">database</span> <span class="n">in</span> <span class="nc">Hive</span>
    <span class="o">--</span><span class="n">help</span><span class="o">,</span> <span class="o">-</span><span class="n">h</span>
       <span class="nl">Default:</span> <span class="kc">false</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">jdbc</span><span class="o">-</span><span class="n">url</span>
       <span class="nc">Hive</span> <span class="n">jdbc</span> <span class="n">connect</span> <span class="n">url</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">pass</span>
       <span class="nc">Hive</span> <span class="n">password</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">table</span>
       <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">target</span> <span class="n">table</span> <span class="n">in</span> <span class="nc">Hive</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">user</span>
       <span class="nc">Hive</span> <span class="n">username</span>
</code></pre></div></div>

<h2 id="删除数据">删除数据</h2>

<p>通过允许用户指定不同的数据记录负载实现，Hudi支持对存储在Hudi数据集中的数据执行两种类型的删除。</p>

<ul>
  <li><strong>Soft Deletes（软删除）</strong> ：使用软删除时，用户希望保留键，但仅使所有其他字段的值都为空。
 通过确保适当的字段在数据集模式中可以为空，并在将这些字段设置为null之后直接向数据集插入更新这些记录，即可轻松实现这一点。</li>
  <li><strong>Hard Deletes（硬删除）</strong> ：这种更强形式的删除是从数据集中彻底删除记录在存储上的任何痕迹。 
 这可以通过触发一个带有自定义负载实现的插入更新来实现，这种实现可以使用总是返回Optional.Empty作为组合值的DataSource或DeltaStreamer。 
 Hudi附带了一个内置的<code class="highlighter-rouge">org.apache.hudi.EmptyHoodieRecordPayload</code>类，它就是实现了这一功能。</li>
</ul>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">deleteDF</span> <span class="c1">// 仅包含要删除的记录的DataFrame</span>
   <span class="o">.</span><span class="na">write</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">"org.apache.hudi"</span><span class="o">)</span>
   <span class="o">.</span><span class="na">option</span><span class="o">(...)</span> <span class="c1">// 根据设置需要添加HUDI参数，例如记录键、分区路径和其他参数</span>
   <span class="c1">// 指定record_key，partition_key，precombine_fieldkey和常规参数</span>
   <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">PAYLOAD_CLASS_OPT_KEY</span><span class="o">,</span> <span class="s">"org.apache.hudi.EmptyHoodieRecordPayload"</span><span class="o">)</span>
 
</code></pre></div></div>

<h2 id="存储管理">存储管理</h2>

<p>Hudi还对存储在Hudi数据集中的数据执行几个关键的存储管理功能。在DFS上存储数据的关键方面是管理文件大小和数量以及回收存储空间。 
例如，HDFS在处理小文件上性能很差，这会对Name Node的内存及RPC施加很大的压力，并可能破坏整个集群的稳定性。
通常，查询引擎可在较大的列文件上提供更好的性能，因为它们可以有效地摊销获得列统计信息等的成本。
即使在某些云数据存储上，列出具有大量小文件的目录也常常比较慢。</p>

<p>以下是一些有效管理Hudi数据集存储的方法。</p>

<ul>
  <li>Hudi中的<a href="/cn/docs/0.5.0-configurations.html#compactionSmallFileSize">小文件处理功能</a>，可以分析传入的工作负载并将插入内容分配到现有文件组中，
 而不是创建新文件组。新文件组会生成小文件。</li>
  <li>可以<a href="/cn/docs/0.5.0-configurations.html#retainCommits">配置</a>Cleaner来清理较旧的文件片，清理的程度可以调整，
 具体取决于查询所需的最长时间和增量拉取所需的回溯。</li>
  <li>用户还可以调整<a href="/cn/docs/0.5.0-configurations.html#limitFileSize">基础/parquet文件</a>、<a href="/cn/docs/0.5.0-configurations.html#logFileMaxSize">日志文件</a>的大小
 和预期的<a href="/cn/docs/0.5.0-configurations.html#parquetCompressionRatio">压缩率</a>，使足够数量的插入被分到同一个文件组中，最终产生大小合适的基础文件。</li>
  <li>智能调整<a href="/cn/docs/0.5.0-configurations.html#withBulkInsertParallelism">批插入并行度</a>，可以产生大小合适的初始文件组。
 实际上，正确执行此操作非常关键，因为文件组一旦创建后就不能删除，只能如前所述对其进行扩展。</li>
  <li>对于具有大量更新的工作负载，<a href="/cn/docs/0.5.0-concepts.html#merge-on-read-storage">读取时合并存储</a>提供了一种很好的机制，
 可以快速将其摄取到较小的文件中，之后通过压缩将它们合并为较大的基础文件。</li>
</ul>

      </section>

      <a href="#masthead__inner-wrap" class="back-to-top">Back to top &uarr;</a>


      

    </div>

  </article>

</div>

    </div>

    <div class="page__footer">
      <footer>
        
<div class="row">
  <div class="col-lg-12 footer">
    <p>
      <a class="footer-link-img" href="https://apache.org">
        <img width="250px" src="/assets/images/asf_logo.svg" alt="The Apache Software Foundation">
      </a>
    </p>
    <p>
      Copyright &copy; <span id="copyright-year">2019</span> <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the Apache License, Version 2.0.
      Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation. <a href="/docs/privacy">Privacy Policy</a>
      <br>
      Apache Hudi is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the <a href="http://incubator.apache.org/">Apache Incubator</a>.
      Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have
      stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a
      reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
    </p>
  </div>
</div>
      </footer>
    </div>

    
<script src="/assets/js/main.min.js"></script>


  </body>
</html>
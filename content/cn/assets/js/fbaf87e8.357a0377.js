"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[52050],{56785:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"0.15.0","label":"0.15.0","banner":"unmaintained","badge":true,"noIndex":false,"className":"docs-version-0.15.0","isLast":false,"docsSidebars":{"docs":[{"type":"category","label":"Getting Started","collapsed":false,"items":[{"type":"link","label":"Overview","href":"/cn/docs/0.15.0/overview","docId":"overview","unlisted":false},{"type":"link","label":"Spark Quick Start","href":"/cn/docs/0.15.0/quick-start-guide","docId":"quick-start-guide","unlisted":false},{"type":"link","label":"Flink Quick Start","href":"/cn/docs/0.15.0/flink-quick-start-guide","docId":"flink-quick-start-guide","unlisted":false},{"type":"link","label":"Python/Rust Quick Start (Hudi-rs)","href":"/cn/docs/0.15.0/python-rust-quick-start-guide","docId":"python-rust-quick-start-guide","unlisted":false},{"type":"link","label":"Docker Demo","href":"/cn/docs/0.15.0/docker_demo","docId":"docker_demo","unlisted":false},{"type":"link","label":"Use Cases","href":"/cn/docs/0.15.0/use_cases","docId":"use_cases","unlisted":false}],"collapsible":true},{"type":"category","label":"Design & Concepts","items":[{"type":"link","label":"Apache Hudi Stack","href":"/cn/docs/0.15.0/hudi_stack","docId":"hudi_stack","unlisted":false},{"type":"link","label":"Timeline","href":"/cn/docs/0.15.0/timeline","docId":"timeline","unlisted":false},{"type":"link","label":"File Layouts","href":"/cn/docs/0.15.0/file_layouts","docId":"file_layouts","unlisted":false},{"type":"link","label":"Table & Query Types","href":"/cn/docs/0.15.0/table_types","docId":"table_types","unlisted":false},{"type":"link","label":"Indexing","href":"/cn/docs/0.15.0/indexing","docId":"indexing","unlisted":false},{"type":"link","label":"Write Operations","href":"/cn/docs/0.15.0/write_operations","docId":"write_operations","unlisted":false},{"type":"link","label":"Key Generation","href":"/cn/docs/0.15.0/key_generation","docId":"key_generation","unlisted":false},{"type":"link","label":"Record Payload","href":"/cn/docs/0.15.0/record_payload","docId":"record_payload","unlisted":false},{"type":"link","label":"Schema Evolution","href":"/cn/docs/0.15.0/schema_evolution","docId":"schema_evolution","unlisted":false},{"type":"link","label":"Metadata Table","href":"/cn/docs/0.15.0/metadata","docId":"metadata","unlisted":false},{"type":"link","label":"Concurrency Control","href":"/cn/docs/0.15.0/concurrency_control","docId":"concurrency_control","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Ingestion","items":[{"type":"link","label":"Using Spark","href":"/cn/docs/0.15.0/hoodie_streaming_ingestion","docId":"hoodie_streaming_ingestion","unlisted":false},{"type":"link","label":"Using Flink","href":"/cn/docs/0.15.0/ingestion_flink","docId":"ingestion_flink","unlisted":false},{"type":"link","label":"Using Kafka Connect","href":"/cn/docs/0.15.0/ingestion_kafka_connect","docId":"ingestion_kafka_connect","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Writing Tables","items":[{"type":"link","label":"SQL DDL","href":"/cn/docs/0.15.0/sql_ddl","docId":"sql_ddl","unlisted":false},{"type":"link","label":"SQL DML","href":"/cn/docs/0.15.0/sql_dml","docId":"sql_dml","unlisted":false},{"type":"link","label":"Batch Writes","href":"/cn/docs/0.15.0/writing_data","docId":"writing_data","unlisted":false},{"type":"link","label":"Streaming Writes","href":"/cn/docs/0.15.0/writing_tables_streaming_writes","docId":"writing_tables_streaming_writes","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Reading Tables","items":[{"type":"link","label":"SQL Queries","href":"/cn/docs/0.15.0/sql_queries","docId":"sql_queries","unlisted":false},{"type":"link","label":"Batch Reads","href":"/cn/docs/0.15.0/reading_tables_batch_reads","docId":"reading_tables_batch_reads","unlisted":false},{"type":"link","label":"Streaming Reads","href":"/cn/docs/0.15.0/reading_tables_streaming_reads","docId":"reading_tables_streaming_reads","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Table Services","items":[{"type":"link","label":"Bootstrapping","href":"/cn/docs/0.15.0/migration_guide","docId":"migration_guide","unlisted":false},{"type":"link","label":"Compaction","href":"/cn/docs/0.15.0/compaction","docId":"compaction","unlisted":false},{"type":"link","label":"Clustering","href":"/cn/docs/0.15.0/clustering","docId":"clustering","unlisted":false},{"type":"link","label":"Metadata Indexing","href":"/cn/docs/0.15.0/metadata_indexing","docId":"metadata_indexing","unlisted":false},{"type":"link","label":"Cleaning","href":"/cn/docs/0.15.0/hoodie_cleaner","docId":"hoodie_cleaner","unlisted":false},{"type":"link","label":"Rollback Mechanism","href":"/cn/docs/0.15.0/rollbacks","docId":"rollbacks","unlisted":false},{"type":"link","label":"Marker Mechanism","href":"/cn/docs/0.15.0/markers","docId":"markers","unlisted":false},{"type":"link","label":"File Sizing","href":"/cn/docs/0.15.0/file_sizing","docId":"file_sizing","unlisted":false},{"type":"link","label":"Disaster Recovery","href":"/cn/docs/0.15.0/disaster_recovery","docId":"disaster_recovery","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Platform Services","items":[{"type":"link","label":"Exporter","href":"/cn/docs/0.15.0/snapshot_exporter","docId":"snapshot_exporter","unlisted":false},{"type":"link","label":"Data Quality","href":"/cn/docs/0.15.0/precommit_validator","docId":"precommit_validator","unlisted":false},{"type":"link","label":"Post-commit Callback","href":"/cn/docs/0.15.0/platform_services_post_commit_callback","docId":"platform_services_post_commit_callback","unlisted":false},{"type":"category","label":"Syncing to Catalogs","items":[{"type":"link","label":"AWS Glue Data Catalog","href":"/cn/docs/0.15.0/syncing_aws_glue_data_catalog","docId":"syncing_aws_glue_data_catalog","unlisted":false},{"type":"link","label":"DataHub","href":"/cn/docs/0.15.0/syncing_datahub","docId":"syncing_datahub","unlisted":false},{"type":"link","label":"Hive Metastore","href":"/cn/docs/0.15.0/syncing_metastore","docId":"syncing_metastore","unlisted":false},{"type":"link","label":"Google BigQuery","href":"/cn/docs/0.15.0/gcp_bigquery","docId":"gcp_bigquery","unlisted":false},{"type":"link","label":"Apache XTable (incubating)","href":"/cn/docs/0.15.0/syncing_xtable","docId":"syncing_xtable","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Operations","items":[{"type":"link","label":"Performance","href":"/cn/docs/0.15.0/performance","docId":"performance","unlisted":false},{"type":"link","label":"Deployment","href":"/cn/docs/0.15.0/deployment","docId":"deployment","unlisted":false},{"type":"link","label":"SQL Procedures","href":"/cn/docs/0.15.0/procedures","docId":"procedures","unlisted":false},{"type":"link","label":"CLI","href":"/cn/docs/0.15.0/cli","docId":"cli","unlisted":false},{"type":"link","label":"Metrics","href":"/cn/docs/0.15.0/metrics","docId":"metrics","unlisted":false},{"type":"link","label":"Encryption","href":"/cn/docs/0.15.0/encryption","docId":"encryption","unlisted":false},{"type":"link","label":"Troubleshooting","href":"/cn/docs/0.15.0/troubleshooting","docId":"troubleshooting","unlisted":false},{"type":"link","label":"Spark Tuning Guide","href":"/cn/docs/0.15.0/tuning-guide","docId":"tuning-guide","unlisted":false},{"type":"link","label":"Flink Tuning Guide","href":"/cn/docs/0.15.0/flink_tuning","docId":"flink_tuning","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Configurations","items":[{"type":"link","label":"Basic Configurations","href":"/cn/docs/0.15.0/basic_configurations","docId":"basic_configurations","unlisted":false},{"type":"link","label":"All Configurations","href":"/cn/docs/0.15.0/configurations","docId":"configurations","unlisted":false},{"type":"category","label":"Storage Configurations","items":[{"type":"link","label":"Cloud Storage","href":"/cn/docs/0.15.0/cloud","docId":"cloud","unlisted":false},{"type":"link","label":"AWS S3","href":"/cn/docs/0.15.0/s3_hoodie","docId":"s3_hoodie","unlisted":false},{"type":"link","label":"Google Cloud","href":"/cn/docs/0.15.0/gcs_hoodie","docId":"gcs_hoodie","unlisted":false},{"type":"link","label":"Alibaba Cloud","href":"/cn/docs/0.15.0/oss_hoodie","docId":"oss_hoodie","unlisted":false},{"type":"link","label":"Microsoft Azure","href":"/cn/docs/0.15.0/azure_hoodie","docId":"azure_hoodie","unlisted":false},{"type":"link","label":"Tencent Cloud","href":"/cn/docs/0.15.0/cos_hoodie","docId":"cos_hoodie","unlisted":false},{"type":"link","label":"IBM Cloud","href":"/cn/docs/0.15.0/ibm_cos_hoodie","docId":"ibm_cos_hoodie","unlisted":false},{"type":"link","label":"Baidu Cloud","href":"/cn/docs/0.15.0/bos_hoodie","docId":"bos_hoodie","unlisted":false},{"type":"link","label":"JuiceFS","href":"/cn/docs/0.15.0/jfs_hoodie","docId":"jfs_hoodie","unlisted":false},{"type":"link","label":"Oracle Cloud Infrastructure","href":"/cn/docs/0.15.0/oci_hoodie","docId":"oci_hoodie","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Frequently Asked Questions(FAQs)","items":[{"type":"link","label":"Overview","href":"/cn/docs/0.15.0/faq","docId":"faq","unlisted":false},{"type":"link","label":"General","href":"/cn/docs/0.15.0/faq_general","docId":"faq_general","unlisted":false},{"type":"link","label":"Design & Concepts","href":"/cn/docs/0.15.0/faq_design_and_concepts","docId":"faq_design_and_concepts","unlisted":false},{"type":"link","label":"Writing Tables","href":"/cn/docs/0.15.0/faq_writing_tables","docId":"faq_writing_tables","unlisted":false},{"type":"link","label":"Reading Tables","href":"/cn/docs/0.15.0/faq_reading_tables","docId":"faq_reading_tables","unlisted":false},{"type":"link","label":"Table Services","href":"/cn/docs/0.15.0/faq_table_services","docId":"faq_table_services","unlisted":false},{"type":"link","label":"Storage","href":"/cn/docs/0.15.0/faq_storage","docId":"faq_storage","unlisted":false},{"type":"link","label":"Integrations","href":"/cn/docs/0.15.0/faq_integrations","docId":"faq_integrations","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Privacy Policy","href":"/cn/docs/0.15.0/privacy","docId":"privacy","unlisted":false}],"quick_links":[{"type":"link","label":"Powered By","href":"powered-by"},{"type":"link","label":"Chat with us on Slack","href":"https://join.slack.com/t/apache-hudi/shared_invite/zt-2ggm1fub8-_yt4Reu9djwqqVRFC7X49g"}]},"docs":{"azure_hoodie":{"id":"azure_hoodie","title":"Microsoft Azure","description":"In this page, we explain how to use Hudi on Microsoft Azure.","sidebar":"docs"},"basic_configurations":{"id":"basic_configurations","title":"Basic Configurations","description":"This page covers the basic configurations you may use to write/read Hudi tables. This page only features a subset of the most frequently used configurations. For a full list of all configs, please visit the All Configurations page.","sidebar":"docs"},"bos_hoodie":{"id":"bos_hoodie","title":"Baidu Cloud","description":"In this page, we explain how to get your Hudi job to store into Baidu BOS.","sidebar":"docs"},"cli":{"id":"cli","title":"CLI","description":"Local set up","sidebar":"docs"},"cloud":{"id":"cloud","title":"Cloud Storage","description":"Talking to Cloud Storage","sidebar":"docs"},"clustering":{"id":"clustering","title":"Clustering","description":"Background","sidebar":"docs"},"compaction":{"id":"compaction","title":"Compaction","description":"Background","sidebar":"docs"},"comparison":{"id":"comparison","title":"Comparison","description":"Apache Hudi fills a big void for processing data on top of DFS, and thus mostly co-exists nicely with these technologies. However,"},"concepts":{"id":"concepts","title":"Concepts","description":"Apache Hudi (pronounced \u201cHudi\u201d) provides the following streaming primitives over hadoop compatible storages"},"concurrency_control":{"id":"concurrency_control","title":"Concurrency Control","description":"Concurrency control defines how different writers/readers coordinate access to the table. Hudi ensures atomic writes, by way of publishing commits atomically to the timeline, stamped with an instant time that denotes the time at which the action is deemed to have occurred. Unlike general purpose file version control, Hudi draws clear distinction between writer processes (that issue user\u2019s upserts/deletes), table services (that write data/metadata to optimize/perform bookkeeping) and readers (that execute queries and read data). Hudi provides snapshot isolation between all three types of processes, meaning they all operate on a consistent snapshot of the table. Hudi provides optimistic concurrency control (OCC) between writers, while providing lock-free, non-blocking Multiversion Concurrency Control (MVCC) based concurrency control between writers and table-services and between different table services.","sidebar":"docs"},"configurations":{"id":"configurations","title":"All Configurations","description":"This page covers the different ways of configuring your job to write/read Hudi tables. At a high level, you can control behaviour at few levels.","sidebar":"docs"},"cos_hoodie":{"id":"cos_hoodie","title":"Tencent Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Tencent Cloud COS.","sidebar":"docs"},"deployment":{"id":"deployment","title":"Deployment","description":"This section provides all the help you need to deploy and operate Hudi tables at scale.","sidebar":"docs"},"disaster_recovery":{"id":"disaster_recovery","title":"Disaster Recovery","description":"Disaster Recovery is very much mission-critical for any software. Especially when it comes to data systems, the impact could be very serious","sidebar":"docs"},"docker_demo":{"id":"docker_demo","title":"Docker Demo","description":"A Demo using Docker containers","sidebar":"docs"},"encryption":{"id":"encryption","title":"Encryption","description":"Since Hudi 0.11.0, Spark 3.2 support has been added and accompanying that, Parquet 1.12 has been included, which brings encryption feature to Hudi. In this section, we will show a guide on how to enable encryption in Hudi tables.","sidebar":"docs"},"faq":{"id":"faq","title":"Overview","description":"The FAQs are split into following pages. Please refer to the specific pages for more info.","sidebar":"docs"},"faq_design_and_concepts":{"id":"faq_design_and_concepts","title":"Design & Concepts","description":"How does Hudi ensure atomicity?","sidebar":"docs"},"faq_general":{"id":"faq_general","title":"General","description":"When is Hudi useful for me or my organization?","sidebar":"docs"},"faq_integrations":{"id":"faq_integrations","title":"Integrations","description":"Does AWS GLUE support Hudi ?","sidebar":"docs"},"faq_reading_tables":{"id":"faq_reading_tables","title":"Reading Tables","description":"Does deleted records appear in Hudi\'s incremental query results?","sidebar":"docs"},"faq_storage":{"id":"faq_storage","title":"Storage","description":"Does Hudi support cloud storage/object stores?","sidebar":"docs"},"faq_table_services":{"id":"faq_table_services","title":"Table Services","description":"What does the Hudi cleaner do?","sidebar":"docs"},"faq_writing_tables":{"id":"faq_writing_tables","title":"Writing Tables","description":"What are some ways to write a Hudi table?","sidebar":"docs"},"file_layouts":{"id":"file_layouts","title":"File Layouts","description":"The following describes the general file layout structure for Apache Hudi. Please refer the tech spec for a more detailed description of the file layouts.","sidebar":"docs"},"file_sizing":{"id":"file_sizing","title":"File Sizing","description":"Solving the small file problem is fundamental to ensuring","sidebar":"docs"},"flink_tuning":{"id":"flink_tuning","title":"Flink Tuning Guide","description":"Global Configurations","sidebar":"docs"},"flink-quick-start-guide":{"id":"flink-quick-start-guide","title":"Flink Quick Start","description":"This page introduces Flink-Hudi integration. We can feel the unique charm of how Flink brings in the power of streaming into Hudi.","sidebar":"docs"},"gcp_bigquery":{"id":"gcp_bigquery","title":"Google BigQuery","description":"Hudi tables can be queried from Google Cloud BigQuery as external tables. As of","sidebar":"docs"},"gcs_hoodie":{"id":"gcs_hoodie","title":"Google Cloud","description":"For Hudi storage on GCS, regional buckets provide an DFS API with strong consistency.","sidebar":"docs"},"hoodie_cleaner":{"id":"hoodie_cleaner","title":"Cleaning","description":"Background","sidebar":"docs"},"hoodie_streaming_ingestion":{"id":"hoodie_streaming_ingestion","title":"Using Spark","description":"Hudi Streamer","sidebar":"docs"},"hudi_stack":{"id":"hudi_stack","title":"Apache Hudi Stack","description":"Apache Hudi is a Transactional Data Lakehouse Platform built around a database kernel. It brings core warehouse and database functionality directly to a data lake thereby providing a table-level abstraction over open file formats like Apache Parquet/ORC (more recently known as the lakehouse architecture) and enabling transactional capabilities such as updates/deletes. Hudi also incorporates essential table services that are tightly integrated with the database kernel. These services can be executed automatically across both ingested and derived data to manage various aspects such as table bookkeeping, metadata, and storage layout. This integration along with various platform-specific services extends Hudi\'s role from being just a \'table format\' to a comprehensive and robust data lakehouse platform.","sidebar":"docs"},"ibm_cos_hoodie":{"id":"ibm_cos_hoodie","title":"IBM Cloud","description":"In this page, we explain how to get your Hudi spark job to store into IBM Cloud Object Storage.","sidebar":"docs"},"indexing":{"id":"indexing","title":"Indexing","description":"Indexing","sidebar":"docs"},"ingestion_flink":{"id":"ingestion_flink","title":"Using Flink","description":"CDC Ingestion","sidebar":"docs"},"ingestion_kafka_connect":{"id":"ingestion_kafka_connect","title":"Using Kafka Connect","description":"Try out the new experimental release of Hudi Kafka Connect Sink. Read","sidebar":"docs"},"jfs_hoodie":{"id":"jfs_hoodie","title":"JuiceFS","description":"In this page, we explain how to use Hudi with JuiceFS.","sidebar":"docs"},"key_generation":{"id":"key_generation","title":"Key Generation","description":"Every record in Hudi is uniquely identified by a primary key, which is a pair of record key and partition path where the record belongs to.","sidebar":"docs"},"markers":{"id":"markers","title":"Marker Mechanism","description":"Purpose of Markers","sidebar":"docs"},"metadata":{"id":"metadata","title":"Metadata Table","description":"Metadata Table","sidebar":"docs"},"metadata_indexing":{"id":"metadata_indexing","title":"Metadata Indexing","description":"Hudi maintains a scalable metadata that has some auxiliary data about the table.","sidebar":"docs"},"metrics":{"id":"metrics","title":"Metrics","description":"In this section, we will introduce the MetricsReporter and HoodieMetrics in Hudi. You can view the metrics-related configurations here.","sidebar":"docs"},"migration_guide":{"id":"migration_guide","title":"Bootstrapping","description":"Hudi maintains metadata such as commit timeline and indexes to manage a table. The commit timelines helps to understand the actions happening on a table as well as the current state of a table. Indexes are used by Hudi to maintain a record key to file id mapping to efficiently locate a record. At the moment, Hudi supports writing only parquet columnar formats.","sidebar":"docs"},"oci_hoodie":{"id":"oci_hoodie","title":"Oracle Cloud Infrastructure","description":"The Oracle Object Storage system provides strongly-consistent operations on all buckets in all regions. OCI Object Storage provides an HDFS Connector your Application will need to access data.","sidebar":"docs"},"oss_hoodie":{"id":"oss_hoodie","title":"Alibaba Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Aliyun OSS.","sidebar":"docs"},"overview":{"id":"overview","title":"Overview","description":"Welcome to Apache Hudi! This overview will provide a high level summary of what Apache Hudi is and will orient you on","sidebar":"docs"},"performance":{"id":"performance","title":"Performance","description":"Optimized DFS Access","sidebar":"docs"},"platform_services_post_commit_callback":{"id":"platform_services_post_commit_callback","title":"Post-commit Callback","description":"Apache Hudi provides the ability to post a callback notification about a write commit. This may be valuable if you need","sidebar":"docs"},"precommit_validator":{"id":"precommit_validator","title":"Data Quality","description":"Data quality refers to the overall accuracy, completeness, consistency, and validity of data. Ensuring data quality is vital for accurate analysis and reporting, as well as for compliance with regulations and maintaining trust in your organization\'s data infrastructure.","sidebar":"docs"},"privacy":{"id":"privacy","title":"Privacy Policy","description":"Information about your use of this website is collected using server access logs and a tracking cookie.","sidebar":"docs"},"procedures":{"id":"procedures","title":"SQL Procedures","description":"Stored procedures are available when use Hudi SparkSQL extensions in all spark\'s version.","sidebar":"docs"},"python-rust-quick-start-guide":{"id":"python-rust-quick-start-guide","title":"Python/Rust Quick Start (Hudi-rs)","description":"This guide will help you get started with Hudi-rs, the native Rust implementation for Apache Hudi with Python bindings. Learn how to install, set up, and perform basic operations using both Python and Rust interfaces.","sidebar":"docs"},"querying_data":{"id":"querying_data","title":"Querying Data","description":"This page is no longer maintained. Please refer to Hudi SQL DDL, SQL DML, SQL Queries and Procedures for the latest documentation."},"quick-start-guide":{"id":"quick-start-guide","title":"Spark Quick Start","description":"This guide provides a quick peek at Hudi\'s capabilities using Spark. Using Spark Datasource APIs(both scala and python) and using Spark SQL,","sidebar":"docs"},"reading_tables_batch_reads":{"id":"reading_tables_batch_reads","title":"Batch Reads","description":"Spark DataSource API","sidebar":"docs"},"reading_tables_streaming_reads":{"id":"reading_tables_streaming_reads","title":"Streaming Reads","description":"Spark Streaming","sidebar":"docs"},"record_payload":{"id":"record_payload","title":"Record Payload","description":"Background","sidebar":"docs"},"rollbacks":{"id":"rollbacks","title":"Rollback Mechanism","description":"Your pipelines could fail due to numerous reasons like crashes, valid bugs in the code, unavailability of any external","sidebar":"docs"},"s3_hoodie":{"id":"s3_hoodie","title":"AWS S3","description":"In this page, we explain how to get your Hudi spark job to store into AWS S3.","sidebar":"docs"},"schema_evolution":{"id":"schema_evolution","title":"Schema Evolution","description":"Schema evolution is an essential aspect of data management, and Hudi supports schema evolution on write out-of-the-box,","sidebar":"docs"},"snapshot_exporter":{"id":"snapshot_exporter","title":"Exporter","description":"Introduction","sidebar":"docs"},"sql_ddl":{"id":"sql_ddl","title":"SQL DDL","description":"This page describes support for creating and altering tables using SQL across various engines.","sidebar":"docs"},"sql_dml":{"id":"sql_dml","title":"SQL DML","description":"Spark SQL","sidebar":"docs"},"sql_queries":{"id":"sql_queries","title":"SQL Queries","description":"Hudi stores and organizes data on storage while providing different ways of querying, across a wide range of query engines.","sidebar":"docs"},"structure":{"id":"structure","title":"Structure","description":"Hudi (pronounced \u201cHoodie\u201d) ingests & manages storage of large analytical tables over DFS (HDFS or cloud stores) and provides three types of queries."},"syncing_aws_glue_data_catalog":{"id":"syncing_aws_glue_data_catalog","title":"AWS Glue Data Catalog","description":"Hudi tables can sync to AWS Glue Data Catalog directly via AWS SDK. Piggyback on HiveSyncTool","sidebar":"docs"},"syncing_datahub":{"id":"syncing_datahub","title":"DataHub","description":"DataHub is a rich metadata platform that supports features like data discovery, data","sidebar":"docs"},"syncing_metastore":{"id":"syncing_metastore","title":"Hive Metastore","description":"Hive Metastore is an","sidebar":"docs"},"syncing_xtable":{"id":"syncing_xtable","title":"Apache XTable (incubating)","description":"Hudi (tables created from 0.14.0 onwards) supports syncing to Iceberg and/or Delta Lake with Apache XTable (incubating), providing users with the option to interoperate with other table formats like Delta Lake and Apache Iceberg.","sidebar":"docs"},"table_types":{"id":"table_types","title":"Table & Query Types","description":"Table and Query Types","sidebar":"docs"},"timeline":{"id":"timeline","title":"Timeline","description":"At its core, Hudi maintains a timeline which is a log of all actions performed on the table at different instants of time that helps provide instantaneous views of the table,","sidebar":"docs"},"troubleshooting":{"id":"troubleshooting","title":"Troubleshooting","description":"For performance related issues, please refer to the tuning guide","sidebar":"docs"},"tuning-guide":{"id":"tuning-guide","title":"Spark Tuning Guide","description":"To get a better understanding of where your Hudi jobs is spending its time, use a tool like YourKit Java Profiler, to obtain heap dumps/flame graphs.","sidebar":"docs"},"use_cases":{"id":"use_cases","title":"Use Cases","description":"Apache Hudi provides the foundational features required to build a state-of-the-art Lakehouse.","sidebar":"docs"},"write_operations":{"id":"write_operations","title":"Write Operations","description":"It may be helpful to understand the different write operations of Hudi and how best to leverage them. These operations","sidebar":"docs"},"writing_data":{"id":"writing_data","title":"Batch Writes","description":"Spark DataSource API","sidebar":"docs"},"writing_tables_streaming_writes":{"id":"writing_tables_streaming_writes","title":"Streaming Writes","description":"Spark Streaming","sidebar":"docs"}}}}')}}]);
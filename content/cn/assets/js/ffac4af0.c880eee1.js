"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[42368],{83565:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>r,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var n=t(74848),i=t(28453);const o={title:"Apache Hudi - The Data Lake Platform",excerpt:"It's been called many things. But, we have always been building a data lake platform",author:"vinoth",category:"blog",image:"/assets/images/blog/hudi_streaming.png",tags:["datalake platform","blog","apache hudi"]},s=void 0,l={permalink:"/cn/blog/2021/07/21/streaming-data-lake-platform",editUrl:"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2021-07-21-streaming-data-lake-platform.md",source:"@site/blog/2021-07-21-streaming-data-lake-platform.md",title:"Apache Hudi - The Data Lake Platform",description:"As early as 2016, we set out a bold, new vision reimagining batch data processing through a new \u201cincremental\u201d data processing stack - alongside the existing batch and streaming stacks.",date:"2021-07-21T00:00:00.000Z",tags:[{inline:!0,label:"datalake platform",permalink:"/cn/blog/tags/datalake-platform"},{inline:!0,label:"blog",permalink:"/cn/blog/tags/blog"},{inline:!0,label:"apache hudi",permalink:"/cn/blog/tags/apache-hudi"}],readingTime:28.99,hasTruncateMarker:!0,authors:[{name:"vinoth",key:null,page:null}],frontMatter:{title:"Apache Hudi - The Data Lake Platform",excerpt:"It's been called many things. But, we have always been building a data lake platform",author:"vinoth",category:"blog",image:"/assets/images/blog/hudi_streaming.png",tags:["datalake platform","blog","apache hudi"]},unlisted:!1,prevItem:{title:"Baixin bank\u2019s real-time data lake evolution scheme based on Apache Hudi",permalink:"/cn/blog/2021/07/26/Baixin-banksreal-time-data-lake-evolution-scheme-based-on-Apache-Hudi"},nextItem:{title:"Amazon Athena expands Apache Hudi support",permalink:"/cn/blog/2021/07/16/Amazon-Athena-expands-Apache-Hudi-support"}},r={authorsImageUrls:[void 0]},c=[];function d(e){const a={a:"a",em:"em",p:"p",strong:"strong",...(0,i.R)(),...e.components};return(0,n.jsxs)(a.p,{children:["As early as 2016, we set out a ",(0,n.jsx)(a.a,{href:"https://www.oreilly.com/content/ubers-case-for-incremental-processing-on-hadoop/",children:"bold, new vision"})," reimagining batch data processing through a new \u201c",(0,n.jsx)(a.strong,{children:"incremental"}),"\u201d data processing stack - alongside the existing batch and streaming stacks.\nWhile a stream processing pipeline does row-oriented processing, delivering a few seconds of processing latency, an incremental pipeline would apply the same principles to ",(0,n.jsx)(a.em,{children:"columnar"})," data in the data lake,\ndelivering orders of magnitude improvements in processing efficiency within few minutes, on extremely scalable batch storage/compute infrastructure. This new stack would be able to effortlessly support regular batch processing for bulk reprocessing/backfilling as well.\nHudi was built as the manifestation of this vision, rooted in real, hard problems faced at ",(0,n.jsx)(a.a,{href:"https://eng.uber.com/uber-big-data-platform/",children:"Uber"})," and later took a life of its own in the open source community. Together, we have been able to\nusher in fully incremental data ingestion and moderately complex ETLs on data lakes already."]})}function p(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},28453:(e,a,t)=>{t.d(a,{R:()=>s,x:()=>l});var n=t(96540);const i={},o=n.createContext(i);function s(e){const a=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),n.createElement(o.Provider,{value:a},e.children)}}}]);
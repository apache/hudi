"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[16163],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>u});var i=t(67294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);a&&(i=i.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,i)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,i,n=function(e,a){if(null==e)return{};var t,i,n={},r=Object.keys(e);for(i=0;i<r.length;i++)t=r[i],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)t=r[i],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var s=i.createContext({}),d=function(e){var a=i.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},p=function(e){var a=d(e.components);return i.createElement(s.Provider,{value:a},e.children)},c={inlineCode:"code",wrapper:function(e){var a=e.children;return i.createElement(i.Fragment,{},a)}},h=i.forwardRef((function(e,a){var t=e.components,n=e.mdxType,r=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),h=d(t),u=n,m=h["".concat(s,".").concat(u)]||h[u]||c[u]||r;return t?i.createElement(m,o(o({ref:a},p),{},{components:t})):i.createElement(m,o({ref:a},p))}));function u(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var r=t.length,o=new Array(r);o[0]=h;var l={};for(var s in a)hasOwnProperty.call(a,s)&&(l[s]=a[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,o[1]=l;for(var d=2;d<r;d++)o[d]=t[d];return i.createElement.apply(null,o)}return i.createElement.apply(null,t)}h.displayName="MDXCreateElement"},773:(e,a,t)=>{t.r(a),t.d(a,{contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>s});var i=t(87462),n=(t(67294),t(3905));const r={title:"Powered By",keywords:["hudi","powered-by"],last_modified_at:new Date("2019-12-31T19:59:57.000Z")},o="Who's Using",l={type:"mdx",permalink:"/cn/powered-by",source:"@site/src/pages/powered-by.md"},s=[{value:"37 Interactive Entertainment",id:"37-interactive-entertainment",children:[],level:3},{value:"Alibaba Cloud",id:"alibaba-cloud",children:[],level:3},{value:"Amazon",id:"amazon",children:[],level:3},{value:"Amazon Web Services",id:"amazon-web-services",children:[],level:3},{value:"ByteDance",id:"bytedance",children:[],level:3},{value:"Clinbrain",id:"clinbrain",children:[],level:3},{value:"DiDi",id:"didi",children:[],level:3},{value:"Disney+ Hotstar",id:"disney-hotstar",children:[],level:3},{value:"EMIS Health",id:"emis-health",children:[],level:3},{value:"GE Aviation",id:"ge-aviation",children:[],level:3},{value:"Grofers",id:"grofers",children:[],level:3},{value:"H3C Digital Platform",id:"h3c-digital-platform",children:[],level:3},{value:"Halodoc",id:"halodoc",children:[],level:3},{value:"Kyligence",id:"kyligence",children:[],level:3},{value:"Lingyue-digital Corporation",id:"lingyue-digital-corporation",children:[],level:3},{value:"Logical Clocks",id:"logical-clocks",children:[],level:3},{value:"Robinhood",id:"robinhood",children:[],level:3},{value:"SF-Express",id:"sf-express",children:[],level:3},{value:"Tathastu.ai",id:"tathastuai",children:[],level:3},{value:"Tencent",id:"tencent",children:[],level:3},{value:"Uber",id:"uber",children:[],level:3},{value:"Udemy",id:"udemy",children:[],level:3},{value:"Walmart",id:"walmart",children:[],level:3},{value:"Yields.io",id:"yieldsio",children:[],level:3},{value:"Yotpo",id:"yotpo",children:[],level:3},{value:"Zendesk",id:"zendesk",children:[],level:3}],d={toc:s};function p(e){let{components:a,...t}=e;return(0,n.kt)("wrapper",(0,i.Z)({},d,t,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"whos-using"},"Who's Using"),(0,n.kt)("p",null,"Apache Hudi is a ",(0,n.kt)("a",{parentName:"p",href:"https://hudi.apache.org/blog/2022/01/06/apache-hudi-2021-a-year-in-review"},"fast growing diverse community"),"\nof people and organizations from all around the globe. The following is a small sample of companies that have adopted or\ncontributed to the Apache Hudi community! ",(0,n.kt)("a",{parentName:"p",href:"https://join.slack.com/t/apache-hudi/shared_invite/enQtODYyNDAxNzc5MTg2LTE5OTBlYmVhYjM0N2ZhOTJjOWM4YzBmMWU2MjZjMGE4NDc5ZDFiOGQ2N2VkYTVkNzU3ZDQ4OTI1NmFmYWQ0NzE"},"Join us on slack"),",\nor come to one of our ",(0,n.kt)("a",{parentName:"p",href:"https://hudi.apache.org/community/syncs"},"virtual community events"),"."),(0,n.kt)("img",{src:"/assets/images/powers/logo-wall.png",alt:"drawing"}),(0,n.kt)("h3",{id:"37-interactive-entertainment"},"37 Interactive Entertainment"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.37wan.net/"},"37 Interactive Entertainment")," is a global Top20 listed game company, and a leading company on A-shares market of China.\nApache Hudi is integrated into our Data Middle Platform offering real-time data warehouse and solving the problem of frequent changes of data.\nMeanwhile, we build a set of data access standards based on Hudi, which provides a guarantee for massive data queries in game operation scenarios."),(0,n.kt)("h3",{id:"alibaba-cloud"},"Alibaba Cloud"),(0,n.kt)("p",null,"Alibaba Cloud provides cloud computing services to online businesses and Alibaba's own e-commerce ecosystem, Apache Hudi is integrated into Alibaba Cloud ",(0,n.kt)("a",{parentName:"p",href:"https://www.alibabacloud.com/help/product/70174.htm"},"Data Lake Analytics"),"\noffering real-time analysis on hudi dataset."),(0,n.kt)("h3",{id:"amazon"},"Amazon"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/big-data/how-amazon-transportation-service-enabled-near-real-time-event-analytics-at-petabyte-scale-using-aws-glue-with-apache-hudi/"},"Amazon Transportation service"),"\nuses Apache Hudi for the backbone of their package delivery system, powering petabyte-scale near real time analytics."),(0,n.kt)("h3",{id:"amazon-web-services"},"Amazon Web Services"),(0,n.kt)("p",null,"Amazon Web Services is the World's leading cloud services provider. Apache Hudi is ",(0,n.kt)("a",{parentName:"p",href:"https://aws.amazon.com/emr/features/hudi/"},"pre-installed")," with the AWS Elastic Map Reduce\noffering, providing means for AWS users to perform record-level updates/deletes and manage storage efficiently."),(0,n.kt)("h3",{id:"bytedance"},"ByteDance"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://hudi.apache.org/blog/2021/09/01/building-eb-level-data-lake-using-hudi-at-bytedance/"},"ByteDance"),"\nuses Apache Hudi to power their Exabyte scale TikTok #ForYouPage realtime recommendation engine."),(0,n.kt)("h3",{id:"clinbrain"},"Clinbrain"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.clinbrain.com/"},"Clinbrain"),"  is the leader of big data platform and usage in medical industry. We have built 200 medical big data centers by integrating Hudi Data Lake solution in numerous hospitals. Hudi provides the ability to upsert and delete on hdfs, at the same time, it can make the fresh data-stream up-to-date efficiently in hadoop system with the hudi incremental view."),(0,n.kt)("h3",{id:"didi"},"DiDi"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.didiglobal.com/"},"DiDi")," is the World\u2018s Leading Transportation Platform. Based on the Hadoop ecosystem, we built a new generation of big data platform based on Apache Hudi, which provides record-level updates/deletes as well as streaming and batch integrated data processing."),(0,n.kt)("h3",{id:"disney-hotstar"},"Disney+ Hotstar"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://youtu.be/ZamXiT9aqs8"},"Disney shared")," how they migrated CDC data to Apache Hudi to power a real-time ads platform for their streaming service. "),(0,n.kt)("h3",{id:"emis-health"},"EMIS Health"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.emishealth.com/"},"EMIS Health")," is the largest provider of Primary Care IT software in the UK with datasets including more than 500Bn healthcare records. HUDI is used to manage their analytics dataset in production and keeping them up-to-date with their upstream source. Presto is being used to query the data written in HUDI format."),(0,n.kt)("h3",{id:"ge-aviation"},"GE Aviation"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/big-data/how-ge-aviation-built-cloud-native-data-pipelines-at-enterprise-scale-using-the-aws-platform/"},"GE Aviation built cloud-native data pipelines at enterprise scale using Apache Hudi in AWS platform")),(0,n.kt)("h3",{id:"grofers"},"Grofers"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://grofers.com"},"Grofers")," is a grocery delivery provider operating across APAC region. Grofers has ",(0,n.kt)("a",{parentName:"p",href:"https://lambda.grofers.com/origins-of-data-lake-at-grofers-6c011f94b86c"},"integrated hudi")," in its central pipelines for replicating backend database CDC into the warehouse."),(0,n.kt)("h3",{id:"h3c-digital-platform"},"H3C Digital Platform"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"http://www.h3c.com/"},"H3C digital platform")," provides the whole process capability of data collection, storage, calculation and governance, and enables the construction of data center and data governance ability for medical, smart park, smart city and other industries;\nApache Hudi is integrated in the digital platform to meet the real-time update needs of massive data"),(0,n.kt)("h3",{id:"halodoc"},"Halodoc"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://blogs.halodoc.io/lake-house-architecture-halodoc-data-platform-2-0/"},"Lake House Architecture at Halodoc: Data Platform 2.0")),(0,n.kt)("h3",{id:"kyligence"},"Kyligence"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://kyligence.io/zh/"},"Kyligence")," is the leading Big Data analytics platform company. We\u2019ve built end to end solutions for various Global Fortune 500 companies in US and China. We adopted Apache Hudi in our Cloud solution on AWS in 2019. With the help of Hudi, we are able to process upserts and deletes easily and we use incremental views to build efficient data pipelines in AWS. The Hudi datasets can also be integrated to Kyligence Cloud directly for high concurrent OLAP access."),(0,n.kt)("h3",{id:"lingyue-digital-corporation"},"Lingyue-digital Corporation"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.lingyue-digital.com/"},"Lingyue-digital Corporation")," belongs to BMW Group. Apache Hudi is used to perform ingest MySQL and PostgreSQL change data capture. We build up upsert scenarios on Hadoop and spark."),(0,n.kt)("h3",{id:"logical-clocks"},"Logical Clocks"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.logicalclocks.com/blog/introducing-the-hopsworks-1-x-series"},"Hopsworks 1.x series")," supports Apache Hudi feature groups, to enable upserts and time travel."),(0,n.kt)("h3",{id:"robinhood"},"Robinhood"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.slideshare.net/BalajiVaradarajan13/rds-data-lake-robinhood"},"Rds data lake at Robinhood using Apache Hudi")),(0,n.kt)("h3",{id:"sf-express"},"SF-Express"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.sf-express.com/cn/sc/"},"SF-Express")," is the leading logistics service provider in China. HUDI is used to build a real-time data warehouse, providing real-time computing solutions with higher efficiency and lower cost for our business."),(0,n.kt)("h3",{id:"tathastuai"},"Tathastu.ai"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.tathastu.ai"},"Tathastu.ai")," offers the largest AI/ML playground of consumer data for data scientists, AI experts and technologists to build upon. They have built a CDC pipeline using Apache Hudi and Debezium. Data from Hudi datasets is being queried using Hive, Presto and Spark."),(0,n.kt)("h3",{id:"tencent"},"Tencent"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://intl.cloud.tencent.com/product/emr"},"EMR from Tencent")," Cloud has integrated Hudi as one of its BigData components ",(0,n.kt)("a",{parentName:"p",href:"https://intl.cloud.tencent.com/document/product/1026/35587"},"since V2.2.0"),". Using Hudi, the end-users can handle either read-heavy or write-heavy use cases, and Hudi will manage the underlying data stored on HDFS/COS/CHDFS using Apache Parquet and Apache Avro."),(0,n.kt)("h3",{id:"uber"},"Uber"),(0,n.kt)("p",null,"Apache Hudi was originally developed at ",(0,n.kt)("a",{parentName:"p",href:"https://uber.com"},"Uber"),", to achieve ",(0,n.kt)("a",{parentName:"p",href:"http://www.slideshare.net/vinothchandar/hadoop-strata-talk-uber-your-hadoop-has-arrived/32"},"low latency database ingestion, with high efficiency"),".\nIt has been in production since Aug 2016, powering the massive ",(0,n.kt)("a",{parentName:"p",href:"https://eng.uber.com/uber-big-data-platform/"},"100PB data lake"),", including highly business critical tables like core trips,riders,partners. It also\npowers several incremental Hive ETL pipelines and being currently integrated into Uber's data dispersal system."),(0,n.kt)("h3",{id:"udemy"},"Udemy"),(0,n.kt)("p",null,"At ",(0,n.kt)("a",{parentName:"p",href:"https://www.udemy.com/"},"Udemy"),", Apache Hudi on AWS EMR is used to perform ingest MySQL change data capture."),(0,n.kt)("h3",{id:"walmart"},"Walmart"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://searchdatamanagement.techtarget.com/feature/Hudi-powering-data-lake-efforts-at-Walmart-and-Disney-Hotstar"},"Walmart"),"\nchose Apache Hudi to manage their data lake of store transactions."),(0,n.kt)("h3",{id:"yieldsio"},"Yields.io"),(0,n.kt)("p",null,"Yields.io is the first FinTech platform that uses AI for automated model validation and real-time monitoring on an enterprise-wide scale. Their ",(0,n.kt)("a",{parentName:"p",href:"https://www.yields.io/Blog/Apache-Hudi-at-Yields"},"data lake")," is managed by Hudi. They are also actively building their infrastructure for incremental, cross language/platform machine learning using Hudi."),(0,n.kt)("h3",{id:"yotpo"},"Yotpo"),(0,n.kt)("p",null,"Using Hudi at Yotpo for several usages. Firstly, integrated Hudi as a writer in their open source ETL framework, ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/YotpoLtd/metorikku"},"Metorikku")," and using as an output writer for a CDC pipeline, with events that are being generated from a database binlog streams to Kafka and then are written to S3. "),(0,n.kt)("h3",{id:"zendesk"},"Zendesk"),(0,n.kt)("p",null,"At ",(0,n.kt)("a",{parentName:"p",href:"https://www.zendesk.com/"},"Zendesk"),", Apache Hudi is adopted for building Data Lake on AWS."))}p.isMDXComponent=!0}}]);
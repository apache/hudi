<!DOCTYPE html>
<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="This section offers an overview of tools available to operate an ecosystem of Hudi datasets">
<meta name="keywords" content="hudi, administration, operation, devops">
<title>Administering Hudi Pipelines | Hudi</title>
<link rel="stylesheet" href="/css/syntax.css">


<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="/css/modern-business.css">
<link rel="stylesheet" href="/css/lavish-bootstrap.css">
<link rel="stylesheet" href="/css/customstyles.css">
<link rel="stylesheet" href="/css/theme-blue.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="/js/jquery.navgoco.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/2.0.0/anchor.min.js"></script>
<script src="/js/toc.js"></script>
<script src="/js/customscripts.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-93561550-1', 'auto');
  ga('send', 'pageview');

</script>

<link rel="shortcut icon" href="/images/favicon.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="" href="http://0.0.0.0:4000feed.xml">

    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    

</head>
<body>
<!-- Navigation -->

<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="fa fa-lg navbar-brand" href="index.html">&nbsp;<span class="projectTitle">
              <img src="https://www.apache.org/img/hudi.png" alt="Hudi logo"/>
              <!--Hudi-->
            </span><br/>
            <p class="navbar-incubate">(Incubating)</p></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- entries without drop-downs appear here -->
                

                
                
                
                <li><a href="releases.html">Releases</a></li>
                
                
                
                <li><a href="community.html">Community</a></li>
                
                
                
                <li><a href="https://github.com/apache/incubator-hudi" target="_blank">Code</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Developers<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        
                        
                        <li><a href="contributing.html">Contributing</a></li>
                        
                        
                        
                        <li><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank">Wiki/Designs</a></li>
                        
                        
                        
                        <li><a href="https://issues.apache.org/jira/projects/HUDI/summary" target="_blank">Issues</a></li>
                        
                        
                        
                        <li><a href="https://cwiki.apache.org/confluence/pages/viewrecentblogposts.action?key=HUDI" target="_blank">Blog</a></li>
                        
                        
                        
                        <li><a href="https://projects.apache.org/project.html?incubator-hudi" target="_blank">Team</a></li>
                        
                        
                    </ul>
                </li>
                
                
                
			<li>



  <a class="email" title="Submit feedback" href="#" onclick="javascript:window.location='mailto:dev@hudi.apache.org?subject=Hudi Documentation feedback&body=I have some feedback about the Administering Hudi Pipelines page: ' + window.location.href;"><i class="fa fa-envelope-o"></i> Feedback</a>

<li>

		
                <li>
                    
                    <!-- link to the Chinese home page when current is blog page -->
                    <a href="/cn/admin_guide.html">中文版</a>
                    
                </li>
                <!--comment out this block if you want to hide search-->
                <li>
                    <!--start search-->
                    <div id="search-demo-container">

                        
                        <input type="text" id="search-input" placeholder="search...">
                        

                        <ul id="results-container"></ul>
                    </div>
                    <script src="/js/jekyll-search.js" type="text/javascript"></script>
                    <script type="text/javascript">
                            SimpleJekyllSearch.init({
                                searchInput: document.getElementById('search-input'),
                                resultsContainer: document.getElementById('results-container'),
                                dataSource: '/search.json',
                                searchResultTemplate: '<li><a href="{url}" title="Administering Hudi Pipelines">{title}</a></li>',
                    noResultsText: 'No results found.',
                            limit: 10,
                            fuzzy: true,
                    })
                    </script>
                    <!--end search-->
                </li>
            </ul>
        </div>
        <p class="alert alert-warning"><i class="fa fa-info-circle"></i> <b>Note:</b> Click here to try our new site. Please <a href="/newsite-content"> Visit new site</a>.</p>

    </div>
        <!-- /.container -->
</nav>

<!-- Page Content -->
<div class="container">
    <div class="col-lg-12">&nbsp;</div>
    <!-- Content Row -->
    <div class="row">
        <!-- Sidebar Column -->
        <div class="col-md-2">
          








<ul id="mysidebar" class="nav">
    <li class="sidebarTitle">Version (0.5.0-incubating)</li>
    
    
    
    <li>
        <a href="#">Getting Started</a>
        <ul>
            
            
            
            <li><a href="quickstart.html">Quickstart</a></li>
            
            
            
            
            
            
            <li><a href="use_cases.html">Use Cases</a></li>
            
            
            
            
            
            
            <li><a href="powered_by.html">Talks & Powered By</a></li>
            
            
            
            
            
            
            <li><a href="comparison.html">Comparison</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Documentation</a>
        <ul>
            
            
            
            <li><a href="concepts.html">Concepts</a></li>
            
            
            
            
            
            
            <li><a href="writing_data.html">Writing Data</a></li>
            
            
            
            
            
            
            <li><a href="querying_data.html">Querying Data</a></li>
            
            
            
            
            
            
            <li><a href="configurations.html">Configuration</a></li>
            
            
            
            
            
            
            <li><a href="performance.html">Performance</a></li>
            
            
            
            
            
            
            <li class="active"><a href="admin_guide.html">Administering</a></li>
            
            
            
            
        </ul>
        
        
        
        <!-- if you aren't using the accordion, uncomment this block:
           <p class="external">
               <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
           </p>
           -->
    </li>
</ul>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>

        </div>
        <!-- Content Column -->
        <div class="col-md-8">
            <div class="post-header">
   <h1 class="post-title-main">Administering Hudi Pipelines</h1>
</div>



<div class="post-content">

   
    <div class="summary">This section offers an overview of tools available to operate an ecosystem of Hudi datasets</div>
   

    

  <p>Admins/ops can gain visibility into Hudi datasets/pipelines in the following ways</p>

<ul>
  <li><a href="#admin-cli">Administering via the Admin CLI</a></li>
  <li><a href="#metrics">Graphite metrics</a></li>
  <li><a href="#spark-ui">Spark UI of the Hudi Application</a></li>
</ul>

<p>This section provides a glimpse into each of these, with some general guidance on <a href="#troubleshooting">troubleshooting</a></p>

<h2 id="admin-cli">Admin CLI</h2>

<p>Once hudi has been built, the shell can be fired by via  <code class="highlighter-rouge">cd hudi-cli &amp;&amp; ./hudi-cli.sh</code>.
A hudi dataset resides on DFS, in a location referred to as the <strong>basePath</strong> and we would need this location in order to connect to a Hudi dataset.
Hudi library effectively manages this dataset internally, using .hoodie subfolder to track all metadata</p>

<p>To initialize a hudi table, use the following command.</p>

<pre><code class="language-Java">18/09/06 15:56:52 INFO annotation.AutowiredAnnotationBeanPostProcessor: JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
============================================
*                                          *
*     _    _           _   _               *
*    | |  | |         | | (_)              *
*    | |__| |       __| |  -               *
*    |  __  ||   | / _` | ||               *
*    | |  | ||   || (_| | ||               *
*    |_|  |_|\___/ \____/ ||               *
*                                          *
============================================

Welcome to Hoodie CLI. Please type help if you are looking for help.
hudi-&gt;create --path /user/hive/warehouse/table1 --tableName hoodie_table_1 --tableType COPY_ON_WRITE
.....
18/09/06 15:57:15 INFO table.HoodieTableMetaClient: Finished Loading Table of type COPY_ON_WRITE from ...
</code></pre>

<p>To see the description of hudi table, use the command:</p>

<pre><code class="language-Java">hoodie:hoodie_table_1-&gt;desc
18/09/06 15:57:19 INFO timeline.HoodieActiveTimeline: Loaded instants []
    _________________________________________________________
    | Property                | Value                        |
    |========================================================|
    | basePath                | ...                          |
    | metaPath                | ...                          |
    | fileSystem              | hdfs                         |
    | hoodie.table.name       | hoodie_table_1               |
    | hoodie.table.type       | COPY_ON_WRITE                |
    | hoodie.archivelog.folder|                              |
</code></pre>

<p>Following is a sample command to connect to a Hudi dataset contains uber trips.</p>

<pre><code class="language-Java">hoodie:trips-&gt;connect --path /app/uber/trips

16/10/05 23:20:37 INFO model.HoodieTableMetadata: Attempting to load the commits under /app/uber/trips/.hoodie with suffix .commit
16/10/05 23:20:37 INFO model.HoodieTableMetadata: Attempting to load the commits under /app/uber/trips/.hoodie with suffix .inflight
16/10/05 23:20:37 INFO model.HoodieTableMetadata: All commits :HoodieCommits{commitList=[20161002045850, 20161002052915, 20161002055918, 20161002065317, 20161002075932, 20161002082904, 20161002085949, 20161002092936, 20161002105903, 20161002112938, 20161002123005, 20161002133002, 20161002155940, 20161002165924, 20161002172907, 20161002175905, 20161002190016, 20161002192954, 20161002195925, 20161002205935, 20161002215928, 20161002222938, 20161002225915, 20161002232906, 20161003003028, 20161003005958, 20161003012936, 20161003022924, 20161003025859, 20161003032854, 20161003042930, 20161003052911, 20161003055907, 20161003062946, 20161003065927, 20161003075924, 20161003082926, 20161003085925, 20161003092909, 20161003100010, 20161003102913, 20161003105850, 20161003112910, 20161003115851, 20161003122929, 20161003132931, 20161003142952, 20161003145856, 20161003152953, 20161003155912, 20161003162922, 20161003165852, 20161003172923, 20161003175923, 20161003195931, 20161003210118, 20161003212919, 20161003215928, 20161003223000, 20161003225858, 20161004003042, 20161004011345, 20161004015235, 20161004022234, 20161004063001, 20161004072402, 20161004074436, 20161004080224, 20161004082928, 20161004085857, 20161004105922, 20161004122927, 20161004142929, 20161004163026, 20161004175925, 20161004194411, 20161004203202, 20161004211210, 20161004214115, 20161004220437, 20161004223020, 20161004225321, 20161004231431, 20161004233643, 20161005010227, 20161005015927, 20161005022911, 20161005032958, 20161005035939, 20161005052904, 20161005070028, 20161005074429, 20161005081318, 20161005083455, 20161005085921, 20161005092901, 20161005095936, 20161005120158, 20161005123418, 20161005125911, 20161005133107, 20161005155908, 20161005163517, 20161005165855, 20161005180127, 20161005184226, 20161005191051, 20161005193234, 20161005203112, 20161005205920, 20161005212949, 20161005223034, 20161005225920]}
Metadata for table trips loaded
hoodie:trips-&gt;
</code></pre>

<p>Once connected to the dataset, a lot of other commands become available. The shell has contextual autocomplete help (press TAB) and below is a list of all commands, few of which are reviewed in this section
are reviewed</p>

<pre><code class="language-Java">hoodie:trips-&gt;help
* ! - Allows execution of operating system (OS) commands
* // - Inline comment markers (start of line only)
* ; - Inline comment markers (start of line only)
* addpartitionmeta - Add partition metadata to a dataset, if not present
* clear - Clears the console
* cls - Clears the console
* commit rollback - Rollback a commit
* commits compare - Compare commits with another Hoodie dataset
* commit showfiles - Show file level details of a commit
* commit showpartitions - Show partition level details of a commit
* commits refresh - Refresh the commits
* commits show - Show the commits
* commits sync - Compare commits with another Hoodie dataset
* connect - Connect to a hoodie dataset
* date - Displays the local date and time
* exit - Exits the shell
* help - List all commands usage
* quit - Exits the shell
* records deduplicate - De-duplicate a partition path contains duplicates &amp; produce repaired files to replace with
* script - Parses the specified resource file and executes its commands
* stats filesizes - File Sizes. Display summary stats on sizes of files
* stats wa - Write Amplification. Ratio of how many records were upserted to how many records were actually written
* sync validate - Validate the sync by counting the number of records
* system properties - Shows the shell's properties
* utils loadClass - Load a class
* version - Displays shell version

hoodie:trips-&gt;
</code></pre>

<h4 id="inspecting-commits">Inspecting Commits</h4>

<p>The task of upserting or inserting a batch of incoming records is known as a <strong>commit</strong> in Hudi. A commit provides basic atomicity guarantees such that only commited data is available for querying.
Each commit has a monotonically increasing string/number called the <strong>commit number</strong>. Typically, this is the time at which we started the commit.</p>

<p>To view some basic information about the last 10 commits,</p>

<pre><code class="language-Java">hoodie:trips-&gt;commits show --sortBy "Total Bytes Written" --desc true --limit 10
    ________________________________________________________________________________________________________________________________________________________________________
    | CommitTime    | Total Bytes Written| Total Files Added| Total Files Updated| Total Partitions Written| Total Records Written| Total Update Records Written| Total Errors|
    |=======================================================================================================================================================================|
    ....
    ....
    ....
hoodie:trips-&gt;
</code></pre>

<p>At the start of each write, Hudi also writes a .inflight commit to the .hoodie folder. You can use the timestamp there to estimate how long the commit has been inflight</p>

<pre><code class="language-Java">$ hdfs dfs -ls /app/uber/trips/.hoodie/*.inflight
-rw-r--r--   3 vinoth supergroup     321984 2016-10-05 23:18 /app/uber/trips/.hoodie/20161005225920.inflight
</code></pre>

<h4 id="drilling-down-to-a-specific-commit">Drilling Down to a specific Commit</h4>

<p>To understand how the writes spread across specific partiions,</p>

<pre><code class="language-Java">hoodie:trips-&gt;commit showpartitions --commit 20161005165855 --sortBy "Total Bytes Written" --desc true --limit 10
    __________________________________________________________________________________________________________________________________________
    | Partition Path| Total Files Added| Total Files Updated| Total Records Inserted| Total Records Updated| Total Bytes Written| Total Errors|
    |=========================================================================================================================================|
     ....
     ....
</code></pre>

<p>If you need file level granularity , we can do the following</p>

<pre><code class="language-Java">hoodie:trips-&gt;commit showfiles --commit 20161005165855 --sortBy "Partition Path"
    ________________________________________________________________________________________________________________________________________________________
    | Partition Path| File ID                             | Previous Commit| Total Records Updated| Total Records Written| Total Bytes Written| Total Errors|
    |=======================================================================================================================================================|
    ....
    ....
</code></pre>

<h4 id="filesystem-view">FileSystem View</h4>

<p>Hudi views each partition as a collection of file-groups with each file-group containing a list of file-slices in commit
order (See Concepts). The below commands allow users to view the file-slices for a data-set.</p>

<pre><code class="language-Java"> hoodie:stock_ticks_mor-&gt;show fsview all
 ....
  _______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
 | Partition | FileId | Base-Instant | Data-File | Data-File Size| Num Delta Files| Total Delta File Size| Delta Files |
 |==============================================================================================================================================================================================================================================================================================================================================================================================================|
 | 2018/08/31| 111415c3-f26d-4639-86c8-f9956f245ac3| 20181002180759| hdfs://namenode:8020/user/hive/warehouse/stock_ticks_mor/2018/08/31/111415c3-f26d-4639-86c8-f9956f245ac3_0_20181002180759.parquet| 432.5 KB | 1 | 20.8 KB | [HoodieLogFile {hdfs://namenode:8020/user/hive/warehouse/stock_ticks_mor/2018/08/31/.111415c3-f26d-4639-86c8-f9956f245ac3_20181002180759.log.1}]|



 hoodie:stock_ticks_mor-&gt;show fsview latest --partitionPath "2018/08/31"
 ......
 __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
 | Partition | FileId | Base-Instant | Data-File | Data-File Size| Num Delta Files| Total Delta Size| Delta Size - compaction scheduled| Delta Size - compaction unscheduled| Delta To Base Ratio - compaction scheduled| Delta To Base Ratio - compaction unscheduled| Delta Files - compaction scheduled | Delta Files - compaction unscheduled|
 |=================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================|
 | 2018/08/31| 111415c3-f26d-4639-86c8-f9956f245ac3| 20181002180759| hdfs://namenode:8020/user/hive/warehouse/stock_ticks_mor/2018/08/31/111415c3-f26d-4639-86c8-f9956f245ac3_0_20181002180759.parquet| 432.5 KB | 1 | 20.8 KB | 20.8 KB | 0.0 B | 0.0 B | 0.0 B | [HoodieLogFile {hdfs://namenode:8020/user/hive/warehouse/stock_ticks_mor/2018/08/31/.111415c3-f26d-4639-86c8-f9956f245ac3_20181002180759.log.1}]| [] |

 hoodie:stock_ticks_mor-&gt;
</code></pre>

<h4 id="statistics">Statistics</h4>

<p>Since Hudi directly manages file sizes for DFS dataset, it might be good to get an overall picture</p>

<pre><code class="language-Java">hoodie:trips-&gt;stats filesizes --partitionPath 2016/09/01 --sortBy "95th" --desc true --limit 10
    ________________________________________________________________________________________________
    | CommitTime    | Min     | 10th    | 50th    | avg     | 95th    | Max     | NumFiles| StdDev  |
    |===============================================================================================|
    | &lt;COMMIT_ID&gt;   | 93.9 MB | 93.9 MB | 93.9 MB | 93.9 MB | 93.9 MB | 93.9 MB | 2       | 2.3 KB  |
    ....
    ....
</code></pre>

<p>In case of Hudi write taking much longer, it might be good to see the write amplification for any sudden increases</p>

<pre><code class="language-Java">hoodie:trips-&gt;stats wa
    __________________________________________________________________________
    | CommitTime    | Total Upserted| Total Written| Write Amplifiation Factor|
    |=========================================================================|
    ....
    ....
</code></pre>

<h4 id="archived-commits">Archived Commits</h4>

<p>In order to limit the amount of growth of .commit files on DFS, Hudi archives older .commit files (with due respect to the cleaner policy) into a commits.archived file.
This is a sequence file that contains a mapping from commitNumber =&gt; json with raw information about the commit (same that is nicely rolled up above).</p>

<h4 id="compactions">Compactions</h4>

<p>To get an idea of the lag between compaction and writer applications, use the below command to list down all
pending compactions.</p>

<pre><code class="language-Java">hoodie:trips-&gt;compactions show all
     ___________________________________________________________________
    | Compaction Instant Time| State    | Total FileIds to be Compacted|
    |==================================================================|
    | &lt;INSTANT_1&gt;            | REQUESTED| 35                           |
    | &lt;INSTANT_2&gt;            | INFLIGHT | 27                           |
</code></pre>

<p>To inspect a specific compaction plan, use</p>

<pre><code class="language-Java">hoodie:trips-&gt;compaction show --instant &lt;INSTANT_1&gt;
    _________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
    | Partition Path| File Id | Base Instant  | Data File Path                                    | Total Delta Files| getMetrics                                                                                                                    |
    |================================================================================================================================================================================================================================================
    | 2018/07/17    | &lt;UUID&gt;  | &lt;INSTANT_1&gt;   | viewfs://ns-default/.../../UUID_&lt;INSTANT&gt;.parquet | 1                | {TOTAL_LOG_FILES=1.0, TOTAL_IO_READ_MB=1230.0, TOTAL_LOG_FILES_SIZE=2.51255751E8, TOTAL_IO_WRITE_MB=991.0, TOTAL_IO_MB=2221.0}|

</code></pre>

<p>To manually schedule or run a compaction, use the below command. This command uses spark launcher to perform compaction
operations. NOTE : Make sure no other application is scheduling compaction for this dataset concurrently</p>

<pre><code class="language-Java">hoodie:trips-&gt;help compaction schedule
Keyword:                   compaction schedule
Description:               Schedule Compaction
 Keyword:                  sparkMemory
   Help:                   Spark executor memory
   Mandatory:              false
   Default if specified:   '__NULL__'
   Default if unspecified: '1G'

* compaction schedule - Schedule Compaction
</code></pre>

<pre><code class="language-Java">hoodie:trips-&gt;help compaction run
Keyword:                   compaction run
Description:               Run Compaction for given instant time
 Keyword:                  tableName
   Help:                   Table name
   Mandatory:              true
   Default if specified:   '__NULL__'
   Default if unspecified: '__NULL__'

 Keyword:                  parallelism
   Help:                   Parallelism for hoodie compaction
   Mandatory:              true
   Default if specified:   '__NULL__'
   Default if unspecified: '__NULL__'

 Keyword:                  schemaFilePath
   Help:                   Path for Avro schema file
   Mandatory:              true
   Default if specified:   '__NULL__'
   Default if unspecified: '__NULL__'

 Keyword:                  sparkMemory
   Help:                   Spark executor memory
   Mandatory:              true
   Default if specified:   '__NULL__'
   Default if unspecified: '__NULL__'

 Keyword:                  retry
   Help:                   Number of retries
   Mandatory:              true
   Default if specified:   '__NULL__'
   Default if unspecified: '__NULL__'

 Keyword:                  compactionInstant
   Help:                   Base path for the target hoodie dataset
   Mandatory:              true
   Default if specified:   '__NULL__'
   Default if unspecified: '__NULL__'

* compaction run - Run Compaction for given instant time
</code></pre>

<h5 id="validate-compaction">Validate Compaction</h5>

<p>Validating a compaction plan : Check if all the files necessary for compactions are present and are valid</p>

<pre><code class="language-Java">hoodie:stock_ticks_mor-&gt;compaction validate --instant 20181005222611
...

   COMPACTION PLAN VALID

    ___________________________________________________________________________________________________________________________________________________________________________________________________________________________
    | File Id                             | Base Instant Time| Base Data File                                                                                                                   | Num Delta Files| Valid| Error|
    |==========================================================================================================================================================================================================================|
    | 05320e98-9a57-4c38-b809-a6beaaeb36bd| 20181005222445   | hdfs://namenode:8020/user/hive/warehouse/stock_ticks_mor/2018/08/31/05320e98-9a57-4c38-b809-a6beaaeb36bd_0_20181005222445.parquet| 1              | true |      |



hoodie:stock_ticks_mor-&gt;compaction validate --instant 20181005222601

   COMPACTION PLAN INVALID

    _______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
    | File Id                             | Base Instant Time| Base Data File                                                                                                                   | Num Delta Files| Valid| Error                                                                           |
    |=====================================================================================================================================================================================================================================================================================================|
    | 05320e98-9a57-4c38-b809-a6beaaeb36bd| 20181005222445   | hdfs://namenode:8020/user/hive/warehouse/stock_ticks_mor/2018/08/31/05320e98-9a57-4c38-b809-a6beaaeb36bd_0_20181005222445.parquet| 1              | false| All log files specified in compaction operation is not present. Missing ....    |
</code></pre>

<h5 id="note">NOTE</h5>

<p>The following commands must be executed without any other writer/ingestion application running.</p>

<p>Sometimes, it becomes necessary to remove a fileId from a compaction-plan inorder to speed-up or unblock compaction
operation. Any new log-files that happened on this file after the compaction got scheduled will be safely renamed
so that are preserved. Hudi provides the following CLI to support it</p>

<h5 id="unscheduling-compaction">UnScheduling Compaction</h5>

<pre><code class="language-Java">hoodie:trips-&gt;compaction unscheduleFileId --fileId &lt;FileUUID&gt;
....
No File renames needed to unschedule file from pending compaction. Operation successful.
</code></pre>

<p>In other cases, an entire compaction plan needs to be reverted. This is supported by the following CLI</p>

<pre><code class="language-Java">hoodie:trips-&gt;compaction unschedule --compactionInstant &lt;compactionInstant&gt;
.....
No File renames needed to unschedule pending compaction. Operation successful.
</code></pre>

<h5 id="repair-compaction">Repair Compaction</h5>

<p>The above compaction unscheduling operations could sometimes fail partially (e:g -&gt; DFS temporarily unavailable). With
partial failures, the compaction operation could become inconsistent with the state of file-slices. When you run
<code class="highlighter-rouge">compaction validate</code>, you can notice invalid compaction operations if there is one.  In these cases, the repair
command comes to the rescue, it will rearrange the file-slices so that there is no loss and the file-slices are
consistent with the compaction plan</p>

<pre><code class="language-Java">hoodie:stock_ticks_mor-&gt;compaction repair --instant 20181005222611
......
Compaction successfully repaired
.....
</code></pre>

<h2 id="metrics">Metrics</h2>

<p>Once the Hudi Client is configured with the right datasetname and environment for metrics, it produces the following graphite metrics, that aid in debugging hudi datasets</p>

<ul>
  <li><strong>Commit Duration</strong> - This is amount of time it took to successfully commit a batch of records</li>
  <li><strong>Rollback Duration</strong> - Similarly, amount of time taken to undo partial data left over by a failed commit (happens everytime automatically after a failing write)</li>
  <li><strong>File Level metrics</strong> - Shows the amount of new files added, versions, deleted (cleaned) in each commit</li>
  <li><strong>Record Level Metrics</strong> - Total records inserted/updated etc per commit</li>
  <li><strong>Partition Level metrics</strong> - number of partitions upserted (super useful to understand sudden spikes in commit duration)</li>
</ul>

<p>These metrics can then be plotted on a standard tool like grafana. Below is a sample commit duration chart.</p>

<figure>
    <img class="docimage" src="/images/hudi_commit_duration.png" alt="hudi_commit_duration.png" style="max-width: 100%" />
</figure>

<h2 id="troubleshooting">Troubleshooting Failures</h2>

<p>Section below generally aids in debugging Hudi failures. Off the bat, the following metadata is added to every record to help triage  issues easily using standard Hadoop SQL engines (Hive/Presto/Spark)</p>

<ul>
  <li><strong>_hoodie_record_key</strong> - Treated as a primary key within each DFS partition, basis of all updates/inserts</li>
  <li><strong>_hoodie_commit_time</strong> - Last commit that touched this record</li>
  <li><strong>_hoodie_file_name</strong> - Actual file name containing the record (super useful to triage duplicates)</li>
  <li><strong>_hoodie_partition_path</strong> - Path from basePath that identifies the partition containing this record</li>
</ul>

<p>Note that as of now, Hudi assumes the application passes in the same deterministic partitionpath for a given recordKey. i.e the uniqueness of record key is only enforced within each partition</p>

<h4 id="missing-records">Missing records</h4>

<p>Please check if there were any write errors using the admin commands above, during the window at which the record could have been written.
If you do find errors, then the record was not actually written by Hudi, but handed back to the application to decide what to do with it.</p>

<h4 id="duplicates">Duplicates</h4>

<p>First of all, please confirm if you do indeed have duplicates <strong>AFTER</strong> ensuring the query is accessing the Hudi datasets <a href="sql_queries.html">properly</a> .</p>

<ul>
  <li>If confirmed, please use the metadata fields above, to identify the physical files &amp; partition files containing the records .</li>
  <li>If duplicates span files across partitionpath, then this means your application is generating different partitionPaths for same recordKey, Please fix your app</li>
  <li>if duplicates span multiple files within the same partitionpath, please engage with mailing list. This should not happen. You can use the <code class="highlighter-rouge">records deduplicate</code> command to fix your data.</li>
</ul>

<h4 id="spark-ui">Spark failures</h4>

<p>Typical upsert() DAG looks like below. Note that Hudi client also caches intermediate RDDs to intelligently profile workload and size files and spark parallelism.
Also Spark UI shows sortByKey twice due to the probe job also being shown, nonetheless its just a single sort.</p>

<figure>
    <img class="docimage" src="/images/hudi_upsert_dag.png" alt="hudi_upsert_dag.png" style="max-width: 100%" />
</figure>

<p>At a high level, there are two steps</p>

<p><strong>Index Lookup to identify files to be changed</strong></p>

<ul>
  <li>Job 1 : Triggers the input data read, converts to HoodieRecord object and then stops at obtaining a spread of input records to target partition paths</li>
  <li>Job 2 : Load the set of file names which we need check against</li>
  <li>Job 3  &amp; 4 : Actual lookup after smart sizing of spark join parallelism, by joining RDDs in 1 &amp; 2 above</li>
  <li>Job 5 : Have a tagged RDD of recordKeys with locations</li>
</ul>

<p><strong>Performing the actual writing of data</strong></p>

<ul>
  <li>Job 6 : Lazy join of incoming records against recordKey, location to provide a final set of HoodieRecord which now contain the information about which file/partitionpath they are found at (or null if insert). Then also profile the workload again to determine sizing of files</li>
  <li>Job 7 : Actual writing of data (update + insert + insert turned to updates to maintain file size)</li>
</ul>

<p>Depending on the exception source (Hudi/Spark), the above knowledge of the DAG can be used to pinpoint the actual issue. The most often encountered failures result from YARN/DFS temporary failures.
In the future, a more sophisticated debug/management UI would be added to the project, that can help automate some of this debugging.</p>


    <div class="tags">
        
    </div>

    

</div>

<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
                  <p>
                  Copyright &copy; <span id="copyright-year">2019</span> <a href="https://apache.org">The Apache Software Foundation</a>,
                  Licensed under the Apache License, Version 2.0<br>
                  Apache and the Apache feather logo are trademarks of The Apache Software Foundation.| <a href="/privacy">Privacy Policy</a><br>
                  <a class="footer-link-img" href="https://apache.org">
                    <img src="/images/asf_logo.svg" alt="The Apache Software Foundation" height="100px" widh="50px"></a>
                  </p>
                  <p>
                  Apache Hudi is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the <a href="http://incubator.apache.org/">Apache Incubator</a>.
                  Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have
                  stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a
                  reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                  </p>
                </div>
                <div class="col-lg-12 footer">
                  <div class="ui link list">
                    <a class="item" rel="external" href="https://incubator.apache.org/"> Apache Incubator </a>
                    <a class="item" rel="external" href="https://www.apache.org/"> About the ASF </a>
                    <a class="item" rel="external" href="https://www.apache.org/events/current-event"> Events </a>
                    <a class="item" rel="external" href="https://www.apache.org/foundation/thanks.html"> Thanks </a>
                    <a class="item" rel="external" href="https://www.apache.org/foundation/sponsorship.html"> Become a Sponsor </a>
                    <a class="item" rel="external" href="https://www.apache.org/security/"> Security </a>
                    <a class="item" rel="external" href="https://www.apache.org/licenses/"> License </a>
                  </div>
                </div>
            </div>
</footer>


        </div>
        <div class="col-md-2">
            
            
<!-- this handles the automatic toc. use ## for subheads to auto-generate the on-page minitoc. if you use html tags, you must supply an ID for the heading element in order for it to appear in the minitoc. -->
<script>
$( document ).ready(function() {
  // Handler for .ready() called.

$('#toc').toc({ minimumHeaders: 0, listType: 'ul', showSpeed: 0, headers: 'h2,h3,h4' });

/* this offset helps account for the space taken up by the floating toolbar. */
$('#toc').on('click', 'a', function() {
  var target = $(this.getAttribute('href'))
    , scroll_target = target.offset().top

  $(window).scrollTop(scroll_target - 130);
  return false
})
  
});
</script>

<div id="toc"></div>

            
        </div>
    <!-- /.row -->
    </div>
<!-- /.container -->
</div>

</body>

</html>
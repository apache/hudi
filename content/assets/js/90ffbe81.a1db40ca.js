"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[30410],{56160:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>d,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"sql_queries","title":"SQL Queries","description":"Hudi stores and organizes data on storage while providing different ways of querying, across a wide range of query engines.","source":"@site/docs/sql_queries.md","sourceDirName":".","slug":"/sql_queries","permalink":"/docs/next/sql_queries","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/docs/sql_queries.md","tags":[],"version":"current","frontMatter":{"title":"SQL Queries","summary":"In this page, we go over querying Hudi tables using SQL","toc":true,"last_modified_at":null},"sidebar":"docs","previous":{"title":"Streaming Writes","permalink":"/docs/next/writing_tables_streaming_writes"},"next":{"title":"Batch Reads","permalink":"/docs/next/reading_tables_batch_reads"}}');var r=t(74848),s=t(28453);t(11470),t(19365);const d={title:"SQL Queries",summary:"In this page, we go over querying Hudi tables using SQL",toc:!0,last_modified_at:null},a=void 0,o={},l=[{value:"Spark SQL",id:"spark-sql",level:2},{value:"Snapshot Query",id:"snapshot-query",level:3},{value:"Snapshot Query without Index Acceleration",id:"snapshot-query-without-index-acceleration",level:3},{value:"Query using Secondary Index",id:"query-using-secondary-index",level:3},{value:"Query using Bloom Filter Expression Index",id:"query-using-bloom-filter-expression-index",level:3},{value:"Query using Column Stats Expression Index",id:"query-using-column-stats-expression-index",level:3},{value:"Query using Partition Stats Index",id:"query-using-partition-stats-index",level:3},{value:"Snapshot Query with Event Time Ordering",id:"snapshot-query-with-event-time-ordering",level:3},{value:"Snapshot Query with Custom Merge Mode",id:"snapshot-query-with-custom-merge-mode",level:3},{value:"Time Travel Query",id:"time-travel-query",level:3},{value:"Change Data Capture",id:"change-data-capture",level:3},{value:"Incremental Query",id:"incremental-query",level:3},{value:"Query Indexes and Timeline",id:"query-indexes-and-timeline",level:3},{value:"Flink SQL",id:"flink-sql",level:2},{value:"Snapshot Query",id:"snapshot-query-1",level:3},{value:"Options",id:"options",level:4},{value:"Streaming Query",id:"streaming-query",level:3},{value:"Options",id:"options-1",level:4},{value:"Incremental Query",id:"incremental-query-1",level:3},{value:"Options",id:"options-2",level:4},{value:"Catalog",id:"catalog",level:3},{value:"Options",id:"options-3",level:4},{value:"Hive",id:"hive",level:2},{value:"Incremental Query",id:"incremental-query-2",level:3},{value:"AWS Athena",id:"aws-athena",level:2},{value:"Presto",id:"presto",level:2},{value:"Trino",id:"trino",level:2},{value:"Impala",id:"impala",level:2},{value:"Redshift Spectrum",id:"redshift-spectrum",level:2},{value:"Doris",id:"doris",level:2},{value:"StarRocks",id:"starrocks",level:2},{value:"ClickHouse",id:"clickhouse",level:2},{value:"Support Matrix",id:"support-matrix",level:2},{value:"Copy-On-Write tables",id:"copy-on-write-tables",level:3},{value:"Merge-On-Read tables",id:"merge-on-read-tables",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["Hudi stores and organizes data on storage while providing different ways of ",(0,r.jsx)(n.a,{href:"/docs/concepts#query-types",children:"querying"}),", across a wide range of query engines.\nThis page will show how to issue different queries and discuss any specific instructions for each query engine."]}),"\n",(0,r.jsx)(n.h2,{id:"spark-sql",children:"Spark SQL"}),"\n",(0,r.jsxs)(n.p,{children:["The Spark ",(0,r.jsx)(n.a,{href:"/docs/quick-start-guide",children:"quickstart"})," provides a good overview of how to use Spark SQL to query Hudi tables. This section will go into more advanced configurations and functionalities."]}),"\n",(0,r.jsx)(n.h3,{id:"snapshot-query",children:"Snapshot Query"}),"\n",(0,r.jsx)(n.p,{children:"Snapshot queries are the most common query type for Hudi tables. Spark SQL supports snapshot queries on both COPY_ON_WRITE and MERGE_ON_READ tables.\nUsing session properties, you can specify options around indexing to optimize query performance, as shown below."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- You can turn on relevant options for indexing. \n\n-- Turn on use of column stat index, to perform range queries.\nSET hoodie.metadata.column.stats.enable=true;\nSELECT * FROM hudi_table\nWHERE price > 1.0 and price < 10.0\n\n-- Turn on use of record level index, to perform point queries.\nSET hoodie.metadata.record.index.enable=true;\nSELECT * FROM hudi_table \nWHERE uuid = 'c8abbe79-8d89-47ea-b4ce-4d224bae5bfa'\n"})}),"\n",(0,r.jsx)(n.admonition,{title:"Integration with Spark",type:"note",children:(0,r.jsx)(n.p,{children:"Users are encouraged to migrate to Hudi versions > 0.12.x, for the best spark experience and discouraged from using any older approaches\nusing path filters. We expect that native integration with Spark's optimized table readers along with Hudi's automatic table\nmanagement will yield great performance benefits in those versions."})}),"\n",(0,r.jsx)(n.h3,{id:"snapshot-query-without-index-acceleration",children:"Snapshot Query without Index Acceleration"}),"\n",(0,r.jsx)(n.p,{children:"In this section we would go over the various indexes and how they help in data skipping in Hudi. We will first create\na hudi table without any index."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Create a table with primary key\nCREATE TABLE hudi_indexed_table (\n    ts BIGINT,\n    uuid STRING,\n    rider STRING,\n    driver STRING,\n    fare DOUBLE,\n    city STRING\n) USING HUDI\noptions(\n    primaryKey ='uuid',\n    hoodie.write.record.merge.mode = \"COMMIT_TIME_ORDERING\"\n)\nPARTITIONED BY (city);\n\nINSERT INTO hudi_indexed_table\nVALUES\n(1695159649,'334e26e9-8355-45cc-97c6-c31daf0df330','rider-A','driver-K',19.10,'san_francisco'),\n(1695091554,'e96c4396-3fad-413a-a942-4cb36106d721','rider-C','driver-M',27.70 ,'san_francisco'),\n(1695046462,'9909a8b1-2d15-4d3d-8ec9-efc48c536a00','rider-D','driver-L',33.90 ,'san_francisco'),\n(1695332066,'1dced545-862b-4ceb-8b43-d2a568f6616b','rider-E','driver-O',93.50,'san_francisco'),\n(1695516137,'e3cf430c-889d-4015-bc98-59bdce1e530c','rider-F','driver-P',34.15,'sao_paulo'    ),\n(1695376420,'7a84095f-737f-40bc-b62f-6b69664712d2','rider-G','driver-Q',43.40 ,'sao_paulo'    ),\n(1695173887,'3eeb61f7-c2b0-4636-99bd-5d7a5a1d2c04','rider-I','driver-S',41.06 ,'chennai'      ),\n(1695115999,'c8abbe79-8d89-47ea-b4ce-4d224bae5bfa','rider-J','driver-T',17.85,'chennai');\nUPDATE hudi_indexed_table SET rider = 'rider-B', driver = 'driver-N', ts = '1697516137' WHERE rider = 'rider-A';\n"})}),"\n",(0,r.jsx)(n.p,{children:"With the query run below, we will see no data skipping or pruning since there is no index created yet in the table as can\nbe seen in the image below. All the files are scanned in the table to fetch the data. Let's create a secondary index on the rider column."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"SHOW INDEXES FROM hudi_indexed_table;\nSELECT * FROM hudi_indexed_table WHERE rider = 'rider-B';\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Secondary Index Without Pruning Image",src:t(52252).A+"",width:"488",height:"272"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning without secondary index"})]}),"\n",(0,r.jsx)(n.h3,{id:"query-using-secondary-index",children:"Query using Secondary Index"}),"\n",(0,r.jsx)(n.p,{children:"We will run the query again after creating secondary index on rider column. The query would now\nshow the files scanned as 1 compared to 3 files scanned without index."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- We will first create a record index since secondary index is dependent upon it\nCREATE INDEX record_index ON hudi_indexed_table (uuid);\n-- We create a secondary index on rider column\nCREATE INDEX idx_rider ON hudi_indexed_table (rider);\n-- We run the same query again\nSELECT * FROM hudi_indexed_table WHERE rider = 'rider-B';\nDROP INDEX record_index on hudi_indexed_table;\nDROP INDEX secondary_index_idx_rider on hudi_indexed_table;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Secondary Index With Pruning Image",src:t(96146).A+"",width:"482",height:"252"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning with secondary index"})]}),"\n",(0,r.jsx)(n.h3,{id:"query-using-bloom-filter-expression-index",children:"Query using Bloom Filter Expression Index"}),"\n",(0,r.jsxs)(n.p,{children:["With the query run below, we will see no data skipping or pruning since there is no index created yet on the ",(0,r.jsx)(n.code,{children:"driver"})," column.\nAll the files are scanned in the table to fetch the data."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"SHOW INDEXES FROM hudi_indexed_table;\nSELECT * FROM hudi_indexed_table WHERE driver = 'driver-N';\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Bloom Filter Expression Index Without Pruning Image",src:t(6373).A+"",width:"486",height:"270"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning without bloom filter expression index"})]}),"\n",(0,r.jsx)(n.p,{children:"We will run the query again after creating bloom filter expression index on rider column. The query would now\nshow the files scanned as 1 compared to 3 files scanned without index."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- We create a bloom filter expression index on driver column\nCREATE INDEX idx_bloom_driver ON hudi_indexed_table USING bloom_filters(driver) OPTIONS(expr='identity');\n-- We run the same query again\nSELECT * FROM hudi_indexed_table WHERE driver = 'driver-N';\nDROP INDEX expr_index_idx_bloom_driver on hudi_indexed_table;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Bloom Filter Expression Index With Pruning Image",src:t(11977).A+"",width:"482",height:"250"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning with bloom filter expression index"})]}),"\n",(0,r.jsx)(n.h3,{id:"query-using-column-stats-expression-index",children:"Query using Column Stats Expression Index"}),"\n",(0,r.jsx)(n.p,{children:"With the query run below, we will see no data skipping or pruning since there is no index created yet in the table as can\nbe seen in the image below. All the files are scanned in the table to fetch the data."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"SHOW INDEXES FROM hudi_indexed_table;\nSELECT uuid, rider FROM hudi_indexed_table WHERE from_unixtime(ts, 'yyyy-MM-dd') = '2023-10-17';\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Column Stats Expression Index Without Pruning Image",src:t(72404).A+"",width:"484",height:"272"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning without column stat expression index"})]}),"\n",(0,r.jsx)(n.p,{children:"We will run the query again after creating column stat expression index on ts column. The query would now\nshow the files scanned as 1 compared to 3 files scanned without index."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- We create a column stat expression index on ts column\nCREATE INDEX idx_column_ts ON hudi_indexed_table USING column_stats(ts) OPTIONS(expr='from_unixtime', format = 'yyyy-MM-dd');\n-- We run the same query again\nSELECT uuid, rider FROM hudi_indexed_table WHERE from_unixtime(ts, 'yyyy-MM-dd') = '2023-10-17';\nDROP INDEX expr_index_idx_column_ts on hudi_indexed_table;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Column Stats Expression Index With Pruning Image",src:t(20746).A+"",width:"482",height:"250"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning with column stat expression index"})]}),"\n",(0,r.jsx)(n.h3,{id:"query-using-partition-stats-index",children:"Query using Partition Stats Index"}),"\n",(0,r.jsx)(n.p,{children:"With the query run below, we will see no data skipping or pruning since there is no partition stats index created yet in the table as can\nbe seen in the image below. All the partitions are scanned in the table to fetch the data."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"SHOW INDEXES FROM hudi_indexed_table;\nSELECT * FROM hudi_indexed_table WHERE rider >= 'rider-H';\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Partition Stats Index Without Pruning Image",src:t(61317).A+"",width:"492",height:"268"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning without partition stats index"})]}),"\n",(0,r.jsx)(n.p,{children:"We will run the query again after creating partition stats index. The query would now show the partitions scanned as 1\ncompared to 3 partitions scanned without index."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- We will need to enable column stats as well since partition stats index leverages it\nSET hoodie.metadata.index.partition.stats.enable=true;\nSET hoodie.metadata.index.column.stats.enable=true;\nINSERT INTO hudi_indexed_table\nVALUES\n(1695159649,'854g46e0-8355-45cc-97c6-c31daf0df330','rider-H','driver-T',19.10,'chennai');\n-- Run the query again on the table with partition stats index\nSELECT * FROM hudi_indexed_table WHERE rider >= 'rider-H';\nDROP INDEX column_stats on hudi_indexed_table;\nDROP INDEX partition_stats on hudi_indexed_table;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.img,{alt:"Partition Stats Index With Pruning Image",src:t(86825).A+"",width:"472",height:"244"}),"\n",(0,r.jsx)("p",{align:"left",children:"Figure: Query pruning with partition stats index"})]}),"\n",(0,r.jsx)(n.h3,{id:"snapshot-query-with-event-time-ordering",children:"Snapshot Query with Event Time Ordering"}),"\n",(0,r.jsxs)(n.p,{children:["Hudi supports different ",(0,r.jsx)(n.a,{href:"/docs/next/record_merger",children:"record merge modes"})," for merging the records from the same key. Event\ntime ordering is one of the merge modes where the records are merged based on the event time. Let's create a table with\nevent time ordering merge mode."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS hudi_table_merge_mode (\n  id INT,\n  name STRING,\n  ts LONG,\n  price DOUBLE\n) USING hudi\nTBLPROPERTIES (\n  type = 'mor',\n  primaryKey = 'id',\n  precombineField = 'ts',\n  recordMergeMode = 'EVENT_TIME_ORDERING'\n)\nLOCATION 'file:///tmp/hudi_table_merge_mode/';\n\n-- insert a record\nINSERT INTO hudi_table_merge_mode VALUES (1, 'a1', 1000, 10.0);\n\n-- another record with the same key but lower ts\nINSERT INTO hudi_table_merge_mode VALUES (1, 'a1', 900, 20.0);\n\n-- query the table, result should be id=1, name=a1, ts=1000, price=10.0\nSELECT id, name, ts, price FROM hudi_table_merge_mode;\n"})}),"\n",(0,r.jsxs)(n.p,{children:["With ",(0,r.jsx)(n.code,{children:"EVENT_TIME_ORDERING"}),", the record with the larger event time (",(0,r.jsx)(n.code,{children:"precombineField"}),") overwrites the record with the\nsmaller event time on the same key, regardless of transaction time."]}),"\n",(0,r.jsx)(n.h3,{id:"snapshot-query-with-custom-merge-mode",children:"Snapshot Query with Custom Merge Mode"}),"\n",(0,r.jsxs)(n.p,{children:["Users can set ",(0,r.jsx)(n.code,{children:"CUSTOM"})," mode to provide their own merge logic. With ",(0,r.jsx)(n.code,{children:"CUSTOM"})," merge mode, you also need to provide your\npayload class that implements the merge logic. For example, you can use ",(0,r.jsx)(n.code,{children:"PartialUpdateAvroPayload"})," to merge the records\nas below."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS hudi_table_merge_mode_custom (\n  id INT,\n  name STRING,\n  ts LONG,\n  price DOUBLE\n) USING hudi\nTBLPROPERTIES (\n  type = 'mor',\n  primaryKey = 'id',\n  precombineField = 'ts',\n  recordMergeMode = 'CUSTOM',\n  'hoodie.datasource.write.payload.class' = 'org.apache.hudi.common.model.PartialUpdateAvroPayload'\n)\nLOCATION 'file:///tmp/hudi_table_merge_mode_custom/';\n\n-- insert a record\nINSERT INTO hudi_table_merge_mode_custom VALUES (1, 'a1', 1000, 10.0);\n\n-- another record with the same key but set higher ts and name as null to show partial update\nINSERT INTO hudi_table_merge_mode_custom VALUES (1, null, 2000, 20.0);\n\n-- query the table, result should be id=1, name=a1, ts=2000, price=20.0\nSELECT id, name, ts, price FROM hudi_table_merge_mode_custom;\n"})}),"\n",(0,r.jsx)(n.p,{children:"As you can see, not only the record with higher ordering field overwrites the record with lower ordering value, but also\nthe name field is partially updated."}),"\n",(0,r.jsx)(n.h3,{id:"time-travel-query",children:"Time Travel Query"}),"\n",(0,r.jsxs)(n.p,{children:["You can also query the table at a specific commit time using the ",(0,r.jsx)(n.code,{children:"AS OF"})," syntax. This is useful for debugging and auditing purposes, as well as for\nmachine learning pipelines where you want to train models on a specific point in time."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM <table name> \nTIMESTAMP AS OF '<timestamp in yyyy-MM-dd HH:mm:ss.SSS or yyyy-MM-dd or yyyyMMddHHmmssSSS>' \nWHERE <filter conditions>\n"})}),"\n",(0,r.jsx)(n.h3,{id:"change-data-capture",children:"Change Data Capture"}),"\n",(0,r.jsxs)(n.p,{children:["Change Data Capture (CDC) queries are useful when you want to obtain all changes to a Hudi table within a given time window, along with before/after images and change operation\nof the changed records. Similar to many relational database counterparts, Hudi provides flexible ways of controlling supplemental logging levels, to balance storage/logging costs\nby materializing more versus compute costs of computing the changes on the fly, using ",(0,r.jsx)(n.code,{children:"hoodie.table.cdc.supplemental.logging.mode"})," configuration."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Supported through the hudi_table_changes TVF \nSELECT * \nFROM hudi_table_changes(\n  <pathToTable | tableName>, \n  'cdc', \n  <'earliest' | <time to capture from>> \n  [, <time to capture to>]\n)\n"})}),"\n",(0,r.jsx)(n.h1,{id:"add-note-on-checkpoint-translation-from-0x-to-1x-same-for-incremental-query-below",children:"add note on checkpoint translation from 0.x to 1.x. same for incremental query below"}),"\n",(0,r.jsx)(n.admonition,{title:"CDC Query Checkpointing between Hudi 0.x and 1.x",type:"note",children:(0,r.jsx)(n.p,{children:"In Hudi 1.0, we switch the incremental and CDC queries to used completion time, instead of requested instant time, to determine the\nrange of commits to incrementally pull from. The checkpoint stored for Hudi incremental source and related sources is\nalso changed to use completion time. To seamless migration without downtime or data duplication, Hudi does an automatic checkpoint\ntranslation from requested instant time to completion time depending on the source table version."})}),"\n",(0,r.jsx)(n.h3,{id:"incremental-query",children:"Incremental Query"}),"\n",(0,r.jsxs)(n.p,{children:["Incremental queries are useful when you want to obtain the latest values for all records that have changed after a given commit time. They help author incremental data pipelines with\norders of magnitude efficiency over batch counterparts by only processing the changed records. Hudi users have realized ",(0,r.jsx)(n.a,{href:"https://www.uber.com/blog/ubers-lakehouse-architecture/",children:"large gains"})," in\nquery efficiency by using incremental queries in this fashion. Hudi supports incremental queries on both COPY_ON_WRITE and MERGE_ON_READ tables."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Supported through the hudi_table_changes TVF \nSELECT * \nFROM hudi_table_changes(\n  <pathToTable | tableName>, \n  'latest_state', \n  <'earliest' | <time to capture from>> \n  [, <time to capture to>]\n)\n"})}),"\n",(0,r.jsx)(n.admonition,{title:"Incremental vs CDC Queries",type:"info",children:(0,r.jsx)(n.p,{children:"Incremental queries offer even better query efficiency than even the CDC queries above, since they amortize the cost of compactions across your data lake.\nFor e.g the table has received 10 million modifications across 1 million records over a time window, incremental queries can fetch the latest value for\n1 million records using Hudi's record level metadata. On the other hand, the CDC queries will process 10 million records and useful in cases, where you want to\nsee all changes in a given time window and not just the latest values."})}),"\n",(0,r.jsxs)(n.p,{children:["Please refer to ",(0,r.jsx)(n.a,{href:"/docs/basic_configurations",children:"configurations"})," section for the important configuration options."]}),"\n",(0,r.jsx)(n.admonition,{title:"Incremental Query Checkpointing between Hudi 0.x and 1.0.",type:"note",children:(0,r.jsx)(n.p,{children:"In Hudi 1.0, we switch the incremental and CDC query to used completion time, instead of instant time, to determine the\nrange of commits to incrementally pull from. The checkpoint stored for Hudi incremental source and related sources is\nalso changed to use completion time. To support compatiblity, Hudi does a checkpoint translation from requested instant\ntime to completion time depending on the source table version."})}),"\n",(0,r.jsx)(n.h3,{id:"query-indexes-and-timeline",children:"Query Indexes and Timeline"}),"\n",(0,r.jsx)(n.p,{children:"Hudi also allows users to directly query the metadata partitions and check the metadata corresponding to the table\nand the various indexes. In this section we will check the various queries which can be used for this purpose."}),"\n",(0,r.jsx)(n.p,{children:"Let's first create a table with various indexes created."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Create a table with primary key\nCREATE TABLE hudi_indexed_table (\n    ts BIGINT,\n    uuid STRING,\n    rider STRING,\n    driver STRING,\n    fare DOUBLE,\n    city STRING\n) USING HUDI\noptions(\n    primaryKey ='uuid',\n    hoodie.write.record.merge.mode = \"COMMIT_TIME_ORDERING\"\n)\nPARTITIONED BY (city);\n\n-- Create partition stat index\nSET hoodie.metadata.index.partition.stats.enable=true;\nSET hoodie.metadata.index.column.stats.enable=true;\n\nINSERT INTO hudi_indexed_table\nVALUES\n(1695159649,'334e26e9-8355-45cc-97c6-c31daf0df330','rider-A','driver-K',19.10,'san_francisco'),\n(1695091554,'e96c4396-3fad-413a-a942-4cb36106d721','rider-C','driver-M',27.70 ,'san_francisco'),\n(1695046462,'9909a8b1-2d15-4d3d-8ec9-efc48c536a00','rider-D','driver-L',33.90 ,'san_francisco'),\n(1695332066,'1dced545-862b-4ceb-8b43-d2a568f6616b','rider-E','driver-O',93.50,'san_francisco'),\n(1695516137,'e3cf430c-889d-4015-bc98-59bdce1e530c','rider-F','driver-P',34.15,'sao_paulo'    ),\n(1695376420,'7a84095f-737f-40bc-b62f-6b69664712d2','rider-G','driver-Q',43.40 ,'sao_paulo'    ),\n(1695173887,'3eeb61f7-c2b0-4636-99bd-5d7a5a1d2c04','rider-I','driver-S',41.06 ,'chennai'      ),\n(1695115999,'c8abbe79-8d89-47ea-b4ce-4d224bae5bfa','rider-J','driver-T',17.85,'chennai');\n\n-- Create column stat expression index on ts column\nCREATE INDEX idx_column_ts ON hudi_indexed_table USING column_stats(ts) OPTIONS(expr='from_unixtime', format = 'yyyy-MM-dd');\n-- Create secondary index on rider column\nCREATE INDEX record_index ON hudi_indexed_table (uuid);\nCREATE INDEX idx_rider ON hudi_indexed_table (rider);\nSET hoodie.metadata.record.index.enable=true;\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"-- Query the secondary keys stores in the secondary index partition\nSELECT key FROM hudi_metadata('hudi_indexed_table') WHERE type=7;\n\n-- Query the column stat records stored in the column stat indexes or column stat expression index\nselect ColumnStatsMetadata.columnName, ColumnStatsMetadata.minValue, ColumnStatsMetadata.maxValue from hudi_metadata('hudi_indexed_table') where type=3; \n-- Query can be further refined to get nested fields and exact values for a particular partition. \n-- Below query fetches the column stats metadata for column stat expression index on ts column.\nselect ColumnStatsMetadata.columnName, ColumnStatsMetadata.minValue.member6.value, ColumnStatsMetadata.maxValue.member6.value from hudi_metadata('hudi_indexed_table') where type=3 AND ColumnStatsMetadata.columnName='ts';\n\n-- Query the partition stat index records for rider column. Partition stat index records use the same schema as column stat index records\nselect ColumnStatsMetadata.columnName, ColumnStatsMetadata.minValue.member6.value, ColumnStatsMetadata.maxValue.member6.value from hudi_metadata('hudi_indexed_table') where type=6 AND ColumnStatsMetadata.columnName='rider';\n"})}),"\n",(0,r.jsx)(n.p,{children:"All the different index types can be queries by specifying the type column for that index. Here are the metadata partitions\nand the corresponding type column value."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"MDT Partition"}),(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"Type Column Value"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Files"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"2"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Column Stat"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"3"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Bloom Filters"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Record Index"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"5"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Secondary Index"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"7"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Partition Stats"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"6"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"flink-sql",children:"Flink SQL"}),"\n",(0,r.jsxs)(n.p,{children:["Once the Flink Hudi tables have been registered to the Flink catalog, they can be queried using the Flink SQL. It supports all query types across both Hudi table types,\nrelying on the custom Hudi input formats like Hive. Typically, notebook users and Flink SQL CLI users leverage flink sql for querying Hudi tables. Please add hudi-flink-bundle as described in the ",(0,r.jsx)(n.a,{href:"/docs/flink-quick-start-guide",children:"Flink Quickstart"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"snapshot-query-1",children:"Snapshot Query"}),"\n",(0,r.jsx)(n.p,{children:"By default, Flink SQL will try to use its optimized native readers (for e.g. reading parquet files) instead of Hive SerDes.\nAdditionally, partition pruning is applied by Flink if a partition predicate is specified in the filter. Filters push down may not be supported yet (please check Flink roadmap)."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"select * from hudi_table/*+ OPTIONS('metadata.enabled'='true', 'read.data.skipping.enabled'='false','hoodie.metadata.index.column.stats.enable'='true')*/;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"options",children:"Options"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Option Name"}),(0,r.jsx)(n.th,{children:"Required"}),(0,r.jsx)(n.th,{children:"Default"}),(0,r.jsx)(n.th,{children:"Remarks"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"metadata.enabled"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsxs)(n.td,{children:["Set to ",(0,r.jsx)(n.code,{children:"true"})," to enable"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"read.data.skipping.enabled"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"Whether to enable data skipping for batch snapshot read, by default disabled"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"hoodie.metadata.index.column.stats.enable"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"Whether to enable column statistics (max/min)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"hoodie.metadata.index.column.stats.column.list"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"N/A"}),(0,r.jsx)(n.td,{children:"Columns(separated by comma) to collect the column statistics"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"streaming-query",children:"Streaming Query"}),"\n",(0,r.jsxs)(n.p,{children:["By default, the hoodie table is read as batch, that is to read the latest snapshot data set and returns. Turns on the streaming read\nmode by setting option ",(0,r.jsx)(n.code,{children:"read.streaming.enabled"})," as ",(0,r.jsx)(n.code,{children:"true"}),". Sets up option ",(0,r.jsx)(n.code,{children:"read.start-commit"})," to specify the read start offset, specifies the\nvalue as ",(0,r.jsx)(n.code,{children:"earliest"})," if you want to consume all the history data set."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"select * from hudi_table/*+ OPTIONS('read.streaming.enabled'='true', 'read.start-commit'='earliest')*/;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"options-1",children:"Options"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Option Name"}),(0,r.jsx)(n.th,{children:"Required"}),(0,r.jsx)(n.th,{children:"Default"}),(0,r.jsx)(n.th,{children:"Remarks"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"read.streaming.enabled"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsxs)(n.td,{children:["Specify ",(0,r.jsx)(n.code,{children:"true"})," to read as streaming"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"read.start-commit"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:"the latest commit"}),(0,r.jsxs)(n.td,{children:["Start commit time in format 'yyyyMMddHHmmss', use ",(0,r.jsx)(n.code,{children:"earliest"})," to consume from the start commit"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"read.streaming.skip_compaction"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsxs)(n.td,{children:["Whether to skip compaction instants for streaming read, generally for two purpose: 1) Avoid consuming duplications from compaction instants created for created by Hudi versions < 0.11.0 or when ",(0,r.jsx)(n.code,{children:"hoodie.compaction.preserve.commit.metadata"})," is disabled 2) When change log mode is enabled, to only consume change for right semantics."]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"clean.retain_commits"})}),(0,r.jsx)(n.td,{children:"false"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"10"})}),(0,r.jsx)(n.td,{children:"The max number of commits to retain before cleaning, when change log mode is enabled, tweaks this option to adjust the change log live time. For example, the default strategy keeps 50 minutes of change logs if the checkpoint interval is set up as 5 minutes."})]})]})]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["Users are encouraged to use Hudi versions > 0.12.3, for the best experience and discouraged from using any older versions.\nSpecifically, ",(0,r.jsx)(n.code,{children:"read.streaming.skip_compaction"})," should only be enabled if the MOR table is compacted by Hudi with versions ",(0,r.jsx)(n.code,{children:"< 0.11.0"}),".\nThis is so as the ",(0,r.jsx)(n.code,{children:"hoodie.compaction.preserve.commit.metadata"})," feature is only introduced in Hudi versions ",(0,r.jsx)(n.code,{children:">=0.11.0"}),".\nOlder versions will overwrite the original commit time for each row with the compaction plan's instant time and cause\nrow-level instant range checks to not work properly."]})}),"\n",(0,r.jsx)(n.h3,{id:"incremental-query-1",children:"Incremental Query"}),"\n",(0,r.jsx)(n.p,{children:"There are 3 use cases for incremental query:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Streaming query: specify the start commit with option ",(0,r.jsx)(n.code,{children:"read.start-commit"}),";"]}),"\n",(0,r.jsxs)(n.li,{children:["Batch query: specify the start commit with option ",(0,r.jsx)(n.code,{children:"read.start-commit"})," and end commit with option ",(0,r.jsx)(n.code,{children:"read.end-commit"}),",\nthe interval is a closed one: both start commit and end commit are inclusive;"]}),"\n",(0,r.jsxs)(n.li,{children:["Time Travel: consume as batch for an instant time, specify the ",(0,r.jsx)(n.code,{children:"read.end-commit"})," is enough because the start commit is latest by default."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"select * from hudi_table/*+ OPTIONS('read.start-commit'='earliest', 'read.end-commit'='20231122155636355')*/;\n"})}),"\n",(0,r.jsx)(n.h4,{id:"options-2",children:"Options"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Option Name"}),(0,r.jsx)(n.th,{children:"Required"}),(0,r.jsx)(n.th,{children:"Default"}),(0,r.jsx)(n.th,{children:"Remarks"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"read.start-commit"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"the latest commit"}),(0,r.jsxs)(n.td,{children:["Specify ",(0,r.jsx)(n.code,{children:"earliest"})," to consume from the start commit"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"read.end-commit"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"the latest commit"}),(0,r.jsx)(n.td,{children:"--"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"catalog",children:"Catalog"}),"\n",(0,r.jsxs)(n.p,{children:["A Hudi catalog can manage the tables created by Flink, table metadata is persisted to avoid redundant table creation.\nThe catalog in ",(0,r.jsx)(n.code,{children:"hms"})," mode will supplement the Hive syncing parameters automatically."]}),"\n",(0,r.jsx)(n.p,{children:"A SQL demo for Catalog SQL in hms mode:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hoodie_catalog\nWITH (\n  'type'='hudi',\n  'catalog.path' = '${catalog root path}', -- only valid if the table options has no explicit declaration of table path\n  'hive.conf.dir' = '${dir path where hive-site.xml is located}',\n  'mode'='hms' -- also support 'dfs' mode so that all the table metadata are stored with the filesystem\n);\n"})}),"\n",(0,r.jsx)(n.h4,{id:"options-3",children:"Options"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Option Name"}),(0,r.jsx)(n.th,{children:"Required"}),(0,r.jsx)(n.th,{children:"Default"}),(0,r.jsx)(n.th,{children:"Remarks"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"catalog.path"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"true"})}),(0,r.jsx)(n.td,{children:"--"}),(0,r.jsxs)(n.td,{children:["Default catalog root path, it is used to infer a full table path in format: ",(0,r.jsx)(n.code,{children:"${catalog.path}/${db_name}/${table_name}"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"default-database"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"default"})}),(0,r.jsx)(n.td,{children:"Default database name"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"hive.conf.dir"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:"--"}),(0,r.jsxs)(n.td,{children:["Directory where hive-site.xml is located, only valid in ",(0,r.jsx)(n.code,{children:"hms"})," mode"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"mode"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"dfs"})}),(0,r.jsxs)(n.td,{children:["Specify as ",(0,r.jsx)(n.code,{children:"hms"})," to keep the table metadata with Hive metastore"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"table.external"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})}),(0,r.jsxs)(n.td,{children:["Whether to create external tables, only valid under ",(0,r.jsx)(n.code,{children:"hms"})," mode"]})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"hive",children:"Hive"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://hive.apache.org/",children:"Hive"})," has support for snapshot and incremental queries (with limitations) on Hudi tables."]}),"\n",(0,r.jsxs)(n.p,{children:["In order for Hive to recognize Hudi tables and query correctly, the ",(0,r.jsx)(n.code,{children:"hudi-hadoop-mr-bundle-<hudi.version>.jar"})," needs to be\nprovided to Hive2Server ",(0,r.jsx)(n.a,{href:"https://www.cloudera.com/documentation/enterprise/5-6-x/topics/cm_mc_hive_udf.html#concept_nc3_mms_lr",children:"aux jars path"}),", as well as\nadditionally, the bundle needs to be put on the hadoop/hive installation across the cluster. In addition to setup above, for beeline cli access,\nthe ",(0,r.jsx)(n.code,{children:"hive.input.format"})," variable needs to be set to the fully qualified path name of the inputformat ",(0,r.jsx)(n.code,{children:"org.apache.hudi.hadoop.HoodieParquetInputFormat"}),".\nFor Tez, additionally, the ",(0,r.jsx)(n.code,{children:"hive.tez.input.format"})," needs to be set to ",(0,r.jsx)(n.code,{children:"org.apache.hadoop.hive.ql.io.HiveInputFormat"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Then users should be able to issue snapshot queries against the table like any other Hive table."}),"\n",(0,r.jsx)(n.h3,{id:"incremental-query-2",children:"Incremental Query"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"# set hive session properties for incremental querying like below\n# type of query on the table\nset hoodie.<table_name>.consume.mode=INCREMENTAL;\n# Specify start timestamp to fetch first commit after this timestamp.\nset hoodie.<table_name>.consume.start.timestamp=20180924064621;\n# Max number of commits to consume from the start commit. Set this to -1 to get all commits after the starting commit.\nset hoodie.<table_name>.consume.max.commits=3;\n\n# usual hive query on hoodie table\nselect `_hoodie_commit_time`, col_1, col_2, col_4  from hudi_table where  col_1 = 'XYZ' and `_hoodie_commit_time` > '20180924064621';\n"})}),"\n",(0,r.jsx)(n.admonition,{title:"Hive incremental queries that are executed using Fetch task",type:"note",children:(0,r.jsxs)(n.p,{children:["Since Hive Fetch tasks invoke InputFormat.listStatus() per partition, metadata can be listed in\nevery such listStatus() call. In order to avoid this, it might be useful to disable fetch tasks\nusing the hive session property for incremental queries: ",(0,r.jsx)(n.code,{children:"set hive.fetch.task.conversion=none;"})," This\nwould ensure Map Reduce execution is chosen for a Hive query, which combines partitions (comma\nseparated) and calls InputFormat.listStatus() only once with all those partitions."]})}),"\n",(0,r.jsx)(n.h2,{id:"aws-athena",children:"AWS Athena"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://aws.amazon.com/athena/",children:"AWS Athena"})," is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL.\nIt supports ",(0,r.jsx)(n.a,{href:"https://docs.aws.amazon.com/athena/latest/ug/querying-hudi.html",children:"querying Hudi tables"})," using the Hive connector.\nCurrently, it supports snapshot queries on COPY_ON_WRITE tables, and snapshot and read optimized queries on MERGE_ON_READ Hudi tables."]}),"\n",(0,r.jsx)(n.admonition,{title:"The most recent release of Athena that supports querying Hudi 0.14.0 tables has a bug that causes _ro query to return 0 records, and occasionally _rt the query to fail with class cast exception.",type:"note",children:(0,r.jsxs)(n.p,{children:["The issue is tracked in ",(0,r.jsx)(n.a,{href:"https://issues.apache.org/jira/browse/HUDI-7362",children:"HUDI-7362"})," and is expected to be fixed in the next release."]})}),"\n",(0,r.jsx)(n.h2,{id:"presto",children:"Presto"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://prestodb.io/",children:"Presto"})," is a popular query engine for interactive query performance. Support for querying Hudi tables using PrestoDB is offered\nvia two connectors - Hive connector and Hudi connector (Presto version 0.275 onwards). Both connectors currently support snapshot queries on\nCOPY_ON_WRITE tables and snapshot and read optimized queries on MERGE_ON_READ Hudi tables."]}),"\n",(0,r.jsx)(n.p,{children:"Since Presto-Hudi integration has evolved over time, the installation instructions for PrestoDB would vary based on versions.\nPlease check the below table for query types supported and installation instructions."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"PrestoDB Version"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Installation description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Query types supported"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"< 0.233"}),(0,r.jsxs)(n.td,{children:["Requires the ",(0,r.jsx)(n.code,{children:"hudi-presto-bundle"})," jar to be placed into ",(0,r.jsx)(n.code,{children:"<presto_install>/plugin/hive-hadoop2/"}),", across the installation."]}),(0,r.jsx)(n.td,{children:"Snapshot querying on COW tables. Read optimized querying on MOR tables."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 0.233"}),(0,r.jsx)(n.td,{children:"No action needed. Hudi (0.5.1-incubating) is a compile time dependency."}),(0,r.jsx)(n.td,{children:"Snapshot querying on COW tables. Read optimized querying on MOR tables."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 0.240"}),(0,r.jsx)(n.td,{children:"No action needed. Hudi 0.5.3 version is a compile time dependency."}),(0,r.jsx)(n.td,{children:"Snapshot querying on both COW and MOR tables."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 0.268"}),(0,r.jsx)(n.td,{children:"No action needed. Hudi 0.9.0 version is a compile time dependency."}),(0,r.jsx)(n.td,{children:"Snapshot querying on bootstrap tables."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 0.272"}),(0,r.jsx)(n.td,{children:"No action needed. Hudi 0.10.1 version is a compile time dependency."}),(0,r.jsx)(n.td,{children:"File listing optimizations. Improved query performance."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 0.275"}),(0,r.jsx)(n.td,{children:"No action needed. Hudi 0.11.0 version is a compile time dependency."}),(0,r.jsx)(n.td,{children:"All of the above. Native Hudi connector that is on par with Hive connector."})]})]})]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["Incremental queries and point in time queries are not supported either through the Hive connector or Hudi\nconnector. However, it is in our roadmap, and you can track the development\nunder ",(0,r.jsx)(n.a,{href:"https://issues.apache.org/jira/browse/HUDI-3210",children:"HUDI-3210"}),"."]})}),"\n",(0,r.jsxs)(n.p,{children:["To use the Hudi connector, please configure hudi catalog in ",(0,r.jsx)(n.code,{children:" /presto-server-0.2xxx/etc/catalog/hudi.properties"})," as follows:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-properties",children:"connector.name=hudi\nhive.metastore.uri=thrift://xxx.xxx.xxx.xxx:9083\nhive.config.resources=.../hadoop-2.x/etc/hadoop/core-site.xml,.../hadoop-2.x/etc/hadoop/hdfs-site.xml\n"})}),"\n",(0,r.jsxs)(n.p,{children:["To learn more about the usage of Hudi connector, please read ",(0,r.jsx)(n.a,{href:"https://prestodb.io/docs/current/connector/hudi.html",children:"prestodb documentation"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"trino",children:"Trino"}),"\n",(0,r.jsxs)(n.p,{children:["Similar to PrestoDB, Trino allows querying Hudi tables via either the ",(0,r.jsx)(n.a,{href:"https://trino.io/docs/current/connector/hive.html",children:"Hive"})," connector or\nthe native ",(0,r.jsx)(n.a,{href:"https://trino.io/docs/current/connector/hudi.html",children:"Hudi"})," connector (introduced in version 398). For Trino version 411 or newer,\nthe Hive connector redirects to the Hudi catalog for Hudi table reads. Ensure you configure the necessary settings for\ntable redirection when using the Hive connector on these versions."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-properties",children:"hive.hudi-catalog-name=hudi\n"})}),"\n",(0,r.jsxs)(n.admonition,{title:"Installation instructions",type:"note",children:[(0,r.jsxs)(n.p,{children:["We recommend using ",(0,r.jsx)(n.code,{children:"hudi-trino-bundle"})," version 0.12.2 or later for optimal query performance with Hive connector. Table below\nsummarizes how the support for Hudi is achieved across different versions of Trino."]}),(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Trino Version"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Installation description"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Query types supported"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"< 398"}),(0,r.jsx)(n.td,{children:"NA - can only use Hive connector to query Hudi tables"}),(0,r.jsx)(n.td,{children:"Same as that of Hive connector version < 406."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 398"}),(0,r.jsx)(n.td,{children:"NA - no need to place bundle jars manually, as they are compile-time dependency"}),(0,r.jsx)(n.td,{children:"Snapshot querying on COW tables. Read optimized querying on MOR tables."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"< 406"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"hudi-trino-bundle"})," jar to be placed into ",(0,r.jsx)(n.code,{children:"<trino_install>/plugin/hive"})]}),(0,r.jsx)(n.td,{children:"Snapshot querying on COW tables. Read optimized querying on MOR tables."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 406"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"hudi-trino-bundle"})," jar to be placed into ",(0,r.jsx)(n.code,{children:"<trino_install>/plugin/hive"})]}),(0,r.jsxs)(n.td,{children:["Snapshot querying on COW tables. Read optimized querying on MOR tables. ",(0,r.jsx)(n.strong,{children:"Redirection to Hudi catalog also supported."})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"> = 411"}),(0,r.jsx)(n.td,{children:"NA"}),(0,r.jsxs)(n.td,{children:["Snapshot querying on COW tables. Read optimized querying on MOR tables. Hudi tables can be ",(0,r.jsx)(n.strong,{children:"only"})," queried by ",(0,r.jsx)(n.a,{href:"https://trino.io/docs/current/connector/hive.html#table-redirection",children:"table redirection"}),"."]})]})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["For details on the Hudi connector, see the ",(0,r.jsx)(n.a,{href:"https://trino.io/docs/current/connector/hudi.html",children:"connector documentation"}),".\nBoth connectors offer 'Snapshot' queries for COW tables and 'Read Optimized' queries for MOR tables.\nSupport for ",(0,r.jsx)(n.a,{href:"https://github.com/trinodb/trino/pull/14786",children:"MOR table snapshot queries"})," is anticipated shortly."]}),"\n",(0,r.jsx)(n.h2,{id:"impala",children:"Impala"}),"\n",(0,r.jsxs)(n.p,{children:["Impala (versions > 3.4) is able to query Hudi Copy-on-write tables as an ",(0,r.jsx)(n.a,{href:"https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_tables.html#external_tables",children:"EXTERNAL TABLES"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"To create a Hudi read optimized table on Impala:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE EXTERNAL TABLE database.table_name\nLIKE PARQUET '/path/to/load/xxx.parquet'\nSTORED AS HUDIPARQUET\nLOCATION '/path/to/load';\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Impala is able to take advantage of the partition pruning to improve the query performance, using traditional Hive style partitioning.\nTo create a partitioned table, the folder should follow the naming convention like ",(0,r.jsx)(n.code,{children:"year=2020/month=1"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"To create a partitioned Hudi table on Impala:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE EXTERNAL TABLE database.table_name\nLIKE PARQUET '/path/to/load/xxx.parquet'\nPARTITION BY (year int, month int, day int)\nSTORED AS HUDIPARQUET\nLOCATION '/path/to/load';\nALTER TABLE database.table_name RECOVER PARTITIONS;\n"})}),"\n",(0,r.jsx)(n.p,{children:"After Hudi made a new commit, refresh the Impala table to get the latest snapshot exposed to queries."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"REFRESH database.table_name\n"})}),"\n",(0,r.jsx)(n.h2,{id:"redshift-spectrum",children:"Redshift Spectrum"}),"\n",(0,r.jsx)(n.p,{children:"Copy on Write Tables in Apache Hudi versions 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.9.0, 0.10.x and 0.11.x can be queried\nvia Amazon Redshift Spectrum external tables. To be able to query Hudi versions 0.10.0 and above please try latest\nversions of Redshift."}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"Hudi tables are supported only when AWS Glue Data Catalog is used. It's not supported when you use an Apache\nHive metastore as the external catalog."})}),"\n",(0,r.jsxs)(n.p,{children:["Please refer\nto ",(0,r.jsx)(n.a,{href:"https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html#c-spectrum-column-mapping-hudi",children:"Redshift Spectrum Integration with Apache Hudi"}),"\nfor more details."]}),"\n",(0,r.jsx)(n.h2,{id:"doris",children:"Doris"}),"\n",(0,r.jsxs)(n.p,{children:["The Doris integration currently support Copy on Write and Merge On Read tables in Hudi since version 0.10.0. You can query Hudi tables via Doris from Doris version 2.0 Doris offers a multi-catalog, which is designed to make it easier to connect to external data catalogs to enhance Doris's data lake analysis and federated data query capabilities. Please refer\nto ",(0,r.jsx)(n.a,{href:"https://doris.apache.org/docs/lakehouse/multi-catalog/hudi/",children:"Doris-Hudi external catalog"})," for more details on the setup."]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"The current default supported version of Hudi is 0.10.0 ~ 0.13.1, and has not been tested in other versions. More versions will be supported in the future."})}),"\n",(0,r.jsx)(n.h2,{id:"starrocks",children:"StarRocks"}),"\n",(0,r.jsxs)(n.p,{children:["For Copy-on-Write tables StarRocks provides support for Snapshot queries and for Merge-on-Read tables, StarRocks provides support for Snapshot and Read Optimized queries.\nPlease refer ",(0,r.jsx)(n.a,{href:"https://docs.starrocks.io/docs/data_source/catalog/hudi_catalog/",children:"StarRocks docs"})," for more details."]}),"\n",(0,r.jsx)(n.h2,{id:"clickhouse",children:"ClickHouse"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/en/intro",children:"ClickHouse"})," is a column-oriented database for online analytical processing. It\nprovides a read-only integration with Copy on Write Hudi tables. To query such Hudi tables, first we need\nto create a table in Clickhouse using ",(0,r.jsx)(n.code,{children:"Hudi"})," ",(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/en/sql-reference/table-functions/hudi",children:"table function"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE hudi_table\n    ENGINE = Hudi(s3_base_path, [aws_access_key_id, aws_secret_access_key,])\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Please refer ",(0,r.jsx)(n.a,{href:"https://clickhouse.com/docs/en/engines/table-engines/integrations/hudi/",children:"Clickhouse docs"})," for more\ndetails."]}),"\n",(0,r.jsx)(n.h2,{id:"support-matrix",children:"Support Matrix"}),"\n",(0,r.jsx)(n.p,{children:"Following tables show whether a given query is supported on specific query engine."}),"\n",(0,r.jsx)(n.h3,{id:"copy-on-write-tables",children:"Copy-On-Write tables"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Query Engine"}),(0,r.jsx)(n.th,{children:"Snapshot Queries"}),(0,r.jsx)(n.th,{children:"Incremental Queries"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Hive"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Spark SQL"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Flink SQL"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"PrestoDB"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Trino"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"AWS Athena"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"BigQuery"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Impala"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Redshift Spectrum"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Doris"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"StarRocks"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"ClickHouse"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"merge-on-read-tables",children:"Merge-On-Read tables"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Query Engine"}),(0,r.jsx)(n.th,{children:"Snapshot Queries"}),(0,r.jsx)(n.th,{children:"Incremental Queries"}),(0,r.jsx)(n.th,{children:"Read Optimized Queries"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Hive"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Spark SQL"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Spark Datasource"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Flink SQL"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"PrestoDB"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"AWS Athena"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Big Query"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Trino"})}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Impala"})}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Redshift Spectrum"})}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Doris"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"StarRocks"})}),(0,r.jsx)(n.td,{children:"Y"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"Y"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"ClickHouse"})}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"N"}),(0,r.jsx)(n.td,{children:"N"})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},19365:(e,n,t)=>{t.d(n,{A:()=>d});t(96540);var i=t(34164);const r={tabItem:"tabItem_Ymn6"};var s=t(74848);function d(e){let{children:n,hidden:t,className:d}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,i.A)(r.tabItem,d),hidden:t,children:n})}},11470:(e,n,t)=>{t.d(n,{A:()=>_});var i=t(96540),r=t(34164),s=t(23104),d=t(56347),a=t(205),o=t(57485),l=t(31682),c=t(70679);function h(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return h(e).map((e=>{let{props:{value:n,label:t,attributes:i,default:r}}=e;return{value:n,label:t,attributes:i,default:r}}))}(t);return function(e){const n=(0,l.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function x(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const r=(0,d.W6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,o.aZ)(s),(0,i.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(r.location.search);n.set(s,e),r.replace({...r.location,search:n.toString()})}),[s,r])]}function p(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,s=u(e),[d,o]=(0,i.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!x({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const i=t.find((e=>e.default))??t[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:s}))),[l,h]=m({queryString:t,groupId:r}),[p,j]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,s]=(0,c.Dv)(t);return[r,(0,i.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:r}),g=(()=>{const e=l??p;return x({value:e,tabValues:s})?e:null})();(0,a.A)((()=>{g&&o(g)}),[g]);return{selectedValue:d,selectValue:(0,i.useCallback)((e=>{if(!x({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);o(e),h(e),j(e)}),[h,j,s]),tabValues:s}}var j=t(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(74848);function f(e){let{className:n,block:t,selectedValue:i,selectValue:d,tabValues:a}=e;const o=[],{blockElementScrollPositionUntilNextRender:l}=(0,s.a_)(),c=e=>{const n=e.currentTarget,t=o.indexOf(n),r=a[t].value;r!==i&&(l(n),d(r))},h=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},n),children:a.map((e=>{let{value:n,label:t,attributes:s}=e;return(0,b.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>o.push(e),onKeyDown:h,onClick:c,...s,className:(0,r.A)("tabs__item",g.tabItem,s?.className,{"tabs__item--active":i===n}),children:t??n},n)}))})}function y(e){let{lazy:n,children:t,selectedValue:s}=e;const d=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=d.find((e=>e.props.value===s));return e?(0,i.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:d.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function v(e){const n=p(e);return(0,b.jsxs)("div",{className:(0,r.A)("tabs-container",g.tabList),children:[(0,b.jsx)(f,{...n,...e}),(0,b.jsx)(y,{...n,...e})]})}function _(e){const n=(0,j.A)();return(0,b.jsx)(v,{...e,children:h(e.children)},String(n))}},11977:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/bloom-filter-expression-index-with-pruning-3db9d660d2d9818ae43bf5ef1de31d7e.png"},6373:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/bloom-filter-expression-index-without-pruning-7b12429bab3b69bd1f9d5497b4f46dff.png"},20746:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/column-stat-expression-index-with-pruning-b16601b3b40cb234876abbeaa852f616.png"},72404:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/column-stat-expression-index-without-pruning-a226bed645b62afb015878dd804ed1cb.png"},86825:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/partition-stat-index-with-pruning-96619526139d552e8ca9e04b34445627.png"},61317:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/partition-stat-index-without-pruning-0410d0a3ed9cb4a7b58b4b3a5248127b.png"},96146:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/secondary-index-with-pruning-fe597dc3c909852d4537c55e0afd61b0.png"},52252:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/secondary-index-without-pruning-f6448697ae2531d825370e94a2536384.png"},28453:(e,n,t)=>{t.d(n,{R:()=>d,x:()=>a});var i=t(96540);const r={},s=i.createContext(r);function d(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);
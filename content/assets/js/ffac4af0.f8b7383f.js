"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[42368],{83565:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>n,toc:()=>c});var n=t(91251),i=t(74848),o=t(28453);const s={title:"Apache Hudi - The Data Lake Platform",excerpt:"It's been called many things. But, we have always been building a data lake platform",author:"vinoth",category:"blog",image:"/assets/images/blog/hudi_streaming.png",tags:["datalake platform","blog","apache hudi"]},r=void 0,l={authorsImageUrls:[void 0]},c=[];function d(e){const a={a:"a",em:"em",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,i.jsxs)(a.p,{children:["As early as 2016, we set out a ",(0,i.jsx)(a.a,{href:"https://www.oreilly.com/content/ubers-case-for-incremental-processing-on-hadoop/",children:"bold, new vision"})," reimagining batch data processing through a new \u201c",(0,i.jsx)(a.strong,{children:"incremental"}),"\u201d data processing stack - alongside the existing batch and streaming stacks.\nWhile a stream processing pipeline does row-oriented processing, delivering a few seconds of processing latency, an incremental pipeline would apply the same principles to ",(0,i.jsx)(a.em,{children:"columnar"})," data in the data lake,\ndelivering orders of magnitude improvements in processing efficiency within few minutes, on extremely scalable batch storage/compute infrastructure. This new stack would be able to effortlessly support regular batch processing for bulk reprocessing/backfilling as well.\nHudi was built as the manifestation of this vision, rooted in real, hard problems faced at ",(0,i.jsx)(a.a,{href:"https://eng.uber.com/uber-big-data-platform/",children:"Uber"})," and later took a life of its own in the open source community. Together, we have been able to\nusher in fully incremental data ingestion and moderately complex ETLs on data lakes already."]})}function p(e={}){const{wrapper:a}={...(0,o.R)(),...e.components};return a?(0,i.jsx)(a,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},28453:(e,a,t)=>{t.d(a,{R:()=>s,x:()=>r});var n=t(96540);const i={},o=n.createContext(i);function s(e){const a=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),n.createElement(o.Provider,{value:a},e.children)}},91251:e=>{e.exports=JSON.parse('{"permalink":"/blog/2021/07/21/streaming-data-lake-platform","editUrl":"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2021-07-21-streaming-data-lake-platform.md","source":"@site/blog/2021-07-21-streaming-data-lake-platform.md","title":"Apache Hudi - The Data Lake Platform","description":"As early as 2016, we set out a bold, new vision reimagining batch data processing through a new \u201cincremental\u201d data processing stack - alongside the existing batch and streaming stacks.","date":"2021-07-21T00:00:00.000Z","tags":[{"inline":true,"label":"datalake platform","permalink":"/blog/tags/datalake-platform"},{"inline":true,"label":"blog","permalink":"/blog/tags/blog"},{"inline":true,"label":"apache hudi","permalink":"/blog/tags/apache-hudi"}],"readingTime":28.99,"hasTruncateMarker":true,"authors":[{"name":"vinoth","key":null,"page":null}],"frontMatter":{"title":"Apache Hudi - The Data Lake Platform","excerpt":"It\'s been called many things. But, we have always been building a data lake platform","author":"vinoth","category":"blog","image":"/assets/images/blog/hudi_streaming.png","tags":["datalake platform","blog","apache hudi"]},"unlisted":false,"prevItem":{"title":"Baixin bank\u2019s real-time data lake evolution scheme based on Apache Hudi","permalink":"/blog/2021/07/26/Baixin-banksreal-time-data-lake-evolution-scheme-based-on-Apache-Hudi"},"nextItem":{"title":"Amazon Athena expands Apache Hudi support","permalink":"/blog/2021/07/16/Amazon-Athena-expands-Apache-Hudi-support"}}')}}]);
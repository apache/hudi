"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[70117],{1983:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>n,metadata:()=>a,toc:()=>c});var a=i(69342),s=i(74848),o=i(28453);const n={title:"Reliable ingestion from AWS S3 using Hudi",excerpt:"From listing to log-based approach, a reliable way of ingesting data from AWS S3 into Hudi.",author:"codope",category:"blog",image:"/assets/images/blog/s3_events_source_design.png",tags:["design","deltastreamer","apache hudi"]},r=void 0,l={authorsImageUrls:[void 0]},c=[];function d(e){const t={a:"a",p:"p",...(0,o.R)(),...e.components};return(0,s.jsxs)(t.p,{children:["In this post we will talk about a new deltastreamer source which reliably and efficiently processes new data files as they arrive in AWS S3.\nAs of today, to ingest data from S3 into Hudi, users leverage DFS source whose ",(0,s.jsx)(t.a,{href:"https://github.com/apache/hudi/blob/178767948e906f673d6d4a357c65c11bc574f619/hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/helpers/DFSPathSelector.java",children:"path selector"})," would identify the source files modified since the last checkpoint based on max modification time.\nThe problem with this approach is that modification time precision is upto seconds in S3. It maybe possible that there were many files (beyond what the configurable source limit allows) modifed in that second and some files might be skipped.\nFor more details, please refer to ",(0,s.jsx)(t.a,{href:"https://issues.apache.org/jira/browse/HUDI-1723",children:"HUDI-1723"}),".\nWhile the workaround is to ignore the source limit and keep reading, the problem motivated us to redesign so that users can reliably ingest from S3."]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>n,x:()=>r});var a=i(96540);const s={},o=a.createContext(s);function n(e){const t=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:n(e.components),a.createElement(o.Provider,{value:t},e.children)}},69342:e=>{e.exports=JSON.parse('{"permalink":"/blog/2021/08/23/s3-events-source","editUrl":"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2021-08-23-s3-events-source.md","source":"@site/blog/2021-08-23-s3-events-source.md","title":"Reliable ingestion from AWS S3 using Hudi","description":"In this post we will talk about a new deltastreamer source which reliably and efficiently processes new data files as they arrive in AWS S3.","date":"2021-08-23T00:00:00.000Z","tags":[{"inline":true,"label":"design","permalink":"/blog/tags/design"},{"inline":true,"label":"deltastreamer","permalink":"/blog/tags/deltastreamer"},{"inline":true,"label":"apache hudi","permalink":"/blog/tags/apache-hudi"}],"readingTime":6.7,"hasTruncateMarker":true,"authors":[{"name":"codope","key":null,"page":null}],"frontMatter":{"title":"Reliable ingestion from AWS S3 using Hudi","excerpt":"From listing to log-based approach, a reliable way of ingesting data from AWS S3 into Hudi.","author":"codope","category":"blog","image":"/assets/images/blog/s3_events_source_design.png","tags":["design","deltastreamer","apache hudi"]},"unlisted":false,"prevItem":{"title":"Asynchronous Clustering using Hudi","permalink":"/blog/2021/08/23/async-clustering"},"nextItem":{"title":"Improving Marker Mechanism in Apache Hudi","permalink":"/blog/2021/08/18/improving-marker-mechanism"}}')}}]);
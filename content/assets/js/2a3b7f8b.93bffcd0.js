"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[39650],{11171(e,r,i){i.r(r),i.d(r,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>d,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"record_merger","title":"Record Merger","description":"Hudi handles mutations to records and streaming data as briefly touched upon in the timeline ordering section.","source":"@site/versioned_docs/version-1.1.0/record_merger.md","sourceDirName":".","slug":"/record_merger","permalink":"/docs/record_merger","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/versioned_docs/version-1.1.0/record_merger.md","tags":[],"version":"1.1.0","frontMatter":{"title":"Record Merger","keywords":["hudi","merge","upsert","precombine"],"toc":true,"toc_min_heading_level":2,"toc_max_heading_level":4},"sidebar":"docs","previous":{"title":"Key Generation","permalink":"/docs/key_generation"},"next":{"title":"Table Metadata","permalink":"/docs/metadata"}}');var n=i(74848),t=i(28453);const d={title:"Record Merger",keywords:["hudi","merge","upsert","precombine"],toc:!0,toc_min_heading_level:2,toc_max_heading_level:4},s=void 0,a={},c=[{value:"Merge Modes",id:"merge-modes",level:2},{value:"<code>COMMIT_TIME_ORDERING</code>",id:"commit_time_ordering",level:3},{value:"<code>EVENT_TIME_ORDERING</code>",id:"event_time_ordering",level:3},{value:"<code>CUSTOM</code>",id:"custom",level:3},{value:"Implementation Guidelines",id:"implementation-guidelines",level:4},{value:"Merge Mode Configs",id:"merge-mode-configs",level:3},{value:"Record Payloads (deprecated)",id:"record-payloads-deprecated",level:2},{value:"OverwriteWithLatestAvroPayload (deprecated)",id:"overwritewithlatestavropayload-deprecated",level:3},{value:"DefaultHoodieRecordPayload (deprecated)",id:"defaulthoodierecordpayload-deprecated",level:3},{value:"EventTimeAvroPayload (deprecated)",id:"eventtimeavropayload-deprecated",level:3},{value:"OverwriteNonDefaultsWithLatestAvroPayload (deprecated)",id:"overwritenondefaultswithlatestavropayload-deprecated",level:3},{value:"PartialUpdateAvroPayload (deprecated)",id:"partialupdateavropayload-deprecated",level:3},{value:"Record Payload Configs (deprecated)",id:"record-payload-configs-deprecated",level:3},{value:"Related Resources",id:"related-resources",level:2},{value:"Blogs",id:"blogs",level:3}];function l(e){const r={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(r.p,{children:["Hudi handles mutations to records and streaming data as briefly touched upon in the ",(0,n.jsx)(r.a,{href:"/docs/timeline#ordering-of-actions",children:"timeline ordering"})," section.\nTo provide users with full-fledged support for stream processing, Hudi goes to great lengths to make the storage engine and the underlying storage format understand how to merge changes to the same record key, which may arrive in different orders at different times. With the rise of mobile applications and IoT, these scenarios have become the norm rather than an exception. For example, a social networking application may upload user events several hours after they occur when the user reconnects to Wi\u2011Fi."]}),"\n",(0,n.jsx)(r.h2,{id:"merge-modes",children:"Merge Modes"}),"\n",(0,n.jsx)(r.p,{children:"To address these challenges, Hudi supports merge modes, which define how the base and log files are ordered in a file slice and how different records with the same record key within that file slice are merged consistently to produce the same deterministic results for snapshot queries, writers, and table services."}),"\n",(0,n.jsx)(r.p,{children:"The merge mode is a table-level configuration used in the following code paths:"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"(writing)"})," Combining multiple change records for the same record key while reading input data during writes. This is an optional optimization that reduces the number of records written to log files to improve query and write performance subsequently."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"(writing)"})," Merging the final change record (partial/full update/delete) against the existing record in storage for COW tables."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"(compaction)"})," Compaction service merges all change records in log files against base files, respecting the merge mode."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"(query)"})," Merging change records in log files, after filtering and projections against the base file for MOR table queries."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(r.p,{children:["There are three merge modes: ",(0,n.jsx)(r.code,{children:"COMMIT_TIME_ORDERING"}),", ",(0,n.jsx)(r.code,{children:"EVENT_TIME_ORDERING"}),", and ",(0,n.jsx)(r.code,{children:"CUSTOM"}),". The default merge mode is automatically inferred based on whether any ordering field is configured. If you do not specify an ordering field (e.g., ",(0,n.jsx)(r.code,{children:"hoodie.table.ordering.fields"}),"), the merge mode defaults to ",(0,n.jsx)(r.code,{children:"COMMIT_TIME_ORDERING"}),", which replaces the old record with the new one from the incoming batch. If you do specify one or more ordering fields, the merge mode defaults to ",(0,n.jsx)(r.code,{children:"EVENT_TIME_ORDERING"}),", which compares records based on the ordering field values to handle out-of-order data."]}),"\n",(0,n.jsxs)(r.p,{children:["You can explicitly configure the merge mode using the write config ",(0,n.jsx)(r.code,{children:"hoodie.write.record.merge.mode"}),". When you create or write to a table with this config, it will be persisted to the table's configuration file (",(0,n.jsx)(r.code,{children:"hoodie.properties"}),") as ",(0,n.jsx)(r.code,{children:"hoodie.record.merge.mode"}),". Once persisted, all subsequent reads and writes will use this merge mode unless explicitly overridden in the write config."]}),"\n",(0,n.jsxs)(r.p,{children:["Merge mode is the way to choose and configure the record merger for your tables. For most use cases, you can choose ",(0,n.jsx)(r.code,{children:"COMMIT_TIME_ORDERING"})," or ",(0,n.jsx)(r.code,{children:"EVENT_TIME_ORDERING"})," by setting the appropriate ordering field(s) without any additional configuration or implementation. These modes provide standard merging behaviors that cover the majority of scenarios. For advanced use cases requiring custom merge logic, you can use the ",(0,n.jsx)(r.code,{children:"CUSTOM"})," merge mode and implement the ",(0,n.jsx)(r.code,{children:"HoodieRecordMerger"})," interface."]}),"\n",(0,n.jsx)(r.admonition,{type:"note",children:(0,n.jsx)(r.p,{children:"The merge mode should not be altered once a table is created to avoid inconsistent behavior due to compaction producing different merge results when switching between modes."})}),"\n",(0,n.jsx)(r.h3,{id:"commit_time_ordering",children:(0,n.jsx)(r.code,{children:"COMMIT_TIME_ORDERING"})}),"\n",(0,n.jsx)(r.p,{children:"Here, we expect the input records to arrive in strict order such that arrival order matches their\ndelta commit order on the table. Merging picks the record belonging to the latest write as the merged result. In relational data model terms,\nthis provides overwrite semantics aligned with serializable writes on the timeline."}),"\n",(0,n.jsx)("figure",{children:(0,n.jsx)("img",{className:"docimage",src:i(38526).A,alt:"upsert_path.png"})}),"\n",(0,n.jsx)(r.p,{children:"In the example above, the writer process consumes a database change log, expected to be in strict order of a logical sequence number (lsn)\nthat denotes the ordering of the writes in the upstream database."}),"\n",(0,n.jsx)(r.h3,{id:"event_time_ordering",children:(0,n.jsx)(r.code,{children:"EVENT_TIME_ORDERING"})}),"\n",(0,n.jsxs)(r.p,{children:["This is the default merge mode. While commit time ordering provides a well-understood standard behavior, it's hardly sufficient. The commit time is unrelated to the actual\nordering of data that a user may care about and strict ordering of input in complex distributed systems is difficult to achieve.\nWith event time ordering, the merging picks the record with the highest value on a user-specified ",(0,n.jsx)(r.em,{children:(0,n.jsx)(r.strong,{children:"ordering or precombine field"})})," as the merged result."]}),"\n",(0,n.jsx)("figure",{children:(0,n.jsx)("img",{className:"docimage",src:i(57159).A,alt:"upsert_path.png"})}),"\n",(0,n.jsxs)(r.p,{children:['In the example above, two microservices produce change records about orders at different times that can arrive out of order. As color-coded,\nthis can lead to application-level inconsistent states in the table if simply merged in commit time order like a canceled order being re-created or\na paid order moved back to just-created state expecting payment again. Event time ordering helps by ignoring older state changes that arrive late and\navoiding order status from "jumping back" in time. Combined with ',(0,n.jsx)(r.a,{href:"/docs/concurrency_control#non-blocking-concurrency-control-mode",children:"non-blocking concurrency control"}),",\nthis provides a very powerful way to process such data streams efficiently and correctly."]}),"\n",(0,n.jsx)(r.h3,{id:"custom",children:(0,n.jsx)(r.code,{children:"CUSTOM"})}),"\n",(0,n.jsx)(r.admonition,{type:"tip",children:(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"For most users:"})," The built-in ",(0,n.jsx)(r.code,{children:"COMMIT_TIME_ORDERING"})," and ",(0,n.jsx)(r.code,{children:"EVENT_TIME_ORDERING"})," merge modes should be sufficient. Only use ",(0,n.jsx)(r.code,{children:"CUSTOM"})," mode if you need specialized merge logic that cannot be achieved with the standard modes."]})}),"\n",(0,n.jsx)(r.p,{children:'In some cases, even more control and customization may be needed. Extending the example above, the two microservices could be updating two different\nsets of columns "order_info" and "payment_info", along with order state. The merge logic is then expected to not only resolve the correct status, but merge\norder_info from the record in created state into the record in the canceled state that already has payment_info fields populated with reasons payment failed.\nSuch reconciliation provides a simple denormalized data model for downstream consumption where queries (for example, fraud detection) can simply filter fields\nacross order_info and payment_info without costly self-joins on each access.'}),"\n",(0,n.jsxs)(r.p,{children:["To implement custom merge logic, you need to implement the ",(0,n.jsx)(r.code,{children:"HoodieRecordMerger"})," interface. Hudi allows the authoring of cross-language custom record mergers on top of a standard record merger API, which supports full and partial merges. The ",(0,n.jsx)(r.code,{children:"HoodieRecordMerger"})," interface uses the ",(0,n.jsx)(r.code,{children:"BufferedRecord"})," class to provide better performance and consistency by working directly with engine-native record formats without requiring conversion to Avro."]}),"\n",(0,n.jsxs)(r.p,{children:["The ",(0,n.jsx)(r.code,{children:"BufferedRecord"})," class wraps the record data along with key information such as the record key, ordering value, schema identifier, and ",(0,n.jsx)(r.code,{children:"HoodieOperation"}),". The ",(0,n.jsx)(r.code,{children:"RecordContext"})," provides a common interface for accessing and manipulating records across different engines (Spark, Flink, etc.), making custom mergers engine-agnostic."]}),"\n",(0,n.jsxs)(r.p,{children:["The Java APIs are sketched below at a high level. The interface takes older/newer records wrapped in ",(0,n.jsx)(r.code,{children:"BufferedRecord"})," instances and produces a merged ",(0,n.jsx)(r.code,{children:"BufferedRecord"}),". The record merger is configured using a ",(0,n.jsx)(r.code,{children:"hoodie.write.record.merge.strategy.id"})," write config whose value is a UUID, which is taken by the writer to persist in the table config, and is expected to be returned by ",(0,n.jsx)(r.code,{children:"getMergingStrategy()"}),"\nmethod below. Using this mechanism, Hudi can automatically deduce the record merger to use for the table across different language and engine runtimes."]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-Java",children:"interface HoodieRecordMerger {\n\n    <T> BufferedRecord<T> merge(BufferedRecord<T> older, BufferedRecord<T> newer,\n                                RecordContext<T> recordContext, TypedProperties props) throws IOException {\n        // Merges full records. Returns a non-null BufferedRecord.\n        // If the result represents a deletion, set HoodieOperation.DELETE on the returned record.\n        // Ordering values must always be set if there are ordering fields for the table.\n        ...\n    }\n\n    <T> BufferedRecord<T> partialMerge(BufferedRecord<T> older, BufferedRecord<T> newer,\n                                       Schema readerSchema, RecordContext<T> recordContext,\n                                       TypedProperties props) throws IOException {\n        // Merges records which can contain partial updates.\n        // Returns a non-null BufferedRecord with only changed fields included.\n        // If the result represents a deletion, set HoodieOperation.DELETE on the returned record.\n        // Ordering values must always be set if there are ordering fields for the table.\n        ...\n    }\n\n    HoodieRecordType getRecordType() {...}\n\n    String getMergingStrategy() {...}\n}\n"})}),"\n",(0,n.jsx)(r.h4,{id:"implementation-guidelines",children:"Implementation Guidelines"}),"\n",(0,n.jsxs)(r.p,{children:["When implementing the ",(0,n.jsx)(r.code,{children:"HoodieRecordMerger"})," interface, follow these guidelines to ensure consistent results:"]}),"\n",(0,n.jsxs)(r.ol,{children:["\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Return non-null records"}),": Both ",(0,n.jsx)(r.code,{children:"merge()"})," and ",(0,n.jsx)(r.code,{children:"partialMerge()"})," methods must return a non-null ",(0,n.jsx)(r.code,{children:"BufferedRecord"}),". The returned record should contain the merged data whenever possible, even if it represents a deletion. This allows future merge operations to reference the previous value of the data. However, if the data is not available or not needed, it is acceptable to return a ",(0,n.jsx)(r.code,{children:"BufferedRecord"})," with null data (e.g., when using ",(0,n.jsx)(r.code,{children:"BufferedRecords.createDelete()"}),")."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Handle deletions"}),": If the merged result should delete the row matching the record key, set the ",(0,n.jsx)(r.code,{children:"HoodieOperation"})," to ",(0,n.jsx)(r.code,{children:"DELETE"})," on the returned ",(0,n.jsx)(r.code,{children:"BufferedRecord"})," using ",(0,n.jsx)(r.code,{children:"setHoodieOperation(HoodieOperation.DELETE)"}),"."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Preserve ordering values"}),": Always set ordering values in the result if there are any ordering fields configured for the table. This ensures that future merge operations can reference these values correctly."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Use RecordContext"}),": The ",(0,n.jsx)(r.code,{children:"RecordContext"})," parameter provides engine-agnostic methods to access field values, extract record keys, and manipulate records. Use methods like ",(0,n.jsx)(r.code,{children:"getValue()"}),", ",(0,n.jsx)(r.code,{children:"getRecordKey()"}),", and ",(0,n.jsx)(r.code,{children:"mergeWithEngineRecord()"})," to work with the underlying data."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Associative property"}),": The ",(0,n.jsx)(r.code,{children:"merge()"})," method should be associative: ",(0,n.jsx)(r.code,{children:"merge(a, merge(b, c))"})," should yield the same result as ",(0,n.jsx)(r.code,{children:"merge(merge(a, b), c)"})," for any three versions A, B, C of the same record."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(r.p,{children:["For more details on the implementation, see ",(0,n.jsx)(r.a,{href:"https://github.com/apache/hudi/blob/master/rfc/rfc-101/rfc-101.md",children:"RFC 101"}),"."]}),"\n",(0,n.jsx)(r.h3,{id:"merge-mode-configs",children:"Merge Mode Configs"}),"\n",(0,n.jsx)(r.p,{children:"The record merge mode and optional record merge strategy ID and custom merge implementation classes can be specified using the below configs."}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{children:"Config Name"}),(0,n.jsx)(r.th,{children:"Default"}),(0,n.jsx)(r.th,{children:"Description"})]})}),(0,n.jsxs)(r.tbody,{children:[(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"hoodie.write.record.merge.mode"}),(0,n.jsxs)(r.td,{children:["EVENT_TIME_ORDERING (when ordering field is set)",(0,n.jsx)("br",{}),"COMMIT_TIME_ORDERING (when ordering field is not set)"]}),(0,n.jsxs)(r.td,{children:["Determines the logic of merging different records with the same record key. Valid values: (1) ",(0,n.jsx)(r.code,{children:"COMMIT_TIME_ORDERING"}),": use commit time to merge records, i.e., the record from later commit overwrites the earlier record with the same key. (2) ",(0,n.jsx)(r.code,{children:"EVENT_TIME_ORDERING"}),": use event time as the ordering to merge records, i.e., the record with the larger event time overwrites the record with the smaller event time on the same key, regardless of commit time. The event time or preCombine field needs to be specified by the user. This is the default when an ordering field is configured. (3) ",(0,n.jsx)(r.code,{children:"CUSTOM"}),": use custom merging logic specified by the user.",(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Config Param: RECORD_MERGE_MODE"}),(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Since Version: 1.0.0"})]})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"hoodie.write.record.merge.strategy.id"}),(0,n.jsx)(r.td,{children:"N/A (Optional)"}),(0,n.jsxs)(r.td,{children:["ID of record merge strategy. Hudi will pick ",(0,n.jsx)(r.code,{children:"HoodieRecordMerger"})," implementations from ",(0,n.jsx)(r.code,{children:"hoodie.write.record.merge.custom.implementation.classes"})," that have the same merge strategy ID. When using custom merge logic, you need to specify both this config and ",(0,n.jsx)(r.code,{children:"hoodie.write.record.merge.custom.implementation.classes"}),".",(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Config Param: RECORD_MERGE_STRATEGY_ID"}),(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Since Version: 0.13.0"}),(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Alternative: hoodie.datasource.write.record.merger.strategy"})," (deprecated)"]})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"hoodie.write.record.merge.custom.implementation.classes"}),(0,n.jsx)(r.td,{children:"N/A (Optional)"}),(0,n.jsxs)(r.td,{children:["List of ",(0,n.jsx)(r.code,{children:"HoodieRecordMerger"})," implementations constituting Hudi's merging strategy based on the engine used. Hudi selects the first implementation from this list that matches the following criteria: (1) has the same merge strategy ID as specified in ",(0,n.jsx)(r.code,{children:"hoodie.write.record.merge.strategy.id"})," (if provided), (2) is compatible with the execution engine (e.g., SPARK merger for Spark, FLINK merger for Flink, AVRO for Java/Hive). The order in the list matters - place your preferred implementation first. Engine-specific implementations (SPARK, FLINK) are more efficient as they avoid Avro serialization/deserialization overhead.",(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Config Param: RECORD_MERGE_IMPL_CLASSES"}),(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Since Version: 0.13.0"}),(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Alternative: hoodie.datasource.write.record.merger.impls"})," (deprecated)"]})]})]})]}),"\n",(0,n.jsx)(r.h2,{id:"record-payloads-deprecated",children:"Record Payloads (deprecated)"}),"\n",(0,n.jsxs)(r.admonition,{type:"caution",children:[(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Deprecation Notice:"})," As of release 1.1.0, the payload-based approach for record merging is deprecated. This approach is closely tied to Avro-formatted records, making it less compatible with native query engine formats (e.g., Spark InternalRow) and more challenging to maintain. We strongly recommends migrating to ",(0,n.jsx)(r.a,{href:"#merge-modes",children:"merge modes"}),", which offer better flexibility, performance, and maintainability for modern lakehouse architectures."]}),(0,n.jsxs)(r.p,{children:["Existing payload-based configurations will continue to work through backwards compatibility, but users are encouraged to migrate their implementations. For details, see ",(0,n.jsx)(r.a,{href:"https://github.com/apache/hudi/pull/13499",children:"RFC 97"}),"."]})]}),"\n",(0,n.jsx)(r.p,{children:"Record payload is an older abstraction/API for achieving similar record-level merge capabilities. While record payloads were very useful and popular,\nthey had drawbacks like lower performance due to conversion of engine-native record formats to Apache Avro for merging and lack of cross-language support.\nAs we shall see below, Hudi provides out-of-the-box support for different payloads for different use cases. Hudi implements fallback from\nrecord merger APIs to payload APIs internally, to provide backwards compatibility for existing payload implementations."}),"\n",(0,n.jsx)(r.h3,{id:"overwritewithlatestavropayload-deprecated",children:"OverwriteWithLatestAvroPayload (deprecated)"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-scala",children:"hoodie.datasource.write.payload.class=org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\n"})}),"\n",(0,n.jsxs)(r.p,{children:["This is the default record payload implementation. It picks the record with the greatest value (determined by calling\n",(0,n.jsx)(r.code,{children:".compareTo()"})," on the value of precombine key) to break ties and simply picks the latest record while merging. This gives\nlatest-write-wins style semantics."]}),"\n",(0,n.jsx)(r.h3,{id:"defaulthoodierecordpayload-deprecated",children:"DefaultHoodieRecordPayload (deprecated)"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-scala",children:"hoodie.datasource.write.payload.class=org.apache.hudi.common.model.DefaultHoodieRecordPayload\n"})}),"\n",(0,n.jsxs)(r.p,{children:["While ",(0,n.jsx)(r.code,{children:"OverwriteWithLatestAvroPayload"})," precombines based on an ordering field and picks the latest record while merging,\n",(0,n.jsx)(r.code,{children:"DefaultHoodieRecordPayload"})," honors the ordering field for both precombining and merging. Let's understand the difference with an example:"]}),"\n",(0,n.jsxs)(r.p,{children:["Let's say the ordering field is ",(0,n.jsx)(r.code,{children:"ts"})," and record key is ",(0,n.jsx)(r.code,{children:"id"})," and schema is:"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-json",children:'{\n  [\n    {"name":"id","type":"string"},\n    {"name":"ts","type":"long"},\n    {"name":"name","type":"string"},\n    {"name":"price","type":"string"}\n  ]\n}\n'})}),"\n",(0,n.jsx)(r.p,{children:"Current record in storage:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       2       name_2  price_2\n"})}),"\n",(0,n.jsx)(r.p,{children:"Incoming record:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       1       name_1    price_1\n"})}),"\n",(0,n.jsxs)(r.p,{children:["Result data after merging using ",(0,n.jsx)(r.code,{children:"OverwriteWithLatestAvroPayload"})," (latest-write-wins):"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       1       name_1  price_1\n"})}),"\n",(0,n.jsxs)(r.p,{children:["Result data after merging using ",(0,n.jsx)(r.code,{children:"DefaultHoodieRecordPayload"})," (always honors ordering field):"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       2       name_2  price_2\n"})}),"\n",(0,n.jsx)(r.h3,{id:"eventtimeavropayload-deprecated",children:"EventTimeAvroPayload (deprecated)"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-scala",children:"hoodie.datasource.write.payload.class=org.apache.hudi.common.model.EventTimeAvroPayload\n"})}),"\n",(0,n.jsxs)(r.p,{children:["This is the default record payload for Flink-based writing. Some use cases require merging records by event time and\nthus event time plays the role of an ordering field. This payload is particularly useful in the case of late-arriving data.\nFor such use cases, users need to set the ",(0,n.jsx)(r.a,{href:"/docs/configurations#RECORD_PAYLOAD",children:"payload event time field"})," configuration."]}),"\n",(0,n.jsx)(r.h3,{id:"overwritenondefaultswithlatestavropayload-deprecated",children:"OverwriteNonDefaultsWithLatestAvroPayload (deprecated)"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-scala",children:"hoodie.datasource.write.payload.class=org.apache.hudi.common.model.OverwriteNonDefaultsWithLatestAvroPayload\n"})}),"\n",(0,n.jsxs)(r.p,{children:["This payload is quite similar to ",(0,n.jsx)(r.code,{children:"OverwriteWithLatestAvroPayload"})," with slight difference while merging records. For\nprecombining, just like ",(0,n.jsx)(r.code,{children:"OverwriteWithLatestAvroPayload"}),", it picks the latest record for a key, based on an ordering\nfield. While merging, it overwrites the existing record on storage only for the specified ",(0,n.jsx)(r.strong,{children:"fields that don't equal\ndefault value"})," for that field."]}),"\n",(0,n.jsx)(r.h3,{id:"partialupdateavropayload-deprecated",children:"PartialUpdateAvroPayload (deprecated)"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-scala",children:"hoodie.datasource.write.payload.class=org.apache.hudi.common.model.PartialUpdateAvroPayload\n"})}),"\n",(0,n.jsxs)(r.p,{children:["This payload supports partial update. Typically, once the merge step resolves which record to pick, then the record on\nstorage is fully replaced by the resolved record. But, in some cases, the requirement is to update only certain fields\nand not replace the whole record. This is called partial update. ",(0,n.jsx)(r.code,{children:"PartialUpdateAvroPayload"})," provides out-of-the-box support\nfor such use cases. To illustrate the point, let us look at a simple example:"]}),"\n",(0,n.jsxs)(r.p,{children:["Let's say the ordering field is ",(0,n.jsx)(r.code,{children:"ts"})," and record key is ",(0,n.jsx)(r.code,{children:"id"})," and schema is:"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-json",children:'{\n  [\n    {"name":"id","type":"string"},\n    {"name":"ts","type":"long"},\n    {"name":"name","type":"string"},\n    {"name":"price","type":"string"}\n  ]\n}\n'})}),"\n",(0,n.jsx)(r.p,{children:"Current record in storage:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       2       name_1  null\n"})}),"\n",(0,n.jsx)(r.p,{children:"Incoming record:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       1       null    price_1\n"})}),"\n",(0,n.jsxs)(r.p,{children:["Result data after merging using ",(0,n.jsx)(r.code,{children:"PartialUpdateAvroPayload"}),":"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-text",children:"    id      ts      name    price\n    1       2       name_1  price_1\n"})}),"\n",(0,n.jsx)(r.h3,{id:"record-payload-configs-deprecated",children:"Record Payload Configs (deprecated)"}),"\n",(0,n.jsxs)(r.p,{children:["Payload class can be specified using the below configs. For more advanced configs, refer to ",(0,n.jsx)(r.a,{href:"https://hudi.apache.org/docs/configurations#RECORD_PAYLOAD",children:"the configurations page"})]}),"\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.strong,{children:"Spark based configs:"})}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{children:"Config Name"}),(0,n.jsx)(r.th,{children:"Default"}),(0,n.jsx)(r.th,{children:"Description"})]})}),(0,n.jsx)(r.tbody,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"hoodie.datasource.write.payload.class"}),(0,n.jsx)(r.td,{children:"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload (Optional)"}),(0,n.jsxs)(r.td,{children:["Payload class used. Override this, if you like to roll your own merge logic, when upserting/inserting. This will render any value set for PRECOMBINE_FIELD_OPT_VAL in-effective",(0,n.jsx)("br",{}),(0,n.jsx)("br",{}),(0,n.jsx)(r.code,{children:"Config Param: WRITE_PAYLOAD_CLASS_NAME"})]})]})})]}),"\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.strong,{children:"Flink-based configs:"})}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{children:"Config Name"}),(0,n.jsx)(r.th,{children:"Default"}),(0,n.jsx)(r.th,{children:"Description"})]})}),(0,n.jsx)(r.tbody,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"payload.class"}),(0,n.jsx)(r.td,{children:"org.apache.hudi.common.model.EventTimeAvroPayload (Optional)"}),(0,n.jsxs)(r.td,{children:["Payload class used. Override this, if you like to roll your own merge logic, when upserting/inserting. This will render any value set for the option in-effective",(0,n.jsx)("br",{}),(0,n.jsx)("br",{})," ",(0,n.jsx)(r.code,{children:"Config Param: PAYLOAD_CLASS_NAME"})]})]})})]}),"\n",(0,n.jsxs)(r.p,{children:["There are also quite a few other implementations. Developers may be interested in looking at the hierarchy of ",(0,n.jsx)(r.code,{children:"HoodieRecordPayload"})," interface. For\nexample, ",(0,n.jsx)(r.a,{href:"https://github.com/apache/hudi/blob/e76dd102bcaf8aec5a932e7277ccdbfd73ce1a32/hudi-common/src/main/java/org/apache/hudi/common/model/debezium/MySqlDebeziumAvroPayload.java",children:(0,n.jsx)(r.code,{children:"MySqlDebeziumAvroPayload"})})," and ",(0,n.jsx)(r.a,{href:"https://github.com/apache/hudi/blob/e76dd102bcaf8aec5a932e7277ccdbfd73ce1a32/hudi-common/src/main/java/org/apache/hudi/common/model/debezium/PostgresDebeziumAvroPayload.java",children:(0,n.jsx)(r.code,{children:"PostgresDebeziumAvroPayload"})})," provide support for seamlessly applying changes\ncaptured via Debezium for MySQL and PostgresDB. ",(0,n.jsx)(r.a,{href:"https://github.com/apache/hudi/blob/e76dd102bcaf8aec5a932e7277ccdbfd73ce1a32/hudi-common/src/main/java/org/apache/hudi/common/model/AWSDmsAvroPayload.java",children:(0,n.jsx)(r.code,{children:"AWSDmsAvroPayload"})})," provides support for applying changes captured via Amazon Database Migration Service onto S3.\nFor full configurations, see ",(0,n.jsx)(r.a,{href:"/docs/configurations#RECORD_PAYLOAD",children:"the configurations page"})," and please check out ",(0,n.jsx)(r.a,{href:"/faq/writing_tables/#can-i-implement-my-own-logic-for-how-input-records-are-merged-with-record-on-storage",children:"the FAQ"})," if you want to implement your own custom payloads."]}),"\n",(0,n.jsx)(r.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,n.jsx)(r.h3,{id:"blogs",children:"Blogs"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"https://medium.com/@simpsons/how-to-define-your-own-merge-logic-with-apache-hudi-622ee5ccab1e",children:"How to define your own merge logic with Apache Hudi"})}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},28453(e,r,i){i.d(r,{R:()=>d,x:()=>s});var o=i(96540);const n={},t=o.createContext(n);function d(e){const r=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function s(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:d(e.components),o.createElement(t.Provider,{value:r},e.children)}},38526(e,r,i){i.d(r,{A:()=>o});const o=i.p+"assets/images/commit-time-ordering-merge-mode-e9b6af3dcdb508053202617218f3ffe6.png"},57159(e,r,i){i.d(r,{A:()=>o});const o=i.p+"assets/images/event-time-ordering-merge-mode-c8164e035840388bf4290fa81ac6262a.png"}}]);
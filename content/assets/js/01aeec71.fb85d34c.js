"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[50014],{94706:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"0.14.0","label":"0.14.0","banner":null,"badge":true,"className":"docs-version-0.14.0","isLast":true,"docsSidebars":{"docs":[{"type":"link","label":"Overview","href":"/docs/overview","docId":"overview"},{"type":"category","label":"Quick Start","collapsed":false,"items":[{"type":"link","label":"Spark Guide","href":"/docs/quick-start-guide","docId":"quick-start-guide"},{"type":"link","label":"Flink Guide","href":"/docs/flink-quick-start-guide","docId":"flink-quick-start-guide"},{"type":"link","label":"Docker Demo","href":"/docs/docker_demo","docId":"docker_demo"}],"collapsible":true},{"type":"category","label":"Concepts","items":[{"type":"link","label":"Timeline","href":"/docs/timeline","docId":"timeline"},{"type":"link","label":"Table & Query Types","href":"/docs/table_types","docId":"table_types"},{"type":"link","label":"Indexing","href":"/docs/indexing","docId":"indexing"},{"type":"link","label":"File Layouts","href":"/docs/file_layouts","docId":"file_layouts"},{"type":"link","label":"Metadata Table","href":"/docs/metadata","docId":"metadata"},{"type":"link","label":"Write Operations","href":"/docs/write_operations","docId":"write_operations"},{"type":"link","label":"Schema Evolution","href":"/docs/schema_evolution","docId":"schema_evolution"},{"type":"link","label":"Key Generation","href":"/docs/key_generation","docId":"key_generation"},{"type":"link","label":"Concurrency Control","href":"/docs/concurrency_control","docId":"concurrency_control"},{"type":"link","label":"Record Payload","href":"/docs/record_payload","docId":"record_payload"}],"collapsible":true,"collapsed":true},{"type":"category","label":"How To","items":[{"type":"category","label":"SQL","items":[{"type":"link","label":"SQL DDL","href":"/docs/sql_ddl","docId":"sql_ddl"},{"type":"link","label":"SQL DML","href":"/docs/sql_dml","docId":"sql_dml"},{"type":"link","label":"SQL Queries","href":"/docs/sql_queries","docId":"sql_queries"},{"type":"link","label":"Procedures","href":"/docs/procedures","docId":"procedures"}],"collapsible":true,"collapsed":true},{"type":"link","label":"Writing Data","href":"/docs/writing_data","docId":"writing_data"},{"type":"link","label":"Streaming Ingestion","href":"/docs/hoodie_streaming_ingestion","docId":"hoodie_streaming_ingestion"},{"type":"category","label":"Syncing to Catalogs","items":[{"type":"link","label":"AWS Glue Data Catalog","href":"/docs/syncing_aws_glue_data_catalog","docId":"syncing_aws_glue_data_catalog"},{"type":"link","label":"DataHub","href":"/docs/syncing_datahub","docId":"syncing_datahub"},{"type":"link","label":"Hive Metastore","href":"/docs/syncing_metastore","docId":"syncing_metastore"},{"type":"link","label":"Google BigQuery","href":"/docs/gcp_bigquery","docId":"gcp_bigquery"}],"collapsible":true,"collapsed":true}],"collapsible":true,"collapsed":true},{"type":"category","label":"Services","items":[{"type":"link","label":"Bootstrapping","href":"/docs/migration_guide","docId":"migration_guide"},{"type":"link","label":"Compaction","href":"/docs/compaction","docId":"compaction"},{"type":"link","label":"Clustering","href":"/docs/clustering","docId":"clustering"},{"type":"link","label":"Metadata Indexing","href":"/docs/metadata_indexing","docId":"metadata_indexing"},{"type":"link","label":"Cleaning","href":"/docs/hoodie_cleaner","docId":"hoodie_cleaner"},{"type":"link","label":"Transformers","href":"/docs/transforms","docId":"transforms"},{"type":"link","label":"Rollback Mechanism","href":"/docs/rollbacks","docId":"rollbacks"},{"type":"link","label":"Marker Mechanism","href":"/docs/markers","docId":"markers"},{"type":"link","label":"File Sizing","href":"/docs/file_sizing","docId":"file_sizing"},{"type":"link","label":"Disaster Recovery","href":"/docs/disaster_recovery","docId":"disaster_recovery"},{"type":"link","label":"Exporter","href":"/docs/snapshot_exporter","docId":"snapshot_exporter"},{"type":"link","label":"Data Quality","href":"/docs/precommit_validator","docId":"precommit_validator"}],"collapsible":true,"collapsed":true},{"type":"category","label":"Configurations","items":[{"type":"link","label":"Basic Configurations","href":"/docs/basic_configurations","docId":"basic_configurations"},{"type":"link","label":"All Configurations","href":"/docs/configurations","docId":"configurations"}],"collapsible":true,"collapsed":true},{"type":"category","label":"Guides","items":[{"type":"link","label":"Performance","href":"/docs/performance","docId":"performance"},{"type":"link","label":"Deployment","href":"/docs/deployment","docId":"deployment"},{"type":"link","label":"CLI","href":"/docs/cli","docId":"cli"},{"type":"link","label":"Metrics","href":"/docs/metrics","docId":"metrics"},{"type":"link","label":"Encryption","href":"/docs/encryption","docId":"encryption"},{"type":"link","label":"Troubleshooting","href":"/docs/troubleshooting","docId":"troubleshooting"},{"type":"link","label":"Tuning Guide","href":"/docs/tuning-guide","docId":"tuning-guide"},{"type":"link","label":"Flink Tuning","href":"/docs/flink_tuning","docId":"flink_tuning"},{"type":"category","label":"Storage Configurations","items":[{"type":"link","label":"Cloud Storage","href":"/docs/cloud","docId":"cloud"},{"type":"link","label":"AWS S3","href":"/docs/s3_hoodie","docId":"s3_hoodie"},{"type":"link","label":"Google Cloud","href":"/docs/gcs_hoodie","docId":"gcs_hoodie"},{"type":"link","label":"Alibaba Cloud","href":"/docs/oss_hoodie","docId":"oss_hoodie"},{"type":"link","label":"Microsoft Azure","href":"/docs/azure_hoodie","docId":"azure_hoodie"},{"type":"link","label":"Tencent Cloud","href":"/docs/cos_hoodie","docId":"cos_hoodie"},{"type":"link","label":"IBM Cloud","href":"/docs/ibm_cos_hoodie","docId":"ibm_cos_hoodie"},{"type":"link","label":"Baidu Cloud","href":"/docs/bos_hoodie","docId":"bos_hoodie"},{"type":"link","label":"JuiceFS","href":"/docs/jfs_hoodie","docId":"jfs_hoodie"},{"type":"link","label":"Oracle Cloud Infrastructure","href":"/docs/oci_hoodie","docId":"oci_hoodie"}],"collapsible":true,"collapsed":true}],"collapsible":true,"collapsed":true},{"type":"link","label":"Use Cases","href":"/docs/use_cases","docId":"use_cases"},{"type":"link","label":"FAQs","href":"/docs/faq","docId":"faq"},{"type":"link","label":"Privacy Policy","href":"/docs/privacy","docId":"privacy"}],"quick_links":[{"type":"link","label":"Powered By","href":"powered-by"},{"type":"link","label":"Chat with us on Slack","href":"https://join.slack.com/t/apache-hudi/shared_invite/zt-20r833rxh-627NWYDUyR8jRtMa2mZ~gg"}]},"docs":{"azure_hoodie":{"id":"azure_hoodie","title":"Microsoft Azure","description":"In this page, we explain how to use Hudi on Microsoft Azure.","sidebar":"docs"},"basic_configurations":{"id":"basic_configurations","title":"Basic Configurations","description":"This page covers the basic configurations you may use to write/read Hudi tables. This page only features a subset of the most frequently used configurations. For a full list of all configs, please visit the All Configurations page.","sidebar":"docs"},"bos_hoodie":{"id":"bos_hoodie","title":"Baidu Cloud","description":"In this page, we explain how to get your Hudi job to store into Baidu BOS.","sidebar":"docs"},"cli":{"id":"cli","title":"CLI","description":"Local set up","sidebar":"docs"},"cloud":{"id":"cloud","title":"Cloud Storage","description":"Talking to Cloud Storage","sidebar":"docs"},"clustering":{"id":"clustering","title":"Clustering","description":"Background","sidebar":"docs"},"compaction":{"id":"compaction","title":"Compaction","description":"Background","sidebar":"docs"},"comparison":{"id":"comparison","title":"Comparison","description":"Apache Hudi fills a big void for processing data on top of DFS, and thus mostly co-exists nicely with these technologies. However,"},"concepts":{"id":"concepts","title":"Concepts","description":"Apache Hudi (pronounced \u201cHudi\u201d) provides the following streaming primitives over hadoop compatible storages"},"concurrency_control":{"id":"concurrency_control","title":"Concurrency Control","description":"Concurrency control defines how different writers/readers coordinate access to the table. Hudi ensures atomic writes, by way of publishing commits atomically to the timeline, stamped with an instant time that denotes the time at which the action is deemed to have occurred. Unlike general purpose file version control, Hudi draws clear distinction between writer processes (that issue user\u2019s upserts/deletes), table services (that write data/metadata to optimize/perform bookkeeping) and readers (that execute queries and read data). Hudi provides snapshot isolation between all three types of processes, meaning they all operate on a consistent snapshot of the table. Hudi provides optimistic concurrency control (OCC) between writers, while providing lock-free, non-blocking Multiversion Concurrency Control (MVCC) based concurrency control between writers and table-services and between different table services.","sidebar":"docs"},"configurations":{"id":"configurations","title":"All Configurations","description":"This page covers the different ways of configuring your job to write/read Hudi tables. At a high level, you can control behaviour at few levels.","sidebar":"docs"},"cos_hoodie":{"id":"cos_hoodie","title":"Tencent Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Tencent Cloud COS.","sidebar":"docs"},"deployment":{"id":"deployment","title":"Deployment","description":"This section provides all the help you need to deploy and operate Hudi tables at scale.","sidebar":"docs"},"disaster_recovery":{"id":"disaster_recovery","title":"Disaster Recovery","description":"Disaster Recovery is very much mission-critical for any software. Especially when it comes to data systems, the impact could be very serious","sidebar":"docs"},"docker_demo":{"id":"docker_demo","title":"Docker Demo","description":"A Demo using Docker containers","sidebar":"docs"},"encryption":{"id":"encryption","title":"Encryption","description":"Since Hudi 0.11.0, Spark 3.2 support has been added and accompanying that, Parquet 1.12 has been included, which brings encryption feature to Hudi. In this section, we will show a guide on how to enable encryption in Hudi tables.","sidebar":"docs"},"faq":{"id":"faq","title":"FAQs","description":"General","sidebar":"docs"},"file_layouts":{"id":"file_layouts","title":"File Layouts","description":"The following describes the general file layout structure for Apache Hudi. Please refer the * tech spec * for a more detailed description of the file layouts.","sidebar":"docs"},"file_sizing":{"id":"file_sizing","title":"File Sizing","description":"Solving the small file problem is fundamental to ensuring","sidebar":"docs"},"flink_tuning":{"id":"flink_tuning","title":"Flink Tuning","description":"Global Configurations","sidebar":"docs"},"flink-quick-start-guide":{"id":"flink-quick-start-guide","title":"Flink Guide","description":"This page introduces Flink-Hudi integration. We can feel the unique charm of how Flink brings in the power of streaming into Hudi.","sidebar":"docs"},"gcp_bigquery":{"id":"gcp_bigquery","title":"Google BigQuery","description":"Hudi tables can be queried from Google Cloud BigQuery as external tables. As of","sidebar":"docs"},"gcs_hoodie":{"id":"gcs_hoodie","title":"Google Cloud","description":"For Hudi storage on GCS, regional buckets provide an DFS API with strong consistency.","sidebar":"docs"},"hoodie_cleaner":{"id":"hoodie_cleaner","title":"Cleaning","description":"Background","sidebar":"docs"},"hoodie_streaming_ingestion":{"id":"hoodie_streaming_ingestion","title":"Streaming Ingestion","description":"Hudi Streamer","sidebar":"docs"},"ibm_cos_hoodie":{"id":"ibm_cos_hoodie","title":"IBM Cloud","description":"In this page, we explain how to get your Hudi spark job to store into IBM Cloud Object Storage.","sidebar":"docs"},"indexing":{"id":"indexing","title":"Indexing","description":"Indexing","sidebar":"docs"},"jfs_hoodie":{"id":"jfs_hoodie","title":"JuiceFS","description":"In this page, we explain how to use Hudi with JuiceFS.","sidebar":"docs"},"key_generation":{"id":"key_generation","title":"Key Generation","description":"Every record in Hudi is uniquely identified by a primary key, which is a pair of record key and partition path where the record belongs to.","sidebar":"docs"},"markers":{"id":"markers","title":"Marker Mechanism","description":"Purpose of Markers","sidebar":"docs"},"metadata":{"id":"metadata","title":"Metadata Table","description":"Metadata Table","sidebar":"docs"},"metadata_indexing":{"id":"metadata_indexing","title":"Metadata Indexing","description":"Hudi maintains a scalable metadata that has some auxiliary data about the table.","sidebar":"docs"},"metrics":{"id":"metrics","title":"Metrics","description":"In this section, we will introduce the MetricsReporter and HoodieMetrics in Hudi. You can view the metrics-related configurations here.","sidebar":"docs"},"migration_guide":{"id":"migration_guide","title":"Bootstrapping","description":"Hudi maintains metadata such as commit timeline and indexes to manage a table. The commit timelines helps to understand the actions happening on a table as well as the current state of a table. Indexes are used by Hudi to maintain a record key to file id mapping to efficiently locate a record. At the moment, Hudi supports writing only parquet columnar formats.","sidebar":"docs"},"oci_hoodie":{"id":"oci_hoodie","title":"Oracle Cloud Infrastructure","description":"The Oracle Object Storage system provides strongly-consistent operations on all buckets in all regions. OCI Object Storage provides an HDFS Connector your Application will need to access data.","sidebar":"docs"},"oss_hoodie":{"id":"oss_hoodie","title":"Alibaba Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Aliyun OSS.","sidebar":"docs"},"overview":{"id":"overview","title":"Overview","description":"Welcome to Apache Hudi! This overview will provide a high level summary of what Apache Hudi is and will orient you on","sidebar":"docs"},"performance":{"id":"performance","title":"Performance","description":"Optimized DFS Access","sidebar":"docs"},"precommit_validator":{"id":"precommit_validator","title":"Data Quality","description":"Data quality refers to the overall accuracy, completeness, consistency, and validity of data. Ensuring data quality is vital for accurate analysis and reporting, as well as for compliance with regulations and maintaining trust in your organization\'s data infrastructure.","sidebar":"docs"},"privacy":{"id":"privacy","title":"Privacy Policy","description":"Information about your use of this website is collected using server access logs and a tracking cookie.","sidebar":"docs"},"procedures":{"id":"procedures","title":"Procedures","description":"Stored procedures available when use Hudi SparkSQL extensions in all spark\'s version.","sidebar":"docs"},"querying_data":{"id":"querying_data","title":"Querying Data","description":"This page is no longer maintained. Please refer to Hudi SQL DDL, SQL DML, SQL Queries and Procedures for the latest documentation."},"quick-start-guide":{"id":"quick-start-guide","title":"Spark Guide","description":"This guide provides a quick peek at Hudi\'s capabilities using Spark. Using Spark Datasource APIs(both scala and python) and using Spark SQL,","sidebar":"docs"},"record_payload":{"id":"record_payload","title":"Record Payload","description":"Background","sidebar":"docs"},"rollbacks":{"id":"rollbacks","title":"Rollback Mechanism","description":"Your pipelines could fail due to numerous reasons like crashes, valid bugs in the code, unavailability of any external","sidebar":"docs"},"s3_hoodie":{"id":"s3_hoodie","title":"AWS S3","description":"In this page, we explain how to get your Hudi spark job to store into AWS S3.","sidebar":"docs"},"schema_evolution":{"id":"schema_evolution","title":"Schema Evolution","description":"Schema evolution is an essential aspect of data management, and Hudi supports schema evolution on write out-of-the-box,","sidebar":"docs"},"snapshot_exporter":{"id":"snapshot_exporter","title":"Exporter","description":"Introduction","sidebar":"docs"},"sql_ddl":{"id":"sql_ddl","title":"SQL DDL","description":"This page describes support for creating and altering tables using SQL across various engines.","sidebar":"docs"},"sql_dml":{"id":"sql_dml","title":"SQL DML","description":"Spark SQL","sidebar":"docs"},"sql_queries":{"id":"sql_queries","title":"SQL Queries","description":"Hudi stores and organizes data on storage while providing different ways of querying, across a wide range of query engines.","sidebar":"docs"},"structure":{"id":"structure","title":"Structure","description":"Hudi (pronounced \u201cHoodie\u201d) ingests & manages storage of large analytical tables over DFS (HDFS or cloud stores) and provides three types of queries."},"syncing_aws_glue_data_catalog":{"id":"syncing_aws_glue_data_catalog","title":"AWS Glue Data Catalog","description":"Hudi tables can sync to AWS Glue Data Catalog directly via AWS SDK. Piggyback on HiveSyncTool","sidebar":"docs"},"syncing_datahub":{"id":"syncing_datahub","title":"DataHub","description":"DataHub is a rich metadata platform that supports features like data discovery, data","sidebar":"docs"},"syncing_metastore":{"id":"syncing_metastore","title":"Hive Metastore","description":"Hive Metastore is an","sidebar":"docs"},"table_types":{"id":"table_types","title":"Table & Query Types","description":"Table and Query Types","sidebar":"docs"},"timeline":{"id":"timeline","title":"Timeline","description":"At its core, Hudi maintains a timeline which is a log of all actions performed on the table at different instants of time that helps provide instantaneous views of the table,","sidebar":"docs"},"transforms":{"id":"transforms","title":"Transformers","description":"Apache Hudi provides a HoodieTransformer Utility that allows you to perform transformations the source data before writing it to a Hudi table.","sidebar":"docs"},"troubleshooting":{"id":"troubleshooting","title":"Troubleshooting","description":"For performance related issues, please refer to the tuning guide","sidebar":"docs"},"tuning-guide":{"id":"tuning-guide","title":"Tuning Guide","description":"To get a better understanding of where your Hudi jobs is spending its time, use a tool like YourKit Java Profiler, to obtain heap dumps/flame graphs.","sidebar":"docs"},"use_cases":{"id":"use_cases","title":"Use Cases","description":"Apache Hudi provides the foundational features required to build a state-of-the-art Lakehouse.","sidebar":"docs"},"write_operations":{"id":"write_operations","title":"Write Operations","description":"It may be helpful to understand the different write operations of Hudi and how best to leverage them. These operations","sidebar":"docs"},"writing_data":{"id":"writing_data","title":"Writing Data","description":"In this section, we will cover ways to ingest new changes from external sources or even other Hudi tables.","sidebar":"docs"}}}')}}]);
"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[58301],{15680:(e,t,a)=>{a.d(t,{xA:()=>s,yg:()=>g});var r=a(96540);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),u=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},s=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),d=u(a),h=n,g=d["".concat(l,".").concat(h)]||d[h]||c[h]||o;return a?r.createElement(g,i(i({ref:t},s),{},{components:a})):r.createElement(g,i({ref:t},s))}));function g(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=h;var p={};for(var l in t)hasOwnProperty.call(t,l)&&(p[l]=t[l]);p.originalType=e,p[d]="string"==typeof e?e:n,i[1]=p;for(var u=2;u<o;u++)i[u]=a[u];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}h.displayName="MDXCreateElement"},99046:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>p,toc:()=>u});var r=a(58168),n=(a(96540),a(15680));const o={title:"Export Hudi datasets as a copy or as different formats",excerpt:"Learn how to copy or export HUDI dataset in various formats.",author:"rxu",category:"blog",tags:["how-to","snapshot exporter","apache hudi"]},i=void 0,p={permalink:"/blog/2020/03/22/exporting-hudi-datasets",editUrl:"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2020-03-22-exporting-hudi-datasets.md",source:"@site/blog/2020-03-22-exporting-hudi-datasets.md",title:"Export Hudi datasets as a copy or as different formats",description:"Copy to Hudi dataset",date:"2020-03-22T00:00:00.000Z",formattedDate:"March 22, 2020",tags:[{label:"how-to",permalink:"/blog/tags/how-to"},{label:"snapshot exporter",permalink:"/blog/tags/snapshot-exporter"},{label:"apache hudi",permalink:"/blog/tags/apache-hudi"}],readingTime:1.695,truncated:!0,authors:[{name:"rxu"}],prevItem:{title:"Apache Hudi Support on Apache Zeppelin",permalink:"/blog/2020/04/27/apache-hudi-apache-zepplin"},nextItem:{title:"Change Capture Using AWS Database Migration Service and Hudi",permalink:"/blog/2020/01/20/change-capture-using-aws"}},l={authorsImageUrls:[void 0]},u=[{value:"Copy to Hudi dataset",id:"copy-to-hudi-dataset",children:[],level:3},{value:"Export to json or parquet dataset",id:"export-to-json-or-parquet-dataset",children:[],level:3},{value:"Re-partitioning",id:"re-partitioning",children:[{value:"<code>--output-partition-field</code>",id:"--output-partition-field",children:[],level:4},{value:"<code>--output-partitioner</code>",id:"--output-partitioner",children:[],level:4}],level:3}],s={toc:u},d="wrapper";function c(e){let{components:t,...a}=e;return(0,n.yg)(d,(0,r.A)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,n.yg)("h3",{id:"copy-to-hudi-dataset"},"Copy to Hudi dataset"),(0,n.yg)("p",null,"Similar to the existing  ",(0,n.yg)("inlineCode",{parentName:"p"},"HoodieSnapshotCopier"),", the Exporter scans the source dataset and then makes a copy of it to the target output path."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},'spark-submit \\\n  --jars "packaging/hudi-spark-bundle/target/hudi-spark-bundle_2.11-0.6.0-SNAPSHOT.jar" \\\n  --deploy-mode "client" \\\n  --class "org.apache.hudi.utilities.HoodieSnapshotExporter" \\\n      packaging/hudi-utilities-bundle/target/hudi-utilities-bundle_2.11-0.6.0-SNAPSHOT.jar \\\n  --source-base-path "/tmp/" \\\n  --target-output-path "/tmp/exported/hudi/" \\\n  --output-format "hudi"\n')),(0,n.yg)("h3",{id:"export-to-json-or-parquet-dataset"},"Export to json or parquet dataset"),(0,n.yg)("p",null,'The Exporter can also convert the source dataset into other formats. Currently only "json" and "parquet" are supported.'),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},'spark-submit \\\n  --jars "packaging/hudi-spark-bundle/target/hudi-spark-bundle_2.11-0.6.0-SNAPSHOT.jar" \\\n  --deploy-mode "client" \\\n  --class "org.apache.hudi.utilities.HoodieSnapshotExporter" \\\n      packaging/hudi-utilities-bundle/target/hudi-utilities-bundle_2.11-0.6.0-SNAPSHOT.jar \\\n  --source-base-path "/tmp/" \\\n  --target-output-path "/tmp/exported/json/" \\\n  --output-format "json"  # or "parquet"\n')),(0,n.yg)("h3",{id:"re-partitioning"},"Re-partitioning"),(0,n.yg)("p",null,"When export to a different format, the Exporter takes parameters to do some custom re-partitioning. By default, if neither of the 2 parameters below is given, the output dataset will have no partition."),(0,n.yg)("h4",{id:"--output-partition-field"},(0,n.yg)("inlineCode",{parentName:"h4"},"--output-partition-field")),(0,n.yg)("p",null,"This parameter uses an existing non-metadata field as the output partitions. All  ",(0,n.yg)("inlineCode",{parentName:"p"},"_hoodie_*"),"  metadata field will be stripped during export."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},'spark-submit \\\n  --jars "packaging/hudi-spark-bundle/target/hudi-spark-bundle_2.11-0.6.0-SNAPSHOT.jar" \\\n  --deploy-mode "client" \\\n  --class "org.apache.hudi.utilities.HoodieSnapshotExporter" \\\n      packaging/hudi-utilities-bundle/target/hudi-utilities-bundle_2.11-0.6.0-SNAPSHOT.jar \\  \n  --source-base-path "/tmp/" \\\n  --target-output-path "/tmp/exported/json/" \\\n  --output-format "json" \\\n  --output-partition-field "symbol"  # assume the source dataset contains a field `symbol`\n')),(0,n.yg)("p",null,"The output directory will look like this"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},"`_SUCCESS symbol=AMRS symbol=AYX symbol=CDMO symbol=CRC symbol=DRNA ...`\n")),(0,n.yg)("h4",{id:"--output-partitioner"},(0,n.yg)("inlineCode",{parentName:"h4"},"--output-partitioner")),(0,n.yg)("p",null,"This parameter takes in a fully-qualified name of a class that implements  ",(0,n.yg)("inlineCode",{parentName:"p"},"HoodieSnapshotExporter.Partitioner"),". This parameter takes higher precedence than  ",(0,n.yg)("inlineCode",{parentName:"p"},"--output-partition-field"),", which will be ignored if this is provided."),(0,n.yg)("p",null,"An example implementation is shown below:"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"MyPartitioner.java")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-java"},'package com.foo.bar;\npublic class MyPartitioner implements HoodieSnapshotExporter.Partitioner {\n\n  private static final String PARTITION_NAME = "date";\n \n  @Override\n  public DataFrameWriter<Row> partition(Dataset<Row> source) {\n    // use the current hoodie partition path as the output partition\n    return source\n        .withColumnRenamed(HoodieRecord.PARTITION_PATH_METADATA_FIELD, PARTITION_NAME)\n        .repartition(new Column(PARTITION_NAME))\n        .write()\n        .partitionBy(PARTITION_NAME);\n  }\n}\n')),(0,n.yg)("p",null,"After putting this class in ",(0,n.yg)("inlineCode",{parentName:"p"},"my-custom.jar"),", which is then placed on the job classpath, the submit command will look like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},'spark-submit \\\n  --jars "packaging/hudi-spark-bundle/target/hudi-spark-bundle_2.11-0.6.0-SNAPSHOT.jar,my-custom.jar" \\\n  --deploy-mode "client" \\\n  --class "org.apache.hudi.utilities.HoodieSnapshotExporter" \\\n      packaging/hudi-utilities-bundle/target/hudi-utilities-bundle_2.11-0.6.0-SNAPSHOT.jar \\\n  --source-base-path "/tmp/" \\\n  --target-output-path "/tmp/exported/json/" \\\n  --output-format "json" \\\n  --output-partitioner "com.foo.bar.MyPartitioner"\n')))}c.isMDXComponent=!0}}]);
"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[9525],{31413:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Current","banner":"unreleased","badge":true,"noIndex":false,"className":"docs-version-current","isLast":false,"docsSidebars":{"docs":[{"type":"category","label":"Getting Started","collapsed":false,"items":[{"type":"link","href":"/docs/next/overview","label":"Overview","docId":"overview","unlisted":false},{"type":"link","href":"/docs/next/quick-start-guide","label":"Spark Quick Start","docId":"quick-start-guide","unlisted":false},{"type":"link","href":"/docs/next/flink-quick-start-guide","label":"Flink Quick Start","docId":"flink-quick-start-guide","unlisted":false},{"type":"link","href":"/docs/next/python-rust-quick-start-guide","label":"Python/Rust Quick Start","docId":"python-rust-quick-start-guide","unlisted":false},{"type":"link","href":"/docs/next/docker_demo","label":"Docker Demo","docId":"docker_demo","unlisted":false},{"type":"link","href":"/docs/next/notebooks","label":"Notebooks","docId":"notebooks","unlisted":false},{"type":"link","href":"/docs/next/use_cases","label":"Use Cases","docId":"use_cases","unlisted":false}],"collapsible":true},{"type":"category","label":"Design & Concepts","items":[{"type":"link","href":"/docs/next/hudi_stack","label":"Apache Hudi Stack","docId":"hudi_stack","unlisted":false},{"type":"link","href":"/docs/next/timeline","label":"Timeline","docId":"timeline","unlisted":false},{"type":"link","href":"/docs/next/storage_layouts","label":"Storage Layouts","docId":"storage_layouts","unlisted":false},{"type":"link","href":"/docs/next/write_operations","label":"Write Operations","docId":"write_operations","unlisted":false},{"type":"link","href":"/docs/next/table_types","label":"Table & Query Types","docId":"table_types","unlisted":false},{"type":"link","href":"/docs/next/key_generation","label":"Key Generation","docId":"key_generation","unlisted":false},{"type":"link","href":"/docs/next/record_merger","label":"Record Merger","docId":"record_merger","unlisted":false},{"type":"link","href":"/docs/next/metadata","label":"Table Metadata","docId":"metadata","unlisted":false},{"type":"link","href":"/docs/next/indexes","label":"Indexes","docId":"indexes","unlisted":false},{"type":"link","href":"/docs/next/concurrency_control","label":"Concurrency Control","docId":"concurrency_control","unlisted":false},{"type":"link","href":"/docs/next/schema_evolution","label":"Schema Evolution","docId":"schema_evolution","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Ingestion","items":[{"type":"link","href":"/docs/next/hoodie_streaming_ingestion","label":"Using Spark","docId":"hoodie_streaming_ingestion","unlisted":false},{"type":"link","href":"/docs/next/ingestion_flink","label":"Using Flink","docId":"ingestion_flink","unlisted":false},{"type":"link","href":"/docs/next/ingestion_kafka_connect","label":"Using Kafka Connect","docId":"ingestion_kafka_connect","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Writing Tables","items":[{"type":"link","href":"/docs/next/sql_ddl","label":"SQL DDL","docId":"sql_ddl","unlisted":false},{"type":"link","href":"/docs/next/sql_dml","label":"SQL DML","docId":"sql_dml","unlisted":false},{"type":"link","href":"/docs/next/writing_data","label":"Batch Writes","docId":"writing_data","unlisted":false},{"type":"link","href":"/docs/next/writing_tables_streaming_writes","label":"Streaming Writes","docId":"writing_tables_streaming_writes","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Reading Tables","items":[{"type":"link","href":"/docs/next/sql_queries","label":"SQL Queries","docId":"sql_queries","unlisted":false},{"type":"link","href":"/docs/next/reading_tables_batch_reads","label":"Batch Reads","docId":"reading_tables_batch_reads","unlisted":false},{"type":"link","href":"/docs/next/reading_tables_streaming_reads","label":"Streaming Reads","docId":"reading_tables_streaming_reads","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Table Services","items":[{"type":"link","href":"/docs/next/cleaning","label":"Cleaning","docId":"cleaning","unlisted":false},{"type":"link","href":"/docs/next/compaction","label":"Compaction","docId":"compaction","unlisted":false},{"type":"link","href":"/docs/next/clustering","label":"Clustering","docId":"clustering","unlisted":false},{"type":"link","href":"/docs/next/metadata_indexing","label":"Indexing","docId":"metadata_indexing","unlisted":false},{"type":"link","href":"/docs/next/rollbacks","label":"Auto Rollbacks","docId":"rollbacks","unlisted":false},{"type":"link","href":"/docs/next/markers","label":"Marker Mechanism","docId":"markers","unlisted":false},{"type":"link","href":"/docs/next/file_sizing","label":"File Sizing","docId":"file_sizing","unlisted":false},{"type":"category","label":"Syncing to Catalogs","items":[{"type":"link","href":"/docs/next/syncing_aws_glue_data_catalog","label":"AWS Glue Data Catalog","docId":"syncing_aws_glue_data_catalog","unlisted":false},{"type":"link","href":"/docs/next/syncing_datahub","label":"DataHub","docId":"syncing_datahub","unlisted":false},{"type":"link","href":"/docs/next/syncing_metastore","label":"Hive Metastore","docId":"syncing_metastore","unlisted":false},{"type":"link","href":"/docs/next/gcp_bigquery","label":"Google BigQuery","docId":"gcp_bigquery","unlisted":false},{"type":"link","href":"/docs/next/syncing_xtable","label":"Apache XTable (incubating)","docId":"syncing_xtable","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Platform & Tools","items":[{"type":"link","href":"/docs/next/snapshot_exporter","label":"Exporter","docId":"snapshot_exporter","unlisted":false},{"type":"link","href":"/docs/next/precommit_validator","label":"Data Quality","docId":"precommit_validator","unlisted":false},{"type":"link","href":"/docs/next/platform_services_post_commit_callback","label":"Post-commit Callback","docId":"platform_services_post_commit_callback","unlisted":false},{"type":"link","href":"/docs/next/disaster_recovery","label":"Disaster Recovery","docId":"disaster_recovery","unlisted":false},{"type":"link","href":"/docs/next/migration_guide","label":"Bootstrapping","docId":"migration_guide","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Operating Hudi","items":[{"type":"link","href":"/docs/next/performance","label":"Performance","docId":"performance","unlisted":false},{"type":"link","href":"/docs/next/deployment","label":"Deployment","docId":"deployment","unlisted":false},{"type":"link","href":"/docs/next/procedures","label":"SQL Procedures","docId":"procedures","unlisted":false},{"type":"link","href":"/docs/next/cli","label":"CLI","docId":"cli","unlisted":false},{"type":"link","href":"/docs/next/metrics","label":"Metrics","docId":"metrics","unlisted":false},{"type":"link","href":"/docs/next/encryption","label":"Encryption","docId":"encryption","unlisted":false},{"type":"link","href":"/docs/next/troubleshooting","label":"Troubleshooting","docId":"troubleshooting","unlisted":false},{"type":"link","href":"/docs/next/tuning-guide","label":"Spark Tuning Guide","docId":"tuning-guide","unlisted":false},{"type":"link","href":"/docs/next/flink_tuning","label":"Flink Tuning Guide","docId":"flink_tuning","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Configurations","items":[{"type":"link","href":"/docs/next/basic_configurations","label":"Basic Configurations","docId":"basic_configurations","unlisted":false},{"type":"link","href":"/docs/next/configurations","label":"All Configurations","docId":"configurations","unlisted":false},{"type":"category","label":"Storage Configurations","items":[{"type":"link","href":"/docs/next/cloud","label":"Cloud Storage","docId":"cloud","unlisted":false},{"type":"link","href":"/docs/next/s3_hoodie","label":"AWS S3","docId":"s3_hoodie","unlisted":false},{"type":"link","href":"/docs/next/gcs_hoodie","label":"Google Cloud","docId":"gcs_hoodie","unlisted":false},{"type":"link","href":"/docs/next/oss_hoodie","label":"Alibaba Cloud","docId":"oss_hoodie","unlisted":false},{"type":"link","href":"/docs/next/azure_hoodie","label":"Microsoft Azure","docId":"azure_hoodie","unlisted":false},{"type":"link","href":"/docs/next/cos_hoodie","label":"Tencent Cloud","docId":"cos_hoodie","unlisted":false},{"type":"link","href":"/docs/next/ibm_cos_hoodie","label":"IBM Cloud","docId":"ibm_cos_hoodie","unlisted":false},{"type":"link","href":"/docs/next/bos_hoodie","label":"Baidu Cloud","docId":"bos_hoodie","unlisted":false},{"type":"link","href":"/docs/next/jfs_hoodie","label":"JuiceFS","docId":"jfs_hoodie","unlisted":false},{"type":"link","href":"/docs/next/oci_hoodie","label":"Oracle Cloud Infrastructure","docId":"oci_hoodie","unlisted":false},{"type":"link","href":"/docs/next/ks3_hoodie","label":"KS3 Filesystem","docId":"ks3_hoodie","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true}],"quick_links":[{"type":"link","label":"Powered By","href":"powered-by"},{"type":"link","label":"Chat with us on Slack","href":"https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA"}]},"docs":{"azure_hoodie":{"id":"azure_hoodie","title":"Microsoft Azure","description":"In this page, we explain how to use Hudi on Microsoft Azure.","sidebar":"docs"},"basic_configurations":{"id":"basic_configurations","title":"Basic Configurations","description":"This page covers the basic configurations you may use to write/read Hudi tables. This page only features a subset of the most frequently used configurations. For a full list of all configs, please visit the All Configurations page.","sidebar":"docs"},"bos_hoodie":{"id":"bos_hoodie","title":"Baidu Cloud","description":"In this page, we explain how to get your Hudi job to store into Baidu BOS.","sidebar":"docs"},"cleaning":{"id":"cleaning","title":"Cleaning","description":"Background","sidebar":"docs"},"cli":{"id":"cli","title":"CLI","description":"Local set up","sidebar":"docs"},"cloud":{"id":"cloud","title":"Cloud Storage","description":"Talking to Cloud Storage","sidebar":"docs"},"clustering":{"id":"clustering","title":"Clustering","description":"Background","sidebar":"docs"},"compaction":{"id":"compaction","title":"Compaction","description":"Background","sidebar":"docs"},"comparison":{"id":"comparison","title":"Comparison","description":"Apache Hudi fills a big void for processing data on top of DFS, and thus mostly co-exists nicely with these technologies. However,"},"concepts":{"id":"concepts","title":"Concepts","description":"Apache Hudi (pronounced \u201cHudi\u201d) provides the following streaming primitives over hadoop compatible storages"},"concurrency_control":{"id":"concurrency_control","title":"Concurrency Control","description":"Concurrency control defines how different writers, readers, and table services coordinate access to a Hudi table. Hudi ensures atomic writes by publishing commits atomically to the timeline, stamped with an instant time that denotes when the action is deemed to have occurred. Unlike general-purpose file version control, Hudi draws a clear distinction between writer processes that issue write operations, table services that (re)write data/metadata to optimize or perform bookkeeping, and readers (that execute queries and read data).","sidebar":"docs"},"configurations":{"id":"configurations","title":"All Configurations","description":"This page covers the different ways of configuring your job to write/read Hudi tables. At a high level, you can control behaviour at few levels.","sidebar":"docs"},"cos_hoodie":{"id":"cos_hoodie","title":"Tencent Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Tencent Cloud COS.","sidebar":"docs"},"deployment":{"id":"deployment","title":"Deployment","description":"This section provides all the help you need to deploy and operate Hudi tables at scale.","sidebar":"docs"},"disaster_recovery":{"id":"disaster_recovery","title":"Disaster Recovery","description":"Disaster Recovery is very much mission-critical for any software. Especially when it comes to data systems, the impact could be very serious","sidebar":"docs"},"docker_demo":{"id":"docker_demo","title":"Docker Demo","description":"A Demo using Docker containers","sidebar":"docs"},"encryption":{"id":"encryption","title":"Encryption","description":"Since Hudi 0.11.0, Spark 3.2 support has been added and accompanying that, Parquet 1.12 has been included, which brings encryption feature to Hudi. In this section, we will show a guide on how to enable encryption in Hudi tables.","sidebar":"docs"},"file_sizing":{"id":"file_sizing","title":"File Sizing","description":"Solving the small file problem is fundamental to ensuring","sidebar":"docs"},"flink_tuning":{"id":"flink_tuning","title":"Flink Tuning Guide","description":"Global Configurations","sidebar":"docs"},"flink-quick-start-guide":{"id":"flink-quick-start-guide","title":"Flink Quick Start","description":"This page introduces Flink\u2013Hudi integration and demonstrates how Flink brings the power of streaming to Hudi.","sidebar":"docs"},"gcp_bigquery":{"id":"gcp_bigquery","title":"Google BigQuery","description":"Hudi tables can be queried from Google Cloud BigQuery as external tables. As of","sidebar":"docs"},"gcs_hoodie":{"id":"gcs_hoodie","title":"Google Cloud","description":"For Hudi storage on GCS, regional buckets provide an DFS API with strong consistency.","sidebar":"docs"},"hoodie_streaming_ingestion":{"id":"hoodie_streaming_ingestion","title":"Using Spark","description":"Hudi Streamer","sidebar":"docs"},"hudi_stack":{"id":"hudi_stack","title":"Apache Hudi Stack","description":"Apache Hudi adds core warehouse and database functionality directly to a data lake (more recently known as the data lakehouse architecture) elevating it from a collection of","sidebar":"docs"},"ibm_cos_hoodie":{"id":"ibm_cos_hoodie","title":"IBM Cloud","description":"In this page, we explain how to get your Hudi spark job to store into IBM Cloud Object Storage.","sidebar":"docs"},"indexes":{"id":"indexes","title":"Indexes","description":"In databases, indexes are auxiliary data structures maintained to quickly locate records needed, without reading unnecessary data","sidebar":"docs"},"ingestion_flink":{"id":"ingestion_flink","title":"Using Flink","description":"CDC Ingestion","sidebar":"docs"},"ingestion_kafka_connect":{"id":"ingestion_kafka_connect","title":"Using Kafka Connect","description":"Kafka Connect is a popularly used framework for integrating and moving streaming data between various systems.","sidebar":"docs"},"jfs_hoodie":{"id":"jfs_hoodie","title":"JuiceFS","description":"In this page, we explain how to use Hudi with JuiceFS.","sidebar":"docs"},"key_generation":{"id":"key_generation","title":"Key Generation","description":"Hudi needs some way to point to records in the table, so that base/log files can be merged efficiently for updates/deletes,","sidebar":"docs"},"ks3_hoodie":{"id":"ks3_hoodie","title":"KS3 Filesystem","description":"In this page, we explain how to get your Hudi spark job to store into KS3.","sidebar":"docs"},"markers":{"id":"markers","title":"Marker Mechanism","description":"Purpose of Markers","sidebar":"docs"},"metadata":{"id":"metadata","title":"Table Metadata","description":"Hudi tracks metadata about a table to remove bottlenecks in achieving great read/write performance, specifically on cloud storage.","sidebar":"docs"},"metadata_indexing":{"id":"metadata_indexing","title":"Indexing","description":"Hudi maintains a scalable metadata that has some auxiliary data about the table.","sidebar":"docs"},"metrics":{"id":"metrics","title":"Metrics","description":"In this section, we will introduce the MetricsReporter and HoodieMetrics in Hudi. You can view the metrics-related configurations here.","sidebar":"docs"},"migration_guide":{"id":"migration_guide","title":"Bootstrapping","description":"Hudi maintains metadata such as commit timeline and indexes to manage a table. The commit timelines helps to understand the actions happening on a table as well as the current state of a table. Indexes are used by Hudi to maintain a record key to file id mapping to efficiently locate a record. At the moment, Hudi supports writing only parquet columnar formats.","sidebar":"docs"},"notebooks":{"id":"notebooks","title":"Notebooks","description":"Get hands-on with Apache Hudi using interactive notebooks!","sidebar":"docs"},"oci_hoodie":{"id":"oci_hoodie","title":"Oracle Cloud Infrastructure","description":"The Oracle Object Storage system provides strongly-consistent operations on all buckets in all regions. OCI Object Storage provides an HDFS Connector your Application will need to access data.","sidebar":"docs"},"oss_hoodie":{"id":"oss_hoodie","title":"Alibaba Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Aliyun OSS.","sidebar":"docs"},"overview":{"id":"overview","title":"Overview","description":"Hello there! This overview will provide a high level summary of what Apache Hudi is and will orient you on","sidebar":"docs"},"performance":{"id":"performance","title":"Performance","description":"Optimized DFS Access","sidebar":"docs"},"platform_services_post_commit_callback":{"id":"platform_services_post_commit_callback","title":"Post-commit Callback","description":"Apache Hudi provides the ability to post a callback notification about a write commit. This may be valuable if you need","sidebar":"docs"},"precommit_validator":{"id":"precommit_validator","title":"Data Quality","description":"Data quality refers to the overall accuracy, completeness, consistency, and validity of data. Ensuring data quality is vital for accurate analysis and reporting, as well as for compliance with regulations and maintaining trust in your organization\'s data infrastructure.","sidebar":"docs"},"procedures":{"id":"procedures","title":"SQL Procedures","description":"Stored procedures are available when use Hudi SparkSQL extensions in all spark\'s version.","sidebar":"docs"},"python-rust-quick-start-guide":{"id":"python-rust-quick-start-guide","title":"Python/Rust Quick Start","description":"This guide will help you get started with Hudi-rs, the native Rust implementation for Apache Hudi with Python bindings. Learn how to install, set up, and perform basic operations using both Python and Rust interfaces.","sidebar":"docs"},"querying_data":{"id":"querying_data","title":"Querying Data","description":"This page is no longer maintained. Please refer to Hudi SQL DDL, SQL DML, SQL Queries and Procedures for the latest documentation."},"quick-start-guide":{"id":"quick-start-guide","title":"Spark Quick Start","description":"This guide provides a quick peek at Hudi\'s capabilities using Spark. Using Spark Datasource APIs(both scala and python) and using Spark SQL,","sidebar":"docs"},"reading_tables_batch_reads":{"id":"reading_tables_batch_reads","title":"Batch Reads","description":"Spark DataSource API","sidebar":"docs"},"reading_tables_streaming_reads":{"id":"reading_tables_streaming_reads","title":"Streaming Reads","description":"Spark Streaming","sidebar":"docs"},"record_merger":{"id":"record_merger","title":"Record Merger","description":"Hudi handles mutations to records and streaming data as briefly touched upon in the timeline ordering section.","sidebar":"docs"},"rollbacks":{"id":"rollbacks","title":"Auto Rollbacks","description":"Your pipelines could fail due to numerous reasons like crashes, valid bugs in the code, unavailability of any external","sidebar":"docs"},"s3_hoodie":{"id":"s3_hoodie","title":"AWS S3","description":"In this page, we explain how to get your Hudi spark job to store into AWS S3.","sidebar":"docs"},"schema_evolution":{"id":"schema_evolution","title":"Schema Evolution","description":"Schema evolution is an essential aspect of data management, and Hudi supports schema evolution on write out-of-the-box,","sidebar":"docs"},"snapshot_exporter":{"id":"snapshot_exporter","title":"Exporter","description":"Introduction","sidebar":"docs"},"sql_ddl":{"id":"sql_ddl","title":"SQL DDL","description":"This page describes support for creating and altering tables using SQL across various engines.","sidebar":"docs"},"sql_dml":{"id":"sql_dml","title":"SQL DML","description":"Spark SQL","sidebar":"docs"},"sql_queries":{"id":"sql_queries","title":"SQL Queries","description":"Hudi stores and organizes data on storage while providing different ways of querying, across a wide range of query engines.","sidebar":"docs"},"storage_layouts":{"id":"storage_layouts","title":"Storage Layouts","description":"The following describes the general organization of files in storage for a Hudi table.","sidebar":"docs"},"structure":{"id":"structure","title":"Structure","description":"Hudi (pronounced \u201cHoodie\u201d) ingests & manages storage of large analytical tables over DFS (HDFS or cloud stores) and provides three types of queries."},"syncing_aws_glue_data_catalog":{"id":"syncing_aws_glue_data_catalog","title":"AWS Glue Data Catalog","description":"Hudi tables can sync to AWS Glue Data Catalog directly via AWS SDK. Piggyback on HiveSyncTool","sidebar":"docs"},"syncing_datahub":{"id":"syncing_datahub","title":"DataHub","description":"DataHub is a rich metadata platform that supports features like data discovery, data","sidebar":"docs"},"syncing_metastore":{"id":"syncing_metastore","title":"Hive Metastore","description":"Hive Metastore is an","sidebar":"docs"},"syncing_xtable":{"id":"syncing_xtable","title":"Apache XTable (incubating)","description":"Hudi (tables created from 0.14.0 onwards) supports syncing to Iceberg and/or Delta Lake with Apache XTable (incubating), providing users with the option to interoperate with other table formats like Delta Lake and Apache Iceberg.","sidebar":"docs"},"table_types":{"id":"table_types","title":"Table & Query Types","description":"Hudi **table types** define how data is stored and how write operations are implemented on top of the table (i.e how data is written).","sidebar":"docs"},"timeline":{"id":"timeline","title":"Timeline","description":"Changes to table state (writes, table services, schema changes, etc) are recorded as actions_** in the Hudi timeline_. The Hudi timeline is a log of all actions performed","sidebar":"docs"},"troubleshooting":{"id":"troubleshooting","title":"Troubleshooting","description":"For performance related issues, please refer to the tuning guide","sidebar":"docs"},"tuning-guide":{"id":"tuning-guide","title":"Spark Tuning Guide","description":"To get a better understanding of where your Hudi jobs is spending its time, use a tool like YourKit Java Profiler, to obtain heap dumps/flame graphs.","sidebar":"docs"},"use_cases":{"id":"use_cases","title":"Use Cases","description":"Apache Hudi is a powerful data lakehouse platform that shines in a variety of use cases due to its high-performance design, rich feature set, and","sidebar":"docs"},"write_operations":{"id":"write_operations","title":"Write Operations","description":"It may be helpful to understand the different write operations supported by Hudi and how best to leverage them. These operations","sidebar":"docs"},"writing_data":{"id":"writing_data","title":"Batch Writes","description":"Spark DataSource API","sidebar":"docs"},"writing_tables_streaming_writes":{"id":"writing_tables_streaming_writes","title":"Streaming Writes","description":"Spark Streaming","sidebar":"docs"}}}}')}}]);
"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[3175],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return c}});var r=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,i=function(e,t){if(null==e)return{};var a,r,i={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=r.createContext({}),d=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=d(e.components);return r.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=d(a),c=i,h=m["".concat(s,".").concat(c)]||m[c]||u[c]||n;return a?r.createElement(h,o(o({ref:t},p),{},{components:a})):r.createElement(h,o({ref:t},p))}));function c(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,o=new Array(n);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,o[1]=l;for(var d=2;d<n;d++)o[d]=a[d];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}m.displayName="MDXCreateElement"},1168:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return d},toc:function(){return p},default:function(){return m}});var r=a(2122),i=a(9756),n=(a(7294),a(3905)),o=["components"],l={title:"Release 0.6.0",sidebar_position:4,layout:"releases",toc:!0,last_modified_at:new Date("2020-05-28T15:40:00.000Z")},s="[Release 0.6.0](https://github.com/apache/hudi/releases/tag/release-0.6.0) ([docs](/docs/quick-start-guide))",d={unversionedId:"release-0.6.0",id:"release-0.6.0",isDocsHomePage:!1,title:"Release 0.6.0",description:"Download Information",source:"@site/releases/release-0.6.0.md",sourceDirName:".",slug:"/release-0.6.0",permalink:"/releases/release-0.6.0",version:"current",lastUpdatedBy:"Vinoth Govindarajan",lastUpdatedAt:1627537876,formattedLastUpdatedAt:"7/28/2021",sidebarPosition:4,frontMatter:{title:"Release 0.6.0",sidebar_position:4,layout:"releases",toc:!0,last_modified_at:"2020-05-28T15:40:00.000Z"},sidebar:"releases",previous:{title:"Release 0.7.0",permalink:"/releases/release-0.7.0"},next:{title:"Release 0.5.3",permalink:"/releases/release-0.5.3"}},p=[{value:"Download Information",id:"download-information",children:[]},{value:"Migration Guide for this release",id:"migration-guide-for-this-release",children:[]},{value:"Release Highlights",id:"release-highlights",children:[{value:"Writer side improvements:",id:"writer-side-improvements",children:[]},{value:"Query side improvements:",id:"query-side-improvements",children:[]},{value:"Usability:",id:"usability",children:[]}]},{value:"Raw Release Notes",id:"raw-release-notes",children:[]}],u={toc:p};function m(e){var t=e.components,a=(0,i.Z)(e,o);return(0,n.kt)("wrapper",(0,r.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"release-060-docs"},(0,n.kt)("a",{parentName:"h1",href:"https://github.com/apache/hudi/releases/tag/release-0.6.0"},"Release 0.6.0")," (",(0,n.kt)("a",{parentName:"h1",href:"/docs/quick-start-guide"},"docs"),")"),(0,n.kt)("h2",{id:"download-information"},"Download Information"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Source Release : ",(0,n.kt)("a",{parentName:"li",href:"https://downloads.apache.org/hudi/0.6.0/hudi-0.6.0.src.tgz"},"Apache Hudi 0.6.0 Source Release")," (",(0,n.kt)("a",{parentName:"li",href:"https://downloads.apache.org/hudi/0.6.0/hudi-0.6.0.src.tgz.asc"},"asc"),", ",(0,n.kt)("a",{parentName:"li",href:"https://downloads.apache.org/hudi/0.6.0/hudi-0.6.0.src.tgz.sha512"},"sha512"),")"),(0,n.kt)("li",{parentName:"ul"},"Apache Hudi jars corresponding to this release is available ",(0,n.kt)("a",{parentName:"li",href:"https://repository.apache.org/#nexus-search;quick~hudi"},"here"))),(0,n.kt)("h2",{id:"migration-guide-for-this-release"},"Migration Guide for this release"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"If migrating from release older than 0.5.3, please also check the upgrade instructions for each subsequent release below."),(0,n.kt)("li",{parentName:"ul"},"With 0.6.0 Hudi is moving from list based rollback to marker based rollbacks. To smoothly aid this transition a\nnew property called ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.table.version")," is added to ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.properties")," file. Whenever Hudi is launched with\nnewer table version i.e 1 (or moving from pre 0.6.0 to 0.6.0), an upgrade step will be executed automatically.\nThis automatic upgrade step will happen just once per Hudi table as the ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.table.version")," will be updated in property file after upgrade is completed."),(0,n.kt)("li",{parentName:"ul"},"Similarly, a command line tool for Downgrading (command - ",(0,n.kt)("inlineCode",{parentName:"li"},"downgrade"),") is added if in case some users want to downgrade Hudi from table version 1 to 0 or move from Hudi 0.6.0 to pre 0.6.0"),(0,n.kt)("li",{parentName:"ul"},"If you were using a user defined partitioner with bulkInsert() RDD API, the base interface has changed to ",(0,n.kt)("inlineCode",{parentName:"li"},"BulkInsertPartitioner")," and will need minor adjustments to your existing implementations.")),(0,n.kt)("h2",{id:"release-highlights"},"Release Highlights"),(0,n.kt)("h3",{id:"writer-side-improvements"},"Writer side improvements:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Bootstrapping existing parquet datasets :  Adds support for bootstrapping existing datasets into Hudi, via both Spark datasource writer and\ndeltastreamer tool, with support for reading from Hive, SparkSQL, AWS Athena (prestoDB support coming soon). See ",(0,n.kt)("a",{parentName:"li",href:"https://cwiki.apache.org/confluence/display/HUDI/RFC+-+15%3A+HUDI+File+Listing+and+Query+Planning+Improvements"},"RFC-15")," for technical details.\nNote that this is an experimental feature, which will be improved upon further in the 0.6.x versions."),(0,n.kt)("li",{parentName:"ul"},"Native row writing for bulk_insert : Avoids any dataframe-rdd conversion for bulk_insert path, which can improve performance of initial bulk loads.\nAlthough, this is typically not the bottleneck for upsert/deletes, subsequent releases in 0.6.x versions will expand this to other write operations\nto make reasoning about schema management easier, avoiding the spark-avro conversion totally."),(0,n.kt)("li",{parentName:"ul"},"Bulk insert sort modes : Hudi bulk_insert sorts the input globally to optimize file sizes and avoid out-of-memory issues encountered when writing parallely to multiple DFS partitions.\nFor users who want to prepare the dataframe for writing outside of Hudi, we have made this configurable using ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.bulkinsert.sort.mode"),"."),(0,n.kt)("li",{parentName:"ul"},"Cleaning can now be run concurrently with writing, using ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.clean.async=true"),"which can speed up time taken to finish committing."),(0,n.kt)("li",{parentName:"ul"},"Async compaction for spark streaming writes to hudi table, is now self managed by default, controlling ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.datasource.compaction.async.enable"),"."),(0,n.kt)("li",{parentName:"ul"},"Rollbacks no longer perform full table listings, by leveraging marker files. To enable, set ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.rollback.using.markers=true"),"."),(0,n.kt)("li",{parentName:"ul"},"Added a new index ",(0,n.kt)("inlineCode",{parentName:"li"},"hoodie.index.type=SIMPLE")," which can be faster than ",(0,n.kt)("inlineCode",{parentName:"li"},"BLOOM_INDEX")," for cases where updates/deletes spread across a large portion of the table.   "),(0,n.kt)("li",{parentName:"ul"},"Hudi now supports ",(0,n.kt)("inlineCode",{parentName:"li"},"Azure Data Lake Storage V2")," , ",(0,n.kt)("inlineCode",{parentName:"li"},"Alluxio")," and ",(0,n.kt)("inlineCode",{parentName:"li"},"Tencent Cloud Object Storage")," storages."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://hudi.apache.org/docs/writing_data#multitabledeltastreamer"},"HoodieMultiDeltaStreamer")," adds support for ingesting multiple kafka streams in a single DeltaStreamer deployment, effectively reducing operational burden for using delta streamer\nas your data lake ingestion tool (Experimental feature)"),(0,n.kt)("li",{parentName:"ul"},"Added a new tool - InitialCheckPointProvider, to set checkpoints when migrating to DeltaStreamer after an initial load of the table is complete."),(0,n.kt)("li",{parentName:"ul"},"Delta Streamer tool now supports ingesting CSV data sources, chaining of multiple transformers to build more advanced ETL jobs."),(0,n.kt)("li",{parentName:"ul"},"Introducing a new ",(0,n.kt)("inlineCode",{parentName:"li"},"CustomKeyGenerator")," key generator class, that provides flexible configurations to provide enable different types of key, partition path generation in  single class.\nWe also added support for more time units and date/time formats in ",(0,n.kt)("inlineCode",{parentName:"li"},"TimestampBasedKeyGenerator"),". See ",(0,n.kt)("a",{parentName:"li",href:"https://hudi.apache.org/docs/writing_data#key-generation"},"docs")," for more.")),(0,n.kt)("h3",{id:"query-side-improvements"},"Query side improvements:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Starting 0.6.0, snapshot queries are feasible on MOR tables using spark datasource. (experimental feature)"),(0,n.kt)("li",{parentName:"ul"},"In prior versions we only supported ",(0,n.kt)("inlineCode",{parentName:"li"},"HoodieCombineHiveInputFormat")," for CopyOnWrite tables to ensure that there is a limit on the number of mappers spawned for\nany query. Hudi now supports Merge on Read tables also using ",(0,n.kt)("inlineCode",{parentName:"li"},"HoodieCombineInputFormat"),"."),(0,n.kt)("li",{parentName:"ul"},"Speedup spark read queries by caching metaclient in HoodieROPathFilter. This helps reduce listing related overheads in S3 when filtering files for read-optimized queries. ")),(0,n.kt)("h3",{id:"usability"},"Usability:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Spark DAGs are named to aid better debuggability."),(0,n.kt)("li",{parentName:"ul"},"Support pluggable metrics reporting by introducing proper abstraction for user defined metrics. Console, JMX, Prometheus and DataDog metric reporters have been added."),(0,n.kt)("li",{parentName:"ul"},"A new utility called Data snapshot exporter has been added. Latest table snapshot as of a certain point in time can be exported as plain parquet files with this tool."),(0,n.kt)("li",{parentName:"ul"},"Introduce write committed callback hooks for incremental pipelines to be notified and act on new commits in the timeline. For e.g, Apache Airflow jobs can be triggered\nas new commits arrive."),(0,n.kt)("li",{parentName:"ul"},"Added support for deleting savepoints via CLI"),(0,n.kt)("li",{parentName:"ul"},"Added a new command - ",(0,n.kt)("inlineCode",{parentName:"li"},"export instants"),", to export metadata of instants")),(0,n.kt)("h2",{id:"raw-release-notes"},"Raw Release Notes"),(0,n.kt)("p",null,"   The raw release notes are available ",(0,n.kt)("a",{parentName:"p",href:"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12322822&version=12346663"},"here")))}m.isMDXComponent=!0}}]);
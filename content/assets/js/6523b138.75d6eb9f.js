"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[94287],{28453:(e,t,a)=>{a.d(t,{R:()=>o,x:()=>d});var n=a(96540);const s={},i=n.createContext(s);function o(e){const t=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(i.Provider,{value:t},e.children)}},41797:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>o,metadata:()=>n,toc:()=>r});const n=JSON.parse('{"id":"syncing_datahub","title":"DataHub","description":"DataHub is a rich metadata platform that supports features like data discovery, data","source":"@site/versioned_docs/version-1.0.2/syncing_datahub.md","sourceDirName":".","slug":"/syncing_datahub","permalink":"/docs/syncing_datahub","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/versioned_docs/version-1.0.2/syncing_datahub.md","tags":[],"version":"1.0.2","frontMatter":{"title":"DataHub","keywords":["hudi","datahub","sync"]},"sidebar":"docs","previous":{"title":"AWS Glue Data Catalog","permalink":"/docs/syncing_aws_glue_data_catalog"},"next":{"title":"Hive Metastore","permalink":"/docs/syncing_metastore"}}');var s=a(74848),i=a(28453);const o={title:"DataHub",keywords:["hudi","datahub","sync"]},d=void 0,c={},r=[{value:"Configurations",id:"configurations",level:3},{value:"Example",id:"example",level:3}];function l(e){const t={a:"a",code:"code",em:"em",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://datahubproject.io/",children:"DataHub"})," is a rich metadata platform that supports features like data discovery, data\nobeservability, federated governance, etc."]}),"\n",(0,s.jsxs)(t.p,{children:["Since Hudi 0.11.0, you can now sync to a DataHub instance by setting ",(0,s.jsx)(t.code,{children:"DataHubSyncTool"})," as one of the sync tool classes\nfor ",(0,s.jsx)(t.code,{children:"HoodieStreamer"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["The target Hudi table will be sync'ed to DataHub as a ",(0,s.jsx)(t.code,{children:"Dataset"}),", which will be created with the following properties:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Hudi table properties and partitioning information"}),"\n",(0,s.jsx)(t.li,{children:"Spark-related properties"}),"\n",(0,s.jsx)(t.li,{children:"User-defined properties"}),"\n",(0,s.jsx)(t.li,{children:"The last commit and the last commit completion timestamps"}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["Additionally, the ",(0,s.jsx)(t.code,{children:"Dataset"})," object will include the following metadata:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["sub-type as ",(0,s.jsx)(t.code,{children:"Table"})]}),"\n",(0,s.jsx)(t.li,{children:"browse path"}),"\n",(0,s.jsx)(t.li,{children:"parent container"}),"\n",(0,s.jsx)(t.li,{children:"Avro schema"}),"\n",(0,s.jsxs)(t.li,{children:["optionally, attached with a ",(0,s.jsx)(t.code,{children:"Domain"})," object"]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["Also, the parent database will be sync'ed to DataHub as a ",(0,s.jsx)(t.code,{children:"Container"}),", including the following metadata:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["sub-type as ",(0,s.jsx)(t.code,{children:"Database"})]}),"\n",(0,s.jsx)(t.li,{children:"browse paths"}),"\n",(0,s.jsxs)(t.li,{children:["optionally, attached with a ",(0,s.jsx)(t.code,{children:"Domain"})," object"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"configurations",children:"Configurations"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"DataHubSyncTool"})," makes use of DataHub's Java Emitter to send the metadata via HTTP REST APIs. It is required to\nset ",(0,s.jsx)(t.code,{children:"hoodie.meta.sync.datahub.emitter.server"})," to the URL of the DataHub instance for sync."]}),"\n",(0,s.jsxs)(t.p,{children:["If needs auth token, set ",(0,s.jsx)(t.code,{children:"hoodie.meta.sync.datahub.emitter.token"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["If needs customized creation of the emitter object,\nimplement ",(0,s.jsx)(t.code,{children:"org.apache.hudi.sync.datahub.config.DataHubEmitterSupplier"})," and supply the implementation's FQCN\nto ",(0,s.jsx)(t.code,{children:"hoodie.meta.sync.datahub.emitter.supplier.class"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["By default, the sync config's database name and table name will be used to make the target ",(0,s.jsx)(t.code,{children:"Dataset"}),"'s URN.\nSubclass ",(0,s.jsx)(t.code,{children:"HoodieDataHubDatasetIdentifier"})," and set it to ",(0,s.jsx)(t.code,{children:"hoodie.meta.sync.datahub.dataset.identifier.class"})," to customize\nthe URN creation."]}),"\n",(0,s.jsxs)(t.p,{children:["Optionally, sync'ed ",(0,s.jsx)(t.code,{children:"Dataset"})," and ",(0,s.jsx)(t.code,{children:"Container"})," objects can be attached with a ",(0,s.jsx)(t.code,{children:"Domain"})," object. To do this, set\n",(0,s.jsx)(t.code,{children:"hoodie.meta.sync.datahub.domain.name"})," to a valid ",(0,s.jsx)(t.code,{children:"Domain"})," URN. Also, sync'ed ",(0,s.jsx)(t.code,{children:"Dataset"})," can be attached with\nuser defined properties. To do this, set ",(0,s.jsx)(t.code,{children:"hoodie.meta.sync.datahub.table.properties"})," to a comma-separated key-value\nstring (",(0,s.jsx)(t.em,{children:"eg"})," ",(0,s.jsx)(t.code,{children:"key1=val1,key2=val2"}),")."]}),"\n",(0,s.jsx)(t.h3,{id:"example",children:"Example"}),"\n",(0,s.jsxs)(t.p,{children:["The following shows an example configuration to run ",(0,s.jsx)(t.code,{children:"HoodieStreamer"})," with ",(0,s.jsx)(t.code,{children:"DataHubSyncTool"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["In addition to ",(0,s.jsx)(t.code,{children:"hudi-utilities-slim-bundle"})," that contains ",(0,s.jsx)(t.code,{children:"HoodieStreamer"}),", you also add ",(0,s.jsx)(t.code,{children:"hudi-datahub-sync-bundle"})," to\nthe classpath."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-shell",children:"spark-submit --master yarn \\\n--packages org.apache.hudi:hudi-utilities-slim-bundle_2.12:1.0.1,org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.1 \\\n--jars /opt/hudi-datahub-sync-bundle-1.0.1.jar \\\n--class org.apache.hudi.utilities.streamer.HoodieStreamer \\\n/opt/hudi-utilities-slim-bundle_2.12-1.0.1.jar \\\n--target-table mytable \\\n# ... other HoodieStreamer's configs\n--enable-sync \\\n--sync-tool-classes org.apache.hudi.sync.datahub.DataHubSyncTool \\\n--hoodie-conf hoodie.meta.sync.datahub.emitter.server=http://url-to-datahub-instance:8080 \\\n--hoodie-conf hoodie.datasource.hive_sync.database=mydb \\\n--hoodie-conf hoodie.datasource.hive_sync.table=mytable \\\n"})})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}}}]);
"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[96740],{28453(e,a,i){i.d(a,{R:()=>r,x:()=>o});var t=i(96540);const n={},l=t.createContext(n);function r(e){const a=t.useContext(l);return t.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),t.createElement(l.Provider,{value:a},e.children)}},36429(e,a,i){i.r(a),i.d(a,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"catalog_polaris","title":"Apache Polaris (Incubating)","description":"Hudi 1.1.0 added support for Apache Polaris catalog integration (see PR #13558). However, a Polaris release that includes this PR is pending before this integration to be available.","source":"@site/docs/catalog_polaris.md","sourceDirName":".","slug":"/catalog_polaris","permalink":"/docs/next/catalog_polaris","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/docs/catalog_polaris.md","tags":[],"version":"current","frontMatter":{"title":"Apache Polaris (Incubating)","toc":true,"toc_min_heading_level":2,"toc_max_heading_level":4,"keywords":["hudi","polaris","catalog","integration"]},"sidebar":"docs","previous":{"title":"Apache XTable (Incubating)","permalink":"/docs/next/syncing_xtable"},"next":{"title":"Exporter","permalink":"/docs/next/snapshot_exporter"}}');var n=i(74848),l=i(28453);const r={title:"Apache Polaris (Incubating)",toc:!0,toc_min_heading_level:2,toc_max_heading_level:4,keywords:["hudi","polaris","catalog","integration"]},o=void 0,s={},d=[{value:"Overview",id:"overview",level:2},{value:"How It Works",id:"how-it-works",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Spark Catalog Configuration",id:"spark-catalog-configuration",level:3},{value:"Hudi Configuration",id:"hudi-configuration",level:3},{value:"Usage Examples",id:"usage-examples",level:2},{value:"Creating a Hudi Table with Polaris Catalog",id:"creating-a-hudi-table-with-polaris-catalog",level:3},{value:"Writing Data to Hudi Tables",id:"writing-data-to-hudi-tables",level:3},{value:"Querying Hudi Tables",id:"querying-hudi-tables",level:3}];function c(e){const a={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.admonition,{title:"Polaris Integration Status",type:"warning",children:(0,n.jsxs)(a.p,{children:["Hudi 1.1.0 added support for Apache Polaris catalog integration (see ",(0,n.jsx)(a.a,{href:"https://github.com/apache/hudi/pull/13558",children:"PR #13558"}),"). However, a Polaris release that includes ",(0,n.jsx)(a.a,{href:"https://github.com/apache/polaris/pull/1862",children:"this PR"})," is pending before this integration to be available."]})}),"\n",(0,n.jsx)(a.h2,{id:"overview",children:"Overview"}),"\n",(0,n.jsxs)(a.p,{children:["Apache Hudi integrates with ",(0,n.jsx)(a.a,{href:"https://polaris.apache.org/",children:"Apache Polaris"})," (Incubating) catalog by delegating table creation operations to the Polaris Spark client. This integration allows Hudi tables to be automatically registered in the Polaris Catalog when created through Spark SQL, enabling unified metadata management across your data lakehouse."]}),"\n",(0,n.jsxs)(a.p,{children:["The integration works by detecting when Polaris catalog is configured in your Spark session and delegating the ",(0,n.jsx)(a.code,{children:"createTable"})," operation to the Polaris Spark catalog implementation, ensuring that Hudi table metadata is properly registered in Polaris."]}),"\n",(0,n.jsx)(a.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,n.jsx)(a.p,{children:"When Polaris catalog is configured, Hudi automatically detects it and routes table creation operations to Polaris. This means:"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsx)(a.li,{children:"Hudi tables created via Spark SQL are automatically registered in the Polaris catalog"}),"\n",(0,n.jsx)(a.li,{children:"Tables remain fully functional Hudi tables with all Hudi features (time travel, incremental queries, etc.)"}),"\n",(0,n.jsx)(a.li,{children:"Tables are discoverable and queryable through Polaris catalog interfaces"}),"\n"]}),"\n",(0,n.jsx)(a.h2,{id:"configuration",children:"Configuration"}),"\n",(0,n.jsx)(a.p,{children:"To enable Polaris catalog integration, you need to configure both the Polaris catalog in Spark and specify the catalog class name in Hudi configuration."}),"\n",(0,n.jsx)(a.h3,{id:"spark-catalog-configuration",children:"Spark Catalog Configuration"}),"\n",(0,n.jsx)(a.p,{children:"First, configure the Polaris catalog in your Spark session:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"set spark.sql.catalog.polaris_catalog=org.apache.polaris.spark.SparkCatalog\n"})}),"\n",(0,n.jsx)(a.h3,{id:"hudi-configuration",children:"Hudi Configuration"}),"\n",(0,n.jsx)(a.p,{children:"Configure Hudi to use the Polaris catalog class:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-properties",children:"hoodie.spark.polaris.catalog.class=org.apache.polaris.spark.SparkCatalog\n"})}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.strong,{children:"Configuration Property:"})}),"\n",(0,n.jsxs)(a.table,{children:[(0,n.jsx)(a.thead,{children:(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.th,{children:"Property"}),(0,n.jsx)(a.th,{children:"Default"}),(0,n.jsx)(a.th,{children:"Description"})]})}),(0,n.jsx)(a.tbody,{children:(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"hoodie.spark.polaris.catalog.class"})}),(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"org.apache.polaris.spark.SparkCatalog"})}),(0,n.jsx)(a.td,{children:"Fully qualified class name of the catalog that is used by the Polaris Spark client"})]})})]}),"\n",(0,n.jsx)(a.p,{children:"This configuration property was introduced in Hudi 1.1.0 and is marked as advanced. The default value matches the standard Polaris Spark catalog implementation."}),"\n",(0,n.jsx)(a.h2,{id:"usage-examples",children:"Usage Examples"}),"\n",(0,n.jsx)(a.h3,{id:"creating-a-hudi-table-with-polaris-catalog",children:"Creating a Hudi Table with Polaris Catalog"}),"\n",(0,n.jsx)(a.p,{children:"Once Polaris catalog is configured, you can create Hudi tables using Spark SQL. Hudi will automatically detect the Polaris catalog configuration and delegate table registration to Polaris:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS mydb.hudi_table (\n  id INT,\n  name STRING,\n  ts BIGINT,\n  dt STRING\n) USING hudi\nPARTITIONED BY (dt)\nTBLPROPERTIES (\n  primaryKey = 'id'\n)\n"})}),"\n",(0,n.jsx)(a.h3,{id:"writing-data-to-hudi-tables",children:"Writing Data to Hudi Tables"}),"\n",(0,n.jsxs)(a.p,{children:["You can write data to Hudi tables using ",(0,n.jsx)(a.code,{children:"INSERT INTO"})," SQL statements:"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"INSERT INTO mydb.hudi_table\nSELECT 1 AS id, 'John' AS name, 1695159649087 AS ts, '2024-01-01' AS dt;\n\n-- Insert with dynamic partitioning\nINSERT INTO mydb.hudi_table PARTITION(dt)\nSELECT 2 AS id, 'Jane' AS name, 1695159649088 AS ts, '2024-01-02' AS dt;\n"})}),"\n",(0,n.jsx)(a.h3,{id:"querying-hudi-tables",children:"Querying Hudi Tables"}),"\n",(0,n.jsx)(a.p,{children:"Query Hudi tables normally - they will be accessible through the configured catalog:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"SELECT * FROM mydb.hudi_table\nWHERE dt = '2024-01-01'\n"})})]})}function h(e={}){const{wrapper:a}={...(0,l.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}}}]);
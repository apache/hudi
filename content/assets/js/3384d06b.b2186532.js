"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[8725],{30031:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"0.12.1","label":"0.12.1","banner":"unmaintained","badge":true,"className":"docs-version-0.12.1","isLast":false,"docsSidebars":{"docs":[{"type":"link","label":"Overview","href":"/docs/0.12.1/overview","docId":"overview"},{"type":"category","label":"Quick Start","collapsed":false,"items":[{"type":"link","label":"Spark Guide","href":"/docs/0.12.1/quick-start-guide","docId":"quick-start-guide"},{"type":"link","label":"Flink Guide","href":"/docs/0.12.1/flink-quick-start-guide","docId":"flink-quick-start-guide"},{"type":"link","label":"Docker Demo","href":"/docs/0.12.1/docker_demo","docId":"docker_demo"}],"collapsible":true},{"type":"category","label":"Concepts","items":[{"type":"link","label":"Timeline","href":"/docs/0.12.1/timeline","docId":"timeline"},{"type":"link","label":"Table & Query Types","href":"/docs/0.12.1/table_types","docId":"table_types"},{"type":"link","label":"Indexing","href":"/docs/0.12.1/indexing","docId":"indexing"},{"type":"link","label":"File Layouts","href":"/docs/0.12.1/file_layouts","docId":"file_layouts"},{"type":"link","label":"Metadata Table","href":"/docs/0.12.1/metadata","docId":"metadata"},{"type":"link","label":"Write Operations","href":"/docs/0.12.1/write_operations","docId":"write_operations"},{"type":"link","label":"Schema Evolution","href":"/docs/0.12.1/schema_evolution","docId":"schema_evolution"},{"type":"link","label":"Key Generation","href":"/docs/0.12.1/key_generation","docId":"key_generation"},{"type":"link","label":"Concurrency Control","href":"/docs/0.12.1/concurrency_control","docId":"concurrency_control"}],"collapsible":true,"collapsed":true},{"type":"category","label":"How To","items":[{"type":"category","label":"SQL","items":[{"type":"link","label":"SQL DDL","href":"/docs/0.12.1/table_management","docId":"table_management"},{"type":"link","label":"Procedures","href":"/docs/0.12.1/procedures","docId":"procedures"}],"collapsible":true,"collapsed":true},{"type":"link","label":"Writing Data","href":"/docs/0.12.1/writing_data","docId":"writing_data"},{"type":"link","label":"Streaming Ingestion","href":"/docs/0.12.1/hoodie_deltastreamer","docId":"hoodie_deltastreamer"},{"type":"link","label":"Querying Data","href":"/docs/0.12.1/querying_data","docId":"querying_data"},{"type":"link","label":"Flink Setup","href":"/docs/0.12.1/flink_configuration","docId":"flink_configuration"},{"type":"category","label":"Syncing to Catalogs","items":[{"type":"link","label":"AWS Glue Data Catalog","href":"/docs/0.12.1/syncing_aws_glue_data_catalog","docId":"syncing_aws_glue_data_catalog"},{"type":"link","label":"DataHub","href":"/docs/0.12.1/syncing_datahub","docId":"syncing_datahub"},{"type":"link","label":"Hive Metastore","href":"/docs/0.12.1/syncing_metastore","docId":"syncing_metastore"},{"type":"link","label":"Google BigQuery","href":"/docs/0.12.1/gcp_bigquery","docId":"gcp_bigquery"}],"collapsible":true,"collapsed":true}],"collapsible":true,"collapsed":true},{"type":"category","label":"Services","items":[{"type":"link","label":"Bootstrapping","href":"/docs/0.12.1/migration_guide","docId":"migration_guide"},{"type":"link","label":"Compaction","href":"/docs/0.12.1/compaction","docId":"compaction"},{"type":"link","label":"Clustering","href":"/docs/0.12.1/clustering","docId":"clustering"},{"type":"link","label":"Metadata Indexing","href":"/docs/0.12.1/metadata_indexing","docId":"metadata_indexing"},{"type":"link","label":"Cleaning","href":"/docs/0.12.1/hoodie_cleaner","docId":"hoodie_cleaner"},{"type":"link","label":"Transformers","href":"/docs/0.12.1/transforms","docId":"transforms"},{"type":"link","label":"Marker Mechanism","href":"/docs/0.12.1/markers","docId":"markers"},{"type":"link","label":"File Sizing","href":"/docs/0.12.1/file_sizing","docId":"file_sizing"},{"type":"link","label":"Disaster Recovery","href":"/docs/0.12.1/disaster_recovery","docId":"disaster_recovery"},{"type":"link","label":"Exporter","href":"/docs/0.12.1/snapshot_exporter","docId":"snapshot_exporter"},{"type":"link","label":"Data Quality","href":"/docs/0.12.1/precommit_validator","docId":"precommit_validator"}],"collapsible":true,"collapsed":true},{"type":"category","label":"Configurations","items":[{"type":"link","label":"Basic Configurations","href":"/docs/0.12.1/basic_configurations","docId":"basic_configurations"},{"type":"link","label":"All Configurations","href":"/docs/0.12.1/configurations","docId":"configurations"}],"collapsible":true,"collapsed":true},{"type":"category","label":"Guides","items":[{"type":"link","label":"Query Engine Setup","href":"/docs/0.12.1/query_engine_setup","docId":"query_engine_setup"},{"type":"link","label":"Performance","href":"/docs/0.12.1/performance","docId":"performance"},{"type":"link","label":"Deployment","href":"/docs/0.12.1/deployment","docId":"deployment"},{"type":"link","label":"CLI","href":"/docs/0.12.1/cli","docId":"cli"},{"type":"link","label":"Metrics","href":"/docs/0.12.1/metrics","docId":"metrics"},{"type":"link","label":"Encryption","href":"/docs/0.12.1/encryption","docId":"encryption"},{"type":"link","label":"Troubleshooting","href":"/docs/0.12.1/troubleshooting","docId":"troubleshooting"},{"type":"link","label":"Tuning Guide","href":"/docs/0.12.1/tuning-guide","docId":"tuning-guide"},{"type":"category","label":"Storage Configurations","items":[{"type":"link","label":"Cloud Storage","href":"/docs/0.12.1/cloud","docId":"cloud"},{"type":"link","label":"AWS S3","href":"/docs/0.12.1/s3_hoodie","docId":"s3_hoodie"},{"type":"link","label":"Google Cloud","href":"/docs/0.12.1/gcs_hoodie","docId":"gcs_hoodie"},{"type":"link","label":"Alibaba Cloud","href":"/docs/0.12.1/oss_hoodie","docId":"oss_hoodie"},{"type":"link","label":"Microsoft Azure","href":"/docs/0.12.1/azure_hoodie","docId":"azure_hoodie"},{"type":"link","label":"Tencent Cloud","href":"/docs/0.12.1/cos_hoodie","docId":"cos_hoodie"},{"type":"link","label":"IBM Cloud","href":"/docs/0.12.1/ibm_cos_hoodie","docId":"ibm_cos_hoodie"},{"type":"link","label":"Baidu Cloud","href":"/docs/0.12.1/bos_hoodie","docId":"bos_hoodie"},{"type":"link","label":"JuiceFS","href":"/docs/0.12.1/jfs_hoodie","docId":"jfs_hoodie"}],"collapsible":true,"collapsed":true}],"collapsible":true,"collapsed":true},{"type":"link","label":"Use Cases","href":"/docs/0.12.1/use_cases","docId":"use_cases"},{"type":"link","label":"FAQs","href":"/docs/0.12.1/faq","docId":"faq"},{"type":"link","label":"Privacy Policy","href":"/docs/0.12.1/privacy","docId":"privacy"}],"quick_links":[{"type":"link","label":"Powered By","href":"powered-by"},{"type":"link","label":"Chat with us on Slack","href":"https://join.slack.com/t/apache-hudi/shared_invite/zt-20r833rxh-627NWYDUyR8jRtMa2mZ~gg"}]},"docs":{"azure_hoodie":{"id":"azure_hoodie","title":"Microsoft Azure","description":"In this page, we explain how to use Hudi on Microsoft Azure.","sidebar":"docs"},"basic_configurations":{"id":"basic_configurations","title":"Basic Configurations","description":"This page covers the basic configurations you may use to write/read Hudi tables. This page only features a subset of the","sidebar":"docs"},"bos_hoodie":{"id":"bos_hoodie","title":"Baidu Cloud","description":"In this page, we explain how to get your Hudi job to store into Baidu BOS.","sidebar":"docs"},"cli":{"id":"cli","title":"CLI","description":"Local set up","sidebar":"docs"},"cloud":{"id":"cloud","title":"Cloud Storage","description":"Talking to Cloud Storage","sidebar":"docs"},"clustering":{"id":"clustering","title":"Clustering","description":"Background","sidebar":"docs"},"compaction":{"id":"compaction","title":"Compaction","description":"Async Compaction","sidebar":"docs"},"comparison":{"id":"comparison","title":"Comparison","description":"Apache Hudi fills a big void for processing data on top of DFS, and thus mostly co-exists nicely with these technologies. However,"},"concepts":{"id":"concepts","title":"Concepts","description":"Apache Hudi (pronounced \u201cHudi\u201d) provides the following streaming primitives over hadoop compatible storages"},"concurrency_control":{"id":"concurrency_control","title":"Concurrency Control","description":"In this section, we will cover Hudi\'s concurrency model and describe ways to ingest data into a Hudi Table from multiple writers; using the DeltaStreamer tool as well as","sidebar":"docs"},"configurations":{"id":"configurations","title":"All Configurations","description":"This page covers the different ways of configuring your job to write/read Hudi tables. At a high level, you can control behaviour at few levels.","sidebar":"docs"},"cos_hoodie":{"id":"cos_hoodie","title":"Tencent Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Tencent Cloud COS.","sidebar":"docs"},"deployment":{"id":"deployment","title":"Deployment","description":"This section provides all the help you need to deploy and operate Hudi tables at scale.","sidebar":"docs"},"disaster_recovery":{"id":"disaster_recovery","title":"Disaster Recovery","description":"Disaster Recovery is very much mission-critical for any software. Especially when it comes to data systems, the impact could be very serious","sidebar":"docs"},"docker_demo":{"id":"docker_demo","title":"Docker Demo","description":"A Demo using docker containers","sidebar":"docs"},"encryption":{"id":"encryption","title":"Encryption","description":"Since Hudi 0.11.0, Spark 3.2 support has been added and accompanying that, Parquet 1.12 has been included, which brings encryption feature to Hudi. In this section, we will show a guide on how to enable encryption in Hudi tables.","sidebar":"docs"},"faq":{"id":"faq","title":"FAQs","description":"General","sidebar":"docs"},"file_layouts":{"id":"file_layouts","title":"File Layouts","description":"The following describes the general file layout structure for Apache Hudi","sidebar":"docs"},"file_sizing":{"id":"file_sizing","title":"File Sizing","description":"This doc will show you how Apache Hudi overcomes the dreaded small files problem. A key design decision in Hudi was to","sidebar":"docs"},"flink_configuration":{"id":"flink_configuration","title":"Flink Setup","description":"Global Configurations","sidebar":"docs"},"flink-quick-start-guide":{"id":"flink-quick-start-guide","title":"Flink Guide","description":"This page introduces Flink-Hudi integration. We can feel the unique charm of how Flink brings in the power of streaming into Hudi.","sidebar":"docs"},"gcp_bigquery":{"id":"gcp_bigquery","title":"Google BigQuery","description":"Hudi tables can be queried from Google Cloud BigQuery as external tables. As of","sidebar":"docs"},"gcs_hoodie":{"id":"gcs_hoodie","title":"Google Cloud","description":"For Hudi storage on GCS, regional buckets provide an DFS API with strong consistency.","sidebar":"docs"},"hoodie_cleaner":{"id":"hoodie_cleaner","title":"Cleaning","description":"Hoodie Cleaner is a utility that helps you reclaim space and keep your storage costs in check. Apache Hudi provides","sidebar":"docs"},"hoodie_deltastreamer":{"id":"hoodie_deltastreamer","title":"Streaming Ingestion","description":"DeltaStreamer","sidebar":"docs"},"ibm_cos_hoodie":{"id":"ibm_cos_hoodie","title":"IBM Cloud","description":"In this page, we explain how to get your Hudi spark job to store into IBM Cloud Object Storage.","sidebar":"docs"},"indexing":{"id":"indexing","title":"Indexing","description":"Hudi provides efficient upserts, by mapping a given hoodie key (record key + partition path) consistently to a file id, via an indexing mechanism.","sidebar":"docs"},"jfs_hoodie":{"id":"jfs_hoodie","title":"JuiceFS","description":"In this page, we explain how to use Hudi with JuiceFS.","sidebar":"docs"},"key_generation":{"id":"key_generation","title":"Key Generation","description":"Every record in Hudi is uniquely identified by a primary key, which is a pair of record key and partition path where the record belongs to.","sidebar":"docs"},"markers":{"id":"markers","title":"Marker Mechanism","description":"Purpose of Markers","sidebar":"docs"},"metadata":{"id":"metadata","title":"Metadata Table","description":"Motivation for a Metadata Table","sidebar":"docs"},"metadata_indexing":{"id":"metadata_indexing","title":"Metadata Indexing","description":"We can now create different metadata indexes, including files, bloom filters and column stats,","sidebar":"docs"},"metrics":{"id":"metrics","title":"Metrics","description":"In this section, we will introduce the MetricsReporter and HoodieMetrics in Hudi. You can view the metrics-related configurations here.","sidebar":"docs"},"migration_guide":{"id":"migration_guide","title":"Bootstrapping","description":"Hudi maintains metadata such as commit timeline and indexes to manage a table. The commit timelines helps to understand the actions happening on a table as well as the current state of a table. Indexes are used by Hudi to maintain a record key to file id mapping to efficiently locate a record. At the moment, Hudi supports writing only parquet columnar formats.","sidebar":"docs"},"oci_hoodie":{"id":"oci_hoodie","title":"Oracle Cloud Infrastructure","description":"The Oracle Object Storage system provides strongly-consistent operations on all buckets in all regions. OCI Object Storage provides an HDFS Connector your Application will need to access data."},"oss_hoodie":{"id":"oss_hoodie","title":"Alibaba Cloud","description":"In this page, we explain how to get your Hudi spark job to store into Aliyun OSS.","sidebar":"docs"},"overview":{"id":"overview","title":"Overview","description":"Welcome to Apache Hudi! This overview will provide a high level summary of what Apache Hudi is and will orient you on","sidebar":"docs"},"performance":{"id":"performance","title":"Performance","description":"Optimized DFS Access","sidebar":"docs"},"precommit_validator":{"id":"precommit_validator","title":"Data Quality","description":"Apache Hudi has what are called Pre-Commit Validators that allow you to validate that your data meets certain data quality","sidebar":"docs"},"privacy":{"id":"privacy","title":"Privacy Policy","description":"Information about your use of this website is collected using server access logs and a tracking cookie.","sidebar":"docs"},"procedures":{"id":"procedures","title":"Procedures","description":"Stored procedures available when use Hudi SparkSQL extensions in all spark\'s version.","sidebar":"docs"},"query_engine_setup":{"id":"query_engine_setup","title":"Query Engine Setup","description":"Spark","sidebar":"docs"},"querying_data":{"id":"querying_data","title":"Querying Data","description":"Conceptually, Hudi stores data physically once on DFS, while providing 3 different ways of querying, as explained before.","sidebar":"docs"},"quick-start-guide":{"id":"quick-start-guide","title":"Spark Guide","description":"This guide provides a quick peek at Hudi\'s capabilities using spark-shell. Using Spark datasources, we will walk through","sidebar":"docs"},"s3_hoodie":{"id":"s3_hoodie","title":"AWS S3","description":"In this page, we explain how to get your Hudi spark job to store into AWS S3.","sidebar":"docs"},"schema_evolution":{"id":"schema_evolution","title":"Schema Evolution","description":"Schema evolution allows users to easily change the current schema of a Hudi table to adapt to the data that is changing over time.","sidebar":"docs"},"snapshot_exporter":{"id":"snapshot_exporter","title":"Exporter","description":"Introduction","sidebar":"docs"},"structure":{"id":"structure","title":"Structure","description":"Hudi (pronounced \u201cHoodie\u201d) ingests & manages storage of large analytical tables over DFS (HDFS or cloud stores) and provides three types of queries."},"syncing_aws_glue_data_catalog":{"id":"syncing_aws_glue_data_catalog","title":"AWS Glue Data Catalog","description":"Hudi tables can sync to AWS Glue Data Catalog directly via AWS SDK. Piggyback on HiveSyncTool","sidebar":"docs"},"syncing_datahub":{"id":"syncing_datahub","title":"DataHub","description":"DataHub is a rich metadata platform that supports features like data discovery, data","sidebar":"docs"},"syncing_metastore":{"id":"syncing_metastore","title":"Hive Metastore","description":"Hive Sync Tool","sidebar":"docs"},"table_management":{"id":"table_management","title":"SQL DDL","description":"The following are SparkSQL table management actions available:","sidebar":"docs"},"table_types":{"id":"table_types","title":"Table & Query Types","description":"Table and Query Types","sidebar":"docs"},"timeline":{"id":"timeline","title":"Timeline","description":"Timeline","sidebar":"docs"},"transforms":{"id":"transforms","title":"Transformers","description":"Apache Hudi provides a HoodieTransformer Utility that allows you to perform transformations the source data before writing it to a Hudi table.","sidebar":"docs"},"troubleshooting":{"id":"troubleshooting","title":"Troubleshooting","description":"Troubleshooting","sidebar":"docs"},"tuning-guide":{"id":"tuning-guide","title":"Tuning Guide","description":"To get a better understanding of where your Hudi jobs is spending its time, use a tool like YourKit Java Profiler, to obtain heap dumps/flame graphs.","sidebar":"docs"},"use_cases":{"id":"use_cases","title":"Use Cases","description":"Apache Hudi provides the foundational features required to build a state-of-the-art Lakehouse.","sidebar":"docs"},"write_operations":{"id":"write_operations","title":"Write Operations","description":"It may be helpful to understand the different write operations of Hudi and how best to leverage them. These operations","sidebar":"docs"},"writing_data":{"id":"writing_data","title":"Writing Data","description":"In this section, we will cover ways to ingest new changes from external sources or even other Hudi tables.","sidebar":"docs"}}}')}}]);
"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[10687],{3987:e=>{e.exports=JSON.parse('{"permalink":"/blog/2025/01/15/outofbox-key-generators-in-hudi","editUrl":"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2025-01-15-outofbox-key-generators-in-hudi.mdx","source":"@site/blog/2025-01-15-outofbox-key-generators-in-hudi.mdx","title":"Out of the box Key Generators in Apache Hudi","description":"Introduction","date":"2025-01-15T00:00:00.000Z","tags":[{"inline":true,"label":"Data Lake","permalink":"/blog/tags/data-lake"},{"inline":true,"label":"Data Lakehouse","permalink":"/blog/tags/data-lakehouse"},{"inline":true,"label":"Apache Hudi","permalink":"/blog/tags/apache-hudi"},{"inline":true,"label":"Key Generators","permalink":"/blog/tags/key-generators"},{"inline":true,"label":"partition","permalink":"/blog/tags/partition"}],"readingTime":9.5,"hasTruncateMarker":false,"authors":[{"name":"Aditya Goenka","key":null,"page":null}],"frontMatter":{"title":"Out of the box Key Generators in Apache Hudi","excerpt":"Explain need for key gerators and out of box key generators in Apache Hudi","author":"Aditya Goenka","category":"blog","image":"/assets/images/blog/2024-06-07-apache-hudi-a-deep-dive-with-python-code-examples.png","tags":["Data Lake","Data Lakehouse","Apache Hudi","Key Generators","partition"]},"unlisted":false,"prevItem":{"title":"Apache Hudi 1.0 Now Generally Available","permalink":"/blog/2025/01/18/apache-hudi-1-0-now-generally-available"},"nextItem":{"title":"Apache Iceberg vs Delta Lake vs Apache Hudi","permalink":"/blog/2025/01/09/apache-iceberg-vs-delta-lake-vs-apache-hudi"}}')},28453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>r});var i=a(96540);const n={},o=i.createContext(n);function s(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),i.createElement(o.Provider,{value:t},e.children)}},60387:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var i=a(3987),n=a(74848),o=a(28453);const s={title:"Out of the box Key Generators in Apache Hudi",excerpt:"Explain need for key gerators and out of box key generators in Apache Hudi",author:"Aditya Goenka",category:"blog",image:"/assets/images/blog/2024-06-07-apache-hudi-a-deep-dive-with-python-code-examples.png",tags:["Data Lake","Data Lakehouse","Apache Hudi","Key Generators","partition"]},r=void 0,d={authorsImageUrls:[void 0]},l=[{value:"Introduction",id:"introduction",level:2},{value:"Challenge",id:"challenge",level:2},{value:"Approaches to Handling this in Data Pipelines",id:"approaches-to-handling-this-in-data-pipelines",level:2},{value:"What are Key Generators in Apache Hudi",id:"what-are-key-generators-in-apache-hudi",level:2},{value:"Out of the Box Key Generators",id:"out-of-the-box-key-generators",level:2},{value:"SimpleKeyGenerator",id:"simplekeygenerator",level:3},{value:"NonpartitionedKeyGenerator",id:"nonpartitionedkeygenerator",level:3},{value:"ComplexKeyGenerator",id:"complexkeygenerator",level:3},{value:"TimestampBasedKeygenerator",id:"timestampbasedkeygenerator",level:3},{value:"Common Use Cases",id:"common-use-cases",level:4},{value:"CustomKeyGenerator",id:"customkeygenerator",level:3},{value:"Conclusion",id:"conclusion",level:2}];function h(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsxs)(t.p,{children:["The goal of Apache Hudi is to bring database-like features to data lakes. This addresses the main shortcoming of traditional data lakes: the inability to easily perform row-level updates or deletions.By integrating database-like management capabilities into data lakes, Hudi revolutionizes how it handles and processes large volumes of data, enabling out-of-the-box upserts and deletes that facilitate efficient record level updating and deletion.\nOne of Hudi's key innovations is the ability for users to explicitly define a Record Key, similar to a unique key in traditional databases, along with a Partition Key that aligns with the data lake paradigm. These two keys make the ",(0,n.jsx)(t.a,{href:"https://github.com/apache/hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieKey.java",children:"HoodieKey"})," that aligns with the data lake paradigm. These two keys make the HoodieKey which is similar to the primary key which uniquely defines each row. This enables hudi to do the upsert based on Hoodiekey. The upsert operation works by utilizing the HoodieKey to locate the exact file group where the data associated with that key resides.  When a new record is ingested into the Hudi table, the system first derives  the HoodieKey of the incoming record based on the unique key and partitioning schema configured. This key is used to determine which file group (a logical grouping of files) the record should be associated with which is usually achieved via an ",(0,n.jsx)(t.a,{href:"https://hudi.apache.org/docs/indexes",children:"indexing"})," mechanism.\nIn this blog, we will explore the concept of Key Generators in Apache Hudi, how they enhance data management, and their role in enabling efficient data operations in modern data lakes."]}),"\n",(0,n.jsx)(t.h2,{id:"challenge",children:"Challenge"}),"\n",(0,n.jsx)(t.p,{children:"The biggest challenge in defining the record key and partition key on a table is  the columns in input data does not naturally lend itself to being used as a primary key or partition key directly. In the realm of databases, we often have below cases -"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Need to have multiple fields that serve as primary key commonly known as composite keys in the database."}),"\n",(0,n.jsx)(t.li,{children:"It is necessary to preprocess the data to derive a specific field that can serve as a primary key before loading it into the database."}),"\n",(0,n.jsx)(t.li,{children:"Sometimes we have to generate unique ids also. Common use case is surrogate key."}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"Similarly, for partition columns also in datalakes, most of the time the raw field can\u2019t be used as a partition key."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Partition columns often have time grain like month level or year level partition but input data mostly contain timestamp and date."}),"\n",(0,n.jsx)(t.li,{children:"Nested primary keys are very common, and necessitates multiple partition columns."}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"approaches-to-handling-this-in-data-pipelines",children:"Approaches to Handling this in Data Pipelines"}),"\n",(0,n.jsx)(t.p,{children:"Data Lake and Lakehouse technologies typically address such scenarios by preprocessing the data. For example, if date-based partitioning is required and a timestamp column is available, the data must be processed using Spark SQL date functions to extract relevant components (e.g., year, month, day). These derived columns are then used for partitioning. However, this process can become cumbersome at scale, especially when multiple data streams are writing to the same Hudi table. The same extraction logic needs to be applied to all streams, and any table maintenance activities (such as bootstrapping or backfilling) also require this logic to be reapplied. This repetition is error-prone and can lead to data consistency issues if the logic is incorrectly applied.\nHudi addresses these challenges with a built-in solution: key generators. These can be configured at the table level, eliminating the need to repeatedly apply the same logic. With key generators, Hudi automatically handles the conversion process every time, ensuring consistency and reducing the risk of errors."}),"\n",(0,n.jsx)(t.h2,{id:"what-are-key-generators-in-apache-hudi",children:"What are Key Generators in Apache Hudi"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://hudi.apache.org/docs/key_generation",children:"Key generators"})," in Apache Hudi are essential components responsible for creating record keys and partition keys for records within a dataset. Hudi uses key generators to extract the Hudi record key, which is a combination of the record key and the partition key, from the incoming record fields. This process allows Hudi to efficiently prepare the hoodie key on which updates can occur. During upserts, Hudi identifies the file group that contains the specified hoodie key using an index and updates the corresponding file group accordingly.\nHudi offers several built-in key generator implementations that cover common use cases, such as generating record keys based on fields from the input data. However, to provide flexibility and support for more complex use cases, Hudi also offers a pluggable interface. This allows users to implement custom key generators tailored to their specific requirements.\nTo create a custom key generator, you can extend the ",(0,n.jsx)(t.a,{href:"https://github.com/apache/hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/keygen/BaseKeyGenerator.java",children:"BaseKeyGenerator"})," class which itself extends the ",(0,n.jsx)(t.a,{href:"https://github.com/apache/hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/keygen/KeyGenerator.java",children:"KeyGenerator"}),"  class and implement methods such as getRecordKey and getPartitionKey. This enables you to define the specific logic required for calculating record and partition keys tailored to your dataset's requirements. Additionally, Hudi includes a variety of built-in key generators that address many common scenarios discussed in the previous section, streamlining the process of key generation for users.\nThe key generator is configured at the table level and stored in the hoodie.properties file, which resides within the .hoodie directory. This file contains all the table-level configurations, including the key generation settings. Once a table is created with a particular key generator we can\u2019t change it. It can be set using the configuration hoodie.datasource.write.keygenerator.class"]}),"\n",(0,n.jsx)(t.h2,{id:"out-of-the-box-key-generators",children:"Out of the Box Key Generators"}),"\n",(0,n.jsx)(t.h3,{id:"simplekeygenerator",children:"SimpleKeyGenerator"}),"\n",(0,n.jsx)(t.p,{children:"The SimpleKeyGenerator is a basic key generator used in Apache Hudi when direct fields from the input dataset can serve as both the record key and partition key. It maps a specific column in the DataFrame to the record key and another column to the partition path. This widely-used generator interprets values as-is from the DataFrame and converts them to strings, making it ideal for straightforward data structures.\nPlease note that this is the default key generator for the partitioned datasets."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'{\n  "hoodie.datasource.write.recordkey.field": "id",\n  "hoodie.datasource.write.partitionpath.field": "date",\n  "hoodie.datasource.write.keygenerator.class": "org.apache.hudi.keygen.SimpleKeyGenerator"\n}\n'})}),"\n",(0,n.jsx)(t.h3,{id:"nonpartitionedkeygenerator",children:"NonpartitionedKeyGenerator"}),"\n",(0,n.jsx)(t.p,{children:"The NonpartitionedKeyGenerator is a key generator in Apache Hudi designed specifically for non-partitioned datasets. Unlike the SimpleKeyGenerator, which uses a field to determine the partition path for the data, the NonpartitionedKeyGenerator does not assign a partition key to the records. Instead, it returns an empty string as the partition key for all records. This is because the dataset is non-partitioned, meaning all records are stored in a single partition."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'{\n  "hoodie.datasource.write.recordkey.field": "id",\n  "hoodie.datasource.write.keygenerator.class": "org.apache.hudi.keygen.NonpartitionedKeyGenerator"\n}\n'})}),"\n",(0,n.jsx)(t.h3,{id:"complexkeygenerator",children:"ComplexKeyGenerator"}),"\n",(0,n.jsxs)(t.p,{children:["This key generator is used when multiple fields are used to create the record key or partition key. We can provide the comma separated list of the columns. In the output, the hoodie record key is generated using the format key1",":value1",",key2",":value2",". If any one of the partition key or record key contains multiple fields, then we have to use ComplexKeyGenerator."]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'{\n  "hoodie.datasource.write.keygenerator.class" : "org.apache.hudi.keygen.ComplexKeyGenerator",\n  "hoodie.datasource.write.recordkey.field" = "key1,key2",\n  "hoodie.datasource.write.partitionpath.field" = "country,state,city"\n}\n'})}),"\n",(0,n.jsx)(t.h3,{id:"timestampbasedkeygenerator",children:"TimestampBasedKeygenerator"}),"\n",(0,n.jsx)(t.p,{children:"The TimestampBasedKeyGenerator allows you to generate partition keys based on timestamp fields in your data. This is especially useful when you want to partition your data by date, month, or year, depending on your use case. The key generator can transform timestamps into different formats, enabling you to create partitions that suit your analytical needs."}),"\n",(0,n.jsx)(t.p,{children:"Relevant Configurations"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.datasource.write.keygenerator.class"}),"\nTo use this key generator, The key gen class should be ",(0,n.jsx)(t.code,{children:"org.apache.hudi.keygen.TimestampBasedKeyGenerator"})]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.deltastreamer.keygen.timebased.timestamp.type"}),"\nThis config determines the nature of the value of input. Below can be the possible values for this -\n",(0,n.jsx)(t.strong,{children:"DATE_STRING"}),": Use this when the input value is in string format."]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"MIXED: This option allows for a combination of formats."}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"UNIX_TIMESTAMP: Select this when the input value is in epoch timestamp format (long type) measured in seconds."}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"EPOCHMILLISECONDS: Use this when the input value is in epoch timestamp format (long type) measured in milliseconds."}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"SCALAR: This option is for epoch timestamp values (long type) where you can specify any time unit."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.deltastreamer.keygen.timebased.timestamp.scalar.time.unit"}),"\nWhen using the SCALAR timestamp type, you can define the unit of the epoch time. Valid options include NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.keygen.timebased.input.dateformat"}),"\nWhen the timestamp type is DATE_STRING or MIXED, this config can be defined to specify the date format in which the field is coming in input."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.keygen.timebased.output.dateformat"}),"\nWhen the timestamp type is set to DATE_STRING or MIXED, this configuration defines the desired date format for the output field. It allows you to specify how the date should be formatted when it is generated or output."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.deltastreamer.keygen.timebased.input.timezone"}),"\nThis setting specifies the timezone for the input date field derived from the raw data. The default value is UTC."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"hoodie.deltastreamer.keygen.timebased.output.timezone"}),"\nThis setting defines the timezone for the output date field that will be used to populate the partition column. The default value is UTC."]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Data Contains Timestamp Field and We Want Date Level Partitions\nIn this scenario, you have a dataset with a timestamp field, and you want to partition the data by the date (i.e., year-month-day)."}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'{\n  "hoodie.datasource.write.keygenerator.class":     "org.apache.hudi.keygen.TimestampBasedKeyGenerator",\n  "hoodie.deltastreamer.keygen.timebased.timestamp.type": "DATE_STRING",\n  "hoodie.keygen.timebased.input.dateformat":"yyyy-MM-dd\'T\'HH:mm:ss.SSSSSSZ",\n  "hoodie.keygen.timebased.output.dateformat":"yyyy-MM-dd",\n  "hoodie.datasource.write.partitionpath.field": "event_time"\n}\n'})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Data Contains Date Field but We Want to Have Month or Year Level Partitions\nHere, you have a dataset with a date field, but you want to create partitions at a higher granularity, such as by month or year."}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'{\n  "hoodie.datasource.write.keygenerator.class":     "org.apache.hudi.keygen.TimestampBasedKeyGenerator",\n  "hoodie.deltastreamer.keygen.timebased.timestamp.type": "DATE_STRING",\n  "hoodie.keygen.timebased.input.dateformat":"yyyy-MM-dd",\n  "hoodie.keygen.timebased.output.dateformat":"yyyyMM",\n  "hoodie.datasource.write.partitionpath.field": "event_date"\n}\n'})}),"\n",(0,n.jsx)(t.p,{children:"In the example above, if we have an input with a date column named event_date in the format 'yyyy-MM-dd', the configurations will convert this format to a monthly level in the format 'yyyyMM' and use it as the partition column."}),"\n",(0,n.jsxs)(t.p,{children:["We can refer ",(0,n.jsx)(t.a,{href:"https://hudi.apache.org/docs/0.10.0/key_generation/#timestampbasedkeygenerator",children:"TimestampBasedKeyGenerator"})," for more examples"]}),"\n",(0,n.jsx)(t.h3,{id:"customkeygenerator",children:"CustomKeyGenerator"}),"\n",(0,n.jsxs)(t.p,{children:["In typical use cases, using the same key generator for both the record key and the partition key often does not meet the requirements. For such scenarios, a Custom Key Generator is particularly useful, as it allows for the use of different key generators for different fields.\nA common use case arises when the partition key consists of multiple fields, and you also need to extract date or month-level partitions from a timestamp field. In these situations, it is essential to utilize both the TimestampBasedKeyGenerator and the ComplexKeyGenerator. However, since you cannot specify two different key generator classes simultaneously, the CustomKeyGenerator serves as an effective solution. We can configure it as list of comma separated fields with the key generator separated by colon. Example - key1",":Timestamp",",key2",":SIMPLE",",key3",":SIMPLE","\nWhen we pass the partition column, we can also provide which key generator to use. The configurations below enable you to use SimpleKeyGenerator to extract the country field and TimestampBasedKeygenerator to transform the event_date field to use only month level partitions."]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-shell",children:'{\n  "hoodie.datasource.write.keygenerator.class":     "org.apache.hudi.keygen.TimestampBasedKeyGenerator",\n  "hoodie.deltastreamer.keygen.timebased.timestamp.type": "DATE_STRING",\n  "hoodie.keygen.timebased.input.dateformat":"yyyy-MM-dd",\n  "hoodie.keygen.timebased.output.dateformat":"yyyyMM",\n  "hoodie.datasource.write.partitionpath.field": "country:SIMPLE,event_date:TIMESTAMP"\n}\n'})}),"\n",(0,n.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,n.jsx)(t.p,{children:"Key generators in Hudi are vital components that enable efficient record identification, partitioning, and data operations in large datasets. Whether you're performing upserts, deletes, or managing time-series data, choosing the right key generator ensures that Hudi can handle the data efficiently, while aligning with your business logic. By addressing challenges like composite keys, timestamp-based partitioning, and complex use cases, Apache Hudi revolutionizes how data lakes handle evolving data, providing database-like management capabilities that are scalable and flexible."})]})}function c(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}}}]);
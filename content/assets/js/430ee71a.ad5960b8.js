"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[20103],{90140:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"release-0.6.0","title":"Release 0.6.0","description":"Release 0.6.0 (docs)","source":"@site/releases/release-0.6.0.md","sourceDirName":".","slug":"/release-0.6.0","permalink":"/releases/release-0.6.0","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":18,"frontMatter":{"title":"Release 0.6.0","sidebar_position":18,"layout":"releases","toc":true},"sidebar":"releases","previous":{"title":"Release 0.7.0","permalink":"/releases/release-0.7.0"},"next":{"title":"Older Releases","permalink":"/releases/older-releases"}}');var a=r(74848),i=r(28453);r(11470),r(19365);const s={title:"Release 0.6.0",sidebar_position:18,layout:"releases",toc:!0},o=void 0,l={},d=[{value:"Release 0.6.0 (docs)",id:"release-060-docs",level:2},{value:"Migration Guide for this release",id:"migration-guide-for-this-release",level:2},{value:"Release Highlights",id:"release-highlights",level:2},{value:"Writer side improvements:",id:"writer-side-improvements",level:3},{value:"Query side improvements:",id:"query-side-improvements",level:3},{value:"Usability:",id:"usability",level:3},{value:"Raw Release Notes",id:"raw-release-notes",level:2}];function u(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.h2,{id:"release-060-docs",children:[(0,a.jsx)(t.a,{href:"https://github.com/apache/hudi/releases/tag/release-0.6.0",children:"Release 0.6.0"})," (",(0,a.jsx)(t.a,{href:"/docs/0.6.0/quick-start-guide",children:"docs"}),")"]}),"\n",(0,a.jsx)(t.h2,{id:"migration-guide-for-this-release",children:"Migration Guide for this release"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"If migrating from release older than 0.5.3, please also check the upgrade instructions for each subsequent release below."}),"\n",(0,a.jsxs)(t.li,{children:["With 0.6.0 Hudi is moving from list based rollback to marker based rollbacks. To smoothly aid this transition a\nnew property called ",(0,a.jsx)(t.code,{children:"hoodie.table.version"})," is added to ",(0,a.jsx)(t.code,{children:"hoodie.properties"})," file. Whenever Hudi is launched with\nnewer table version i.e 1 (or moving from pre 0.6.0 to 0.6.0), an upgrade step will be executed automatically.\nThis automatic upgrade step will happen just once per Hudi table as the ",(0,a.jsx)(t.code,{children:"hoodie.table.version"})," will be updated in property file after upgrade is completed."]}),"\n",(0,a.jsxs)(t.li,{children:["Similarly, a command line tool for Downgrading (command - ",(0,a.jsx)(t.code,{children:"downgrade"}),") is added if in case some users want to downgrade Hudi from table version 1 to 0 or move from Hudi 0.6.0 to pre 0.6.0"]}),"\n",(0,a.jsxs)(t.li,{children:["If you were using a user defined partitioner with bulkInsert() RDD API, the base interface has changed to ",(0,a.jsx)(t.code,{children:"BulkInsertPartitioner"})," and will need minor adjustments to your existing implementations."]}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"release-highlights",children:"Release Highlights"}),"\n",(0,a.jsx)(t.h3,{id:"writer-side-improvements",children:"Writer side improvements:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Bootstrapping existing parquet datasets :  Adds support for bootstrapping existing datasets into Hudi, via both Spark datasource writer and\ndeltastreamer tool, with support for reading from Hive, SparkSQL, AWS Athena (prestoDB support coming soon). See ",(0,a.jsx)(t.a,{href:"https://cwiki.apache.org/confluence/display/HUDI/RFC+-+15%3A+HUDI+File+Listing+and+Query+Planning+Improvements",children:"RFC-15"})," for technical details.\nNote that this is an experimental feature, which will be improved upon further in the 0.6.x versions."]}),"\n",(0,a.jsx)(t.li,{children:"Native row writing for bulk_insert : Avoids any dataframe-rdd conversion for bulk_insert path, which can improve performance of initial bulk loads.\nAlthough, this is typically not the bottleneck for upsert/deletes, subsequent releases in 0.6.x versions will expand this to other write operations\nto make reasoning about schema management easier, avoiding the spark-avro conversion totally."}),"\n",(0,a.jsxs)(t.li,{children:["Bulk insert sort modes : Hudi bulk_insert sorts the input globally to optimize file sizes and avoid out-of-memory issues encountered when writing parallely to multiple DFS partitions.\nFor users who want to prepare the dataframe for writing outside of Hudi, we have made this configurable using ",(0,a.jsx)(t.code,{children:"hoodie.bulkinsert.sort.mode"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:["Cleaning can now be run concurrently with writing, using ",(0,a.jsx)(t.code,{children:"hoodie.clean.async=true"}),"which can speed up time taken to finish committing."]}),"\n",(0,a.jsxs)(t.li,{children:["Async compaction for spark streaming writes to hudi table, is now self managed by default, controlling ",(0,a.jsx)(t.code,{children:"hoodie.datasource.compaction.async.enable"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:["Rollbacks no longer perform full table listings, by leveraging marker files. To enable, set ",(0,a.jsx)(t.code,{children:"hoodie.rollback.using.markers=true"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:["Added a new index ",(0,a.jsx)(t.code,{children:"hoodie.index.type=SIMPLE"})," which can be faster than ",(0,a.jsx)(t.code,{children:"BLOOM_INDEX"})," for cases where updates/deletes spread across a large portion of the table."]}),"\n",(0,a.jsxs)(t.li,{children:["Hudi now supports ",(0,a.jsx)(t.code,{children:"Azure Data Lake Storage V2"})," , ",(0,a.jsx)(t.code,{children:"Alluxio"})," and ",(0,a.jsx)(t.code,{children:"Tencent Cloud Object Storage"})," storages."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"https://hudi.apache.org/docs/writing_data#multitabledeltastreamer",children:"HoodieMultiDeltaStreamer"})," adds support for ingesting multiple kafka streams in a single DeltaStreamer deployment, effectively reducing operational burden for using delta streamer\nas your data lake ingestion tool (Experimental feature)"]}),"\n",(0,a.jsx)(t.li,{children:"Added a new tool - InitialCheckPointProvider, to set checkpoints when migrating to DeltaStreamer after an initial load of the table is complete."}),"\n",(0,a.jsx)(t.li,{children:"Delta Streamer tool now supports ingesting CSV data sources, chaining of multiple transformers to build more advanced ETL jobs."}),"\n",(0,a.jsxs)(t.li,{children:["Introducing a new ",(0,a.jsx)(t.code,{children:"CustomKeyGenerator"})," key generator class, that provides flexible configurations to provide enable different types of key, partition path generation in  single class.\nWe also added support for more time units and date/time formats in ",(0,a.jsx)(t.code,{children:"TimestampBasedKeyGenerator"}),". See ",(0,a.jsx)(t.a,{href:"https://hudi.apache.org/docs/writing_data#key-generation",children:"docs"})," for more."]}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"query-side-improvements",children:"Query side improvements:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Starting 0.6.0, snapshot queries are feasible on MOR tables using spark datasource. (experimental feature)"}),"\n",(0,a.jsxs)(t.li,{children:["In prior versions we only supported ",(0,a.jsx)(t.code,{children:"HoodieCombineHiveInputFormat"})," for CopyOnWrite tables to ensure that there is a limit on the number of mappers spawned for\nany query. Hudi now supports Merge on Read tables also using ",(0,a.jsx)(t.code,{children:"HoodieCombineInputFormat"}),"."]}),"\n",(0,a.jsx)(t.li,{children:"Speedup spark read queries by caching metaclient in HoodieROPathFilter. This helps reduce listing related overheads in S3 when filtering files for read-optimized queries."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"usability",children:"Usability:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Spark DAGs are named to aid better debuggability."}),"\n",(0,a.jsx)(t.li,{children:"Support pluggable metrics reporting by introducing proper abstraction for user defined metrics. Console, JMX, Prometheus and DataDog metric reporters have been added."}),"\n",(0,a.jsx)(t.li,{children:"A new utility called Data snapshot exporter has been added. Latest table snapshot as of a certain point in time can be exported as plain parquet files with this tool."}),"\n",(0,a.jsx)(t.li,{children:"Introduce write committed callback hooks for incremental pipelines to be notified and act on new commits in the timeline. For e.g, Apache Airflow jobs can be triggered\nas new commits arrive."}),"\n",(0,a.jsx)(t.li,{children:"Added support for deleting savepoints via CLI"}),"\n",(0,a.jsxs)(t.li,{children:["Added a new command - ",(0,a.jsx)(t.code,{children:"export instants"}),", to export metadata of instants"]}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"raw-release-notes",children:"Raw Release Notes"}),"\n",(0,a.jsxs)(t.p,{children:["The raw release notes are available ",(0,a.jsx)(t.a,{href:"https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12322822&version=12346663",children:"here"})]})]})}function c(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},19365:(e,t,r)=>{r.d(t,{A:()=>s});r(96540);var n=r(34164);const a={tabItem:"tabItem_Ymn6"};var i=r(74848);function s(e){let{children:t,hidden:r,className:s}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,n.A)(a.tabItem,s),hidden:r,children:t})}},11470:(e,t,r)=>{r.d(t,{A:()=>y});var n=r(96540),a=r(34164),i=r(23104),s=r(56347),o=r(205),l=r(57485),d=r(31682),u=r(70679);function c(e){return n.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,n.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:t,children:r}=e;return(0,n.useMemo)((()=>{const e=t??function(e){return c(e).map((e=>{let{props:{value:t,label:r,attributes:n,default:a}}=e;return{value:t,label:r,attributes:n,default:a}}))}(r);return function(e){const t=(0,d.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,r])}function p(e){let{value:t,tabValues:r}=e;return r.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:r}=e;const a=(0,s.W6)(),i=function(e){let{queryString:t=!1,groupId:r}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!r)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return r??null}({queryString:t,groupId:r});return[(0,l.aZ)(i),(0,n.useCallback)((e=>{if(!i)return;const t=new URLSearchParams(a.location.search);t.set(i,e),a.replace({...a.location,search:t.toString()})}),[i,a])]}function f(e){const{defaultValue:t,queryString:r=!1,groupId:a}=e,i=h(e),[s,l]=(0,n.useState)((()=>function(e){let{defaultValue:t,tabValues:r}=e;if(0===r.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!p({value:t,tabValues:r}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${r.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=r.find((e=>e.default))??r[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:i}))),[d,c]=m({queryString:r,groupId:a}),[f,b]=function(e){let{groupId:t}=e;const r=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,i]=(0,u.Dv)(r);return[a,(0,n.useCallback)((e=>{r&&i.set(e)}),[r,i])]}({groupId:a}),g=(()=>{const e=d??f;return p({value:e,tabValues:i})?e:null})();(0,o.A)((()=>{g&&l(g)}),[g]);return{selectedValue:s,selectValue:(0,n.useCallback)((e=>{if(!p({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),c(e),b(e)}),[c,b,i]),tabValues:i}}var b=r(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=r(74848);function x(e){let{className:t,block:r,selectedValue:n,selectValue:s,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.a_)(),u=e=>{const t=e.currentTarget,r=l.indexOf(t),a=o[r].value;a!==n&&(d(t),s(a))},c=e=>{let t=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const r=l.indexOf(e.currentTarget)+1;t=l[r]??l[0];break}case"ArrowLeft":{const r=l.indexOf(e.currentTarget)-1;t=l[r]??l[l.length-1];break}}t?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":r},t),children:o.map((e=>{let{value:t,label:r,attributes:i}=e;return(0,v.jsx)("li",{role:"tab",tabIndex:n===t?0:-1,"aria-selected":n===t,ref:e=>l.push(e),onKeyDown:c,onClick:u,...i,className:(0,a.A)("tabs__item",g.tabItem,i?.className,{"tabs__item--active":n===t}),children:r??t},t)}))})}function w(e){let{lazy:t,children:r,selectedValue:i}=e;const s=(Array.isArray(r)?r:[r]).filter(Boolean);if(t){const e=s.find((e=>e.props.value===i));return e?(0,n.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:s.map(((e,t)=>(0,n.cloneElement)(e,{key:t,hidden:e.props.value!==i})))})}function j(e){const t=f(e);return(0,v.jsxs)("div",{className:(0,a.A)("tabs-container",g.tabList),children:[(0,v.jsx)(x,{...t,...e}),(0,v.jsx)(w,{...t,...e})]})}function y(e){const t=(0,b.A)();return(0,v.jsx)(j,{...e,children:c(e.children)},String(t))}},28453:(e,t,r)=>{r.d(t,{R:()=>s,x:()=>o});var n=r(96540);const a={},i=n.createContext(a);function s(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);
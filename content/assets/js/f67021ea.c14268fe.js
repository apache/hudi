"use strict";(self.webpackChunkhudi=self.webpackChunkhudi||[]).push([[17987],{26947:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"indexes","title":"Indexes","description":"In databases, indexes are auxiliary data structures maintained to quickly locate records needed, without reading unnecessary data","source":"@site/docs/indexes.md","sourceDirName":".","slug":"/indexes","permalink":"/docs/next/indexes","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/docs/indexes.md","tags":[],"version":"current","frontMatter":{"title":"Indexes","toc":true,"toc_min_heading_level":2,"toc_max_heading_level":4},"sidebar":"docs","previous":{"title":"Table Metadata","permalink":"/docs/next/metadata"},"next":{"title":"Concurrency Control","permalink":"/docs/next/concurrency_control"}}');var s=i(74848),a=i(28453);const o={title:"Indexes",toc:!0,toc_min_heading_level:2,toc_max_heading_level:4},r=void 0,d={},l=[{value:"Mapping keys to file groups",id:"mapping-keys-to-file-groups",level:2},{value:"Need for indexing",id:"need-for-indexing",level:2},{value:"Multi-modal Indexing",id:"multi-modal-indexing",level:2},{value:"Bloom Filters",id:"bloom-filters",level:3},{value:"Record Indexes",id:"record-indexes",level:3},{value:"Expression Index",id:"expression-index",level:3},{value:"Secondary Index",id:"secondary-index",level:3},{value:"Additional writer-side indexes",id:"additional-writer-side-indexes",level:2},{value:"Global and Non-Global Indexes",id:"global-and-non-global-indexes",level:3},{value:"Configs",id:"configs",level:3},{value:"Spark based configs",id:"spark-based-configs",level:4},{value:"Flink based configs",id:"flink-based-configs",level:4},{value:"Picking Indexing Strategies",id:"picking-indexing-strategies",level:3},{value:"Workload 1: Late arriving updates to fact tables",id:"workload-1-late-arriving-updates-to-fact-tables",level:4},{value:"Workload 2: De-Duplication in event tables",id:"workload-2-de-duplication-in-event-tables",level:4},{value:"Workload 3: Random updates/deletes to a dimension table",id:"workload-3-random-updatesdeletes-to-a-dimension-table",level:4},{value:"Related Resources",id:"related-resources",level:2}];function c(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["In databases, indexes are auxiliary data structures maintained to quickly locate records needed, without reading unnecessary data\nfrom storage. Given that Hudi\u2019s design has been heavily optimized for handling mutable change streams, with different\nwrite patterns, Hudi considers ",(0,s.jsx)(n.a,{href:"#indexing",children:"indexing"})," as an integral part of its design and has uniquely supported\n",(0,s.jsx)(n.a,{href:"https://hudi.apache.org/blog/2020/11/11/hudi-indexing-mechanisms/",children:"indexing capabilities"})," from its inception, to speed\nup writes on the ",(0,s.jsx)(n.a,{href:"https://hudi.apache.org/blog/2024/07/11/what-is-a-data-lakehouse/",children:"data lakehouse"}),", while still providing\ncolumnar query performance."]}),"\n",(0,s.jsx)(n.h2,{id:"mapping-keys-to-file-groups",children:"Mapping keys to file groups"}),"\n",(0,s.jsx)(n.p,{children:"The most foundational index mechanism in Hudi tracks a mapping from a given key (record key + optionally partition path) consistently to a file id. Other types of indexes like secondary indexes,\nbuild on this foundation. This mapping between record key and file group/file id rarely changes once the first version of a record has been written to a file group.\nOnly clustering or cross-partition updates that are implemented as deletes + inserts remap the record key to a different file group. Even then, a given record key is associated with exactly one\nfile group at any completed instant on the timeline."}),"\n",(0,s.jsx)(n.h2,{id:"need-for-indexing",children:"Need for indexing"}),"\n",(0,s.jsxs)(n.p,{children:["For ",(0,s.jsx)(n.a,{href:"/docs/next/table_types#copy-on-write-table",children:"Copy-On-Write tables"}),", indexing enables fast upsert/delete operations, by avoiding the need to join against the entire dataset to determine which files to rewrite.\nFor ",(0,s.jsx)(n.a,{href:"/docs/next/table_types#merge-on-read-table",children:"Merge-On-Read tables"}),", indexing allows Hudi to bound the amount of change records any given base file needs to be merged against. Specifically, a given base file needs to merged\nonly against updates for records that are part of that base file."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Fact table",src:i(82301).A+"",width:"3994",height:"1704"}),"\n",(0,s.jsx)("p",{align:"center",children:"Figure: Comparison of merge cost for updates (dark blue blocks) against base files (light blue blocks)"})]}),"\n",(0,s.jsx)(n.p,{children:"In contrast,"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Designs without an indexing component (e.g: ",(0,s.jsx)(n.a,{href:"https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions",children:"Apache Hive/Apache Iceberg"}),") end up having to merge all the base files against all incoming updates/delete records\n(10-100x more ",(0,s.jsx)(n.a,{href:"/docs/next/table_types#comparison",children:"read amplification"}),")."]}),"\n",(0,s.jsx)(n.li,{children:"Designs that implement heavily write-optimized OLTP data structures like LSM trees do not require an indexing component. But they perform poorly scan heavy workloads\nagainst cloud storage making them unsuitable for serving analytical queries."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Hudi shines by achieving both great write performance and read performance, at the extra storage costs of an index, which can however unlock a lot more, as we explore below."}),"\n",(0,s.jsx)(n.h2,{id:"multi-modal-indexing",children:"Multi-modal Indexing"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://www.onehouse.ai/blog/introducing-multi-modal-index-for-the-lakehouse-in-apache-hudi",children:"Multi-modal indexing"}),",\nintroduced in ",(0,s.jsx)(n.a,{href:"https://hudi.apache.org/releases/release-0.11.0/#multi-modal-index",children:"0.11.0 Hudi release"}),",\nis a re-imagination of what a general purpose indexing subsystem should look like for the lake. Multi-modal indexing is\nimplemented by enhancing the metadata table with the flexibility to extend to new index types as new partitions,\nalong with an ",(0,s.jsx)(n.a,{href:"https://hudi.apache.org/docs/metadata_indexing/#setup-async-indexing",children:"asynchronous index"})," building"]}),"\n",(0,s.jsxs)(n.p,{children:["Hudi supports a multi-modal index by augmenting the metadata table with the capability to incorporate new types of indexes, complemented by an\nasynchronous mechanism for ",(0,s.jsx)(n.a,{href:"/docs/next/metadata_indexing",children:"index construction"}),". This enhancement supports a range of indexes within\nthe ",(0,s.jsx)(n.a,{href:"/docs/next/metadata#metadata-table",children:"metadata table"}),", significantly improving the efficiency of both writing to and reading from the table."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Indexes",src:i(4390).A+"",width:"1124",height:"639"}),"\n",(0,s.jsx)("p",{align:"center",children:"Figure: Indexes in Hudi"})]}),"\n",(0,s.jsx)(n.h3,{id:"bloom-filters",children:"Bloom Filters"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://github.com/apache/hudi/blob/46f41d186c6c84a6af2c54a907ff2736b6013e15/rfc/rfc-37/rfc-37.md",children:"Bloom filter"})," indexes as ",(0,s.jsx)(n.em,{children:"bloom_filter"})," partition in the metadata table.\nThis index employs range-based pruning on the minimum and maximum values of the record keys and bloom-filter-based lookups to tag incoming records. For large tables, this\ninvolves reading the footers of all matching data files for bloom filters, which can be expensive in the case of random\nupdates across the entire dataset. This index stores bloom filters of all data files centrally to avoid scanning the\nfooters directly from all data files."]}),"\n",(0,s.jsx)(n.h3,{id:"record-indexes",children:"Record Indexes"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://cwiki.apache.org/confluence/display/HUDI/RFC-08++Record+level+indexing+mechanisms+for+Hudi+datasets",children:"Record indexes"})," as ",(0,s.jsx)(n.em,{children:"record_index"})," partition in the metadata table.\nContains the mapping of the record key to location. Record index is a global index, enforcing key uniqueness across all partitions in the table. This index aids in locating records faster than\nother existing indexes and can provide a speedup orders of magnitude faster in large deployments where index lookup dominates write latencies. To accommodate very high scales, it utilizes hash-based\nsharding of the key space. Additionally, when it comes to reading data, the index allows for point lookups significantly speeding up index mapping retrieval process."]}),"\n",(0,s.jsx)(n.h3,{id:"expression-index",children:"Expression Index"}),"\n",(0,s.jsxs)(n.p,{children:["An ",(0,s.jsx)(n.a,{href:"https://github.com/apache/hudi/blob/3789840be3d041cbcfc6b24786740210e4e6d6ac/rfc/rfc-63/rfc-63.md",children:"expression index"})," is an index on a function of a column. If a query has a predicate on a function of a column, the expression index can\nbe used to speed up the query. Expression index is stored in ",(0,s.jsx)(n.em,{children:"expr_index_"})," prefixed partitions (one for each\nexpression index) under metadata table. Expression index can be created using SQL syntax. Please checkout SQL DDL\ndocs ",(0,s.jsx)(n.a,{href:"/docs/next/sql_ddl#create-functional-index-experimental",children:"here"})," for more details."]}),"\n",(0,s.jsx)(n.h3,{id:"secondary-index",children:"Secondary Index"}),"\n",(0,s.jsxs)(n.p,{children:["Secondary indexes allow users to create indexes on columns that are not part of record key columns in Hudi tables (for\nrecord key fields, Hudi supports ",(0,s.jsx)(n.a,{href:"/blog/2023/11/01/record-level-index",children:"Record-level Index"}),". Secondary indexes\ncan be used to speed up queries with predicate on columns other than record key columns."]}),"\n",(0,s.jsx)(n.h2,{id:"additional-writer-side-indexes",children:"Additional writer-side indexes"}),"\n",(0,s.jsx)(n.p,{children:"All the indexes discussed above are available both readers/writers using integration with metadata table. There are also indexing mechanisms\nimplemented by the storage engine, by efficiently reading/joining/processing incoming input records against information stored in base/log\nfiles themselves (e.g. bloom filters stored in parquet file footers) or intelligent data layout (e.g. bucket index)."}),"\n",(0,s.jsxs)(n.p,{children:["Currently, Hudi supports the following index types. Default is SIMPLE on Spark engine, and INMEMORY on Flink and Java\nengines. Writers can pick one of these options using ",(0,s.jsx)(n.code,{children:"hoodie.index.type"})," config option."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SIMPLE (default for Spark engines)"}),": This is the standard index type for the Spark engine. It executes an efficient join of incoming records with keys retrieved from the table stored on disk. It requires keys to be partition-level unique so it can function correctly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"RECORD_INDEX"})," : Use the record index from section above as the writer side index."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"BLOOM"}),": Uses bloom filters generated from record keys, with the option to further narrow down candidate files based on the ranges of the record keys. It requires keys to be partition-level unique so it can function correctly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"GLOBAL_BLOOM"}),": Utilizes bloom filters created from record keys, and may also refine the selection of candidate files by using the ranges of record keys. It requires keys to be table/global-level unique so it can function correctly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"GLOBAL_SIMPLE"}),": Performs a lean join of the incoming records against keys extracted from the table on storage. It requires keys to be table/global-level unique so it can function correctly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"HBASE"}),": Mangages the index mapping through an external table in Apache HBase."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"INMEMORY (default for Flink and Java)"}),": Uses in-memory hashmap in Spark and Java engine and Flink in-memory state in Flink for indexing."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"BUCKET"}),": Utilizes bucket hashing to identify the file group that houses the records, which proves to be particularly advantageous on a large scale. To select the type of bucket engine\u2014that is, the method by which buckets are created\u2014use the ",(0,s.jsx)(n.code,{children:"hoodie.index.bucket.engine"})," configuration option."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SIMPLE(default)"}),": This index employs a fixed number of buckets for file groups within each partition, which do not have the capacity to decrease or increase in size. It is applicable to both COW and MOR tables. Due to the unchangeable number of buckets and the design principle of mapping each bucket to a single file group, this indexing method may not be ideal for partitions with significant data skew."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"CONSISTENT_HASHING"}),": This index accommodates a dynamic number of buckets, with the capability for bucket resizing to ensure each bucket is sized appropriately. This addresses the issue of data skew in partitions with a high volume of data by allowing these partitions to be dynamically resized. As a result, partitions can have multiple reasonably sized buckets, unlike the fixed bucket count per partition seen in the SIMPLE bucket engine type. This feature is exclusively compatible with MOR tables."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Bring your own implementation:"})," You can extend this ",(0,s.jsx)(n.a,{href:"https://github.com/apache/hudi/blob/master/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/index/HoodieIndex.java",children:"public API"}),"\nand supply a subclass of ",(0,s.jsx)(n.code,{children:"SparkHoodieIndex"})," (for Apache Spark writers) using ",(0,s.jsx)(n.code,{children:"hoodie.index.class"})," to implement custom indexing."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"global-and-non-global-indexes",children:"Global and Non-Global Indexes"}),"\n",(0,s.jsxs)(n.p,{children:["Another key aspect worth understanding is the difference between global and non-global indexes. Both bloom and simple index have\nglobal options - ",(0,s.jsx)(n.code,{children:"hoodie.index.type=GLOBAL_BLOOM"})," and ",(0,s.jsx)(n.code,{children:"hoodie.index.type=GLOBAL_SIMPLE"})," - respectively. Record index and\nHBase index are by nature a global index."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Global index:"}),"  Global indexes enforce uniqueness of keys across all partitions of a table i.e guarantees that exactly\none record exists in the table for a given record key. Global indexes offer stronger guarantees, but the update/delete\ncost can still grow with size of the table ",(0,s.jsx)(n.code,{children:"O(size of table)"}),", since the record could belong to any partition in storage.\nIn case of non-global index, lookup involves file groups only for the matching partitions from the incoming records and\nso its not impacted by the total size of the table. These global indexes(GLOBAL_SIMPLE or GLOBAL_BLOOM), might be\nacceptable for decent sized tables, but for large tables, a newly added index (0.14.0) called Record Level Index (RLI),\ncan offer pretty good index lookup performance compared to other global indexes(GLOBAL_SIMPLE or GLOBAL_BLOOM) or\nHbase and also avoids the operational overhead of maintaining external systems."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Non Global index:"})," On the other hand, the default index implementations enforce this constraint only within a specific partition.\nAs one might imagine, non global indexes depends on the writer to provide the same consistent partition path for a given record key during update/delete,\nbut can deliver much better performance since the index lookup operation becomes ",(0,s.jsx)(n.code,{children:"O(number of records updated/deleted)"})," and\nscales well with write volume."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"configs",children:"Configs"}),"\n",(0,s.jsx)(n.h4,{id:"spark-based-configs",children:"Spark based configs"}),"\n",(0,s.jsxs)(n.p,{children:["For Spark DataSource, Spark SQL, DeltaStreamer and Structured Streaming following are the key configs that control\nindexing behavior. Please refer to ",(0,s.jsx)(n.a,{href:"https://hudi.apache.org/docs/next/configurations#Common-Index-Configs-advanced-configs",children:"Advanced Configs"}),"\nfor more details. All these, support the index types mentioned ",(0,s.jsx)(n.a,{href:"#index-types-in-hudi",children:"above"}),"."]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Config Name"}),(0,s.jsx)(n.th,{children:"Default"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.index.type"}),(0,s.jsxs)(n.td,{children:["N/A ",(0,s.jsx)(n.strong,{children:"(Required)"})]}),(0,s.jsxs)(n.td,{children:["org.apache.hudi.index.HoodieIndex$IndexType: Determines how input records are indexed, i.e., looked up based on the key for the location in the existing table. Default is SIMPLE on Spark engine, and INMEMORY on Flink and Java engines. Possible Values: ",(0,s.jsx)("br",{})," ",(0,s.jsxs)("ul",{children:[(0,s.jsx)("li",{children:"BLOOM"}),(0,s.jsx)("li",{children:"GLOBAL_BLOOM"}),(0,s.jsx)("li",{children:"SIMPLE"}),(0,s.jsx)("li",{children:"GLOBAL_SIMPLE"}),(0,s.jsx)("li",{children:"HBASE"}),(0,s.jsx)("li",{children:"INMEMORY"}),(0,s.jsx)("li",{children:"FLINK_STATE"}),(0,s.jsx)("li",{children:"BUCKET"}),(0,s.jsx)("li",{children:"RECORD_INDEX"})]}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: INDEX_TYPE"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.index.bucket.engine"}),(0,s.jsx)(n.td,{children:"SIMPLE (Optional)"}),(0,s.jsxs)(n.td,{children:["org.apache.hudi.index.HoodieIndex$BucketIndexEngineType: Determines the type of bucketing or hashing to use when ",(0,s.jsx)(n.code,{children:"hoodie.index.type"})," is set to ",(0,s.jsx)(n.code,{children:"BUCKET"}),".    Possible Values: ",(0,s.jsx)("br",{})," ",(0,s.jsxs)("ul",{children:[(0,s.jsx)("li",{children:"SIMPLE"}),(0,s.jsx)("li",{children:"CONSISTENT_HASHING"})]})," ",(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: BUCKET_INDEX_ENGINE_TYPE"}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Since Version: 0.11.0"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.index.class"}),(0,s.jsx)(n.td,{children:"(Optional)"}),(0,s.jsxs)(n.td,{children:["Full path of user-defined index class and must be a subclass of HoodieIndex class. It will take precedence over the hoodie.index.type configuration if specified",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: INDEX_CLASS_NAME"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.bloom.index.update.partition.path"}),(0,s.jsx)(n.td,{children:"true (Optional)"}),(0,s.jsxs)(n.td,{children:["Only applies if index type is GLOBAL_BLOOM. When set to true, an update including the partition path of a record that already exists will result in inserting the incoming record into the new partition and deleting the original record in the old partition. When set to false, the original record will only be updated in the old partition, ignoring the new incoming partition if there is a mis-match between partition value for an incoming record with whats in storage.",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: BLOOM_INDEX_UPDATE_PARTITION_PATH_ENABLE"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.record.index.update.partition.path"}),(0,s.jsx)(n.td,{children:"false (Optional)"}),(0,s.jsxs)(n.td,{children:["Similar to Key: 'hoodie.bloom.index.update.partition.path' , Only applies if index type is RECORD_INDEX. When set to true, an update including the partition path of a record that already exists will result in inserting the incoming record into the new partition and deleting the original record in the old partition. When set to false, the original record will only be updated in the old partition, ignoring the new incoming partition if there is a mis-match between partition value for an incoming record with whats in storage. ",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: RECORD_INDEX_UPDATE_PARTITION_PATH_ENABLE"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.simple.index.update.partition.path"}),(0,s.jsx)(n.td,{children:"true (Optional)"}),(0,s.jsxs)(n.td,{children:["Similar to Key: 'hoodie.bloom.index.update.partition.path' , Only applies if index type is GLOBAL_SIMPLE. When set to true, an update including the partition path of a record that already exists will result in inserting the incoming record into the new partition and deleting the original record in the old partition. When set to false, the original record will only be updated in the old partition, ignoring the new incoming partition if there is a mis-match between partition value for an incoming record with whats in storage. ",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: SIMPLE_INDEX_UPDATE_PARTITION_PATH_ENABLE"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.hbase.index.update.partition.path"}),(0,s.jsx)(n.td,{children:"false (Optional)"}),(0,s.jsxs)(n.td,{children:["Only applies if index type is HBASE. When an already existing record is upserted to a new partition compared to whats in storage, this config when set, will delete old record in old partition and will insert it as new record in new partition.",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),(0,s.jsx)(n.code,{children:"Config Param: UPDATE_PARTITION_PATH_ENABLE"})]})]})]})]}),"\n",(0,s.jsx)(n.h4,{id:"flink-based-configs",children:"Flink based configs"}),"\n",(0,s.jsxs)(n.p,{children:["For Flink DataStream and Flink SQL only support Bucket Index and internal Flink state store backed in memory index.\nFollowing are the basic configs that control the indexing behavior. Please refer ",(0,s.jsx)(n.a,{href:"https://hudi.apache.org/docs/next/configurations#Flink-Options-advanced-configs",children:"here"}),"\nfor advanced configs."]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Config Name"}),(0,s.jsx)(n.th,{children:"Default"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"index.type"}),(0,s.jsx)(n.td,{children:"FLINK_STATE (Optional)"}),(0,s.jsxs)(n.td,{children:["Index type of Flink write job, default is using state backed index. Possible values:",(0,s.jsx)("br",{})," ",(0,s.jsxs)("ul",{children:[(0,s.jsx)("li",{children:"FLINK_STATE"}),(0,s.jsx)("li",{children:"BUCKET"})]}),(0,s.jsx)("br",{}),"  ",(0,s.jsx)(n.code,{children:"Config Param: INDEX_TYPE"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"hoodie.index.bucket.engine"}),(0,s.jsx)(n.td,{children:"SIMPLE (Optional)"}),(0,s.jsxs)(n.td,{children:["org.apache.hudi.index.HoodieIndex$BucketIndexEngineType: Determines the type of bucketing or hashing to use when ",(0,s.jsx)(n.code,{children:"hoodie.index.type"})," is set to ",(0,s.jsx)(n.code,{children:"BUCKET"}),".    Possible Values: ",(0,s.jsx)("br",{})," ",(0,s.jsxs)("ul",{children:[(0,s.jsx)("li",{children:"SIMPLE"}),(0,s.jsx)("li",{children:"CONSISTENT_HASHING"})]})]})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"picking-indexing-strategies",children:"Picking Indexing Strategies"}),"\n",(0,s.jsx)(n.p,{children:"Since data comes in at different volumes, velocity and has different access patterns, different indexes could be used for different workload types.\nLet\u2019s walk through some typical workload types and see how to leverage the right Hudi index for such use-cases.\nThis is based on our experience and you should diligently decide if the same strategies are best for your workloads."}),"\n",(0,s.jsx)(n.h4,{id:"workload-1-late-arriving-updates-to-fact-tables",children:"Workload 1: Late arriving updates to fact tables"}),"\n",(0,s.jsx)(n.p,{children:"Many companies store large volumes of transactional data in NoSQL data stores. For eg, trip tables in case of ride-sharing, buying and selling of shares,\norders in an e-commerce site. These tables are usually ever growing with random updates on most recent data with long tail updates going to older data, either\ndue to transactions settling at a later date/data corrections. In other words, most updates go into the latest partitions with few updates going to older ones."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Fact table",src:i(50042).A+"",width:"3191",height:"1327"}),"\n",(0,s.jsx)("p",{align:"center",children:"Figure: Typical update pattern for Fact tables"})]}),"\n",(0,s.jsxs)(n.p,{children:["For such workloads, the ",(0,s.jsx)(n.code,{children:"BLOOM"})," index performs well, since index look-up will prune a lot of data files based on a well-sized bloom filter.\nAdditionally, if the keys can be constructed such that they have a certain ordering, the number of files to be compared is further reduced by range pruning.\nHudi constructs an interval tree with all the file key ranges and efficiently filters out the files that don't match any key ranges in the updates/deleted records."]}),"\n",(0,s.jsxs)(n.p,{children:["In order to efficiently compare incoming record keys against bloom filters i.e with minimal number of bloom filter reads and uniform distribution of work across\nthe executors, Hudi leverages caching of input records and employs a custom partitioner that can iron out data skews using statistics. At times, if the bloom filter\nfalse positive ratio is high, it could increase the amount of data shuffled to perform the lookup. Hudi supports dynamic bloom filters\n(enabled using ",(0,s.jsx)(n.code,{children:"hoodie.bloom.index.filter.type=DYNAMIC_V0"}),"), which adjusts its size based on the number of records stored in a given file to deliver the\nconfigured false positive ratio."]}),"\n",(0,s.jsx)(n.h4,{id:"workload-2-de-duplication-in-event-tables",children:"Workload 2: De-Duplication in event tables"}),"\n",(0,s.jsx)(n.p,{children:'Event Streaming is everywhere. Events coming from Apache Kafka or similar message bus are typically 10-100x the size of fact tables and often treat "time" (event\'s arrival time/processing\ntime) as a first class citizen. For eg, IoT event stream, click stream data, ad impressions etc. Inserts and updates only span the last few partitions as these are mostly append only data.\nGiven duplicate events can be introduced anywhere in the end-end pipeline, de-duplication before storing on the data lake is a common requirement.'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Event table",src:i(39506).A+"",width:"6218",height:"2609"}),"\n",(0,s.jsx)("p",{align:"center",children:"Figure showing the spread of updates for Event table."})]}),"\n",(0,s.jsxs)(n.p,{children:["In general, this is a very challenging problem to solve at lower cost. Although, we could even employ a key value store to perform this de-duplication with HBASE index, the index storage\ncosts would grow linear with number of events and thus can be prohibitively expensive. In fact, ",(0,s.jsx)(n.code,{children:"BLOOM"})," index with range pruning is the optimal solution here. One can leverage the fact\nthat time is often a first class citizen and construct a key such as ",(0,s.jsx)(n.code,{children:"event_ts + event_id"})," such that the inserted records have monotonically increasing keys. This yields great returns\nby pruning large amounts of files even within the latest table partitions."]}),"\n",(0,s.jsx)(n.h4,{id:"workload-3-random-updatesdeletes-to-a-dimension-table",children:"Workload 3: Random updates/deletes to a dimension table"}),"\n",(0,s.jsx)(n.p,{children:"These types of tables usually contain high dimensional data and hold reference data e.g user profile, merchant information. These are high fidelity tables where the updates are often small but also spread\nacross a lot of partitions and data files ranging across the dataset from old to new. Often times, these tables are also un-partitioned, since there is also not a good way to partition these tables."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Dimensions table",src:i(17429).A+"",width:"13365",height:"5602"}),"\n",(0,s.jsx)("p",{align:"center",children:"Figure showing the spread of updates for Dimensions table."})]}),"\n",(0,s.jsxs)(n.p,{children:["As discussed before, the ",(0,s.jsx)(n.code,{children:"BLOOM"})," index may not yield benefits if a good number of files cannot be pruned out by comparing ranges/filters. In such a random write workload, updates end up touching\nmost files within in the table and thus bloom filters will typically indicate a true positive for all files based on some incoming update. Consequently, we would end up comparing ranges/filter, only\nto finally check the incoming updates against all files. The ",(0,s.jsx)(n.code,{children:"SIMPLE"})," Index will be a better fit as it does not do any upfront pruning based, but directly joins with interested fields from every data file.\n",(0,s.jsx)(n.code,{children:"HBASE"})," index can be employed, if the operational overhead is acceptable and would provide much better lookup times for these tables."]}),"\n",(0,s.jsxs)(n.p,{children:["When using a global index, users should also consider setting ",(0,s.jsx)(n.code,{children:"hoodie.bloom.index.update.partition.path=true"})," or ",(0,s.jsx)(n.code,{children:"hoodie.simple.index.update.partition.path=true"})," to deal with cases where the\npartition path value could change due to an update e.g users table partitioned by home city; user relocates to a different city. These tables are also excellent candidates for the Merge-On-Read table type."]}),"\n",(0,s.jsx)(n.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,s.jsx)("h3",{children:"Videos"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://youtu.be/XlRvMFJ7g9c",children:"Global Bloom Index: Remove duplicates & guarantee uniquness - Hudi Labs"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.onehouse.ai/blog/introducing-multi-modal-index-for-the-lakehouse-in-apache-hudi",children:"Multi-Modal Index for the Lakehouse in Apache Hudi"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},17429:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/dimension-c1a4d25a9b59f1ae577b2159336b2a4e.png"},39506:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/event_bus-0066b1fff4c3b67ef966404738e53e59.png"},50042:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/nosql-bc8be272a92982296f05780fb60394ff.png"},82301:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/with_without_index-c0808363df23ac1aba63bc81a68b6c8c.png"},4390:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/hudi-stack-indexes-589506d411b969d14a9087633253a391.png"},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var t=i(96540);const s={},a=t.createContext(s);function o(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);
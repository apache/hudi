"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[98392],{7604:(e,i,n)=>{n.d(i,{A:()=>s});const s=n.p+"assets/images/bin_packing_existing_data_files-021f5b531f048bfd9cc1230f93c22a71.png"},28453:(e,i,n)=>{n.d(i,{R:()=>l,x:()=>o});var s=n(96540);const a={},t=s.createContext(a);function l(e){const i=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),s.createElement(t.Provider,{value:i},e.children)}},78564:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>r,contentTitle:()=>o,default:()=>c,frontMatter:()=>l,metadata:()=>s,toc:()=>d});var s=n(86840),a=n(74848),t=n(28453);const l={title:"Streaming Responsibly - How Apache Hudi maintains optimum sized files",excerpt:"Maintaining well-sized files can improve query performance significantly",author:"shivnarayan",category:"blog",image:"/assets/images/blog/2021-03-01-hudi-file-sizing.png",tags:["design","file sizing","apache hudi"]},o=void 0,r={authorsImageUrls:[void 0]},d=[{value:"During Write vs After Write",id:"during-write-vs-after-write",level:2},{value:"Configs",id:"configs",level:3},{value:"Example",id:"example",level:3}];function h(e){const i={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.p,{children:"Apache Hudi is a data lake platform technology that provides several functionalities needed to build and manage data lakes.\nOne such key feature that hudi provides is self-managing file sizing so that users don\u2019t need to worry about\nmanual table maintenance. Having a lot of small files will make it harder to achieve good query performance, due to query engines\nhaving to open/read/close files way too many times, to plan and execute queries. But for streaming data lake use-cases,\ninherently ingests are going to end up having smaller volume of writes, which might result in lot of small files if no special handling is done."}),"\n",(0,a.jsx)(i.h2,{id:"during-write-vs-after-write",children:"During Write vs After Write"}),"\n",(0,a.jsxs)(i.p,{children:["Common approaches to writing very small files and then later stitching them together solve for system scalability issues posed\nby small files but might violate query SLA's by exposing small files to them. In fact, you can easily do so on a Hudi table,\nby running a clustering operation, as detailed in a ",(0,a.jsx)(i.a,{href:"/blog/2021/01/27/hudi-clustering-intro",children:"previous blog"}),"."]}),"\n",(0,a.jsx)(i.p,{children:"In this blog, we discuss file sizing optimizations in Hudi, during the initial write time, so we don't have to effectively\nre-write all data again, just for file sizing. If you want to have both (a) self managed file sizing and\n(b) Avoid exposing small files to queries, automatic file sizing feature saves the day."}),"\n",(0,a.jsxs)(i.p,{children:["Hudi has the ability to maintain a configured target file size, when performing inserts/upsert operations.\n(Note: bulk_insert operation does not provide this functionality and is designed as a simpler replacement for\nnormal ",(0,a.jsx)(i.code,{children:"spark.write.parquet"}),")."]}),"\n",(0,a.jsx)(i.h3,{id:"configs",children:"Configs"}),"\n",(0,a.jsx)(i.p,{children:"For illustration purposes, we are going to consider only COPY_ON_WRITE table."}),"\n",(0,a.jsx)(i.p,{children:"Configs of interest before we dive into the algorithm:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.a,{href:"/docs/configurations#hoodieparquetmaxfilesize",children:"Max file size"}),": Max size for a given data file. Hudi will try to maintain file sizes to this configured value ",(0,a.jsx)("br",{})]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.a,{href:"/docs/configurations#hoodieparquetsmallfilelimit",children:"Soft file limit"}),": Max file size below which a given data file is considered to a small file ",(0,a.jsx)("br",{})]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.a,{href:"/docs/configurations#hoodiecopyonwriteinsertsplitsize",children:"Insert split size"}),": Number of inserts grouped for a single partition. This value should match\nthe number of records in a single file (you can determine based on max file size and per record size)"]}),"\n"]}),"\n",(0,a.jsx)(i.p,{children:"For instance, if your first config value is 120MB and 2nd config value is set to 100MB, any file whose size is < 100MB\nwould be considered a small file."}),"\n",(0,a.jsx)(i.p,{children:"If you wish to turn off this feature, set the config value for soft file limit to 0."}),"\n",(0,a.jsx)(i.h3,{id:"example",children:"Example"}),"\n",(0,a.jsx)(i.p,{children:"Let\u2019s say this is the layout of data files for a given partition."}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.img,{alt:"Initial layout",src:n(94519).A+"",width:"886",height:"426"}),"\n",(0,a.jsx)(i.em,{children:"Figure: Initial data file sizes for a given partition of interest"})]}),"\n",(0,a.jsx)(i.p,{children:"Let\u2019s assume the configured values for max file size and small file size limit are 120MB and 100MB. File_1\u2019s current\nsize is 40MB, File_2\u2019s size is 80MB, File_3\u2019s size is 90MB, File_4\u2019s size is 130MB and File_5\u2019s size is 105MB. Let\u2019s see\nwhat happens when a new write happens."}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.strong,{children:"Step 1:"})," Assigning updates to files. In this step, We look up the index to find the tagged location and records are\nassigned to respective files. Note that we assume updates are only going to increase the file size and that would simply result\nin a much bigger file. When updates lower the file size (by say, nulling out lot of fields), then a subsequent write will deem\nit a small file."]}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.strong,{children:"Step 2:"}),"  Determine small files for each partition path. The soft file limit config value will be leveraged here\nto determine eligible small files. In our example, given the config value is set to 100MB, the small files are File_1(40MB)\nand File_2(80MB) and file_3\u2019s (90MB)."]}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.strong,{children:"Step 3:"})," Once small files are determined, incoming inserts are assigned to them so that they reach their max capacity of\n120MB. File_1 will be ingested with 80MB worth of inserts, file_2 will be ingested with 40MB worth of inserts and\nFile_3 will be ingested with 30MB worth of inserts."]}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.img,{alt:"Bin packing small files",src:n(7604).A+"",width:"1280",height:"625"}),"\n",(0,a.jsx)(i.em,{children:"Figure: Incoming records are bin packed to existing small files"})]}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.strong,{children:"Step 4:"})," Once all small files are bin packed to its max capacity and if there are pending inserts unassigned, new file\ngroups/data files are created and inserts are assigned to them. Number of records per new data file is determined from insert split\nsize config. Assuming the insert split size is configured to 120k records, if there are 300k remaining records, 3 new\nfiles will be created in which 2 of them (File_6 and File_7) will be filled with 120k records and the last one (File_8)\nwill be filled with 60k records (assuming each record is 1000 bytes). In future ingestions, 3rd new file will be\nconsidered as a small file to be packed with more data."]}),"\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.img,{alt:"Assigning to new files",src:n(86214).A+"",width:"1300",height:"963"}),"\n",(0,a.jsx)(i.em,{children:"Figure: Remaining records are assigned to new files"})]}),"\n",(0,a.jsx)(i.p,{children:"Hudi leverages mechanisms such as custom partitioning for optimized record distribution to different files, executing\nthe algorithm above. After this round of ingestion is complete, all files except File_8 are nicely sized to the optimum size.\nThis process is followed during every ingestion to ensure there are no small files in your Hudi tables."}),"\n",(0,a.jsx)(i.p,{children:"Hopefully the blog gave you an overview into how hudi manages small files and assists in boosting your query performance."})]})}function c(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},86214:(e,i,n)=>{n.d(i,{A:()=>s});const s=n.p+"assets/images/adding_new_files-13e5a1cf0c213c07a412b09a29be4e3d.png"},86840:e=>{e.exports=JSON.parse('{"permalink":"/blog/2021/03/01/hudi-file-sizing","editUrl":"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2021-03-01-hudi-file-sizing.md","source":"@site/blog/2021-03-01-hudi-file-sizing.md","title":"Streaming Responsibly - How Apache Hudi maintains optimum sized files","description":"Apache Hudi is a data lake platform technology that provides several functionalities needed to build and manage data lakes.","date":"2021-03-01T00:00:00.000Z","tags":[{"inline":true,"label":"design","permalink":"/blog/tags/design"},{"inline":true,"label":"file sizing","permalink":"/blog/tags/file-sizing"},{"inline":true,"label":"apache hudi","permalink":"/blog/tags/apache-hudi"}],"readingTime":4.56,"hasTruncateMarker":true,"authors":[{"name":"shivnarayan","key":null,"page":null}],"frontMatter":{"title":"Streaming Responsibly - How Apache Hudi maintains optimum sized files","excerpt":"Maintaining well-sized files can improve query performance significantly","author":"shivnarayan","category":"blog","image":"/assets/images/blog/2021-03-01-hudi-file-sizing.png","tags":["design","file sizing","apache hudi"]},"unlisted":false,"prevItem":{"title":"Build a data lake using amazon kinesis data stream for amazon dynamodb and apache hudi","permalink":"/blog/2021/03/04/Build-a-data-lake-using-amazon-kinesis-data-stream-for-amazon-dynamodb-and-apache-hudi"},"nextItem":{"title":"Data Lakehouse: Building the Next Generation of Data Lakes using Apache Hudi","permalink":"/blog/2021/03/01/Data-Lakehouse-Building-the-Next-Generation-of-Data-Lakes-using-Apache-Hudi"}}')},94519:(e,i,n)=>{n.d(i,{A:()=>s});const s=n.p+"assets/images/initial_layout-ba5e4c454e6d2328f74dfc5e9fa2966a.png"}}]);
"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[86705],{28453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>r});var i=n(96540);const t={},a=i.createContext(t);function o(e){const s=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(a.Provider,{value:s},e.children)}},33499:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"azure_hoodie","title":"Microsoft Azure","description":"In this page, we explain how to use Hudi on Microsoft Azure.","source":"@site/versioned_docs/version-1.0.2/azure_hoodie.md","sourceDirName":".","slug":"/azure_hoodie","permalink":"/docs/azure_hoodie","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/versioned_docs/version-1.0.2/azure_hoodie.md","tags":[],"version":"1.0.2","frontMatter":{"title":"Microsoft Azure","keywords":["hudi","hive","azure","spark","presto"],"summary":"In this page, we go over how to configure Hudi with Azure filesystem.","last_modified_at":"2020-05-25T23:00:57.000Z"},"sidebar":"docs","previous":{"title":"Alibaba Cloud","permalink":"/docs/oss_hoodie"},"next":{"title":"Tencent Cloud","permalink":"/docs/cos_hoodie"}}');var t=n(74848),a=n(28453);const o={title:"Microsoft Azure",keywords:["hudi","hive","azure","spark","presto"],summary:"In this page, we go over how to configure Hudi with Azure filesystem.",last_modified_at:new Date("2020-05-25T23:00:57.000Z")},r=void 0,d={},l=[{value:"Disclaimer",id:"disclaimer",level:2},{value:"Supported Storage System",id:"supported-storage-system",level:2},{value:"Verified Combination of Spark and storage system",id:"verified-combination-of-spark-and-storage-system",level:2},{value:"HDInsight Spark2.4 on Azure Data Lake Storage Gen 2",id:"hdinsight-spark24-on-azure-data-lake-storage-gen-2",level:4},{value:"Databricks Spark2.4 on Azure Data Lake Storage Gen 2",id:"databricks-spark24-on-azure-data-lake-storage-gen-2",level:4},{value:"Related Resources",id:"related-resources",level:2}];function c(e){const s={a:"a",code:"code",h2:"h2",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.p,{children:"In this page, we explain how to use Hudi on Microsoft Azure."}),"\n",(0,t.jsx)(s.h2,{id:"disclaimer",children:"Disclaimer"}),"\n",(0,t.jsx)(s.p,{children:"This page is maintained by the Hudi community.\nIf the information is inaccurate or you have additional information to add.\nPlease feel free to create a GitHub issue. Contribution is highly appreciated."}),"\n",(0,t.jsx)(s.h2,{id:"supported-storage-system",children:"Supported Storage System"}),"\n",(0,t.jsx)(s.p,{children:"There are two storage systems support Hudi ."}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Azure Blob Storage"}),"\n",(0,t.jsx)(s.li,{children:"Azure Data Lake Gen 2"}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"verified-combination-of-spark-and-storage-system",children:"Verified Combination of Spark and storage system"}),"\n",(0,t.jsx)(s.h4,{id:"hdinsight-spark24-on-azure-data-lake-storage-gen-2",children:"HDInsight Spark2.4 on Azure Data Lake Storage Gen 2"}),"\n",(0,t.jsx)(s.p,{children:"This combination works out of the box. No extra config needed."}),"\n",(0,t.jsx)(s.h4,{id:"databricks-spark24-on-azure-data-lake-storage-gen-2",children:"Databricks Spark2.4 on Azure Data Lake Storage Gen 2"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"Import Hudi jar to databricks workspace"}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"Mount the file system to dbutils."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-scala",children:'dbutils.fs.mount(\n  source = "abfss://xxx@xxx.dfs.core.windows.net",\n  mountPoint = "/mountpoint",\n  extraConfigs = configs)\n'})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"When writing Hudi dataset, use abfss URL"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-scala",children:'inputDF.write\n  .format("org.apache.hudi")\n  .options(opts)\n  .mode(SaveMode.Append)\n  .save("abfss://<<storage-account>>.dfs.core.windows.net/hudi-tables/customer")\n'})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"When reading Hudi dataset, use the mounting point"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-scala",children:'spark.read\n  .format("org.apache.hudi")\n  .load("/mountpoint/hudi-tables/customer")\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"related-resources",children:"Related Resources"}),"\n",(0,t.jsx)("h3",{children:"Blogs"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"https://www.onehouse.ai/blog/how-to-use-apache-hudi-with-databricks",children:"How to use Apache Hudi with Databricks"})}),"\n"]})]})}function u(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);
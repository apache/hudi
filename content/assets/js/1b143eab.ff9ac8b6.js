"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[67044],{2969(e,n,t){t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"sql_ddl","title":"SQL DDL","description":"This page describes support for creating and altering tables using SQL across various engines.","source":"@site/versioned_docs/version-0.15.0/sql_ddl.md","sourceDirName":".","slug":"/sql_ddl","permalink":"/docs/0.15.0/sql_ddl","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/hudi/tree/asf-site/website/versioned_docs/version-0.15.0/sql_ddl.md","tags":[],"version":"0.15.0","frontMatter":{"title":"SQL DDL","summary":"In this page, we discuss using SQL DDL commands with Hudi","toc":true,"last_modified_at":null},"sidebar":"docs","previous":{"title":"Using Kafka Connect","permalink":"/docs/0.15.0/ingestion_kafka_connect"},"next":{"title":"SQL DML","permalink":"/docs/0.15.0/sql_dml"}}');var a=t(74848),r=t(28453);t(11470),t(19365);const s={title:"SQL DDL",summary:"In this page, we discuss using SQL DDL commands with Hudi",toc:!0,last_modified_at:null},l=void 0,d={},o=[{value:"Spark SQL",id:"spark-sql",level:2},{value:"Create table",id:"create-table",level:3},{value:"Create non-partitioned table",id:"create-non-partitioned-table",level:3},{value:"Create partitioned table",id:"create-partitioned-table",level:3},{value:"Create table with record keys and ordering fields",id:"create-table-with-record-keys-and-ordering-fields",level:3},{value:"Create table from an external location",id:"create-table-from-an-external-location",level:3},{value:"Create Table As Select (CTAS)",id:"create-table-as-select-ctas",level:3},{value:"Create Index (Experimental)",id:"create-index-experimental",level:3},{value:"Create Functional Index",id:"create-functional-index",level:4},{value:"Setting Hudi configs",id:"setting-hudi-configs",level:3},{value:"Using set command",id:"using-set-command",level:4},{value:"Using table properties",id:"using-table-properties",level:4},{value:"Table Properties",id:"table-properties",level:3},{value:"Passing Lock Providers for Concurrent Writers",id:"passing-lock-providers-for-concurrent-writers",level:4},{value:"Enabling Column Stats / Record Level Index for the table",id:"enabling-column-stats--record-level-index-for-the-table",level:4},{value:"Spark Alter Table",id:"spark-alter-table",level:3},{value:"Modifying Table Properties",id:"modifying-table-properties",level:3},{value:"Alter config options",id:"alter-config-options",level:3},{value:"Show and drop partitions",id:"show-and-drop-partitions",level:3},{value:"Caveats",id:"caveats",level:3},{value:"Flink SQL",id:"flink-sql",level:2},{value:"Create Catalog",id:"create-catalog",level:3},{value:"Options",id:"options",level:4},{value:"Create Table",id:"create-table-1",level:3},{value:"Create non-partitioned table",id:"create-non-partitioned-table-1",level:3},{value:"Create partitioned table",id:"create-partitioned-table-1",level:3},{value:"Create table with record keys and ordering fields",id:"create-table-with-record-keys-and-ordering-fields-1",level:3},{value:"Alter Table",id:"alter-table",level:3},{value:"Setting Hudi configs",id:"setting-hudi-configs-1",level:3},{value:"Using table options",id:"using-table-options",level:4},{value:"Supported Types",id:"supported-types",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:"This page describes support for creating and altering tables using SQL across various engines."}),"\n",(0,a.jsx)(n.h2,{id:"spark-sql",children:"Spark SQL"}),"\n",(0,a.jsx)(n.h3,{id:"create-table",children:"Create table"}),"\n",(0,a.jsx)(n.p,{children:"You can create tables using standard CREATE TABLE syntax, which supports partitioning and passing table properties."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE [IF NOT EXISTS] [db_name.]table_name\n  [(col_name data_type [COMMENT col_comment], ...)]\n  [COMMENT table_comment]\n  [PARTITIONED BY (col_name, ...)]\n  [ROW FORMAT row_format]\n  [STORED AS file_format]\n  [LOCATION path]\n  [TBLPROPERTIES (property_name=property_value, ...)]\n  [AS select_statement];\n"})}),"\n",(0,a.jsxs)(n.admonition,{title:"NOTE:",type:"note",children:[(0,a.jsxs)(n.p,{children:["For users running this tutorial locally and have a Spark-Hive(HMS) integration in their environment: If you use\n",(0,a.jsx)(n.code,{children:"default"})," database or if you don't provide ",(0,a.jsx)(n.code,{children:"[LOCATION path]"})," with the DDL statement, Spark will return\n",(0,a.jsx)(n.code,{children:"java.io.IOException: Mkdirs failed to create file:/user/hive/warehouse/hudi_table/.hoodie"})," error.\nTo get around this, you can follow either of the two options mentioned below:"]}),(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Create a database i.e. ",(0,a.jsx)(n.code,{children:"CREATE DATABASE hudidb;"})," and use it i.e. ",(0,a.jsx)(n.code,{children:"USE hudidb;"})," before running the DDL statement."]}),"\n",(0,a.jsxs)(n.li,{children:["Or provide a path using ",(0,a.jsx)(n.code,{children:"LOCATION"})," keyword to persist the data with the DDL statement."]}),"\n"]})]}),"\n",(0,a.jsx)(n.h3,{id:"create-non-partitioned-table",children:"Create non-partitioned table"}),"\n",(0,a.jsx)(n.p,{children:"Creating a non-partitioned table is as simple as creating a regular table."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- create a Hudi table\nCREATE TABLE IF NOT EXISTS hudi_table (\n  id INT,\n  name STRING,\n  price DOUBLE\n) USING hudi;\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-partitioned-table",children:"Create partitioned table"}),"\n",(0,a.jsxs)(n.p,{children:["A partitioned table can be created by adding a ",(0,a.jsx)(n.code,{children:"partitioned by"})," clause. Partitioning helps to organize the data into multiple folders\nbased on the partition columns. It can also help speed up queries and index lookups by limiting the amount of metadata, index and data scanned."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS hudi_table_partitioned (\n  id BIGINT,\n  name STRING,\n  dt STRING,\n  hh STRING\n) USING hudi\nTBLPROPERTIES (\n  type = 'cow'\n)\nPARTITIONED BY (dt);\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["You can also create a table partitioned by multiple fields by supplying comma-separated field names.\nWhen creating a table partitioned by multiple fields, ensure that you specify the columns in the ",(0,a.jsx)(n.code,{children:"PARTITIONED BY"})," clause\nin the same order as they appear in the ",(0,a.jsx)(n.code,{children:"CREATE TABLE"})," schema. For example, for the above table, the partition fields\nshould be specified as ",(0,a.jsx)(n.code,{children:"PARTITIONED BY (dt, hh)"}),"."]})}),"\n",(0,a.jsx)(n.h3,{id:"create-table-with-record-keys-and-ordering-fields",children:"Create table with record keys and ordering fields"}),"\n",(0,a.jsxs)(n.p,{children:["As discussed ",(0,a.jsx)(n.a,{href:"quick-start-guide#keys",children:"here"}),", tables track each record in the table using a record key. Hudi auto-generated a highly compressed\nkey for each new record in the examples so far. If you want to use an existing field as the key, you can set the ",(0,a.jsx)(n.code,{children:"primaryKey"})," option.\nTypically, this is also accompanied by configuring a ",(0,a.jsx)(n.code,{children:"preCombineField"})," option to deal with out-of-order data and potential\nduplicate records with the same key in the incoming writes."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"You can choose multiple fields as primary keys for a given table on a need basis. For eg, \"primaryKey = 'id, name'\", and\nthis materializes a composite key of the two fields, which can be useful for exploring the table."})}),"\n",(0,a.jsxs)(n.p,{children:["Here is an example of creating a table using both options. Typically, a field that denotes the time of the event or\nfact, e.g., order creation time, event generation time etc., is used as the ",(0,a.jsx)(n.em,{children:"preCombineField"}),". Hudi resolves multiple versions\nof the same record by ordering based on this field when queries are run on the table."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS hudi_table_keyed (\n  id INT,\n  name STRING,\n  price DOUBLE,\n  ts BIGINT\n) USING hudi\nTBLPROPERTIES (\n  type = 'cow',\n  primaryKey = 'id',\n  preCombineField = 'ts'\n);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-table-from-an-external-location",children:"Create table from an external location"}),"\n",(0,a.jsxs)(n.p,{children:["Often, Hudi tables are created from streaming writers like the ",(0,a.jsx)(n.a,{href:"hoodie_streaming_ingestion#hudi-streamer",children:"streamer tool"}),", which\nmay later need some SQL statements to run on them. You can create an External table using the ",(0,a.jsx)(n.code,{children:"location"})," statement."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE hudi_table_external\nUSING hudi\nLOCATION 'file:///tmp/hudi_table/';\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsx)(n.p,{children:"You don't need to specify the schema and any properties except the partitioned columns if they exist. Hudi can automatically\nrecognize the schema and configurations."})}),"\n",(0,a.jsx)(n.h3,{id:"create-table-as-select-ctas",children:"Create Table As Select (CTAS)"}),"\n",(0,a.jsxs)(n.p,{children:["Hudi supports CTAS(Create table as select) to support initial loads into Hudi tables. To ensure this is done efficiently,\neven for large loads, CTAS uses ",(0,a.jsx)(n.strong,{children:"bulk insert"})," as the write operation"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"# create managed parquet table\nCREATE TABLE parquet_table\nUSING parquet\nLOCATION 'file:///tmp/parquet_dataset/';\n\n# CTAS by loading data into Hudi table\nCREATE TABLE hudi_table_ctas\nUSING hudi\nTBLPROPERTIES (\n  type = 'cow',\n  preCombineField = 'ts'\n)\nPARTITIONED BY (dt)\nAS SELECT * FROM parquet_table;\n"})}),"\n",(0,a.jsx)(n.p,{children:"You can create a non-partitioned table as well"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"# create managed parquet table\nCREATE TABLE parquet_table\nUSING parquet\nLOCATION 'file:///tmp/parquet_dataset/';\n\n# CTAS by loading data into Hudi table\nCREATE TABLE hudi_table_ctas\nUSING hudi\nTBLPROPERTIES (\n  type = 'cow',\n  preCombineField = 'ts'\n)\nAS SELECT * FROM parquet_table;\n"})}),"\n",(0,a.jsxs)(n.p,{children:["If you prefer explicitly setting the record keys, you can do so by setting ",(0,a.jsx)(n.code,{children:"primaryKey"})," config in table properties."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE hudi_table_ctas\nUSING hudi\nTBLPROPERTIES (\n  type = 'cow',\n  primaryKey = 'id'\n)\nPARTITIONED BY (dt)\nAS\nSELECT 1 AS id, 'a1' AS name, 10 AS price, 1000 AS dt;\n"})}),"\n",(0,a.jsx)(n.p,{children:"You can also use CTAS to copy data across external locations"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"# create managed parquet table\nCREATE TABLE parquet_table\nUSING parquet\nLOCATION 'file:///tmp/parquet_dataset/*.parquet';\n\n# CTAS by loading data into hudi table\nCREATE TABLE hudi_table_ctas\nUSING hudi\nLOCATION 'file:///tmp/hudi/hudi_tbl/'\nTBLPROPERTIES (\n  type = 'cow'\n)\nAS SELECT * FROM parquet_table;\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-index-experimental",children:"Create Index (Experimental)"}),"\n",(0,a.jsx)(n.p,{children:"Hudi supports creating and dropping indexes, including functional indexes, on a table."}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Creating indexes through SQL is in preview in version 1.0.0-beta only. It will be generally available in version 1.0.0.\nPlease report any issues you find either via ",(0,a.jsx)(n.a,{href:"https://github.com/apache/hudi/issues",children:"GitHub issues"})," or creating a ",(0,a.jsx)(n.a,{href:"https://issues.apache.org/jira/projects/HUDI/issues",children:"JIRA"}),"."]})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- Create Index\nCREATE INDEX [IF NOT EXISTS] index_name ON [TABLE] table_name \n[USING index_type] \n(column_name1 [OPTIONS(key1=value1, key2=value2, ...)], column_name2 [OPTIONS(key1=value1, key2=value2, ...)], ...) \n[OPTIONS (key1=value1, key2=value2, ...)]\n\n-- Drop Index\nDROP INDEX [IF EXISTS] index_name ON [TABLE] table_name\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"index_name"})," is the name of the index to be created or dropped."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"table_name"})," is the name of the table on which the index is created or dropped."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"index_type"})," is the type of the index to be created. Currently, only ",(0,a.jsx)(n.code,{children:"files"}),", ",(0,a.jsx)(n.code,{children:"column_stats"})," and ",(0,a.jsx)(n.code,{children:"bloom_filters"})," is supported."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"column_name"})," is the name of the column on which the index is created."]}),"\n",(0,a.jsx)(n.li,{children:"Both index and column on which the index is created can be qualified with some options in the form of key-value pairs.\nWe will see this with an example of functional index below."}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"create-functional-index",children:"Create Functional Index"}),"\n",(0,a.jsxs)(n.p,{children:["A ",(0,a.jsx)(n.a,{href:"https://github.com/apache/hudi/blob/00ece7bce0a4a8d0019721a28049723821e01842/rfc/rfc-63/rfc-63.md",children:"functional index"}),"\nis an index on a function of a column. It is a new addition to Hudi's ",(0,a.jsx)(n.a,{href:"https://hudi.apache.org/blog/2022/05/17/Introducing-Multi-Modal-Index-for-the-Lakehouse-in-Apache-Hudi",children:"multi-modal indexing"}),"\nsubsystem which provides faster access method and also absorb partitioning as part of the indexing system. Let us see\nsome examples of creating a functional index."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- Create a functional index on the column `ts` (unix epoch) of the table `hudi_table` using the function `from_unixtime` with the format `yyyy-MM-dd`\nCREATE INDEX IF NOT EXISTS ts_datestr ON hudi_table USING column_stats(ts) OPTIONS(func='from_unixtime', format='yyyy-MM-dd');\n-- Create a functional index on the column `ts` (timestamp in yyyy-MM-dd HH:mm:ss) of the table `hudi_table` using the function `hour`\nCREATE INDEX ts_hour ON hudi_table USING column_stats(ts) options(func='hour');\n"})}),"\n",(0,a.jsx)(n.p,{children:"Few things to note:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["The ",(0,a.jsx)(n.code,{children:"func"})," option is required for creating functional index, and it should be a valid Spark SQL function. Currently,\nonly the functions that take a single column as input are supported. Some useful functions that are supported are listed below.","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"identity"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"from_unixtime"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"date_format"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"to_date"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"to_timestamp"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"year"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"month"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"day"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"hour"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"lower"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"upper"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"substring"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"regexp_extract"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"regexp_replace"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"concat"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"length"})}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["Please check the syntax for the above functions in\nthe ",(0,a.jsx)(n.a,{href:"https://spark.apache.org/docs/latest/sql-ref-functions.html",children:"Spark SQL documentation"})," and provide the options\naccordingly. For example, the ",(0,a.jsx)(n.code,{children:"format"})," option is required for ",(0,a.jsx)(n.code,{children:"from_unixtime"})," function."]}),"\n",(0,a.jsx)(n.li,{children:"UDFs are not supported."}),"\n"]}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Example of creating and using functional index"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- create a Hudi table\nCREATE TABLE hudi_table_func_index (\n    ts STRING,\n    uuid STRING,\n    rider STRING,\n    driver STRING,\n    fare DOUBLE,\n    city STRING\n) USING HUDI\ntblproperties (primaryKey = 'uuid')\nPARTITIONED BY (city)\nlocation 'file:///tmp/hudi_table_func_index';\n\n-- disable small file handling so the each insert creates new file --\nset hoodie.parquet.small.file.limit=0;\n\nINSERT INTO hudi_table_func_index VALUES ('2023-09-20 03:58:59','334e26e9-8355-45cc-97c6-c31daf0df330','rider-A','driver-K',19.10,'san_francisco');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-19 08:46:34','e96c4396-3fad-413a-a942-4cb36106d721','rider-C','driver-M',27.70 ,'san_francisco');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-18 17:45:31','9909a8b1-2d15-4d3d-8ec9-efc48c536a00','rider-D','driver-L',33.90 ,'san_francisco');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-22 13:12:56','1dced545-862b-4ceb-8b43-d2a568f6616b','rider-E','driver-O',93.50,'san_francisco');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-24 06:15:45','e3cf430c-889d-4015-bc98-59bdce1e530c','rider-F','driver-P',34.15,'sao_paulo');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-22 15:21:36','7a84095f-737f-40bc-b62f-6b69664712d2','rider-G','driver-Q',43.40 ,'sao_paulo');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-20 12:35:45','3eeb61f7-c2b0-4636-99bd-5d7a5a1d2c04','rider-I','driver-S',41.06 ,'chennai');\nINSERT INTO hudi_table_func_index VALUES ('2023-09-19 05:34:56','c8abbe79-8d89-47ea-b4ce-4d224bae5bfa','rider-J','driver-T',17.85,'chennai');\n\n-- Query with hour function filter but no idex yet --\nspark-sql> SELECT city, fare, rider, driver FROM  hudi_table_func_index WHERE  city NOT IN ('chennai') AND hour(ts) > 12;\nsan_francisco\t93.5\trider-E\tdriver-O\nsan_francisco\t33.9\trider-D\tdriver-L\nsao_paulo\t43.4\trider-G\tdriver-Q\nTime taken: 0.208 seconds, Fetched 3 row(s)\n\nspark-sql> EXPLAIN COST SELECT city, fare, rider, driver FROM  hudi_table_func_index WHERE  city NOT IN ('chennai') AND hour(ts) > 12;\n== Optimized Logical Plan ==\nProject [city#3465, fare#3464, rider#3462, driver#3463], Statistics(sizeInBytes=899.5 KiB)\n+- Filter ((isnotnull(city#3465) AND isnotnull(ts#3460)) AND (NOT (city#3465 = chennai) AND (hour(cast(ts#3460 as timestamp), Some(Asia/Kolkata)) > 12))), Statistics(sizeInBytes=2.5 MiB)\n   +- Relation default.hudi_table_func_index[_hoodie_commit_time#3455,_hoodie_commit_seqno#3456,_hoodie_record_key#3457,_hoodie_partition_path#3458,_hoodie_file_name#3459,ts#3460,uuid#3461,rider#3462,driver#3463,fare#3464,city#3465] parquet, Statistics(sizeInBytes=2.5 MiB)\n\n== Physical Plan ==\n*(1) Project [city#3465, fare#3464, rider#3462, driver#3463]\n+- *(1) Filter (isnotnull(ts#3460) AND (hour(cast(ts#3460 as timestamp), Some(Asia/Kolkata)) > 12))\n   +- *(1) ColumnarToRow\n      +- FileScan parquet default.hudi_table_func_index[ts#3460,rider#3462,driver#3463,fare#3464,city#3465] Batched: true, DataFilters: [isnotnull(ts#3460), (hour(cast(ts#3460 as timestamp), Some(Asia/Kolkata)) > 12)], Format: Parquet, Location: HoodieFileIndex(1 paths)[file:/tmp/hudi_table_func_index], PartitionFilters: [isnotnull(city#3465), NOT (city#3465 = chennai)], PushedFilters: [IsNotNull(ts)], ReadSchema: struct<ts:string,rider:string,driver:string,fare:double>\n      \n     \n-- create the functional index --\nCREATE INDEX ts_hour ON hudi_table_func_index USING column_stats(ts) options(func='hour');\n\n-- query after creating the index --\nspark-sql> SELECT city, fare, rider, driver FROM  hudi_table_func_index WHERE  city NOT IN ('chennai') AND hour(ts) > 12;\nsan_francisco\t93.5\trider-E\tdriver-O\nsan_francisco\t33.9\trider-D\tdriver-L\nsao_paulo\t43.4\trider-G\tdriver-Q\nTime taken: 0.202 seconds, Fetched 3 row(s)\nspark-sql> EXPLAIN COST SELECT city, fare, rider, driver FROM  hudi_table_func_index WHERE  city NOT IN ('chennai') AND hour(ts) > 12;\n== Optimized Logical Plan ==\nProject [city#2970, fare#2969, rider#2967, driver#2968], Statistics(sizeInBytes=449.8 KiB)\n+- Filter ((isnotnull(city#2970) AND isnotnull(ts#2965)) AND (NOT (city#2970 = chennai) AND (hour(cast(ts#2965 as timestamp), Some(Asia/Kolkata)) > 12))), Statistics(sizeInBytes=1278.3 KiB)\n   +- Relation default.hudi_table_func_index[_hoodie_commit_time#2960,_hoodie_commit_seqno#2961,_hoodie_record_key#2962,_hoodie_partition_path#2963,_hoodie_file_name#2964,ts#2965,uuid#2966,rider#2967,driver#2968,fare#2969,city#2970] parquet, Statistics(sizeInBytes=1278.3 KiB)\n\n== Physical Plan ==\n*(1) Project [city#2970, fare#2969, rider#2967, driver#2968]\n+- *(1) Filter (isnotnull(ts#2965) AND (hour(cast(ts#2965 as timestamp), Some(Asia/Kolkata)) > 12))\n   +- *(1) ColumnarToRow\n      +- FileScan parquet default.hudi_table_func_index[ts#2965,rider#2967,driver#2968,fare#2969,city#2970] Batched: true, DataFilters: [isnotnull(ts#2965), (hour(cast(ts#2965 as timestamp), Some(Asia/Kolkata)) > 12)], Format: Parquet, Location: HoodieFileIndex(1 paths)[file:/tmp/hudi_table_func_index], PartitionFilters: [isnotnull(city#2970), NOT (city#2970 = chennai)], PushedFilters: [IsNotNull(ts)], ReadSchema: struct<ts:string,rider:string,driver:string,fare:double>\n      \n"})})]}),"\n",(0,a.jsx)(n.h3,{id:"setting-hudi-configs",children:"Setting Hudi configs"}),"\n",(0,a.jsx)(n.p,{children:"There are different ways you can pass the configs for a given hudi table."}),"\n",(0,a.jsx)(n.h4,{id:"using-set-command",children:"Using set command"}),"\n",(0,a.jsxs)(n.p,{children:["You can use the ",(0,a.jsx)(n.strong,{children:"set"})," command to set any of Hudi's write configs. This will apply to operations across the whole spark session."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"set hoodie.insert.shuffle.parallelism = 100;\nset hoodie.upsert.shuffle.parallelism = 100;\nset hoodie.delete.shuffle.parallelism = 100;\n"})}),"\n",(0,a.jsx)(n.h4,{id:"using-table-properties",children:"Using table properties"}),"\n",(0,a.jsx)(n.p,{children:"You can also configure table options when creating a table. This will be applied only for the table and override any SET command values."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS tableName (\n  colName1 colType1,\n  colName2 colType2,\n  ...\n) USING hudi\nTBLPROPERTIES (\n  primaryKey = '${colName1}',\n  type = 'cow',\n  ${hoodie.config.key1} = '${hoodie.config.value1}',\n  ${hoodie.config.key2} = '${hoodie.config.value2}',\n  ....\n);\n\ne.g.\nCREATE TABLE IF NOT EXISTS hudi_table (\n  id BIGINT,\n  name STRING,\n  price DOUBLE\n) USING hudi\nTBLPROPERTIES (\n  primaryKey = 'id',\n  type = 'cow',\n  hoodie.cleaner.fileversions.retained = '20',\n  hoodie.keep.max.commits = '20'\n);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"table-properties",children:"Table Properties"}),"\n",(0,a.jsx)(n.p,{children:"Users can set table properties while creating a table. The important table properties are discussed below."}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Parameter Name"}),(0,a.jsx)(n.th,{children:"Default"}),(0,a.jsx)(n.th,{children:"Description"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"type"}),(0,a.jsx)(n.td,{children:"cow"}),(0,a.jsxs)(n.td,{children:["The table type to create. ",(0,a.jsx)(n.code,{children:"type = 'cow'"})," creates a COPY-ON-WRITE table, while ",(0,a.jsx)(n.code,{children:"type = 'mor'"})," creates a MERGE-ON-READ table. Same as ",(0,a.jsx)(n.code,{children:"hoodie.datasource.write.table.type"}),". More details can be found ",(0,a.jsx)(n.a,{href:"table_types",children:"here"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"primaryKey"}),(0,a.jsx)(n.td,{children:"uuid"}),(0,a.jsxs)(n.td,{children:["The primary key field names of the table separated by commas. Same as ",(0,a.jsx)(n.code,{children:"hoodie.datasource.write.recordkey.field"}),". If this config is ignored, hudi will auto-generate primary keys. If explicitly set, primary key generation will honor user configuration."]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"preCombineField"}),(0,a.jsx)(n.td,{}),(0,a.jsxs)(n.td,{children:["The pre-combine field of the table. It is used for resolving the final version of the record among multiple versions. Generally, ",(0,a.jsx)(n.code,{children:"event time"})," or another similar column will be used for ordering purposes. Hudi will be able to handle out-of-order data using the preCombine field value."]})]})]})]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"primaryKey"}),", ",(0,a.jsx)(n.code,{children:"preCombineField"}),", and ",(0,a.jsx)(n.code,{children:"type"})," and other properties are case-sensitive."]})}),"\n",(0,a.jsx)(n.h4,{id:"passing-lock-providers-for-concurrent-writers",children:"Passing Lock Providers for Concurrent Writers"}),"\n",(0,a.jsxs)(n.p,{children:["Hudi requires a lock provider to support concurrent writers or asynchronous table services when using OCC\nand ",(0,a.jsx)(n.a,{href:"concurrency_control#non-blocking-concurrency-control",children:"NBCC"})," (Non-Blocking Concurrency Control)\nconcurrency mode. For NBCC mode, locking is only used to write the commit metadata file in the timeline. Writes are\nserialized by completion time. Users can pass these table properties into ",(0,a.jsx)(n.em,{children:"TBLPROPERTIES"})," as well. Below is an example\nfor a Zookeeper based configuration."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'-- Properties to use Lock configurations to support Multi Writers\nTBLPROPERTIES(\n  hoodie.write.lock.zookeeper.url = "zookeeper",\n  hoodie.write.lock.zookeeper.port = "2181",\n  hoodie.write.lock.zookeeper.lock_key = "tableName",\n  hoodie.write.lock.provider = "org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider",\n  hoodie.write.concurrency.mode = "optimistic_concurrency_control",\n  hoodie.write.lock.zookeeper.base_path = "/tableName"\n)\n'})}),"\n",(0,a.jsx)(n.h4,{id:"enabling-column-stats--record-level-index-for-the-table",children:"Enabling Column Stats / Record Level Index for the table"}),"\n",(0,a.jsx)(n.p,{children:"Hudi provides the ability to leverage rich metadata and index about the table, speed up DMLs and queries.\nFor e.g: collection of column statistics can be enabled to perform quick data skipping or a record-level index can be used to perform fast updates or point lookups\nusing the following table properties."}),"\n",(0,a.jsxs)(n.p,{children:["For more, see ",(0,a.jsx)("a",{href:"/docs/configurations/#Metadata-Configs",children:"Metadata Configurations"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"TBLPROPERTIES(\n  'hoodie.metadata.index.column.stats.enable' = 'true'\n  'hoodie.metadata.record.index.enable' = 'true' \n)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"spark-alter-table",children:"Spark Alter Table"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Syntax"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- Alter table name\nALTER TABLE oldTableName RENAME TO newTableName;\n\n-- Alter table add columns\nALTER TABLE tableIdentifier ADD COLUMNS(colAndType [, colAndType]);\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Examples"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"--rename to:\nALTER TABLE hudi_table RENAME TO hudi_table_renamed;\n\n--add column:\nALTER TABLE hudi_table ADD COLUMNS(remark STRING);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"modifying-table-properties",children:"Modifying Table Properties"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Syntax"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- alter table ... set|unset\nALTER TABLE tableIdentifier SET|UNSET TBLPROPERTIES (table_property = 'property_value');\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Examples"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"ALTER TABLE hudi_table SET TBLPROPERTIES (hoodie.keep.max.commits = '10');\nALTER TABLE hudi_table SET TBLPROPERTIES (\"note\" = \"don't drop this table\");\n\nALTER TABLE hudi_table UNSET TBLPROPERTIES IF EXISTS (hoodie.keep.max.commits);\nALTER TABLE hudi_table UNSET TBLPROPERTIES IF EXISTS ('note');\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Currently, trying to change the column type may throw an error ",(0,a.jsx)(n.code,{children:"ALTER TABLE CHANGE COLUMN is not supported for changing column colName with oldColType to colName with newColType."}),", due to an ",(0,a.jsx)(n.a,{href:"https://issues.apache.org/jira/browse/SPARK-21823",children:"open SPARK issue"})]})}),"\n",(0,a.jsx)(n.h3,{id:"alter-config-options",children:"Alter config options"}),"\n",(0,a.jsxs)(n.p,{children:["You can also alter the write config for a table by the ",(0,a.jsx)(n.strong,{children:"ALTER TABLE SET SERDEPROPERTIES"})]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Syntax"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- alter table ... set|unset\nALTER TABLE tableName SET SERDEPROPERTIES ('property' = 'property_value');\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Example"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:" ALTER TABLE hudi_table SET SERDEPROPERTIES ('key1' = 'value1');\n"})}),"\n",(0,a.jsx)(n.h3,{id:"show-and-drop-partitions",children:"Show and drop partitions"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Syntax"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- Show partitions\nSHOW PARTITIONS tableIdentifier;\n\n-- Drop partition\nALTER TABLE tableIdentifier DROP PARTITION ( partition_col_name = partition_col_val [ , ... ] );\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Examples"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"--Show partition:\nSHOW PARTITIONS hudi_table;\n\n--Drop partition\uff1a\nALTER TABLE hudi_table DROP PARTITION (dt='2021-12-09', hh='10');\n"})}),"\n",(0,a.jsx)(n.h3,{id:"caveats",children:"Caveats"}),"\n",(0,a.jsx)(n.p,{children:"Hudi currently has the following limitations when using Spark SQL, to create/alter tables."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"ALTER TABLE ... RENAME TO ..."})," is not supported when using AWS Glue Data Catalog as hive metastore as Glue itself does\nnot support table renames."]}),"\n",(0,a.jsxs)(n.li,{children:["A new Hudi table created by Spark SQL will by default set ",(0,a.jsx)(n.code,{children:"hoodie.datasource.write.hive_style_partitioning=true"}),", for ease\nof use. This can be overridden using table properties."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"flink-sql",children:"Flink SQL"}),"\n",(0,a.jsx)(n.h3,{id:"create-catalog",children:"Create Catalog"}),"\n",(0,a.jsxs)(n.p,{children:["The catalog helps to manage the SQL tables, the table can be shared among sessions if the catalog persists the table definitions.\nFor ",(0,a.jsx)(n.code,{children:"hms"})," mode, the catalog also supplements the hive syncing options."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Example"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG hoodie_catalog\n  WITH (\n    'type'='hudi',\n    'catalog.path' = '${catalog default root path}',\n    'hive.conf.dir' = '${directory where hive-site.xml is located}',\n    'mode'='hms' -- supports 'dfs' mode that uses the DFS backend for table DDLs persistence\n  );\n"})}),"\n",(0,a.jsx)(n.h4,{id:"options",children:"Options"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Option Name"}),(0,a.jsx)(n.th,{children:"Required"}),(0,a.jsx)(n.th,{children:"Default"}),(0,a.jsx)(n.th,{children:"Remarks"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"catalog.path"})}),(0,a.jsx)(n.td,{children:"true"}),(0,a.jsx)(n.td,{children:"--"}),(0,a.jsxs)(n.td,{children:["Default path for the catalog's table storage, the path is used to infer the table path automatically, the default table path: ",(0,a.jsx)(n.code,{children:"${catalog.path}/${db_name}/${table_name}"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"default-database"})}),(0,a.jsx)(n.td,{children:"false"}),(0,a.jsx)(n.td,{children:"default"}),(0,a.jsx)(n.td,{children:"default database name"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"hive.conf.dir"})}),(0,a.jsx)(n.td,{children:"false"}),(0,a.jsx)(n.td,{children:"--"}),(0,a.jsxs)(n.td,{children:["The directory where hive-site.xml is located, only valid in ",(0,a.jsx)(n.code,{children:"hms"})," mode"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"mode"})}),(0,a.jsx)(n.td,{children:"false"}),(0,a.jsx)(n.td,{children:"dfs"}),(0,a.jsxs)(n.td,{children:["Supports ",(0,a.jsx)(n.code,{children:"hms"})," mode that uses HMS to persist the table options"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"table.external"})}),(0,a.jsx)(n.td,{children:"false"}),(0,a.jsx)(n.td,{children:"false"}),(0,a.jsxs)(n.td,{children:["Whether to create the external table, only valid in ",(0,a.jsx)(n.code,{children:"hms"})," mode"]})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"create-table-1",children:"Create Table"}),"\n",(0,a.jsx)(n.p,{children:"You can create tables using standard FLINK SQL CREATE TABLE syntax, which supports partitioning and passing Flink options using WITH."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE [IF NOT EXISTS] [catalog_name.][db_name.]table_name\n  (\n    { <physical_column_definition> \n    [ <table_constraint> ][ , ...n]\n  )\n  [COMMENT table_comment]\n  [PARTITIONED BY (partition_column_name1, partition_column_name2, ...)]\n  WITH (key1=val1, key2=val2, ...)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-non-partitioned-table-1",children:"Create non-partitioned table"}),"\n",(0,a.jsx)(n.p,{children:"Creating a non-partitioned table is as simple as creating a regular table."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- create a Hudi table\nCREATE TABLE hudi_table(\n  id BIGINT,\n  name STRING,\n  price DOUBLE\n)\nWITH (\n'connector' = 'hudi',\n'path' = 'file:///tmp/hudi_table',\n'table.type' = 'MERGE_ON_READ'\n);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-partitioned-table-1",children:"Create partitioned table"}),"\n",(0,a.jsx)(n.p,{children:"The following is an example of creating a Flink partitioned table."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE hudi_table(\n  id BIGINT,\n  name STRING,\n  dt STRING,\n  hh STRING\n)\nPARTITIONED BY (`dt`)\nWITH (\n'connector' = 'hudi',\n'path' = 'file:///tmp/hudi_table',\n'table.type' = 'MERGE_ON_READ'\n);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-table-with-record-keys-and-ordering-fields-1",children:"Create table with record keys and ordering fields"}),"\n",(0,a.jsx)(n.p,{children:"The following is an example of creating a Flink table with record key and ordering field similarly to spark."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE hudi_table(\n  id BIGINT PRIMARY KEY NOT ENFORCED,\n  name STRING,\n  price DOUBLE,\n  ts BIGINT\n)\nPARTITIONED BY (`dt`)\nWITH (\n'connector' = 'hudi',\n'path' = 'file:///tmp/hudi_table',\n'table.type' = 'MERGE_ON_READ',\n'precombine.field' = 'ts'\n);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"alter-table",children:"Alter Table"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"ALTER TABLE tableA RENAME TO tableB;\n"})}),"\n",(0,a.jsx)(n.h3,{id:"setting-hudi-configs-1",children:"Setting Hudi configs"}),"\n",(0,a.jsx)(n.h4,{id:"using-table-options",children:"Using table options"}),"\n",(0,a.jsxs)(n.p,{children:["You can configure hoodie configs in table options when creating a table. You can refer Flink specific hoodie configs ",(0,a.jsx)(n.a,{href:"configurations#FLINK_SQL",children:"here"}),"\nThese configs will be applied to all the operations on that table."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE IF NOT EXISTS tableName (\n  colName1 colType1 PRIMARY KEY NOT ENFORCED,\n  colName2 colType2,\n  ...\n)\nWITH (\n  'connector' = 'hudi',\n  'path' = '${path}',\n  ${hoodie.config.key1} = '${hoodie.config.value1}',\n  ${hoodie.config.key2} = '${hoodie.config.value2}',\n  ....\n);\n\ne.g.\nCREATE TABLE hudi_table(\n  id BIGINT PRIMARY KEY NOT ENFORCED,\n  name STRING,\n  price DOUBLE,\n  ts BIGINT\n)\nPARTITIONED BY (`dt`)\nWITH (\n'connector' = 'hudi',\n'path' = 'file:///tmp/hudi_table',\n'table.type' = 'MERGE_ON_READ',\n'precombine.field' = 'ts',\n'hoodie.cleaner.fileversions.retained' = '20',\n'hoodie.keep.max.commits' = '20',\n'hoodie.datasource.write.hive_style_partitioning' = 'true'\n);\n"})}),"\n",(0,a.jsx)(n.h2,{id:"supported-types",children:"Supported Types"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Spark"}),(0,a.jsx)(n.th,{children:"Hudi"}),(0,a.jsx)(n.th,{children:"Notes"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"boolean"}),(0,a.jsx)(n.td,{children:"boolean"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"byte"}),(0,a.jsx)(n.td,{children:"int"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"short"}),(0,a.jsx)(n.td,{children:"int"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"integer"}),(0,a.jsx)(n.td,{children:"int"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"long"}),(0,a.jsx)(n.td,{children:"long"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"date"}),(0,a.jsx)(n.td,{children:"date"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"timestamp"}),(0,a.jsx)(n.td,{children:"timestamp"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"float"}),(0,a.jsx)(n.td,{children:"float"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"double"}),(0,a.jsx)(n.td,{children:"double"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"decimal"}),(0,a.jsx)(n.td,{children:"decimal"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"binary"}),(0,a.jsx)(n.td,{children:"bytes"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"array"}),(0,a.jsx)(n.td,{children:"array"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"map"}),(0,a.jsx)(n.td,{children:"map"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"struct"}),(0,a.jsx)(n.td,{children:"struct"}),(0,a.jsx)(n.td,{})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"char"}),(0,a.jsx)(n.td,{}),(0,a.jsx)(n.td,{children:"not supported"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"varchar"}),(0,a.jsx)(n.td,{}),(0,a.jsx)(n.td,{children:"not supported"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"numeric"}),(0,a.jsx)(n.td,{}),(0,a.jsx)(n.td,{children:"not supported"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"null"}),(0,a.jsx)(n.td,{}),(0,a.jsx)(n.td,{children:"not supported"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"object"}),(0,a.jsx)(n.td,{}),(0,a.jsx)(n.td,{children:"not supported"})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},11470(e,n,t){t.d(n,{A:()=>S});var i=t(96540),a=t(34164),r=t(17559),s=t(23104),l=t(56347),d=t(205),o=t(57485),c=t(31682),h=t(70679);function u(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,i.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function x({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const t=(0,l.W6)(),a=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(a),(0,i.useCallback)(e=>{if(!a)return;const n=new URLSearchParams(t.location.search);n.set(a,e),t.replace({...t.location,search:n.toString()})},[a,t])]}function b(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,r=p(e),[s,l]=(0,i.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!x({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:r})),[o,c]=m({queryString:t,groupId:a}),[u,b]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,a]=(0,h.Dv)(n);return[t,(0,i.useCallback)(e=>{n&&a.set(e)},[n,a])]}({groupId:a}),j=(()=>{const e=o??u;return x({value:e,tabValues:r})?e:null})();(0,d.A)(()=>{j&&l(j)},[j]);return{selectedValue:s,selectValue:(0,i.useCallback)(e=>{if(!x({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),c(e),b(e)},[c,b,r]),tabValues:r}}var j=t(92303);const f="tabList__CuJ",g="tabItem_LNqP";var T=t(74848);function E({className:e,block:n,selectedValue:t,selectValue:i,tabValues:r}){const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.a_)(),o=e=>{const n=e.currentTarget,a=l.indexOf(n),s=r[a].value;s!==t&&(d(n),i(s))},c=e=>{let n=null;switch(e.key){case"Enter":o(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,T.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:r.map(({value:e,label:n,attributes:i})=>(0,T.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{l.push(e)},onKeyDown:c,onClick:o,...i,className:(0,a.A)("tabs__item",g,i?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function y({lazy:e,children:n,selectedValue:t}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===t);return e?(0,i.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,T.jsx)("div",{className:"margin-top--md",children:r.map((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function _(e){const n=b(e);return(0,T.jsxs)("div",{className:(0,a.A)(r.G.tabs.container,"tabs-container",f),children:[(0,T.jsx)(E,{...n,...e}),(0,T.jsx)(y,{...n,...e})]})}function S(e){const n=(0,j.A)();return(0,T.jsx)(_,{...e,children:u(e.children)},String(n))}},19365(e,n,t){t.d(n,{A:()=>s});t(96540);var i=t(34164);const a="tabItem_Ymn6";var r=t(74848);function s({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,i.A)(a,t),hidden:n,children:e})}},28453(e,n,t){t.d(n,{R:()=>s,x:()=>l});var i=t(96540);const a={},r=i.createContext(a);function s(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);
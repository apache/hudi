"use strict";(globalThis.webpackChunkhudi=globalThis.webpackChunkhudi||[]).push([[90135],{9368:e=>{e.exports=JSON.parse('{"permalink":"/blog/2020/08/22/ingest-multiple-tables-using-hudi","editUrl":"https://github.com/apache/hudi/edit/asf-site/website/blog/blog/2020-08-22-ingest-multiple-tables-using-hudi.md","source":"@site/blog/2020-08-22-ingest-multiple-tables-using-hudi.md","title":"Ingest multiple tables using Hudi","description":"When building a change data capture pipeline for already existing or newly created relational databases, one of the most common problems that one faces is simplifying the onboarding process for multiple tables. Ingesting multiple tables to Hudi dataset at a single go is now possible using HoodieMultiTableDeltaStreamer class which is a wrapper on top of the more popular HoodieDeltaStreamer class. Currently HoodieMultiTableDeltaStreamer supports COPY_ON_WRITE storage type only and the ingestion is done in a sequential way.","date":"2020-08-22T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"multi deltastreamer","permalink":"/blog/tags/multi-deltastreamer"},{"inline":true,"label":"apache hudi","permalink":"/blog/tags/apache-hudi"}],"readingTime":4.31,"hasTruncateMarker":true,"authors":[{"name":"pratyakshsharma","key":null,"page":null}],"frontMatter":{"title":"Ingest multiple tables using Hudi","excerpt":"Ingesting multiple tables using Hudi at a single go is now possible. This blog gives a detailed explanation of how to achieve the same using `HoodieMultiTableDeltaStreamer.java`","author":"pratyakshsharma","category":"blog","tags":["how-to","multi deltastreamer","apache hudi"]},"unlisted":false,"prevItem":{"title":"How nClouds Helps Accelerate Data Delivery with Apache Hudi on Amazon EMR","permalink":"/blog/2020/10/06/cdc-solution-using-hudi-by-nclouds"},"nextItem":{"title":"Async Compaction Deployment Models","permalink":"/blog/2020/08/21/async-compaction-deployment-model"}}')},28453:(e,t,a)=>{a.d(t,{R:()=>l,x:()=>n});var i=a(96540);const o={},s=i.createContext(o);function l(e){const t=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function n(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),i.createElement(s.Provider,{value:t},e.children)}},30162:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>r,contentTitle:()=>n,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>u});var i=a(9368),o=a(74848),s=a(28453);const l={title:"Ingest multiple tables using Hudi",excerpt:"Ingesting multiple tables using Hudi at a single go is now possible. This blog gives a detailed explanation of how to achieve the same using `HoodieMultiTableDeltaStreamer.java`",author:"pratyakshsharma",category:"blog",tags:["how-to","multi deltastreamer","apache hudi"]},n=void 0,r={authorsImageUrls:[void 0]},u=[];function p(e){const t={code:"code",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,o.jsxs)(t.p,{children:["When building a change data capture pipeline for already existing or newly created relational databases, one of the most common problems that one faces is simplifying the onboarding process for multiple tables. Ingesting multiple tables to Hudi dataset at a single go is now possible using ",(0,o.jsx)(t.code,{children:"HoodieMultiTableDeltaStreamer"})," class which is a wrapper on top of the more popular ",(0,o.jsx)(t.code,{children:"HoodieDeltaStreamer"})," class. Currently ",(0,o.jsx)(t.code,{children:"HoodieMultiTableDeltaStreamer"})," supports ",(0,o.jsx)(t.strong,{children:"COPY_ON_WRITE"})," storage type only and the ingestion is done in a ",(0,o.jsx)(t.strong,{children:"sequential"})," way."]})}function d(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}}}]);
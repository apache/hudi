<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-hoodie_streaming_ingestion" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Using Spark | Apache Hudi</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://hudi.apache.org/docs/next/hoodie_streaming_ingestion"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="cn"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Using Spark | Apache Hudi"><meta data-rh="true" name="description" content="Hudi Streamer"><meta data-rh="true" property="og:description" content="Hudi Streamer"><meta data-rh="true" name="keywords" content="hudi,streamer,hoodiestreamer,spark_streaming"><link data-rh="true" rel="icon" href="/assets/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://hudi.apache.org/docs/next/hoodie_streaming_ingestion"><link data-rh="true" rel="alternate" href="https://hudi.apache.org/docs/next/hoodie_streaming_ingestion" hreflang="en"><link data-rh="true" rel="alternate" href="https://hudi.apache.org/cn/docs/next/hoodie_streaming_ingestion" hreflang="cn"><link data-rh="true" rel="alternate" href="https://hudi.apache.org/docs/next/hoodie_streaming_ingestion" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Using Spark","item":"https://hudi.apache.org/docs/next/hoodie_streaming_ingestion"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Hudi: User-Facing Analytics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Hudi: User-Facing Analytics Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Apache Hudi: User-Facing Analytics JSON Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Apache Hudi" href="/opensearch.xml">
<link rel="alternate" type="application/rss+xml" href="/videos/rss.xml" title="Apache Hudi RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/videos/atom.xml" title="Apache Hudi Atom Feed">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Comfortaa|Ubuntu|Roboto|Source+Code+Pro">
<link rel="stylesheet" href="https://at-ui.github.io/feather-font/css/iconfont.css">
<script src="https://widget.kapa.ai/kapa-widget.bundle.js" data-website-id="9e4444ba-93cc-45ea-b143-783ae0fbeb6f" data-project-name="Apache Hudi" data-project-color="#FFFFFF" data-project-logo="https://hudi.apache.org/assets/images/logo-big.png" data-modal-disclaimer="This AI assistant answers Apache Hudi questions using your [documentation](https://hudi.apache.org/docs/quick-start-guide/), [dev setup](https://hudi.apache.org/contribute/developer-setup/), the [tech specs](https://hudi.apache.org/tech-specs-1point0/) and open GitHub Issues from the last year." data-modal-title="Apache Hudi AI Assistant" data-modal-example-questions-title="Try asking me..." data-modal-example-questions="How can I convert an existing COW table to MOR?,How do I set up incremental queries with Hudi tables?" data-modal-image="https://hudi.apache.org/assets/images/logo-big-2.png" data-modal-image-ask-ai="https://hudi.apache.org/assets/images/logo-big-2.png" data-modal-header-min-height="64px" data-modal-image-height="40" data-modal-image-width="40" data-modal-header-bg-color="#ffffff" data-modal-title-color="rgb(13, 177, 249)" data-button-text-color="rgb(41, 85, 122)" data-button-text="Ask AI" data-consent-required="true" data-consent-screen-title="Help us improve our AI assistant" data-consent-screen-disclaimer="By clicking &amp;quot;Allow tracking&amp;quot;, you consent to the use of the AI assistant in accordance with kapa.ai&#39;s [Privacy Policy](https://www.kapa.ai/content/privacy-policy). This service uses reCAPTCHA, which requires your consent to Google&#39;s [Privacy Policy](https://policies.google.com/privacy) and [Terms of Service](https://policies.google.com/terms). By proceeding, you explicitly agree to both kapa.ai&#39;s and Google&#39;s privacy policies." data-consent-screen-accept-button-text="Allow tracking" data-query-input-placeholder-text-color="rgb(41, 85, 122)" data-submit-query-button-bg-color="#000" data-user-analytics-cookie-enabled="false" async></script><link rel="stylesheet" href="/assets/css/styles.d44ac021.css">
<script src="/assets/js/runtime~main.db816043.js" defer="defer"></script>
<script src="/assets/js/main.15f65901.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="theme-announcement-bar announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">⭐️ If you like <b>Apache Hudi</b>, give it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/apache/hudi"><b>GitHub!<svg xmlns="http://www.w3.org/2000/svg\" width="16" height="16" fill="currentColor" class="bi bi-github" viewBox="0 -2 16 16"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg></b></a> ⭐</div></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarWrapper_j_uY"><div class="navbar__inner navbarInnerStyle_KoMw"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo navbarLogo_aghy"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/docs/overview">Docs</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Learn</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/learn/tutorial-series">Tutorial Series</a></li><li><a class="dropdown__link" href="/talks">Talks</a></li><li><a class="dropdown__link" href="/videos">Video Guides</a></li><li><a class="dropdown__link" href="/docs/faq">FAQ</a></li><li><a class="dropdown__link" href="/tech-specs">Tech Specs</a></li><li><a class="dropdown__link" href="/tech-specs-1point0">Tech Specs 1.0</a></li><li><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank" rel="noopener noreferrer" class="dropdown__link">Technical Wiki<svg width="12" height="12" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Contribute</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/contribute/developer-sync-call">Developer Sync Call</a></li><li><a class="dropdown__link" href="/contribute/how-to-contribute">How to Contribute</a></li><li><a class="dropdown__link" href="/contribute/developer-setup">Developer Setup</a></li><li><a class="dropdown__link" href="/contribute/rfc-process">RFC Process</a></li><li><a class="dropdown__link" href="/contribute/report-security-issues">Report Security Issues</a></li><li><a href="https://issues.apache.org/jira/projects/HUDI/summary" target="_blank" rel="noopener noreferrer" class="dropdown__link">Report Issues<svg width="12" height="12" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/community/get-involved">Get Involved</a></li><li><a class="dropdown__link" href="/community/syncs">Community Syncs</a></li><li><a class="dropdown__link" href="/community/office_hours">Office Hours</a></li><li><a class="dropdown__link" href="/community/team">Team</a></li><li><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA" target="_blank" rel="noopener noreferrer" class="dropdown__link">Join Our Slack Space<svg width="12" height="12" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><a class="navbar__item navbar__link" href="/ecosystem">Ecosystem</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/powered-by">Who&#x27;s Using</a><a class="navbar__item navbar__link" href="/roadmap">Roadmap</a><a class="navbar__item navbar__link" href="/releases/download">Download</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/docs/next/hoodie_streaming_ingestion">Current</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/docs/next/hoodie_streaming_ingestion">Current</a></li><li><a class="dropdown__link" href="/docs/hoodie_streaming_ingestion">1.0.2</a></li><li><a class="dropdown__link" href="/docs/1.0.1/hoodie_streaming_ingestion">1.0.1</a></li><li><a class="dropdown__link" href="/docs/1.0.0/hoodie_streaming_ingestion">1.0.0</a></li><li><a class="dropdown__link" href="/docs/0.15.0/hoodie_streaming_ingestion">0.15.0</a></li><li><a class="dropdown__link" href="/docs/0.14.1/hoodie_streaming_ingestion">0.14.1</a></li><li><a class="dropdown__link" href="/docs/0.14.0/hoodie_streaming_ingestion">0.14.0</a></li><li><a class="dropdown__link" href="/docs/0.13.1/overview">0.13.1</a></li><li><a class="dropdown__link" href="/docs/0.13.0/overview">0.13.0</a></li><li><a class="dropdown__link" href="/docs/0.12.3/overview">0.12.3</a></li><li><a class="dropdown__link" href="/docs/0.12.2/overview">0.12.2</a></li><li><a class="dropdown__link" href="/docs/0.12.1/overview">0.12.1</a></li><li><a class="dropdown__link" href="/docs/0.12.0/overview">0.12.0</a></li><li><a class="dropdown__link" href="/docs/0.11.1/overview">0.11.1</a></li><li><a class="dropdown__link" href="/docs/0.11.0/overview">0.11.0</a></li><li><a class="dropdown__link" href="/docs/0.10.1/overview">0.10.1</a></li><li><a class="dropdown__link" href="/docs/0.10.0/overview">0.10.0</a></li><li><a class="dropdown__link" href="/docs/0.9.0/overview">0.9.0</a></li><li><a class="dropdown__link" href="/docs/0.8.0/overview">0.8.0</a></li><li><a class="dropdown__link" href="/docs/0.7.0/overview">0.7.0</a></li><li><a class="dropdown__link" href="/docs/0.6.0/quick-start-guide">0.6.0</a></li><li><a class="dropdown__link" href="/docs/0.5.3/quick-start-guide">0.5.3</a></li><li><a class="dropdown__link" href="/docs/0.5.2/quick-start-guide">0.5.2</a></li><li><a class="dropdown__link" href="/docs/0.5.1/quick-start-guide">0.5.1</a></li><li><a class="dropdown__link" href="/docs/0.5.0/quick-start-guide">0.5.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link locale-dropdown-wrapper"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="none" viewBox="0 0 14 14" class="globeIcon_RxQM"><g clip-path="url(#a)"><path fill="#1C1E21" d="M14 6.457a6.84 6.84 0 0 0-7-6.02 6.843 6.843 0 0 0-7 6.02v1.085a6.843 6.843 0 0 0 7 6.02 6.843 6.843 0 0 0 7-6.02zm-1.094 0h-2.625a10 10 0 0 0-.376-2.222 6.7 6.7 0 0 0 1.531-.875 5.25 5.25 0 0 1 1.444 3.097zm-8.032 0a8.5 8.5 0 0 1 .324-1.872 7.4 7.4 0 0 0 3.63 0c.175.61.284 1.239.325 1.872zm4.305 1.085a8.4 8.4 0 0 1-.324 1.873 7.46 7.46 0 0 0-3.658 0 8.5 8.5 0 0 1-.323-1.873zm.35-4.375A10.3 10.3 0 0 0 8.75 1.75c.627.194 1.218.49 1.75.875a5.8 5.8 0 0 1-.998.577zM7.254 1.54A8.8 8.8 0 0 1 8.46 3.552c-.48.11-.97.165-1.461.167-.492-.001-.982-.057-1.461-.167.308-.722.715-1.4 1.207-2.012zM4.498 3.202a5.8 5.8 0 0 1-.998-.577 6 6 0 0 1 1.75-.875c-.294.46-.546.947-.753 1.452m-1.873.15c.47.358.984.652 1.531.874A9.6 9.6 0 0 0 3.78 6.45H1.155a5.25 5.25 0 0 1 1.47-3.098M1.12 7.541h2.625c.038.753.164 1.5.376 2.223a6.7 6.7 0 0 0-1.531.875 5.25 5.25 0 0 1-1.47-3.098m3.377 3.255q.311.76.753 1.453a6 6 0 0 1-1.75-.875q.47-.34.997-.578m2.25 1.663a8.6 8.6 0 0 1-1.208-2.013 6.5 6.5 0 0 1 2.922 0 8.5 8.5 0 0 1-1.207 2.013zm2.755-1.663q.552.235 1.042.578a6.3 6.3 0 0 1-1.75.875q.413-.697.708-1.453m1.873-.148a6.7 6.7 0 0 0-1.531-.875 9.5 9.5 0 0 0 .376-2.223h2.625a5.25 5.25 0 0 1-1.47 3.098"></path></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h14v14H0z"></path></clipPath></defs></svg></a><ul class="dropdown__menu"><li><a href="/docs/next/hoodie_streaming_ingestion" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/cn/docs/next/hoodie_streaming_ingestion" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="cn">Chinese</a></li></ul></div><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-twitter-link" aria-label="Hudi Twitter Handle"></a><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-slack-link" aria-label="Hudi Slack Channel"></a><a href="https://www.youtube.com/channel/UCs7AhE0BWaEPZSChrBR-Muw" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-youtube-link" aria-label="Hudi YouTube Channel"></a><a href="https://www.linkedin.com/company/apache-hudi/?viewAsMember=true" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="Hudi Linkedin Page"></a><div class="navbarSearchContainer_Bca1"><div><div role="button" class="searchButton_o6KI" aria-label="Search"><span class="searchText_sHOJ">Search</span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="none" viewBox="0 0 14 14"><circle cx="6.864" cy="6.864" r="5.243" stroke="#1C1E21" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5"></circle><path stroke="#1C1E21" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m10.51 10.783 2.056 2.05"></path></svg></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar navbarSideMenu_TODO"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><div class="navbar__logo navbarLogo_aghy"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><button type="button" aria-label="Close navigation bar" class="clean-btn navbar-sidebar__close"><svg viewBox="0 0 15 15" width="21" height="21"><g stroke="var(--ifm-color-emphasis-600)" stroke-width="1.2"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><div class="navbar-sidebar__items"><div class="navbar-sidebar__item menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/docs/overview">Docs</a></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Learn</a></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Contribute</a></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Community</a></li><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/ecosystem">Ecosystem</a></li><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/blog">Blog</a></li><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/powered-by">Who&#x27;s Using</a></li><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/roadmap">Roadmap</a></li><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/releases/download">Download</a></li><li class="menu__list-item"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Versions</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active" href="/docs/next/hoodie_streaming_ingestion">Current</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/hoodie_streaming_ingestion">1.0.2</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/1.0.1/hoodie_streaming_ingestion">1.0.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/1.0.0/hoodie_streaming_ingestion">1.0.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.15.0/hoodie_streaming_ingestion">0.15.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.14.1/hoodie_streaming_ingestion">0.14.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.14.0/hoodie_streaming_ingestion">0.14.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.13.1/overview">0.13.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.13.0/overview">0.13.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.12.3/overview">0.12.3</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.12.2/overview">0.12.2</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.12.1/overview">0.12.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.12.0/overview">0.12.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.11.1/overview">0.11.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.11.0/overview">0.11.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.10.1/overview">0.10.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.10.0/overview">0.10.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.9.0/overview">0.9.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.8.0/overview">0.8.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.7.0/overview">0.7.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.6.0/quick-start-guide">0.6.0</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.5.3/quick-start-guide">0.5.3</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.5.2/quick-start-guide">0.5.2</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.5.1/quick-start-guide">0.5.1</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/0.5.0/quick-start-guide">0.5.0</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret locale-dropdown-wrapper"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Languages<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="none" viewBox="0 0 14 14" class="globeIcon_RxQM"><g clip-path="url(#a)"><path fill="#1C1E21" d="M14 6.457a6.84 6.84 0 0 0-7-6.02 6.843 6.843 0 0 0-7 6.02v1.085a6.843 6.843 0 0 0 7 6.02 6.843 6.843 0 0 0 7-6.02zm-1.094 0h-2.625a10 10 0 0 0-.376-2.222 6.7 6.7 0 0 0 1.531-.875 5.25 5.25 0 0 1 1.444 3.097zm-8.032 0a8.5 8.5 0 0 1 .324-1.872 7.4 7.4 0 0 0 3.63 0c.175.61.284 1.239.325 1.872zm4.305 1.085a8.4 8.4 0 0 1-.324 1.873 7.46 7.46 0 0 0-3.658 0 8.5 8.5 0 0 1-.323-1.873zm.35-4.375A10.3 10.3 0 0 0 8.75 1.75c.627.194 1.218.49 1.75.875a5.8 5.8 0 0 1-.998.577zM7.254 1.54A8.8 8.8 0 0 1 8.46 3.552c-.48.11-.97.165-1.461.167-.492-.001-.982-.057-1.461-.167.308-.722.715-1.4 1.207-2.012zM4.498 3.202a5.8 5.8 0 0 1-.998-.577 6 6 0 0 1 1.75-.875c-.294.46-.546.947-.753 1.452m-1.873.15c.47.358.984.652 1.531.874A9.6 9.6 0 0 0 3.78 6.45H1.155a5.25 5.25 0 0 1 1.47-3.098M1.12 7.541h2.625c.038.753.164 1.5.376 2.223a6.7 6.7 0 0 0-1.531.875 5.25 5.25 0 0 1-1.47-3.098m3.377 3.255q.311.76.753 1.453a6 6 0 0 1-1.75-.875q.47-.34.997-.578m2.25 1.663a8.6 8.6 0 0 1-1.208-2.013 6.5 6.5 0 0 1 2.922 0 8.5 8.5 0 0 1-1.207 2.013zm2.755-1.663q.552.235 1.042.578a6.3 6.3 0 0 1-1.75.875q.413-.697.708-1.453m1.873-.148a6.7 6.7 0 0 0-1.531-.875 9.5 9.5 0 0 0 .376-2.223h2.625a5.25 5.25 0 0 1-1.47 3.098"></path></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h14v14H0z"></path></clipPath></defs></svg></a></li><li class="menu__list-item"><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="menu__link header-github-link" aria-label="GitHub repository"></a></li><li class="menu__list-item"><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="menu__link header-twitter-link" aria-label="Hudi Twitter Handle"></a></li><li class="menu__list-item"><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA" target="_blank" rel="noopener noreferrer" class="menu__link header-slack-link" aria-label="Hudi Slack Channel"></a></li><li class="menu__list-item"><a href="https://www.youtube.com/channel/UCs7AhE0BWaEPZSChrBR-Muw" target="_blank" rel="noopener noreferrer" class="menu__link header-youtube-link" aria-label="Hudi YouTube Channel"></a></li><li class="menu__list-item"><a href="https://www.linkedin.com/company/apache-hudi/?viewAsMember=true" target="_blank" rel="noopener noreferrer" class="menu__link header-linkedin-link" aria-label="Hudi Linkedin Page"></a></li></ul></div><div class="navbar-sidebar__item menu"><button type="button" class="clean-btn navbar-sidebar__back">← Back to main menu</button></div></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_bSxm"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_cWv0"><aside class="theme-doc-sidebar-container docSidebarContainer_RSuS"><div class="sidebarViewport_pYEE"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/next/overview">Getting Started</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/overview">Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/quick-start-guide">Spark Quick Start</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/flink-quick-start-guide">Flink Quick Start</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/python-rust-quick-start-guide">Python/Rust Quick Start</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/docker_demo">Docker Demo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/use_cases">Use Cases</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/hudi_stack">Design &amp; Concepts</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/next/hoodie_streaming_ingestion">Ingestion</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/next/hoodie_streaming_ingestion">Using Spark</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/ingestion_flink">Using Flink</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/next/ingestion_kafka_connect">Using Kafka Connect</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/sql_ddl">Writing Tables</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/sql_queries">Reading Tables</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/cleaning">Table Services</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/snapshot_exporter">Platform &amp; Tools</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/performance">Operating Hudi</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/basic_configurations">Configurations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/next/faq">Frequently Asked Questions(FAQs)</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_hjYf"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is unreleased documentation for <!-- -->Apache Hudi<!-- --> <b>Current</b> version.</div><div class="margin-top--md">For up-to-date documentation, see the <b><a href="/docs/hoodie_streaming_ingestion">latest version</a></b> (<!-- -->1.0.2<!-- -->).</div></div><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Ingestion</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Using Spark</span></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: Current</span><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Using Spark</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="hudi-streamer">Hudi Streamer<a href="#hudi-streamer" class="hash-link" aria-label="Direct link to Hudi Streamer" title="Direct link to Hudi Streamer">​</a></h2>
<p>The <code>HoodieStreamer</code> utility (part of <code>hudi-utilities-slim-bundle</code> and <code>hudi-utilities-bundle</code>) provides ways to ingest
from different sources such as DFS or Kafka, with the following capabilities.</p>
<ul>
<li>Exactly once ingestion of new events from
Kafka, <a href="https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide#_incremental_imports" target="_blank" rel="noopener noreferrer">incremental imports</a> from Sqoop or
output of <code>HiveIncrementalPuller</code> or files under a DFS folder</li>
<li>Support json, avro or a custom record types for the incoming data</li>
<li>Manage checkpoints, rollback &amp; recovery</li>
<li>Leverage Avro schemas from DFS or Confluent <a href="https://github.com/confluentinc/schema-registry" target="_blank" rel="noopener noreferrer">schema registry</a>.</li>
<li>Support for plugging in transformations</li>
</ul>
<div class="theme-admonition theme-admonition-danger admonition_xJq3 alert alert--danger"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"></path></svg></span>Important</div><div class="admonitionContent_BuS1"><p>The following classes were renamed and relocated to <code>org.apache.hudi.utilities.streamer</code> package.</p><ul>
<li><code>DeltastreamerMultiWriterCkptUpdateFunc</code> is renamed to <code>StreamerMultiWriterCkptUpdateFunc</code></li>
<li><code>DeltaSync</code> is renamed to <code>StreamSync</code></li>
<li><code>HoodieDeltaStreamer</code> is renamed to <code>HoodieStreamer</code></li>
<li><code>HoodieDeltaStreamerMetrics</code> is renamed to <code>HoodieStreamerMetrics</code></li>
<li><code>HoodieMultiTableDeltaStreamer</code> is renamed to <code>HoodieMultiTableStreamer</code></li>
</ul><p>To maintain backward compatibility, the original classes are still present in the <code>org.apache.hudi.utilities.deltastreamer</code>
package, but have been deprecated.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="options">Options<a href="#options" class="hash-link" aria-label="Direct link to Options" title="Direct link to Options">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><p>Expand this to see HoodieStreamer&#x27;s &quot;--help&quot; output describing its capabilities in more details.</p></summary><div><div class="collapsibleContent_i85q"><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[hoodie]$ spark-submit \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --packages org.apache.hudi:hudi-utilities-slim-bundle_2.12:1.0.1,org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.1 \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --class org.apache.hudi.utilities.streamer.HoodieStreamer `ls packaging/hudi-utilities-slim-bundle/target/hudi-utilities-slim-bundle-*.jar` --help</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Usage: &lt;main class&gt; [options]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  Options:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --allow-commit-on-no-checkpoint-change</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      allow commits even if checkpoint has not changed before and after fetch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      datafrom source. This might be useful in sources like SqlSource where</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      there is not checkpoint. And is not recommended to enable in continuous</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      mode.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --base-file-format</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      File format for the base files. PARQUET (or) HFILE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: PARQUET</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --bootstrap-index-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      subclass of BootstrapIndex</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --bootstrap-overwrite</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Overwrite existing target table, default false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --checkpoint</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Resume Hudi Streamer from this checkpoint.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --cluster-scheduling-minshare</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Minshare for clustering as defined in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      https://spark.apache.org/docs/latest/job-scheduling.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --cluster-scheduling-weight</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Scheduling weight for clustering as defined in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      https://spark.apache.org/docs/latest/job-scheduling.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --commit-on-errors</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Commit even when some records failed to be written</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --compact-scheduling-minshare</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Minshare for compaction as defined in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      https://spark.apache.org/docs/latest/job-scheduling.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --compact-scheduling-weight</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Scheduling weight for compaction as defined in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      https://spark.apache.org/docs/latest/job-scheduling.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --config-hot-update-strategy-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Configuration hot update in continuous mode</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: &lt;empty string&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --continuous</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Hudi Streamer runs in continuous mode running source-fetch -&gt; Transform</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      -&gt; Hudi Write in loop</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --delta-sync-scheduling-minshare</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Minshare for delta sync as defined in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      https://spark.apache.org/docs/latest/job-scheduling.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --delta-sync-scheduling-weight</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Scheduling weight for delta sync as defined in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      https://spark.apache.org/docs/latest/job-scheduling.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --disable-compaction</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Compaction is enabled for MoR table by default. This flag disables it</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --enable-hive-sync</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Enable syncing to hive</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --enable-sync</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Enable syncing meta</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --filter-dupes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Should duplicate records from source be dropped/filtered out before</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      insert/bulk-insert</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --force-empty-sync</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Force syncing meta even on empty commit</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --help, -h</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --hoodie-conf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Any configuration that can be set in the properties file (using the CLI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      parameter &quot;--props&quot;) can also be passed command line using this</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      parameter. This can be repeated</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --ingestion-metrics-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Ingestion metrics class for reporting metrics during ingestion</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      lifecycles.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: org.apache.hudi.utilities.streamer.HoodieStreamerMetrics</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --initial-checkpoint-provider</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      subclass of</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      org.apache.hudi.utilities.checkpointing.InitialCheckpointProvider.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Generate check point for Hudi Streamer for the first run. This field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      will override the checkpoint of last commit using the checkpoint field.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Use this field only when switching source, for example, from DFS source</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      to Kafka Source.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --max-pending-clustering</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Maximum number of outstanding inflight/requested clustering. Delta Sync</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      will not happen unlessoutstanding clustering is less than this number</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --max-pending-compactions</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Maximum number of outstanding inflight/requested compactions. Delta Sync</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      will not happen unlessoutstanding compactions is less than this number</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --max-retry-count</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      the max retry count if --retry-on-source-failures is enabled</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --min-sync-interval-seconds</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      the min sync interval of each sync in continuous mode</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --op</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Takes one of these values : UPSERT (default), INSERT, BULK_INSERT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      INSERT_OVERWRITE, INSERT_OVERWRITE_TABLE, DELETE_PARTITION</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: UPSERT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Possible Values: [INSERT, INSERT_PREPPED, UPSERT, UPSERT_PREPPED, BULK_INSERT, BULK_INSERT_PREPPED, DELETE, DELETE_PREPPED, BOOTSTRAP, INSERT_OVERWRITE, CLUSTER, DELETE_PARTITION, INSERT_OVERWRITE_TABLE, COMPACT, INDEX, ALTER_SCHEMA, LOG_COMPACT, UNKNOWN]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --payload-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      subclass of HoodieRecordPayload, that works off a GenericRecord.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Implement your own, if you want to do something other than overwriting</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      existing value</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: org.apache.hudi.common.model.OverwriteWithLatestAvroPayload</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --post-write-termination-strategy-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Post writer termination strategy class to gracefully shutdown</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      deltastreamer in continuous mode</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: &lt;empty string&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --props</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      path to properties file on localfs or dfs, with configurations for</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      hoodie client, schema provider, key generator and data source. For</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      hoodie client props, sane defaults are used, but recommend use to</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      provide basic things like metrics endpoints, hive configs etc. For</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      sources, referto individual classes, for supported properties.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Properties in this file can be overridden by &quot;--hoodie-conf&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: file:///Users/shiyanxu/src/test/resources/streamer-config/dfs-source.properties</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --retry-interval-seconds</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      the retry interval for source failures if --retry-on-source-failures is</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      enabled</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 30</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --retry-last-pending-inline-clustering, -rc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Retry last pending inline clustering plan before writing to sink.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --retry-last-pending-inline-compaction</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Retry last pending inline compaction plan before writing to sink.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --retry-on-source-failures</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Retry on any source failures</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --run-bootstrap</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Run bootstrap if bootstrap index is not found</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --schemaprovider-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      subclass of org.apache.hudi.utilities.schema.SchemaProvider to attach</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      schemas to input &amp; target table data, built in options:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      org.apache.hudi.utilities.schema.FilebasedSchemaProvider.Source (See</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      org.apache.hudi.utilities.sources.Source) implementation can implement</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      their own SchemaProvider. For Sources that return Dataset&lt;Row&gt;, the</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      schema is obtained implicitly. However, this CLI option allows</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      overriding the schemaprovider returned by Source.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --source-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Subclass of org.apache.hudi.utilities.sources to read data. Built-in</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      options: org.apache.hudi.utilities.sources.{JsonDFSSource (default),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      AvroDFSSource, JsonKafkaSource, AvroKafkaSource, HiveIncrPullSource}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: org.apache.hudi.utilities.sources.JsonDFSSource</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --source-limit</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Maximum amount of data to read from source. Default: No limit, e.g:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      DFS-Source =&gt; max bytes to read, Kafka-Source =&gt; max events to read</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: 9223372036854775807</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --source-ordering-field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Field within source record to decide how to break ties between records</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      with same key in input data. Default: &#x27;ts&#x27; holding unix timestamp of</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      record</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: ts</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --spark-master</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      spark master to use, if not defined inherits from your environment</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      taking into account Spark Configuration priority rules (e.g. not using</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      spark-submit command).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: &lt;empty string&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --sync-tool-classes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Meta sync client tool, using comma to separate multi tools</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Default: org.apache.hudi.hive.HiveSyncTool</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  * --table-type</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Type of table. COPY_ON_WRITE (or) MERGE_ON_READ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  * --target-base-path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      base path for the target hoodie table. (Will be created if did not exist</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      first time around. If exists, expected to be a hoodie table)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  * --target-table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      name of the target table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --transformer-class</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      A subclass or a list of subclasses of</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      org.apache.hudi.utilities.transform.Transformer. Allows transforming raw</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      source Dataset to a target Dataset (conforming to target schema) before</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      writing. Default : Not set. E.g. -</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      org.apache.hudi.utilities.transform.SqlQueryBasedTransformer (which</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      allows a SQL query templated to be passed as a transformation function).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Pass a comma-separated list of subclass names to chain the</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      transformations. If there are two or more transformers using the same</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      config keys and expect different values for those keys, then transformer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      can include an identifier. E.g. -</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tr1:org.apache.hudi.utilities.transform.SqlQueryBasedTransformer. Here</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      the identifier tr1 can be used along with property key like</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      `hoodie.streamer.transformer.sql.tr1` to identify properties related to</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      the transformer. So effective value for</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      `hoodie.streamer.transformer.sql` is determined by key</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      `hoodie.streamer.transformer.sql.tr1` for this transformer. If</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      identifier is used, it should be specified for all the transformers.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Further the order in which transformer is applied is determined by the</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      occurrence of transformer irrespective of the identifier used for the</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      transformer. For example: In the configured value below tr2:org.apache.hudi.utilities.transform.SqlQueryBasedTransformer,tr1:org.apache.hudi.utilities.transform.SqlQueryBasedTransformer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      , tr2 is applied before tr1 based on order of occurrence.</span><br></span></code></pre></div></div></div></div></details>
<p>The tool takes a hierarchically composed property file and has pluggable interfaces for extracting data, key generation and providing schema. Sample configs for ingesting from kafka and dfs are
provided under <code>hudi-utilities/src/test/resources/streamer-config</code>.</p>
<p>For e.g: once you have Confluent Kafka, Schema registry up &amp; running, produce some test data using (<a href="https://docs.confluent.io/current/ksql/docs/tutorials/generate-custom-test-data" target="_blank" rel="noopener noreferrer">impressions.avro</a> provided by schema-registry repo)</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[confluent-5.0.0]$ bin/ksql-datagen schema=../impressions.avro format=avro topic=impressions key=impressionid</span><br></span></code></pre></div></div>
<p>and then ingest it as follows.</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[hoodie]$ spark-submit \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --packages org.apache.hudi:hudi-utilities-slim-bundle_2.12:1.0.1,org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.1 \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --class org.apache.hudi.utilities.streamer.HoodieStreamer `ls packaging/hudi-utilities-slim-bundle/target/hudi-utilities-slim-bundle-*.jar` \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --props file://${PWD}/hudi-utilities/src/test/resources/streamer-config/kafka-source.properties \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --schemaprovider-class org.apache.hudi.utilities.schema.SchemaRegistryProvider \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --source-class org.apache.hudi.utilities.sources.AvroKafkaSource \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --source-ordering-field impresssiontime \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --target-base-path file:\/\/\/tmp/hudi-streamer-op \ </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --target-table uber.impressions \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --op BULK_INSERT</span><br></span></code></pre></div></div>
<p>In some cases, you may want to migrate your existing table into Hudi beforehand. Please refer to <a href="/docs/migration_guide">migration guide</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-hudi-utilities-slim-bundle-bundle-jar">Using <code>hudi-utilities-slim-bundle</code> bundle jar<a href="#using-hudi-utilities-slim-bundle-bundle-jar" class="hash-link" aria-label="Direct link to using-hudi-utilities-slim-bundle-bundle-jar" title="Direct link to using-hudi-utilities-slim-bundle-bundle-jar">​</a></h3>
<p>It is recommended to use <code>hudi-utilities-slim-bundle</code>, which should be used along with a Hudi Spark bundle
corresponding the Spark version used to make utilities work with Spark, e.g.,
<code>--packages org.apache.hudi:hudi-utilities-slim-bundle_2.12:1.0.1,org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.1</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="concurrency-control">Concurrency Control<a href="#concurrency-control" class="hash-link" aria-label="Direct link to Concurrency Control" title="Direct link to Concurrency Control">​</a></h3>
<p>Using optimistic concurrency control (OCC) via Hudi Streamer requires the configs below to the properties file that can be passed to the
job.</p>
<div class="language-properties codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-properties codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.write.concurrency.mode=optimistic_concurrency_control</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.write.lock.provider=&lt;lock-provider-classname&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.cleaner.policy.failed.writes=LAZY</span><br></span></code></pre></div></div>
<p>As an example, adding the configs to <code>kafka-source.properties</code> file and passing them to Hudi Streamer will enable OCC.
A Hudi Streamer job can then be triggered as follows:</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[hoodie]$ spark-submit \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --packages org.apache.hudi:hudi-utilities-slim-bundle_2.12:1.0.1,org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.1 \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --class org.apache.hudi.utilities.streamer.HoodieStreamer `ls packaging/hudi-utilities-slim-bundle/target/hudi-utilities-slim-bundle-*.jar` \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --props file://${PWD}/hudi-utilities/src/test/resources/streamer-config/kafka-source.properties \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --schemaprovider-class org.apache.hudi.utilities.schema.SchemaRegistryProvider \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --source-class org.apache.hudi.utilities.sources.AvroKafkaSource \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --source-ordering-field impresssiontime \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --target-base-path file:///tmp/hudi-streamer-op \ </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --target-table uber.impressions \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --op BULK_INSERT</span><br></span></code></pre></div></div>
<p>Read more in depth about concurrency control in the <a href="/docs/concurrency_control">concurrency control concepts</a> section</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="checkpointing">Checkpointing<a href="#checkpointing" class="hash-link" aria-label="Direct link to Checkpointing" title="Direct link to Checkpointing">​</a></h3>
<p><code>HoodieStreamer</code> uses checkpoints to keep track of what data has been read already so it can resume without needing to reprocess all data.
When using a Kafka source, the checkpoint is the <a href="https://cwiki.apache.org/confluence/display/KAFKA/Offset+Management" target="_blank" rel="noopener noreferrer">Kafka Offset</a>
When using a DFS source, the checkpoint is the &#x27;last modified&#x27; timestamp of the latest file read.
Checkpoints are saved in the .hoodie commit file as <code>streamer.checkpoint.key</code>.</p>
<p>If you need to change the checkpoints for reprocessing or replaying data you can use the following options:</p>
<ul>
<li><code>--checkpoint</code> will set <code>streamer.checkpoint.reset_key</code> in the commit file to overwrite the current checkpoint. Format of checkpoint depends on <a href="/docs/configurations#hoodiestreamersourcekafkacheckpointtype">KAFKA_CHECKPOINT_TYPE</a>. By default (for type <code>string</code>), checkpoint should be provided as: <code>topicName,0:offset0,1:offset1,2:offset2</code>. For type <code>timestamp</code>, checkpoint should be provided as long value of desired timestamp. For type <code>single_offset</code>, we assume that topic consists of a single partition, so checkpoint should be provided as long value of desired offset.</li>
<li><code>--source-limit</code> will set a maximum amount of data to read from the source. For DFS sources, this is max # of bytes read.
For Kafka, this is the max # of events to read.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transformers">Transformers<a href="#transformers" class="hash-link" aria-label="Direct link to Transformers" title="Direct link to Transformers">​</a></h3>
<p><code>HoodieStreamer</code> supports custom transformation on records before writing to storage. This is done by supplying
implementation of <code>org.apache.hudi.utilities.transform.Transformer</code> via <code>--transformer-class</code> option.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sql-query-transformer">SQL Query Transformer<a href="#sql-query-transformer" class="hash-link" aria-label="Direct link to SQL Query Transformer" title="Direct link to SQL Query Transformer">​</a></h4>
<p>You can pass a SQL Query to be executed during write.</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">--transformer-class org.apache.hudi.utilities.transform.SqlQueryBasedTransformer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--hoodie-conf hoodie.streamer.transformer.sql=SELECT a.col1, a.col3, a.col4 FROM &lt;SRC&gt; a</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sql-file-transformer">SQL File Transformer<a href="#sql-file-transformer" class="hash-link" aria-label="Direct link to SQL File Transformer" title="Direct link to SQL File Transformer">​</a></h4>
<p>You can specify a File with a SQL script to be executed during write. The SQL file is configured with this hoodie property:
hoodie.streamer.transformer.sql.file</p>
<p>The query should reference the source as a table named &quot;&lt;SRC&gt;&quot;</p>
<p>The final sql statement result is used as the write payload.</p>
<p>Example Spark SQL Query:</p>
<div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CACHE </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> tmp_personal_trips </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> </span><span class="token operator">&lt;</span><span class="token plain">SRC</span><span class="token operator">&gt;</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WHERE</span><span class="token plain"> trip_type</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;personal_trips&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> tmp_personal_trips</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="flattening-transformer">Flattening Transformer<a href="#flattening-transformer" class="hash-link" aria-label="Direct link to Flattening Transformer" title="Direct link to Flattening Transformer">​</a></h4>
<p>This transformer can flatten nested objects. It flattens the nested fields in the incoming records by prefixing
inner-fields with outer-field and _ in a nested fashion. Currently flattening of arrays is not supported.</p>
<p>An example schema may look something like the below where name is a nested field of StructType in the original source</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">age as intColumn,address as stringColumn,name.first as name_first,name.last as name_last, name.middle as name_middle</span><br></span></code></pre></div></div>
<p>Set the config as:</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">--transformer-class org.apache.hudi.utilities.transform.FlatteningTransformer</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="chained-transformer">Chained Transformer<a href="#chained-transformer" class="hash-link" aria-label="Direct link to Chained Transformer" title="Direct link to Chained Transformer">​</a></h4>
<p>If you wish to use multiple transformers together, you can use the Chained transformers to pass multiple to be executed sequentially.</p>
<p>Example below first flattens the incoming records and then does sql projection based on the query specified:</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">--transformer-class org.apache.hudi.utilities.transform.FlatteningTransformer,org.apache.hudi.utilities.transform.SqlQueryBasedTransformer   </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--hoodie-conf hoodie.streamer.transformer.sql=SELECT a.col1, a.col3, a.col4 FROM &lt;SRC&gt; a</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-dms-transformer">AWS DMS Transformer<a href="#aws-dms-transformer" class="hash-link" aria-label="Direct link to AWS DMS Transformer" title="Direct link to AWS DMS Transformer">​</a></h4>
<p>This transformer is specific for AWS DMS data. It adds <code>Op</code> field with value <code>I</code> if the field is not present.</p>
<p>Set the config as:</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">--transformer-class org.apache.hudi.utilities.transform.AWSDmsTransformer</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="custom-transformer-implementation">Custom Transformer Implementation<a href="#custom-transformer-implementation" class="hash-link" aria-label="Direct link to Custom Transformer Implementation" title="Direct link to Custom Transformer Implementation">​</a></h4>
<p>You can write your own custom transformer by extending <a href="https://github.com/apache/hudi/tree/master/hudi-utilities/src/main/java/org/apache/hudi/utilities/transform" target="_blank" rel="noopener noreferrer">this class</a></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="related-resources">Related Resources<a href="#related-resources" class="hash-link" aria-label="Direct link to Related Resources" title="Direct link to Related Resources">​</a></h4>
<ul>
<li><a href="https://www.youtube.com/watch?v=AprlZ8hGdJo" target="_blank" rel="noopener noreferrer">Learn about Apache Hudi Transformers with Hands on Lab</a></li>
<li><a href="https://youtu.be/DH3LEaPG6ss" target="_blank" rel="noopener noreferrer">Apache Hudi with DBT Hands on Lab.Transform Raw Hudi tables with DBT and Glue Interactive Session</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="schema-providers">Schema Providers<a href="#schema-providers" class="hash-link" aria-label="Direct link to Schema Providers" title="Direct link to Schema Providers">​</a></h3>
<p>By default, Spark will infer the schema of the source and use that inferred schema when writing to a table. If you need
to explicitly define the schema you can use one of the following Schema Providers below.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="schema-registry-provider">Schema Registry Provider<a href="#schema-registry-provider" class="hash-link" aria-label="Direct link to Schema Registry Provider" title="Direct link to Schema Registry Provider">​</a></h4>
<p>You can obtain the latest schema from an online registry. You pass a URL to the registry and if needed, you can also
pass userinfo and credentials in the url like: <code>https://foo:bar@schemaregistry.org</code> The credentials are then extracted
and are set on the request as an Authorization Header.</p>
<p>When fetching schemas from a registry, you can specify both the source schema and the target schema separately.</p>
<table><thead><tr><th>Config</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>hoodie.streamer.schemaprovider.registry.url</td><td>The schema of the source you are reading from</td><td><a href="https://foo:bar@schemaregistry.org" target="_blank" rel="noopener noreferrer">https://foo:bar@schemaregistry.org</a></td></tr><tr><td>hoodie.streamer.schemaprovider.registry.targetUrl</td><td>The schema of the target you are writing to</td><td><a href="https://foo:bar@schemaregistry.org" target="_blank" rel="noopener noreferrer">https://foo:bar@schemaregistry.org</a></td></tr></tbody></table>
<p>The above configs are passed to Hudi Streamer spark-submit command like:</p>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">--hoodie-conf hoodie.streamer.schemaprovider.registry.url=https://foo:bar@schemaregistry.org</span><br></span></code></pre></div></div>
<p>There are other optional configs to work with schema registry provider such as SSL-store related configs, and supporting
custom transformation of schema returned by schema registry, e.g., converting the original json schema to avro schema
via <code>org.apache.hudi.utilities.schema.converter.JsonToAvroSchemaConverter</code>.</p>
<table><thead><tr><th>Config</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>hoodie.streamer.schemaprovider.registry.schemaconverter</td><td>The class name of the custom schema converter to use</td><td><code>org.apache.hudi.utilities.schema.converter.JsonToAvroSchemaConverter</code></td></tr><tr><td>schema.registry.ssl.keystore.location</td><td>SSL key store location</td><td></td></tr><tr><td>schema.registry.ssl.keystore.password</td><td>SSL key store password</td><td></td></tr><tr><td>schema.registry.ssl.truststore.location</td><td>SSL trust store location</td><td></td></tr><tr><td>schema.registry.ssl.truststore.password</td><td>SSL trust store password</td><td></td></tr><tr><td>schema.registry.ssl.key.password</td><td>SSL key password</td><td></td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="jdbc-schema-provider">JDBC Schema Provider<a href="#jdbc-schema-provider" class="hash-link" aria-label="Direct link to JDBC Schema Provider" title="Direct link to JDBC Schema Provider">​</a></h4>
<p>You can obtain the latest schema through a JDBC connection.</p>
<table><thead><tr><th>Config</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.connection.url</td><td>The JDBC URL to connect to. You can specify source specific connection properties in the URL</td><td>jdbc:postgresql://localhost/test?user=fred&amp;password=secret</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.driver.type</td><td>The class name of the JDBC driver to use to connect to this URL</td><td>org.h2.Driver</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.username</td><td>username for the connection</td><td>fred</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.password</td><td>password for the connection</td><td>secret</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.dbtable</td><td>The table with the schema to reference</td><td>test_database.test1_table or test1_table</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.timeout</td><td>The number of seconds the driver will wait for a Statement object to execute to the given number of seconds. Zero means there is no limit. In the write path, this option depends on how JDBC drivers implement the API setQueryTimeout, e.g., the h2 JDBC driver checks the timeout of each query instead of an entire JDBC batch. It defaults to 0.</td><td>0</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.jdbc.nullable</td><td>If true, all columns are nullable</td><td>true</td></tr></tbody></table>
<p>The above configs are passed to Hudi Streamer spark-submit command like:
<code>--hoodie-conf hoodie.streamer.jdbcbasedschemaprovider.connection.url=jdbc:postgresql://localhost/test?user=fred&amp;password=secret</code></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="file-based-schema-provider">File Based Schema Provider<a href="#file-based-schema-provider" class="hash-link" aria-label="Direct link to File Based Schema Provider" title="Direct link to File Based Schema Provider">​</a></h4>
<p>You can use a .avsc file to define your schema. You can then point to this file on DFS as a schema provider.</p>
<table><thead><tr><th>Config</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>hoodie.streamer.schemaprovider.source.schema.file</td><td>The schema of the source you are reading from</td><td><a href="https://github.com/apache/hudi/blob/a8fb69656f522648233f0310ca3756188d954281/docker/demo/config/test-suite/source.avsc" target="_blank" rel="noopener noreferrer">example schema file</a></td></tr><tr><td>hoodie.streamer.schemaprovider.target.schema.file</td><td>The schema of the target you are writing to</td><td><a href="https://github.com/apache/hudi/blob/a8fb69656f522648233f0310ca3756188d954281/docker/demo/config/test-suite/target.avsc" target="_blank" rel="noopener noreferrer">example schema file</a></td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="hive-schema-provider">Hive Schema Provider<a href="#hive-schema-provider" class="hash-link" aria-label="Direct link to Hive Schema Provider" title="Direct link to Hive Schema Provider">​</a></h4>
<p>You can use hive tables to fetch source and target schema.</p>
<table><thead><tr><th>Config</th><th>Description</th></tr></thead><tbody><tr><td>hoodie.streamer.schemaprovider.source.schema.hive.database</td><td>Hive database from where source schema can be fetched</td></tr><tr><td>hoodie.streamer.schemaprovider.source.schema.hive.table</td><td>Hive table from where source schema can be fetched</td></tr><tr><td>hoodie.streamer.schemaprovider.target.schema.hive.database</td><td>Hive database from where target schema can be fetched</td></tr><tr><td>hoodie.streamer.schemaprovider.target.schema.hive.table</td><td>Hive table from where target schema can be fetched</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="schema-provider-with-post-processor">Schema Provider with Post Processor<a href="#schema-provider-with-post-processor" class="hash-link" aria-label="Direct link to Schema Provider with Post Processor" title="Direct link to Schema Provider with Post Processor">​</a></h4>
<p>The SchemaProviderWithPostProcessor, will extract the schema from one of the previously mentioned Schema Providers and
then will apply a post processor to change the schema before it is used. You can write your own post processor by extending
this class: <a href="https://github.com/apache/hudi/blob/master/hudi-utilities/src/main/java/org/apache/hudi/utilities/schema/SchemaPostProcessor.java" target="_blank" rel="noopener noreferrer">https://github.com/apache/hudi/blob/master/hudi-utilities/src/main/java/org/apache/hudi/utilities/schema/SchemaPostProcessor.java</a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sources">Sources<a href="#sources" class="hash-link" aria-label="Direct link to Sources" title="Direct link to Sources">​</a></h3>
<p>Hoodie Streamer can read data from a wide variety of sources. The following are a list of supported sources:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="distributed-file-system-dfs">Distributed File System (DFS)<a href="#distributed-file-system-dfs" class="hash-link" aria-label="Direct link to Distributed File System (DFS)" title="Direct link to Distributed File System (DFS)">​</a></h4>
<p>See the storage configurations page to see some examples of DFS applications Hudi can read from. The following are the
supported file formats Hudi can read/write with on DFS Sources. (Note: you can still use Spark/Flink readers to read from
other formats and then write data as Hudi format.)</p>
<ul>
<li>CSV</li>
<li>AVRO</li>
<li>JSON</li>
<li>PARQUET</li>
<li>ORC</li>
<li>HUDI</li>
</ul>
<p>For DFS sources the following behaviors are expected:</p>
<ul>
<li>For JSON DFS source, you always need to set a schema. If the target Hudi table follows the same schema as from the source file, you just need to set the source schema. If not, you need to set schemas for both source and target.</li>
<li><code>HoodieStreamer</code> reads the files under the source base path (<code>hoodie.streamer.source.dfs.root</code>) directly, and it won&#x27;t use the partition paths under this base path as fields of the dataset. Detailed examples can be found <a href="https://github.com/apache/hudi/issues/5485" target="_blank" rel="noopener noreferrer">here</a>.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="kafka">Kafka<a href="#kafka" class="hash-link" aria-label="Direct link to Kafka" title="Direct link to Kafka">​</a></h4>
<p>Hudi can read directly from Kafka clusters. See more details on <code>HoodieStreamer</code> to learn how to setup streaming
ingestion with exactly once semantics, checkpointing, and plugin transformations. The following formats are supported
when reading data from Kafka:</p>
<ul>
<li>AVRO: <code>org.apache.hudi.utilities.sources.AvroKafkaSource</code></li>
<li>JSON: <code>org.apache.hudi.utilities.sources.JsonKafkaSource</code></li>
<li>Proto: <code>org.apache.hudi.utilities.sources.ProtoKafkaSource</code></li>
</ul>
<p>Check out <a href="https://hudi.apache.org/docs/configurations#Kafka-Source-Configs" target="_blank" rel="noopener noreferrer">Kafka source config</a> for more details.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pulsar">Pulsar<a href="#pulsar" class="hash-link" aria-label="Direct link to Pulsar" title="Direct link to Pulsar">​</a></h4>
<p><code>HoodieStreamer</code> also supports ingesting from Apache Pulsar via <code>org.apache.hudi.utilities.sources.PulsarSource</code>.
Check out <a href="https://hudi.apache.org/docs/configurations#Pulsar-Source-Configs" target="_blank" rel="noopener noreferrer">Pulsar source config</a> for more details.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cloud-storage-event-sources">Cloud storage event sources<a href="#cloud-storage-event-sources" class="hash-link" aria-label="Direct link to Cloud storage event sources" title="Direct link to Cloud storage event sources">​</a></h4>
<p>AWS S3 storage provides an event notification service which will post notifications when certain events happen in your S3 bucket:
<a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html</a>
AWS will put these events in a Simple Queue Service (SQS). Apache Hudi provides <code>S3EventsSource</code>
and <code>S3EventsHoodieIncrSource</code> that can read from SQS to trigger/processing of new or changed data as soon as it is
available on S3. Check out <a href="https://hudi.apache.org/docs/configurations#S3-Source-Configs" target="_blank" rel="noopener noreferrer">S3 source configs</a> for more details.</p>
<p>Similar to S3 event source, Google Cloud Storage (GCS) event source is also supported via <code>GcsEventsSource</code> and
<code>GcsEventsHoodieIncrSource</code>. Check out <a href="https://hudi.apache.org/docs/configurations#GCS-Events-Source-Configs" target="_blank" rel="noopener noreferrer">GCS events source configs</a> for more details.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="aws-setup">AWS Setup<a href="#aws-setup" class="hash-link" aria-label="Direct link to AWS Setup" title="Direct link to AWS Setup">​</a></h5>
<ol>
<li>Enable S3 Event Notifications <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html</a></li>
<li>Download the aws-java-sdk-sqs jar.</li>
<li>Find the queue URL and Region to set these configurations:<!-- -->
<ol>
<li>hoodie.streamer.s3.source.queue.url=<a href="https://sqs.us-west-2.amazonaws.com/queue/url" target="_blank" rel="noopener noreferrer">https://sqs.us-west-2.amazonaws.com/queue/url</a></li>
<li>hoodie.streamer.s3.source.queue.region=us-west-2</li>
</ol>
</li>
<li>Start the <code>S3EventsSource</code> and <code>S3EventsHoodieIncrSource</code> using the <code>HoodieStreamer</code> utility as shown in sample commands below:</li>
</ol>
<p>Insert code sample from this blog: <a href="https://hudi.apache.org/blog/2021/08/23/s3-events-source/#configuration-and-setup" target="_blank" rel="noopener noreferrer">https://hudi.apache.org/blog/2021/08/23/s3-events-source/#configuration-and-setup</a></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="jdbc-source">JDBC Source<a href="#jdbc-source" class="hash-link" aria-label="Direct link to JDBC Source" title="Direct link to JDBC Source">​</a></h4>
<p>Hudi can read from a JDBC source with a full fetch of a table, or Hudi can even read incrementally with checkpointing from a JDBC source.</p>
<table><thead><tr><th>Config</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>hoodie.streamer.jdbc.url</td><td>URL of the JDBC connection</td><td>jdbc:postgresql://localhost/test</td></tr><tr><td>hoodie.streamer.jdbc.user</td><td>User to use for authentication of the JDBC connection</td><td>fred</td></tr><tr><td>hoodie.streamer.jdbc.password</td><td>Password to use for authentication of the JDBC connection</td><td>secret</td></tr><tr><td>hoodie.streamer.jdbc.password.file</td><td>If you prefer to use a password file for the connection</td><td></td></tr><tr><td>hoodie.streamer.jdbc.driver.class</td><td>Driver class to use for the JDBC connection</td><td></td></tr><tr><td>hoodie.streamer.jdbc.table.name</td><td></td><td>my_table</td></tr><tr><td>hoodie.streamer.jdbc.table.incr.column.name</td><td>If run in incremental mode, this field will be used to pull new data incrementally</td><td></td></tr><tr><td>hoodie.streamer.jdbc.incr.pull</td><td>Will the JDBC connection perform an incremental pull?</td><td></td></tr><tr><td>hoodie.streamer.jdbc.extra.options.</td><td>How you pass extra configurations that would normally by specified as spark.read.option()</td><td>hoodie.streamer.jdbc.extra.options.fetchSize=100 hoodie.streamer.jdbc.extra.options.upperBound=1 hoodie.streamer.jdbc.extra.options.lowerBound=100</td></tr><tr><td>hoodie.streamer.jdbc.storage.level</td><td>Used to control the persistence level</td><td>Default = MEMORY_AND_DISK_SER</td></tr><tr><td>hoodie.streamer.jdbc.incr.fallback.to.full.fetch</td><td>Boolean which if set true makes an incremental fetch fallback to a full fetch if there is any error in the incremental read</td><td>FALSE</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sql-sources">SQL Sources<a href="#sql-sources" class="hash-link" aria-label="Direct link to SQL Sources" title="Direct link to SQL Sources">​</a></h4>
<p>SQL Source <code>org.apache.hudi.utilities.sources.SqlSource</code> reads from any table, used mainly for backfill jobs which will process specific partition dates.
This won&#x27;t update the streamer.checkpoint.key to the processed commit, instead it will fetch the latest successful
checkpoint key and set that value as this backfill commits checkpoint so that it won&#x27;t interrupt the regular incremental
processing. To fetch and use the latest incremental checkpoint, you need to also set this hoodie_conf for Hudi Streamer
jobs: <code>hoodie.write.meta.key.prefixes = &#x27;streamer.checkpoint.key&#x27;</code></p>
<p>Spark SQL should be configured using this hoodie config:
<code>hoodie.streamer.source.sql.sql.query = &#x27;select * from source_table&#x27;</code></p>
<p>Using <code>org.apache.hudi.utilities.sources.SqlFileBasedSource</code> allows setting the SQL queries in a file to read from any
table. SQL file path should be configured using this hoodie config:
<code>hoodie.streamer.source.sql.file = &#x27;hdfs://xxx/source.sql&#x27;</code></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="error-table">Error Table<a href="#error-table" class="hash-link" aria-label="Direct link to Error Table" title="Direct link to Error Table">​</a></h3>
<p><code>HoodieStreamer</code> supports segregating error records into a separate table called &quot;Error table&quot; alongside with the
target data table. This allows easy integration with dead-letter queues (DLQ). Error Table is supported with
user-provided subclass of <code>org.apache.hudi.utilities.streamer.BaseErrorTableWriter</code> supplied via
config <code>hoodie.errortable.write.class</code>. Check out more in <code>org.apache.hudi.config.HoodieErrorTableConfig</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="termination-strategy">Termination Strategy<a href="#termination-strategy" class="hash-link" aria-label="Direct link to Termination Strategy" title="Direct link to Termination Strategy">​</a></h3>
<p>Users can configure a post-write termination strategy under <code>continuous</code> mode if need be. For instance,
users can configure graceful shutdown if there is no new data from the configured source for 5 consecutive times.
Here is the interface for the termination strategy.</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">/**</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> * Post write termination strategy for deltastreamer in continuous mode.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> */</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">public interface PostWriteTerminationStrategy {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  /**</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   * Returns whether HoodieStreamer needs to be shutdown.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   * @param scheduledCompactionInstantAndWriteStatuses optional pair of scheduled compaction instant and write statuses.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   * @return true if HoodieStreamer has to be shutdown. false otherwise.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   */</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  boolean shouldShutdown(Option&lt;Pair&lt;Option&lt;String&gt;, JavaRDD&lt;WriteStatus&gt;&gt;&gt; scheduledCompactionInstantAndWriteStatuses);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>Also, this might help in bootstrapping a new table. Instead of doing one bulk load or bulk_insert leveraging a large
cluster for a large input of data, one could start <code>HoodieStreamer</code> on the <code>continuous</code> mode and add a shutdown strategy
to terminate, once all data has been bootstrapped. This way, each batch could be smaller and may not need a large
cluster to bootstrap data. There is a concrete implementation provided out-of-the-box: <a href="https://github.com/apache/hudi/blob/0d0a4152cfd362185066519ae926ac4513c7a152/hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/NoNewDataTerminationStrategy.java" target="_blank" rel="noopener noreferrer">NoNewDataTerminationStrategy</a>.
Users can feel free to implement their own strategy as they see fit.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dynamic-configuration-updates">Dynamic configuration updates<a href="#dynamic-configuration-updates" class="hash-link" aria-label="Direct link to Dynamic configuration updates" title="Direct link to Dynamic configuration updates">​</a></h3>
<p>When Hoodie Streamer is running in <code>continuous</code> mode, the properties can be refreshed/updated before each sync calls.
Interested users can implement <code>org.apache.hudi.utilities.deltastreamer.ConfigurationHotUpdateStrategy</code> to leverage this.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="multitablestreamer">MultiTableStreamer<a href="#multitablestreamer" class="hash-link" aria-label="Direct link to MultiTableStreamer" title="Direct link to MultiTableStreamer">​</a></h2>
<p><code>HoodieMultiTableStreamer</code>, an extension of <code>HoodieStreamer</code>, facilitates the simultaneous ingestion of multiple tables into Hudi datasets. At present, it supports the sequential ingestion of tables and accommodates both COPY_ON_WRITE and MERGE_ON_READ storage types. The command line parameters for <code>HoodieMultiTableStreamer</code> largely mirror those of <code>HoodieStreamer</code>, with the notable difference being the necessity to supply table-specific configurations in separate files in a dedicated config folder. New command line options have been introduced to support this functionality:</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">  * --config-folder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    the path to the folder which contains all the table wise config files</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --base-path-prefix</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    this is added to enable users to create all the hudi datasets for related tables under one path in FS. The datasets are then created under the path - &lt;base_path_prefix&gt;/&lt;database&gt;/&lt;table_to_be_ingested&gt;. However you can override the paths for every table by setting the property hoodie.streamer.ingestion.targetBasePath</span><br></span></code></pre></div></div>
<p>The following properties are needed to be set properly to ingest data using <code>HoodieMultiTableStreamer</code>.</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.streamer.ingestion.tablesToBeIngested</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  comma separated names of tables to be ingested in the format &lt;database&gt;.&lt;table&gt;, for example db1.table1,db1.table2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.streamer.ingestion.targetBasePath</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  if you wish to ingest a particular table in a separate path, you can mention that path here</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hoodie.streamer.ingestion.&lt;database&gt;.&lt;table&gt;.configFile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  path to the config file in dedicated config folder which contains table overridden properties for the particular table to be ingested.</span><br></span></code></pre></div></div>
<p>Sample config files for table wise overridden properties can be found
under <code>hudi-utilities/src/test/resources/streamer-config</code>. The command to run <code>HoodieMultiTableStreamer</code> is also similar
to how you run <code>HoodieStreamer</code>.</p>
<div class="language-java codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-java codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[hoodie]$ spark-submit \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --packages org.apache.hudi:hudi-utilities-slim-bundle_2.12:1.0.1,org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.1 \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --class org.apache.hudi.utilities.streamer.HoodieMultiTableStreamer `ls packaging/hudi-utilities-slim-bundle/target/hudi-utilities-slim-bundle-*.jar` \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --props file://${PWD}/hudi-utilities/src/test/resources/streamer-config/kafka-source.properties \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --config-folder file://tmp/hudi-ingestion-config \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --schemaprovider-class org.apache.hudi.utilities.schema.SchemaRegistryProvider \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --source-class org.apache.hudi.utilities.sources.AvroKafkaSource \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --source-ordering-field impresssiontime \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --base-path-prefix file:\/\/\/tmp/hudi-streamer-op \ </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --target-table uber.impressions \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  --op BULK_INSERT</span><br></span></code></pre></div></div>
<p>For detailed information on how to configure and use <code>HoodieMultiTableStreamer</code>, please refer <a href="/blog/2020/08/22/ingest-multiple-tables-using-hudi">blog section</a>.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/apache/hudi/tree/asf-site/website/docs/hoodie_streaming_ingestion.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/next/schema_evolution"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Schema Evolution</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/next/ingestion_flink"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Using Flink</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#hudi-streamer" class="table-of-contents__link toc-highlight">Hudi Streamer</a><ul><li><a href="#options" class="table-of-contents__link toc-highlight">Options</a></li><li><a href="#using-hudi-utilities-slim-bundle-bundle-jar" class="table-of-contents__link toc-highlight">Using <code>hudi-utilities-slim-bundle</code> bundle jar</a></li><li><a href="#concurrency-control" class="table-of-contents__link toc-highlight">Concurrency Control</a></li><li><a href="#checkpointing" class="table-of-contents__link toc-highlight">Checkpointing</a></li><li><a href="#transformers" class="table-of-contents__link toc-highlight">Transformers</a></li><li><a href="#schema-providers" class="table-of-contents__link toc-highlight">Schema Providers</a></li><li><a href="#sources" class="table-of-contents__link toc-highlight">Sources</a></li><li><a href="#error-table" class="table-of-contents__link toc-highlight">Error Table</a></li><li><a href="#termination-strategy" class="table-of-contents__link toc-highlight">Termination Strategy</a></li><li><a href="#dynamic-configuration-updates" class="table-of-contents__link toc-highlight">Dynamic configuration updates</a></li></ul></li><li><a href="#multitablestreamer" class="table-of-contents__link toc-highlight">MultiTableStreamer</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">About</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog/2021/07/21/streaming-data-lake-platform">Our Vision</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/concepts">Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/community/team">Team</a></li><li class="footer__item"><a class="footer__link-item" href="/releases/release-1.0.2">Releases</a></li><li class="footer__item"><a class="footer__link-item" href="/releases/download">Download</a></li><li class="footer__item"><a class="footer__link-item" href="/powered-by">Who&#x27;s Using</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/quick-start-guide">Quick Start</a></li><li class="footer__item"><a class="footer__link-item" href="/learn/tutorial-series">Tutorial Series</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/talks">Talks</a></li><li class="footer__item"><a class="footer__link-item" href="/videos">Video Guides</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/faq">FAQ</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Hudi On Cloud</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/s3_hoodie">AWS</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/gcs_hoodie">Google Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/oss_hoodie">Alibaba Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/azure_hoodie">Microsoft Azure</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cos_hoodie">Tencent Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/ibm_cos_hoodie">IBM Cloud</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/community/get-involved">Get Involved</a></li><li class="footer__item"><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/channel/UCs7AhE0BWaEPZSChrBR-Muw" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/apache-hudi/?viewAsMember=true" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="mailto:dev-subscribe@hudi.apache.org?Subject=SubscribeToHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">Mailing List</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Apache</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="footer__link-item">Events</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Thanks</a></li><li class="footer__item"><a href="https://www.apache.org/licenses" target="_blank" rel="noopener noreferrer" class="footer__link-item">License</a></li><li class="footer__item"><a href="https://www.apache.org/security" target="_blank" rel="noopener noreferrer" class="footer__link-item">Security</a></li><li class="footer__item"><a class="footer__link-item" href="/asf/privacy">Privacy</a></li><li class="footer__item"><a class="footer__link-item" href="/asf/telemetry">Telemetry</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Sponsorship</a></li><li class="footer__item"><a href="https://www.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Foundation</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://hudi.apache.org/" rel="noopener noreferrer" class="footerLogoLink_BH7S"><img src="/assets/images/logo-big.png" alt="Apache Hudi™" class="footer__logo themedComponent_mlkZ themedComponent--light_NVdE"><img src="/assets/images/logo-big.png" alt="Apache Hudi™" class="footer__logo themedComponent_mlkZ themedComponent--dark_xIcU"></a></div><div class="footer__copyright">Copyright © 2021 <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0"> Apache License, Version 2.0</a>. <br>Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation.<img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=8f594acf-9b77-44fb-9475-3e82ead1910c"><img referrerpolicy="no-referrer-when-downgrade" src="https://analytics.apache.org/matomo.php?idsite=47&amp;rec=1"></div></div></div></footer></div>
</body>
</html>
<!doctype html>
<html class="docs-version-0.7.0" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Hudi: User-Facing Analytics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Hudi: User-Facing Analytics Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Apache Hudi: User-Facing Analytics JSON Feed">
<link rel="search" type="application/opensearchdescription+xml" title="Apache Hudi" href="/opensearch.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Comfortaa|Ubuntu|Roboto|Source+Code+Pro">
<link rel="stylesheet" href="https://at-ui.github.io/feather-font/css/iconfont.css"><title data-react-helmet="true">Querying Hudi Tables | Apache Hudi</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://hudi.apache.org/docs/0.7.0/querying_data"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="0.7.0"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-0.7.0"><meta data-react-helmet="true" property="og:title" content="Querying Hudi Tables | Apache Hudi"><meta data-react-helmet="true" name="description" content="Conceptually, Hudi stores data physically once on DFS, while providing 3 different ways of querying, as explained before."><meta data-react-helmet="true" property="og:description" content="Conceptually, Hudi stores data physically once on DFS, while providing 3 different ways of querying, as explained before."><meta data-react-helmet="true" name="keywords" content="hudi,hive,spark,sql,presto"><link data-react-helmet="true" rel="icon" href="/assets/images/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://hudi.apache.org/docs/0.7.0/querying_data"><link data-react-helmet="true" rel="alternate" href="https://hudi.apache.org/docs/0.7.0/querying_data" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://hudi.apache.org/cn/docs/0.7.0/querying_data" hreflang="cn"><link data-react-helmet="true" rel="alternate" href="https://hudi.apache.org/docs/0.7.0/querying_data" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.635c4f43.css">
<link rel="preload" href="/assets/js/runtime~main.abb344ce.js" as="script">
<link rel="preload" href="/assets/js/main.a3e38e91.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><div class="announcementBar_axC9" role="banner"><div class="announcementBarPlaceholder_xYHE"></div><div class="announcementBarContent_6uhP">⭐️ If you like Apache Hudi, give it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/apache/hudi">GitHub</a>! ⭐</div><button type="button" class="clean-btn close announcementBarClose_A3A1" aria-label="Close"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedImage_TMUO themedImage--dark_uzRr"></div></a><a class="navbar__item navbar__link" href="/docs/overview">Docs</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Learn</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/talks">Talks</a></li><li><a class="dropdown__link" href="/docs/faq">FAQ</a></li><li><a class="dropdown__link" href="/tech-specs">Tech Specs</a></li><li><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Technical Wiki<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Contribute</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/contribute/how-to-contribute">How to Contribute</a></li><li><a class="dropdown__link" href="/contribute/developer-setup">Developer Setup</a></li><li><a class="dropdown__link" href="/contribute/rfc-process">RFC Process</a></li><li><a class="dropdown__link" href="/contribute/report-security-issues">Report Security Issues</a></li><li><a href="https://issues.apache.org/jira/projects/HUDI/summary" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Report Issues<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/community/get-involved">Get Involved</a></li><li><a class="dropdown__link" href="/community/syncs">Community Syncs</a></li><li><a class="dropdown__link" href="/community/office_hours">Office Hours</a></li><li><a class="dropdown__link" href="/community/team">Team</a></li></ul></div><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/powered-by">Who&#x27;s Using</a><a class="navbar__item navbar__link" href="/roadmap">Roadmap</a><a class="navbar__item navbar__link" href="/releases/download">Download</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/docs/0.7.0/overview">0.7.0</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/next/querying_data">Current</a></li><li><a class="dropdown__link" href="/docs/querying_data">0.12.1</a></li><li><a class="dropdown__link" href="/docs/0.12.0/querying_data">0.12.0</a></li><li><a class="dropdown__link" href="/docs/0.11.1/querying_data">0.11.1</a></li><li><a class="dropdown__link" href="/docs/0.11.0/querying_data">0.11.0</a></li><li><a class="dropdown__link" href="/docs/0.10.1/querying_data">0.10.1</a></li><li><a class="dropdown__link" href="/docs/0.10.0/querying_data">0.10.0</a></li><li><a class="dropdown__link" href="/docs/0.9.0/querying_data">0.9.0</a></li><li><a class="dropdown__link" href="/docs/0.8.0/querying_data">0.8.0</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/docs/0.7.0/querying_data">0.7.0</a></li><li><a class="dropdown__link" href="/docs/0.6.0/querying_data">0.6.0</a></li><li><a class="dropdown__link" href="/docs/0.5.3/querying_data">0.5.3</a></li><li><a class="dropdown__link" href="/docs/0.5.2/querying_data">0.5.2</a></li><li><a class="dropdown__link" href="/docs/0.5.1/querying_data">0.5.1</a></li><li><a class="dropdown__link" href="/docs/0.5.0/querying_data">0.5.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" class="iconLanguage_EbrZ"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>English</span></span></a><ul class="dropdown__menu"><li><a href="/docs/0.7.0/querying_data" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active">English</a></li><li><a href="/cn/docs/0.7.0/querying_data" target="_self" rel="noopener noreferrer" class="dropdown__link">Chinese</a></li></ul></div><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-twitter-link" aria-label="Hudi Twitter Handle"></a><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-1e94d3xro-JvlNO1kSeIHJBTVfLPlI5w" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-slack-link" aria-label="Hudi Slack Channel"></a><a href="https://www.youtube.com/channel/UCs7AhE0BWaEPZSChrBR-Muw" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-youtube-link" aria-label="Hudi YouTube Channel"></a><div class="searchBox_Utm0"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_i9tI" type="button"></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh menuWithAnnouncementBar_+O1J"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/overview">Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/quick-start-guide">Quick-Start Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/use_cases">Use Cases</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/writing_data">Writing Hudi Tables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/docs/0.7.0/querying_data">Querying Hudi Tables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/configurations">Configurations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/performance">Performance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/0.7.0/deployment">Deployment Guide</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_TwRn" href="/docs/0.7.0/cloud">Storage Configurations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_TwRn" href="/docs/0.7.0/docker_demo">Resources</a></div></li></ul></nav></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_zHA2"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is documentation for <!-- -->Apache Hudi<!-- --> <b>0.7.0</b>, which is no longer actively maintained.</div><div class="margin-top--md">For up-to-date documentation, see the <b><a href="/docs/querying_data">latest version</a></b> (<!-- -->0.12.1<!-- -->).</div></div><div class="docItemContainer_oiyr"><article><span class="theme-doc-version-badge badge badge--secondary">Version: <!-- -->0.7.0</span><div class="tocCollapsible_aw-L theme-doc-toc-mobile tocMobile_Tx6Y"><button type="button" class="clean-btn tocCollapsibleButton_zr6a">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Querying Hudi Tables</h1></header><p>Conceptually, Hudi stores data physically once on DFS, while providing 3 different ways of querying, as explained <a href="/docs/concepts#query-types">before</a>.
Once the table is synced to the Hive metastore, it provides external Hive tables backed by Hudi&#x27;s custom inputformats. Once the proper hudi
bundle has been installed, the table can be queried by popular query engines like Hive, Spark SQL, Spark Datasource API and PrestoDB.</p><p>Specifically, following Hive tables are registered based off <a href="/docs/configurations#TABLE_NAME_OPT_KEY">table name</a>
and <a href="/docs/configurations#TABLE_TYPE_OPT_KEY">table type</a> configs passed during write.   </p><p>If <code>table name = hudi_trips</code> and <code>table type = COPY_ON_WRITE</code>, then we get: </p><ul><li><code>hudi_trips</code> supports snapshot query and incremental query on the table backed by <code>HoodieParquetInputFormat</code>, exposing purely columnar data.</li></ul><p>If <code>table name = hudi_trips</code> and <code>table type = MERGE_ON_READ</code>, then we get:</p><ul><li><code>hudi_trips_rt</code> supports snapshot query and incremental query (providing near-real time data) on the table  backed by <code>HoodieParquetRealtimeInputFormat</code>, exposing merged view of base and log data.</li><li><code>hudi_trips_ro</code> supports read optimized query on the table backed by <code>HoodieParquetInputFormat</code>, exposing purely columnar data stored in base files.</li></ul><p>As discussed in the concepts section, the one key capability needed for <a href="https://www.oreilly.com/ideas/ubers-case-for-incremental-processing-on-hadoop" target="_blank" rel="noopener noreferrer">incrementally processing</a>,
is obtaining a change stream/log from a table. Hudi tables can be queried incrementally, which means you can get ALL and ONLY the updated &amp; new rows
since a specified instant time. This, together with upserts, is particularly useful for building data pipelines where 1 or more source Hudi tables are incrementally queried (streams/facts),
joined with other tables (tables/dimensions), to <a href="/docs/writing_data">write out deltas</a> to a target Hudi table. Incremental queries are realized by querying one of the tables above,
with special configurations that indicates to query planning that only incremental data needs to be fetched out of the table. </p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="support-matrix">Support Matrix<a class="hash-link" href="#support-matrix" title="Direct link to heading">​</a></h2><p>Following tables show whether a given query is supported on specific query engine.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="copy-on-write-tables">Copy-On-Write tables<a class="hash-link" href="#copy-on-write-tables" title="Direct link to heading">​</a></h3><table><thead><tr><th>Query Engine</th><th>Snapshot Queries</th><th>Incremental Queries</th></tr></thead><tbody><tr><td><strong>Hive</strong></td><td>Y</td><td>Y</td></tr><tr><td><strong>Spark SQL</strong></td><td>Y</td><td>Y</td></tr><tr><td><strong>Spark Datasource</strong></td><td>Y</td><td>Y</td></tr><tr><td><strong>PrestoDB</strong></td><td>Y</td><td>N</td></tr><tr><td><strong>Impala</strong></td><td>Y</td><td>N</td></tr><tr><td><strong>Redshift Spectrum</strong></td><td>Y</td><td>N</td></tr></tbody></table><p>Note that <code>Read Optimized</code> queries are not applicable for COPY_ON_WRITE tables.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="merge-on-read-tables">Merge-On-Read tables<a class="hash-link" href="#merge-on-read-tables" title="Direct link to heading">​</a></h3><table><thead><tr><th>Query Engine</th><th>Snapshot Queries</th><th>Incremental Queries</th><th>Read Optimized Queries</th></tr></thead><tbody><tr><td><strong>Hive</strong></td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td><strong>Spark SQL</strong></td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td><strong>Spark Datasource</strong></td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td><strong>PrestoDB</strong></td><td>Y</td><td>N</td><td>Y</td></tr><tr><td><strong>Impala</strong></td><td>N</td><td>N</td><td>Y</td></tr></tbody></table><p>In sections, below we will discuss specific setup to access different query types from different query engines. </p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="hive">Hive<a class="hash-link" href="#hive" title="Direct link to heading">​</a></h2><p>In order for Hive to recognize Hudi tables and query correctly, </p><ul><li>the HiveServer2 needs to be provided with the <code>hudi-hadoop-mr-bundle-x.y.z-SNAPSHOT.jar</code> in its <a href="https://www.cloudera.com/documentation/enterprise/5-6-x/topics/cm_mc_hive_udf#concept_nc3_mms_lr" target="_blank" rel="noopener noreferrer">aux jars path</a>. This will ensure the input format
classes with its dependencies are available for query planning &amp; execution. </li><li>For MERGE_ON_READ tables, additionally the bundle needs to be put on the hadoop/hive installation across the cluster, so that queries can pick up the custom RecordReader as well.</li></ul><p>In addition to setup above, for beeline cli access, the <code>hive.input.format</code> variable needs to be set to the fully qualified path name of the
inputformat <code>org.apache.hudi.hadoop.HoodieParquetInputFormat</code>. For Tez, additionally the <code>hive.tez.input.format</code> needs to be set
to <code>org.apache.hadoop.hive.ql.io.HiveInputFormat</code>. Then proceed to query the table like any other Hive table.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="incremental-query">Incremental query<a class="hash-link" href="#incremental-query" title="Direct link to heading">​</a></h3><p><code>HiveIncrementalPuller</code> allows incrementally extracting changes from large fact/dimension tables via HiveQL, combining the benefits of Hive (reliably process complex SQL queries) and
incremental primitives (speed up querying tables incrementally instead of scanning fully). The tool uses Hive JDBC to run the hive query and saves its results in a temp table.
that can later be upserted. Upsert utility (<code>HoodieDeltaStreamer</code>) has all the state it needs from the directory structure to know what should be the commit time on the target table.
e.g: <code>/app/incremental-hql/intermediate/{source_table_name}_temp/{last_commit_included}</code>.The Delta Hive table registered will be of the form <code>{tmpdb}.{source_table}_{last_commit_included}</code>.</p><p>The following are the configuration options for HiveIncrementalPuller</p><table><thead><tr><th><strong>Config</strong></th><th><strong>Description</strong></th><th><strong>Default</strong></th></tr></thead><tbody><tr><td>hiveUrl</td><td>Hive Server 2 URL to connect to</td><td></td></tr><tr><td>hiveUser</td><td>Hive Server 2 Username</td><td></td></tr><tr><td>hivePass</td><td>Hive Server 2 Password</td><td></td></tr><tr><td>queue</td><td>YARN Queue name</td><td></td></tr><tr><td>tmp</td><td>Directory where the temporary delta data is stored in DFS. The directory structure will follow conventions. Please see the below section.</td><td></td></tr><tr><td>extractSQLFile</td><td>The SQL to execute on the source table to extract the data. The data extracted will be all the rows that changed since a particular point in time.</td><td></td></tr><tr><td>sourceTable</td><td>Source Table Name. Needed to set hive environment properties.</td><td></td></tr><tr><td>sourceDb</td><td>Source DB name. Needed to set hive environment properties.</td><td></td></tr><tr><td>targetTable</td><td>Target Table Name. Needed for the intermediate storage directory structure.</td><td></td></tr><tr><td>targetDb</td><td>Target table&#x27;s DB name.</td><td></td></tr><tr><td>tmpdb</td><td>The database to which the intermediate temp delta table will be created</td><td>hoodie_temp</td></tr><tr><td>fromCommitTime</td><td>This is the most important parameter. This is the point in time from which the changed records are queried from.</td><td></td></tr><tr><td>maxCommits</td><td>Number of commits to include in the query. Setting this to -1 will include all the commits from fromCommitTime. Setting this to a value &gt; 0, will include records that ONLY changed in the specified number of commits after fromCommitTime. This may be needed if you need to catch up say 2 commits at a time.</td><td>3</td></tr><tr><td>help</td><td>Utility Help</td><td></td></tr></tbody></table><p>Setting fromCommitTime=0 and maxCommits=-1 will fetch the entire source table and can be used to initiate backfills. If the target table is a Hudi table,
then the utility can determine if the target table has no commits or is behind more than 24 hour (this is configurable),
it will automatically use the backfill configuration, since applying the last 24 hours incrementally could take more time than doing a backfill. The current limitation of the tool
is the lack of support for self-joining the same table in mixed mode (snapshot and incremental modes).</p><p><strong>NOTE on Hive incremental queries that are executed using Fetch task:</strong>
Since Fetch tasks invoke InputFormat.listStatus() per partition, Hoodie metadata can be listed in
every such listStatus() call. In order to avoid this, it might be useful to disable fetch tasks
using the hive session property for incremental queries: <code>set hive.fetch.task.conversion=none;</code> This
would ensure Map Reduce execution is chosen for a Hive query, which combines partitions (comma
separated) and calls InputFormat.listStatus() only once with all those partitions.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="spark-sql">Spark SQL<a class="hash-link" href="#spark-sql" title="Direct link to heading">​</a></h2><p>Once the Hudi tables have been registered to the Hive metastore, it can be queried using the Spark-Hive integration. It supports all query types across both Hudi table types,
relying on the custom Hudi input formats again like Hive. Typically notebook users and spark-shell users leverage spark sql for querying Hudi tables. Please add hudi-spark-bundle as described above via --jars or --packages.</p><p>By default, Spark SQL will try to use its own parquet reader instead of Hive SerDe when reading from Hive metastore parquet tables. However, for MERGE_ON_READ tables which has
both parquet and avro data, this default setting needs to be turned off using set <code>spark.sql.hive.convertMetastoreParquet=false</code>.
This will force Spark to fallback to using the Hive Serde to read the data (planning/executions is still Spark). </p><div class="codeBlockContainer_J+bg language-java theme-code-block"><div class="codeBlockContent_csEI java"><pre tabindex="0" class="prism-code language-java codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">$ spark-shell --driver-class-path /etc/hive/conf  --packages org.apache.hudi:hudi-spark-bundle_2.11:0.5.3,org.apache.spark:spark-avro_2.11:2.4.4 --conf spark.sql.hive.convertMetastoreParquet=false --num-executors 10 --driver-memory 7g --executor-memory 2g  --master yarn-client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; sqlContext.sql(&quot;select count(*) from hudi_trips_mor_rt where datestr = &#x27;2016-10-02&#x27;&quot;).show()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scala&gt; sqlContext.sql(&quot;select count(*) from hudi_trips_mor_rt where datestr = &#x27;2016-10-02&#x27;&quot;).show()</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>For COPY_ON_WRITE tables, either Hive SerDe can be used by turning off <code>spark.sql.hive.convertMetastoreParquet=false</code> as described above or Spark&#x27;s built in support can be leveraged.
If using spark&#x27;s built in support, additionally a path filter needs to be pushed into sparkContext as follows. This method retains Spark built-in optimizations for reading parquet files like vectorized reading on Hudi Hive tables.</p><div class="codeBlockContainer_J+bg language-scala theme-code-block"><div class="codeBlockContent_csEI scala"><pre tabindex="0" class="prism-code language-scala codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark.sparkContext.hadoopConfiguration.setClass(&quot;mapreduce.input.pathFilter.class&quot;, classOf[org.apache.hudi.hadoop.HoodieROTablePathFilter], classOf[org.apache.hadoop.fs.PathFilter]);</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_y2LR" id="spark-datasource">Spark Datasource<a class="hash-link" href="#spark-datasource" title="Direct link to heading">​</a></h2><p>The Spark Datasource API is a popular way of authoring Spark ETL pipelines. Hudi COPY_ON_WRITE and MERGE_ON_READ tables can be queried via Spark datasource similar to how standard
datasources work (e.g: <code>spark.read.parquet</code>). MERGE_ON_READ table supports snapshot querying and COPY_ON_WRITE table supports both snapshot and incremental querying via Spark datasource. Typically spark jobs require adding <code>--jars &lt;path to jar&gt;/hudi-spark-bundle_2.11-&lt;hudi version&gt;.jar</code> to classpath of drivers
and executors. Alternatively, hudi-spark-bundle can also fetched via the <code>--packages</code> options (e.g: <code>--packages org.apache.hudi:hudi-spark-bundle_2.11:0.5.3</code>).</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="spark-snap-query">Snapshot query<a class="hash-link" href="#spark-snap-query" title="Direct link to heading">​</a></h3><p>This method can be used to retrieve the data table at the present point in time.
Note: The file path must be suffixed with a number of wildcard asterisk (<code>/*</code>) one greater than the number of partition levels. Eg: with table file path &quot;tablePath&quot; partitioned by columns &quot;a&quot;, &quot;b&quot;, and &quot;c&quot;, the load path must be <code>tablePath + &quot;/*/*/*/*&quot;</code></p><div class="codeBlockContainer_J+bg language-scala theme-code-block"><div class="codeBlockContent_csEI scala"><pre tabindex="0" class="prism-code language-scala codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">val hudiIncQueryDF = spark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .read()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .format(&quot;org.apache.hudi&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .option(DataSourceReadOptions.QUERY_TYPE_OPT_KEY(), DataSourceReadOptions.QUERY_TYPE_SNAPSHOT_OPT_VAL())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .load(tablePath + &quot;/*&quot;) //The number of wildcard asterisks here must be one greater than the number of partition</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_y2LR" id="spark-incr-query">Incremental query<a class="hash-link" href="#spark-incr-query" title="Direct link to heading">​</a></h3><p>Of special interest to spark pipelines, is Hudi&#x27;s ability to support incremental queries, like below. A sample incremental query, that will obtain all records written since <code>beginInstantTime</code>, looks like below.
Thanks to Hudi&#x27;s support for record level change streams, these incremental pipelines often offer 10x efficiency over batch counterparts, by only processing the changed records.
The following snippet shows how to obtain all records changed after <code>beginInstantTime</code> and run some SQL on them.</p><div class="codeBlockContainer_J+bg language-java theme-code-block"><div class="codeBlockContent_csEI java"><pre tabindex="0" class="prism-code language-java codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain"> Dataset&lt;Row&gt; hudiIncQueryDF = spark.read()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .format(&quot;org.apache.hudi&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .option(DataSourceReadOptions.QUERY_TYPE_OPT_KEY(), DataSourceReadOptions.QUERY_TYPE_INCREMENTAL_OPT_VAL())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .option(DataSourceReadOptions.BEGIN_INSTANTTIME_OPT_KEY(), &lt;beginInstantTime&gt;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .option(DataSourceReadOptions.INCR_PATH_GLOB_OPT_KEY(), &quot;/year=2020/month=*/day=*&quot;) // Optional, use glob pattern if querying certain partitions</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     .load(tablePath); // For incremental query, pass in the root/base path of table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hudiIncQueryDF.createOrReplaceTempView(&quot;hudi_trips_incremental&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark.sql(&quot;select `_hoodie_commit_time`, fare, begin_lon, begin_lat, ts from  hudi_trips_incremental where fare &gt; 20.0&quot;).show()</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>For examples, refer to <a href="/docs/quick-start-guide#setup-spark-shell">Setup spark-shell in quickstart</a>.
Please refer to <a href="/docs/configurations#spark-datasource">configurations</a> section, to view all datasource options.</p><p>Additionally, <code>HoodieReadClient</code> offers the following functionality using Hudi&#x27;s implicit indexing.</p><table><thead><tr><th><strong>API</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>read(keys)</td><td>Read out the data corresponding to the keys as a DataFrame, using Hudi&#x27;s own index for faster lookup</td></tr><tr><td>filterExists()</td><td>Filter out already existing records from the provided <code>RDD[HoodieRecord]</code>. Useful for de-duplication</td></tr><tr><td>checkExists(keys)</td><td>Check if the provided keys exist in a Hudi table</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_y2LR" id="prestodb">PrestoDB<a class="hash-link" href="#prestodb" title="Direct link to heading">​</a></h2><p>PrestoDB is a popular query engine, providing interactive query performance. PrestoDB currently supports snapshot querying on COPY_ON_WRITE tables.
Both snapshot and read optimized queries are supported on MERGE_ON_READ Hudi tables. Since PrestoDB-Hudi integration has evolved over time, the installation
instructions for PrestoDB would vary based on versions. Please check the below table for query types supported and installation instructions
for different versions of PrestoDB.</p><table><thead><tr><th><strong>PrestoDB Version</strong></th><th><strong>Installation description</strong></th><th><strong>Query types supported</strong></th></tr></thead><tbody><tr><td>&lt; 0.233</td><td>Requires the <code>hudi-presto-bundle</code> jar to be placed into <code>&lt;presto_install&gt;/plugin/hive-hadoop2/</code>, across the installation.</td><td>Snapshot querying on COW tables. Read optimized querying on MOR tables.</td></tr><tr><td>&gt;= 0.233</td><td>No action needed. Hudi (0.5.1-incubating) is a compile time dependency.</td><td>Snapshot querying on COW tables. Read optimized querying on MOR tables.</td></tr><tr><td>&gt;= 0.240</td><td>No action needed. Hudi 0.5.3 version is a compile time dependency.</td><td>Snapshot querying on both COW and MOR tables</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_y2LR" id="impala-34-or-later">Impala (3.4 or later)<a class="hash-link" href="#impala-34-or-later" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_y2LR" id="snapshot-query">Snapshot Query<a class="hash-link" href="#snapshot-query" title="Direct link to heading">​</a></h3><p>Impala is able to query Hudi Copy-on-write table as an <a href="https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_tables#external_tables" target="_blank" rel="noopener noreferrer">EXTERNAL TABLE</a> on HDFS.  </p><p>To create a Hudi read optimized table on Impala:</p><div class="codeBlockContainer_J+bg theme-code-block"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE EXTERNAL TABLE database.table_name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">LIKE PARQUET &#x27;/path/to/load/xxx.parquet&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">STORED AS HUDIPARQUET</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">LOCATION &#x27;/path/to/load&#x27;;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>Impala is able to take advantage of the physical partition structure to improve the query performance.
To create a partitioned table, the folder should follow the naming convention like <code>year=2020/month=1</code>.
Impala use <code>=</code> to separate partition name and partition value.<br>
<!-- -->To create a partitioned Hudi read optimized table on Impala:</p><div class="codeBlockContainer_J+bg theme-code-block"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE EXTERNAL TABLE database.table_name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">LIKE PARQUET &#x27;/path/to/load/xxx.parquet&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PARTITION BY (year int, month int, day int)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">STORED AS HUDIPARQUET</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">LOCATION &#x27;/path/to/load&#x27;;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ALTER TABLE database.table_name RECOVER PARTITIONS;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>After Hudi made a new commit, refresh the Impala table to get the latest results.</p><div class="codeBlockContainer_J+bg theme-code-block"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">REFRESH database.table_name</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_y2LR" id="redshift-spectrum">Redshift Spectrum<a class="hash-link" href="#redshift-spectrum" title="Direct link to heading">​</a></h2><p>Copy on Write Tables in Apache Hudi versions 0.5.2, 0.6.0, 0.7.0, 0.8.0, 0.9.0, 0.10.x, 0.11.x and 0.12.0 can be queried via Amazon Redshift Spectrum external tables.
To be able to query Hudi versions 0.10.0 and above please try latest versions of Redshift.</p><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>Hudi tables are supported only when AWS Glue Data Catalog is used. It&#x27;s not supported when you use an Apache Hive metastore as the external catalog.</p></div></div><p>Please refer to <a href="https://docs.aws.amazon.com/redshift/latest/dg/c-spectrum-external-tables.html#c-spectrum-column-mapping-hudi" target="_blank" rel="noopener noreferrer">Redshift Spectrum Integration with Apache Hudi</a>
for more details.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/apache/hudi/tree/asf-site/website/versioned_docs/version-0.7.0/querying_data.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mt2f"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/0.7.0/writing_data"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Writing Hudi Tables</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/0.7.0/configurations"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Configurations</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#support-matrix" class="table-of-contents__link toc-highlight">Support Matrix</a><ul><li><a href="#copy-on-write-tables" class="table-of-contents__link toc-highlight">Copy-On-Write tables</a></li><li><a href="#merge-on-read-tables" class="table-of-contents__link toc-highlight">Merge-On-Read tables</a></li></ul></li><li><a href="#hive" class="table-of-contents__link toc-highlight">Hive</a><ul><li><a href="#incremental-query" class="table-of-contents__link toc-highlight">Incremental query</a></li></ul></li><li><a href="#spark-sql" class="table-of-contents__link toc-highlight">Spark SQL</a></li><li><a href="#spark-datasource" class="table-of-contents__link toc-highlight">Spark Datasource</a><ul><li><a href="#spark-snap-query" class="table-of-contents__link toc-highlight">Snapshot query</a></li><li><a href="#spark-incr-query" class="table-of-contents__link toc-highlight">Incremental query</a></li></ul></li><li><a href="#prestodb" class="table-of-contents__link toc-highlight">PrestoDB</a></li><li><a href="#impala-34-or-later" class="table-of-contents__link toc-highlight">Impala (3.4 or later)</a><ul><li><a href="#snapshot-query" class="table-of-contents__link toc-highlight">Snapshot Query</a></li></ul></li><li><a href="#redshift-spectrum" class="table-of-contents__link toc-highlight">Redshift Spectrum</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog/2021/07/21/streaming-data-lake-platform">Our Vision</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/concepts">Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/community/team">Team</a></li><li class="footer__item"><a class="footer__link-item" href="/releases/release-0.12.1">Releases</a></li><li class="footer__item"><a class="footer__link-item" href="/releases/download">Download</a></li><li class="footer__item"><a class="footer__link-item" href="/powered-by">Who&#x27;s Using</a></li></ul></div><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/quick-start-guide">Quick Start</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/docker_demo">Docker Demo</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/talks">Talks</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/faq">FAQ</a></li><li class="footer__item"><a href="https://cwiki.apache.org/confluence/display/HUDI" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Technical Wiki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Hudi On Cloud</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/s3_hoodie">AWS</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/gcs_hoodie">Google Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/oss_hoodie">Alibaba Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/azure_hoodie">Microsoft Azure</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cos_hoodie">Tencent Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/ibm_cos_hoodie">IBM Cloud</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/contribute/get-involved">Get Involved</a></li><li class="footer__item"><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-1e94d3xro-JvlNO1kSeIHJBTVfLPlI5w" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://twitter.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://www.youtube.com/channel/UCs7AhE0BWaEPZSChrBR-Muw" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>YouTube<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="mailto:dev-subscribe@hudi.apache.org?Subject=SubscribeToHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">Mailing List</a></li></ul></div><div class="col footer__col"><div class="footer__title">Apache</div><ul class="footer__items"><li class="footer__item"><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="footer__link-item">Events</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Thanks</a></li><li class="footer__item"><a href="https://www.apache.org/licenses" target="_blank" rel="noopener noreferrer" class="footer__link-item">License</a></li><li class="footer__item"><a href="https://www.apache.org/security" target="_blank" rel="noopener noreferrer" class="footer__link-item">Security</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Sponsorship</a></li><li class="footer__item"><a href="https://www.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Foundation</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://hudi.apache.org/" target="_blank" rel="noopener noreferrer" class="footerLogoLink_SRtH"><img src="/assets/images/logo-big.png" alt="Apache Hudi™" class="themedImage_TMUO themedImage--light_4Vu1 footer__logo"><img src="/assets/images/logo-big.png" alt="Apache Hudi™" class="themedImage_TMUO themedImage--dark_uzRr footer__logo"></a></div><div class="footer__copyright">Copyright © 2021 <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0"> Apache License, Version 2.0</a>. <br>Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.abb344ce.js"></script>
<script src="/assets/js/main.a3e38e91.js"></script>
</body>
</html>
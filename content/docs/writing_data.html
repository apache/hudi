<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Writing Hudi Tables - Apache Hudi</title>
<meta name="description" content="In this section, we will cover ways to ingest new changes from external sources or even other Hudi tables using the DeltaStreamer tool, as well as speeding up large Spark jobs via upserts using the Hudi datasource. Such tables can then be queried using various query engines.">

<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="">
<meta property="og:title" content="Writing Hudi Tables">
<meta property="og:url" content="https://hudi.apache.org/docs/writing_data.html">


  <meta property="og:description" content="In this section, we will cover ways to ingest new changes from external sources or even other Hudi tables using the DeltaStreamer tool, as well as speeding up large Spark jobs via upserts using the Hudi datasource. Such tables can then be queried using various query engines.">





  <meta property="article:modified_time" content="2019-12-30T14:59:57-05:00">







<!-- end _includes/seo.html -->


<!--<link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">-->

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



<link rel="icon" type="image/x-icon" href="/assets/images/favicon.ico">
<link rel="stylesheet" href="/assets/css/font-awesome.min.css">
<script src="/assets/js/jquery.min.js"></script>

    
<script src="/assets/js/main.min.js"></script>

  </head>

  <body class="layout--single">
    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap" id="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/">
              <div style="width: 150px; height: 40px">
              </div>
          </a>
        
        <a class="site-title" href="/">
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/docs/spark_quick-start-guide.html" target="_self" >Documentation</a>
            </li><li class="masthead__menu-item">
              <a href="/community.html" target="_self" >Community</a>
            </li><li class="masthead__menu-item">
              <a href="/blog.html" target="_self" >Blog</a>
            </li><li class="masthead__menu-item">
              <a href="https://cwiki.apache.org/confluence/display/HUDI/FAQ" target="_blank" >FAQ</a>
            </li><li class="masthead__menu-item">
              <a href="/docs/powered_by.html" target="_self" >Powered By</a>
            </li><li class="masthead__menu-item">
              <a href="/releases.html" target="_self" >Releases</a>
            </li><li class="masthead__menu-item">
              <a href="/download.html" target="_self" >Download</a>
            </li></ul>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>
<!--
<p class="notice--warning" style="margin: 0 !important; text-align: center !important;"><strong>Note:</strong> This site is work in progress, if you notice any issues, please <a target="_blank" href="https://github.com/apache/hudi/issues">Report on Issue</a>.
  Click <a href="/"> here</a> back to old site.</p>
-->

    <div class="initial-content">
      <div id="main" role="main">
  

  <div class="sidebar sticky">

  

  

    
      







<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Documentation</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/docs/overview.html" class="">Overview</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/spark_quick-start-guide.html" class="">Quick Start(Spark)</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/flink-quick-start-guide.html" class="">Quick Start(Flink)</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/use_cases.html" class="">Use Cases</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/writing_data.html" class="active">Writing Data</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/concurrency_control.html" class="">Concurrency Control</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/querying_data.html" class="">Querying Data</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/configurations.html" class="">Configuration</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/performance.html" class="">Performance</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/deployment.html" class="">Deployment</a></li>
            

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Resources</span>
        

        
        <ul>
          
            
            

            
            

            
              <li><a href="/docs/docker_demo.html" class="">Dockerized Demo</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/cloud.html" class="">Storage Configuration</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/metrics.html" class="">Metrics</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/docs-versions.html" class="">Docs Versions</a></li>
            

          
            
            

            
            

            
              <li><a href="/docs/privacy.html" class="">Privacy Policy</a></li>
            

          
        </ul>
        
      </li>
    
  </ul>
</nav>

    

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <!-- Look the author details up from the site config. -->
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Writing Hudi Tables
</h1>
          <!-- Output author details if some exist. -->
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <aside class="sidebar__right sticky">
          <nav class="toc">
            <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> IN THIS PAGE</h4></header>
            <ul class="toc__menu">
  <li><a href="#write-operations">Write Operations</a></li>
  <li><a href="#deltastreamer">DeltaStreamer</a></li>
  <li><a href="#multitabledeltastreamer">MultiTableDeltaStreamer</a></li>
  <li><a href="#datasource-writer">Datasource Writer</a></li>
  <li><a href="#flink-sql-writer">Flink SQL Writer</a></li>
  <li><a href="#key-generation">Key Generation</a></li>
  <li><a href="#syncing-to-hive">Syncing to Hive</a></li>
  <li><a href="#deletes">Deletes</a></li>
  <li><a href="#optimized-dfs-access">Optimized DFS Access</a></li>
  <li><a href="#schema-evolution">Schema Evolution</a></li>
</ul>
          </nav>
        </aside>
        
        <p>In this section, we will cover ways to ingest new changes from external sources or even other Hudi tables using the <a href="#deltastreamer">DeltaStreamer</a> tool, as well as 
speeding up large Spark jobs via upserts using the <a href="#datasource-writer">Hudi datasource</a>. Such tables can then be <a href="/docs/querying_data.html">queried</a> using various query engines.</p>

<h2 id="write-operations">Write Operations</h2>

<p>Before that, it may be helpful to understand the 3 different write operations provided by Hudi datasource or the delta streamer tool and how best to leverage them. These operations
can be chosen/changed across each commit/deltacommit issued against the table.</p>

<ul>
  <li><strong>UPSERT</strong> : This is the default operation where the input records are first tagged as inserts or updates by looking up the index. 
 The records are ultimately written after heuristics are run to determine how best to pack them on storage to optimize for things like file sizing. 
 This operation is recommended for use-cases like database change capture where the input almost certainly contains updates. The target table will never show duplicates.</li>
  <li><strong>INSERT</strong> : This operation is very similar to upsert in terms of heuristics/file sizing but completely skips the index lookup step. Thus, it can be a lot faster than upserts 
 for use-cases like log de-duplication (in conjunction with options to filter duplicates mentioned below). This is also suitable for use-cases where the table can tolerate duplicates, but just 
 need the transactional writes/incremental pull/storage management capabilities of Hudi.</li>
  <li><strong>BULK_INSERT</strong> : Both upsert and insert operations keep input records in memory to speed up storage heuristics computations faster (among other things) and thus can be cumbersome for 
 initial loading/bootstrapping a Hudi table at first. Bulk insert provides the same semantics as insert, while implementing a sort-based data writing algorithm, which can scale very well for several hundred TBs 
 of initial load. However, this just does a best-effort job at sizing files vs guaranteeing file sizes like inserts/upserts do.</li>
</ul>

<h2 id="deltastreamer">DeltaStreamer</h2>

<p>The <code class="highlighter-rouge">HoodieDeltaStreamer</code> utility (part of hudi-utilities-bundle) provides the way to ingest from different sources such as DFS or Kafka, with the following capabilities.</p>

<ul>
  <li>Exactly once ingestion of new events from Kafka, <a href="https://sqoop.apache.org/docs/1.4.2/SqoopUserGuide.html#_incremental_imports">incremental imports</a> from Sqoop or output of <code class="highlighter-rouge">HiveIncrementalPuller</code> or files under a DFS folder</li>
  <li>Support json, avro or a custom record types for the incoming data</li>
  <li>Manage checkpoints, rollback &amp; recovery</li>
  <li>Leverage Avro schemas from DFS or Confluent <a href="https://github.com/confluentinc/schema-registry">schema registry</a>.</li>
  <li>Support for plugging in transformations</li>
</ul>

<p>Command line options describe capabilities in more detail</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">hoodie</span><span class="o">]</span><span class="err">$</span> <span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">HoodieDeltaStreamer</span> <span class="err">`</span><span class="n">ls</span> <span class="n">packaging</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">/</span><span class="n">target</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">-*.</span><span class="na">jar</span><span class="err">`</span> <span class="o">--</span><span class="n">help</span>
<span class="nl">Usage:</span> <span class="o">&lt;</span><span class="n">main</span> <span class="kd">class</span><span class="err">&gt;</span> <span class="err">[</span><span class="nc">options</span><span class="o">]</span>
<span class="nl">Options:</span>
    <span class="o">--</span><span class="n">checkpoint</span>
      <span class="nc">Resume</span> <span class="nc">Delta</span> <span class="nc">Streamer</span> <span class="n">from</span> <span class="k">this</span> <span class="n">checkpoint</span><span class="o">.</span>
    <span class="o">--</span><span class="n">commit</span><span class="o">-</span><span class="n">on</span><span class="o">-</span><span class="n">errors</span>
      <span class="nc">Commit</span> <span class="n">even</span> <span class="n">when</span> <span class="n">some</span> <span class="n">records</span> <span class="n">failed</span> <span class="n">to</span> <span class="n">be</span> <span class="n">written</span>
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">compact</span><span class="o">-</span><span class="n">scheduling</span><span class="o">-</span><span class="n">minshare</span>
      <span class="nc">Minshare</span> <span class="k">for</span> <span class="n">compaction</span> <span class="n">as</span> <span class="n">defined</span> <span class="n">in</span>
      <span class="nl">https:</span><span class="c1">//spark.apache.org/docs/latest/job-scheduling.html</span>
      <span class="nl">Default:</span> <span class="mi">0</span>
    <span class="o">--</span><span class="n">compact</span><span class="o">-</span><span class="n">scheduling</span><span class="o">-</span><span class="n">weight</span>
      <span class="nc">Scheduling</span> <span class="n">weight</span> <span class="k">for</span> <span class="n">compaction</span> <span class="n">as</span> <span class="n">defined</span> <span class="n">in</span>
      <span class="nl">https:</span><span class="c1">//spark.apache.org/docs/latest/job-scheduling.html</span>
      <span class="nl">Default:</span> <span class="mi">1</span>
    <span class="o">--</span><span class="n">continuous</span>
      <span class="nc">Delta</span> <span class="nc">Streamer</span> <span class="n">runs</span> <span class="n">in</span> <span class="n">continuous</span> <span class="n">mode</span> <span class="n">running</span> <span class="n">source</span><span class="o">-</span><span class="n">fetch</span> <span class="o">-&gt;</span> <span class="nc">Transform</span>
      <span class="o">-&gt;</span> <span class="nc">Hudi</span> <span class="nc">Write</span> <span class="n">in</span> <span class="n">loop</span>
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">delta</span><span class="o">-</span><span class="n">sync</span><span class="o">-</span><span class="n">scheduling</span><span class="o">-</span><span class="n">minshare</span>
      <span class="nc">Minshare</span> <span class="k">for</span> <span class="n">delta</span> <span class="n">sync</span> <span class="n">as</span> <span class="n">defined</span> <span class="n">in</span>
      <span class="nl">https:</span><span class="c1">//spark.apache.org/docs/latest/job-scheduling.html</span>
      <span class="nl">Default:</span> <span class="mi">0</span>
    <span class="o">--</span><span class="n">delta</span><span class="o">-</span><span class="n">sync</span><span class="o">-</span><span class="n">scheduling</span><span class="o">-</span><span class="n">weight</span>
      <span class="nc">Scheduling</span> <span class="n">weight</span> <span class="k">for</span> <span class="n">delta</span> <span class="n">sync</span> <span class="n">as</span> <span class="n">defined</span> <span class="n">in</span>
      <span class="nl">https:</span><span class="c1">//spark.apache.org/docs/latest/job-scheduling.html</span>
      <span class="nl">Default:</span> <span class="mi">1</span>
    <span class="o">--</span><span class="n">disable</span><span class="o">-</span><span class="n">compaction</span>
      <span class="nc">Compaction</span> <span class="n">is</span> <span class="n">enabled</span> <span class="k">for</span> <span class="nc">MoR</span> <span class="n">table</span> <span class="n">by</span> <span class="k">default</span><span class="o">.</span> <span class="nc">This</span> <span class="n">flag</span> <span class="n">disables</span> <span class="n">it</span>
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">enable</span><span class="o">-</span><span class="n">hive</span><span class="o">-</span><span class="n">sync</span>
      <span class="nc">Enable</span> <span class="n">syncing</span> <span class="n">to</span> <span class="n">hive</span>
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">filter</span><span class="o">-</span><span class="n">dupes</span>
      <span class="nc">Should</span> <span class="n">duplicate</span> <span class="n">records</span> <span class="n">from</span> <span class="n">source</span> <span class="n">be</span> <span class="n">dropped</span><span class="o">/</span><span class="n">filtered</span> <span class="n">out</span> <span class="n">before</span>
      <span class="n">insert</span><span class="o">/</span><span class="n">bulk</span><span class="o">-</span><span class="n">insert</span>
      <span class="nl">Default:</span> <span class="kc">false</span>
    <span class="o">--</span><span class="n">help</span><span class="o">,</span> <span class="o">-</span><span class="n">h</span>

    <span class="o">--</span><span class="n">hoodie</span><span class="o">-</span><span class="n">conf</span>
      <span class="nc">Any</span> <span class="n">configuration</span> <span class="n">that</span> <span class="n">can</span> <span class="n">be</span> <span class="n">set</span> <span class="n">in</span> <span class="n">the</span> <span class="n">properties</span> <span class="nf">file</span> <span class="o">(</span><span class="n">using</span> <span class="n">the</span> <span class="no">CLI</span>
      <span class="n">parameter</span> <span class="s">"--propsFilePath"</span><span class="o">)</span> <span class="n">can</span> <span class="n">also</span> <span class="n">be</span> <span class="n">passed</span> <span class="n">command</span> <span class="n">line</span> <span class="n">using</span> <span class="k">this</span>
      <span class="n">parameter</span>
      <span class="nl">Default:</span> <span class="o">[]</span>
    <span class="o">--</span><span class="n">max</span><span class="o">-</span><span class="n">pending</span><span class="o">-</span><span class="n">compactions</span>
      <span class="nc">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">outstanding</span> <span class="n">inflight</span><span class="o">/</span><span class="n">requested</span> <span class="n">compactions</span><span class="o">.</span> <span class="nc">Delta</span> <span class="nc">Sync</span>
      <span class="n">will</span> <span class="n">not</span> <span class="n">happen</span> <span class="n">unlessoutstanding</span> <span class="n">compactions</span> <span class="n">is</span> <span class="n">less</span> <span class="n">than</span> <span class="k">this</span> <span class="n">number</span>
      <span class="nl">Default:</span> <span class="mi">5</span>
    <span class="o">--</span><span class="n">min</span><span class="o">-</span><span class="n">sync</span><span class="o">-</span><span class="n">interval</span><span class="o">-</span><span class="n">seconds</span>
      <span class="n">the</span> <span class="n">min</span> <span class="n">sync</span> <span class="n">interval</span> <span class="n">of</span> <span class="n">each</span> <span class="n">sync</span> <span class="n">in</span> <span class="n">continuous</span> <span class="n">mode</span>
      <span class="nl">Default:</span> <span class="mi">0</span>
    <span class="o">--</span><span class="n">op</span>
      <span class="nc">Takes</span> <span class="n">one</span> <span class="n">of</span> <span class="n">these</span> <span class="n">values</span> <span class="o">:</span> <span class="no">UPSERT</span> <span class="o">(</span><span class="k">default</span><span class="o">),</span> <span class="no">INSERT</span> <span class="o">(</span><span class="n">use</span> <span class="n">when</span> <span class="n">input</span> <span class="n">is</span>
      <span class="n">purely</span> <span class="k">new</span> <span class="n">data</span><span class="o">/</span><span class="n">inserts</span> <span class="n">to</span> <span class="n">gain</span> <span class="n">speed</span><span class="o">)</span>
      <span class="nl">Default:</span> <span class="no">UPSERT</span>
      <span class="nc">Possible</span> <span class="nl">Values:</span> <span class="o">[</span><span class="no">UPSERT</span><span class="o">,</span> <span class="no">INSERT</span><span class="o">,</span> <span class="no">BULK_INSERT</span><span class="o">]</span>
    <span class="o">--</span><span class="n">payload</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">subclass</span> <span class="n">of</span> <span class="nc">HoodieRecordPayload</span><span class="o">,</span> <span class="n">that</span> <span class="n">works</span> <span class="n">off</span> <span class="n">a</span> <span class="nc">GenericRecord</span><span class="o">.</span>
      <span class="nc">Implement</span> <span class="n">your</span> <span class="n">own</span><span class="o">,</span> <span class="k">if</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="k">do</span> <span class="n">something</span> <span class="n">other</span> <span class="n">than</span> <span class="n">overwriting</span>
      <span class="n">existing</span> <span class="n">value</span>
      <span class="nl">Default:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">common</span><span class="o">.</span><span class="na">model</span><span class="o">.</span><span class="na">OverwriteWithLatestAvroPayload</span>
    <span class="o">--</span><span class="n">props</span>
      <span class="n">path</span> <span class="n">to</span> <span class="n">properties</span> <span class="n">file</span> <span class="n">on</span> <span class="n">localfs</span> <span class="n">or</span> <span class="n">dfs</span><span class="o">,</span> <span class="n">with</span> <span class="n">configurations</span> <span class="k">for</span>
      <span class="n">hoodie</span> <span class="n">client</span><span class="o">,</span> <span class="n">schema</span> <span class="n">provider</span><span class="o">,</span> <span class="n">key</span> <span class="n">generator</span> <span class="n">and</span> <span class="n">data</span> <span class="n">source</span><span class="o">.</span> <span class="nc">For</span>
      <span class="n">hoodie</span> <span class="n">client</span> <span class="n">props</span><span class="o">,</span> <span class="n">sane</span> <span class="n">defaults</span> <span class="n">are</span> <span class="n">used</span><span class="o">,</span> <span class="n">but</span> <span class="n">recommend</span> <span class="n">use</span> <span class="n">to</span>
      <span class="n">provide</span> <span class="n">basic</span> <span class="n">things</span> <span class="n">like</span> <span class="n">metrics</span> <span class="n">endpoints</span><span class="o">,</span> <span class="n">hive</span> <span class="n">configs</span> <span class="n">etc</span><span class="o">.</span> <span class="nc">For</span>
      <span class="n">sources</span><span class="o">,</span> <span class="n">referto</span> <span class="n">individual</span> <span class="n">classes</span><span class="o">,</span> <span class="k">for</span> <span class="n">supported</span> <span class="n">properties</span><span class="o">.</span>
      <span class="nl">Default:</span> <span class="nl">file:</span><span class="c1">///Users/vinoth/bin/hoodie/src/test/resources/delta-streamer-config/dfs-source.properties</span>
    <span class="o">--</span><span class="n">schemaprovider</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">subclass</span> <span class="n">of</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">SchemaProvider</span> <span class="n">to</span> <span class="n">attach</span>
      <span class="n">schemas</span> <span class="n">to</span> <span class="n">input</span> <span class="o">&amp;</span> <span class="n">target</span> <span class="n">table</span> <span class="n">data</span><span class="o">,</span> <span class="n">built</span> <span class="n">in</span> <span class="nl">options:</span>
      <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">FilebasedSchemaProvider</span><span class="o">.</span><span class="na">Source</span> <span class="o">(</span><span class="nc">See</span>
      <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.</span><span class="na">Source</span><span class="o">)</span> <span class="n">implementation</span> <span class="n">can</span> <span class="n">implement</span>
      <span class="n">their</span> <span class="n">own</span> <span class="nc">SchemaProvider</span><span class="o">.</span> <span class="nc">For</span> <span class="nc">Sources</span> <span class="n">that</span> <span class="k">return</span> <span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;,</span> <span class="n">the</span>
      <span class="n">schema</span> <span class="n">is</span> <span class="n">obtained</span> <span class="n">implicitly</span><span class="o">.</span> <span class="nc">However</span><span class="o">,</span> <span class="k">this</span> <span class="no">CLI</span> <span class="n">option</span> <span class="n">allows</span>
      <span class="n">overriding</span> <span class="n">the</span> <span class="n">schemaprovider</span> <span class="n">returned</span> <span class="n">by</span> <span class="nc">Source</span><span class="o">.</span>
    <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">Subclass</span> <span class="n">of</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span> <span class="n">to</span> <span class="n">read</span> <span class="n">data</span><span class="o">.</span> <span class="nc">Built</span><span class="o">-</span><span class="n">in</span>
      <span class="nl">options:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.{</span><span class="nc">JsonDFSSource</span> <span class="o">(</span><span class="k">default</span><span class="o">),</span>
      <span class="nc">AvroDFSSource</span><span class="o">,</span> <span class="nc">JsonKafkaSource</span><span class="o">,</span> <span class="nc">AvroKafkaSource</span><span class="o">,</span> <span class="nc">HiveIncrPullSource</span><span class="o">}</span>
      <span class="nl">Default:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.</span><span class="na">JsonDFSSource</span>
    <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">limit</span>
      <span class="nc">Maximum</span> <span class="n">amount</span> <span class="n">of</span> <span class="n">data</span> <span class="n">to</span> <span class="n">read</span> <span class="n">from</span> <span class="n">source</span><span class="o">.</span> <span class="nl">Default:</span> <span class="nc">No</span> <span class="n">limit</span> <span class="nc">For</span> <span class="n">e</span><span class="o">.</span><span class="na">g</span><span class="o">:</span>
      <span class="no">DFS</span><span class="o">-</span><span class="nc">Source</span> <span class="o">=&gt;</span> <span class="n">max</span> <span class="n">bytes</span> <span class="n">to</span> <span class="n">read</span><span class="o">,</span> <span class="nc">Kafka</span><span class="o">-</span><span class="nc">Source</span> <span class="o">=&gt;</span> <span class="n">max</span> <span class="n">events</span> <span class="n">to</span> <span class="n">read</span>
      <span class="nl">Default:</span> <span class="mi">9223372036854775807</span>
    <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">ordering</span><span class="o">-</span><span class="n">field</span>
      <span class="nc">Field</span> <span class="n">within</span> <span class="n">source</span> <span class="n">record</span> <span class="n">to</span> <span class="n">decide</span> <span class="n">how</span> <span class="n">to</span> <span class="k">break</span> <span class="n">ties</span> <span class="n">between</span> <span class="n">records</span>
      <span class="n">with</span> <span class="n">same</span> <span class="n">key</span> <span class="n">in</span> <span class="n">input</span> <span class="n">data</span><span class="o">.</span> <span class="nl">Default:</span> <span class="err">'</span><span class="n">ts</span><span class="err">'</span> <span class="n">holding</span> <span class="n">unix</span> <span class="n">timestamp</span> <span class="n">of</span>
      <span class="n">record</span>
      <span class="nl">Default:</span> <span class="n">ts</span>
    <span class="o">--</span><span class="n">spark</span><span class="o">-</span><span class="n">master</span>
      <span class="n">spark</span> <span class="n">master</span> <span class="n">to</span> <span class="n">use</span><span class="o">.</span>
      <span class="nl">Default:</span> <span class="n">local</span><span class="o">[</span><span class="mi">2</span><span class="o">]</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">table</span><span class="o">-</span><span class="n">type</span>
      <span class="nc">Type</span> <span class="n">of</span> <span class="n">table</span><span class="o">.</span> <span class="nf">COPY_ON_WRITE</span> <span class="o">(</span><span class="n">or</span><span class="o">)</span> <span class="no">MERGE_ON_READ</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">path</span>
      <span class="n">base</span> <span class="n">path</span> <span class="k">for</span> <span class="n">the</span> <span class="n">target</span> <span class="n">hoodie</span> <span class="n">table</span><span class="o">.</span> <span class="o">(</span><span class="nc">Will</span> <span class="n">be</span> <span class="n">created</span> <span class="k">if</span> <span class="n">did</span> <span class="n">not</span> <span class="n">exist</span>
      <span class="n">first</span> <span class="n">time</span> <span class="n">around</span><span class="o">.</span> <span class="nc">If</span> <span class="n">exists</span><span class="o">,</span> <span class="n">expected</span> <span class="n">to</span> <span class="n">be</span> <span class="n">a</span> <span class="n">hoodie</span> <span class="n">table</span><span class="o">)</span>
  <span class="o">*</span> <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">table</span>
      <span class="n">name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">target</span> <span class="n">table</span> <span class="n">in</span> <span class="nc">Hive</span>
    <span class="o">--</span><span class="n">transformer</span><span class="o">-</span><span class="kd">class</span>
      <span class="nc">subclass</span> <span class="n">of</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">transform</span><span class="o">.</span><span class="na">Transformer</span><span class="o">.</span> <span class="nc">Allows</span>
      <span class="n">transforming</span> <span class="n">raw</span> <span class="n">source</span> <span class="nc">Dataset</span> <span class="n">to</span> <span class="n">a</span> <span class="n">target</span> <span class="nf">Dataset</span> <span class="o">(</span><span class="n">conforming</span> <span class="n">to</span>
      <span class="n">target</span> <span class="n">schema</span><span class="o">)</span> <span class="n">before</span> <span class="n">writing</span><span class="o">.</span> <span class="nc">Default</span> <span class="o">:</span> <span class="nc">Not</span> <span class="n">set</span><span class="o">.</span> <span class="nl">E:</span><span class="n">g</span> <span class="o">-</span>
      <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">transform</span><span class="o">.</span><span class="na">SqlQueryBasedTransformer</span> <span class="o">(</span><span class="n">which</span>
      <span class="n">allows</span> <span class="n">a</span> <span class="no">SQL</span> <span class="n">query</span> <span class="n">templated</span> <span class="n">to</span> <span class="n">be</span> <span class="n">passed</span> <span class="n">as</span> <span class="n">a</span> <span class="n">transformation</span> <span class="n">function</span><span class="o">)</span>
</code></pre></div></div>

<p>The tool takes a hierarchically composed property file and has pluggable interfaces for extracting data, key generation and providing schema. Sample configs for ingesting from kafka and dfs are
provided under <code class="highlighter-rouge">hudi-utilities/src/test/resources/delta-streamer-config</code>.</p>

<p>For e.g: once you have Confluent Kafka, Schema registry up &amp; running, produce some test data using (<a href="https://docs.confluent.io/current/ksql/docs/tutorials/generate-custom-test-data.html">impressions.avro</a> provided by schema-registry repo)</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">confluent</span><span class="o">-</span><span class="mf">5.0</span><span class="o">.</span><span class="mi">0</span><span class="o">]</span><span class="err">$</span> <span class="n">bin</span><span class="o">/</span><span class="n">ksql</span><span class="o">-</span><span class="n">datagen</span> <span class="n">schema</span><span class="o">=../</span><span class="n">impressions</span><span class="o">.</span><span class="na">avro</span> <span class="n">format</span><span class="o">=</span><span class="n">avro</span> <span class="n">topic</span><span class="o">=</span><span class="n">impressions</span> <span class="n">key</span><span class="o">=</span><span class="n">impressionid</span>
</code></pre></div></div>

<p>and then ingest it as follows.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">hoodie</span><span class="o">]</span><span class="err">$</span> <span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">HoodieDeltaStreamer</span> <span class="err">`</span><span class="n">ls</span> <span class="n">packaging</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">/</span><span class="n">target</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">-*.</span><span class="na">jar</span><span class="err">`</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">props</span> <span class="nl">file:</span><span class="c1">//${PWD}/hudi-utilities/src/test/resources/delta-streamer-config/kafka-source.properties \</span>
  <span class="o">--</span><span class="n">schemaprovider</span><span class="o">-</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">SchemaRegistryProvider</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.</span><span class="na">AvroKafkaSource</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">ordering</span><span class="o">-</span><span class="n">field</span> <span class="n">impresssiontime</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">path</span> <span class="nl">file:</span><span class="err">\</span><span class="o">/</span><span class="err">\</span><span class="o">/</span><span class="err">\</span><span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">deltastreamer</span><span class="o">-</span><span class="n">op</span> <span class="err">\</span> 
  <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">table</span> <span class="n">uber</span><span class="o">.</span><span class="na">impressions</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">op</span> <span class="no">BULK_INSERT</span>
</code></pre></div></div>

<p>In some cases, you may want to migrate your existing table into Hudi beforehand. Please refer to <a href="/docs/migration_guide.html">migration guide</a>.</p>

<h2 id="multitabledeltastreamer">MultiTableDeltaStreamer</h2>

<p><code class="highlighter-rouge">HoodieMultiTableDeltaStreamer</code>, a wrapper on top of <code class="highlighter-rouge">HoodieDeltaStreamer</code>, enables one to ingest multiple tables at a single go into hudi datasets. Currently it only supports sequential processing of tables to be ingested and COPY_ON_WRITE storage type. The command line options for <code class="highlighter-rouge">HoodieMultiTableDeltaStreamer</code> are pretty much similar to <code class="highlighter-rouge">HoodieDeltaStreamer</code> with the only exception that you are required to provide table wise configs in separate files in a dedicated config folder. The following command line options are introduced</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">*</span> <span class="o">--</span><span class="n">config</span><span class="o">-</span><span class="n">folder</span>
    <span class="n">the</span> <span class="n">path</span> <span class="n">to</span> <span class="n">the</span> <span class="n">folder</span> <span class="n">which</span> <span class="n">contains</span> <span class="n">all</span> <span class="n">the</span> <span class="n">table</span> <span class="n">wise</span> <span class="n">config</span> <span class="n">files</span>
    <span class="o">--</span><span class="n">base</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">prefix</span>
    <span class="k">this</span> <span class="n">is</span> <span class="n">added</span> <span class="n">to</span> <span class="n">enable</span> <span class="n">users</span> <span class="n">to</span> <span class="n">create</span> <span class="n">all</span> <span class="n">the</span> <span class="n">hudi</span> <span class="n">datasets</span> <span class="k">for</span> <span class="n">related</span> <span class="n">tables</span> <span class="n">under</span> <span class="n">one</span> <span class="n">path</span> <span class="n">in</span> <span class="no">FS</span><span class="o">.</span> <span class="nc">The</span> <span class="n">datasets</span> <span class="n">are</span> <span class="n">then</span> <span class="n">created</span> <span class="n">under</span> <span class="n">the</span> <span class="n">path</span> <span class="o">-</span> <span class="o">&lt;</span><span class="n">base_path_prefix</span><span class="o">&gt;/&lt;</span><span class="n">database</span><span class="o">&gt;/&lt;</span><span class="n">table_to_be_ingested</span><span class="o">&gt;.</span> <span class="nc">However</span> <span class="n">you</span> <span class="n">can</span> <span class="n">override</span> <span class="n">the</span> <span class="n">paths</span> <span class="k">for</span> <span class="n">every</span> <span class="n">table</span> <span class="n">by</span> <span class="n">setting</span> <span class="n">the</span> <span class="n">property</span> <span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">ingestion</span><span class="o">.</span><span class="na">targetBasePath</span>
</code></pre></div></div>

<p>The following properties are needed to be set properly to ingest data using <code class="highlighter-rouge">HoodieMultiTableDeltaStreamer</code>.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">ingestion</span><span class="o">.</span><span class="na">tablesToBeIngested</span>
  <span class="n">comma</span> <span class="n">separated</span> <span class="n">names</span> <span class="n">of</span> <span class="n">tables</span> <span class="n">to</span> <span class="n">be</span> <span class="n">ingested</span> <span class="n">in</span> <span class="n">the</span> <span class="n">format</span> <span class="o">&lt;</span><span class="n">database</span><span class="o">&gt;.&lt;</span><span class="n">table</span><span class="o">&gt;,</span> <span class="k">for</span> <span class="n">example</span> <span class="n">db1</span><span class="o">.</span><span class="na">table1</span><span class="o">,</span><span class="n">db1</span><span class="o">.</span><span class="na">table2</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">ingestion</span><span class="o">.</span><span class="na">targetBasePath</span>
  <span class="k">if</span> <span class="n">you</span> <span class="n">wish</span> <span class="n">to</span> <span class="n">ingest</span> <span class="n">a</span> <span class="n">particular</span> <span class="n">table</span> <span class="n">in</span> <span class="n">a</span> <span class="n">separate</span> <span class="n">path</span><span class="o">,</span> <span class="n">you</span> <span class="n">can</span> <span class="n">mention</span> <span class="n">that</span> <span class="n">path</span> <span class="n">here</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">ingestion</span><span class="o">.&lt;</span><span class="n">database</span><span class="o">&gt;.&lt;</span><span class="n">table</span><span class="o">&gt;.</span><span class="na">configFile</span>
  <span class="n">path</span> <span class="n">to</span> <span class="n">the</span> <span class="n">config</span> <span class="n">file</span> <span class="n">in</span> <span class="n">dedicated</span> <span class="n">config</span> <span class="n">folder</span> <span class="n">which</span> <span class="n">contains</span> <span class="n">table</span> <span class="n">overridden</span> <span class="n">properties</span> <span class="k">for</span> <span class="n">the</span> <span class="n">particular</span> <span class="n">table</span> <span class="n">to</span> <span class="n">be</span> <span class="n">ingested</span><span class="o">.</span>
</code></pre></div></div>

<p>Sample config files for table wise overridden properties can be found under <code class="highlighter-rouge">hudi-utilities/src/test/resources/delta-streamer-config</code>. The command to run <code class="highlighter-rouge">HoodieMultiTableDeltaStreamer</code> is also similar to how you run <code class="highlighter-rouge">HoodieDeltaStreamer</code>.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="n">hoodie</span><span class="o">]</span><span class="err">$</span> <span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">HoodieMultiTableDeltaStreamer</span> <span class="err">`</span><span class="n">ls</span> <span class="n">packaging</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">/</span><span class="n">target</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">utilities</span><span class="o">-</span><span class="n">bundle</span><span class="o">-*.</span><span class="na">jar</span><span class="err">`</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">props</span> <span class="nl">file:</span><span class="c1">//${PWD}/hudi-utilities/src/test/resources/delta-streamer-config/kafka-source.properties \</span>
  <span class="o">--</span><span class="n">config</span><span class="o">-</span><span class="n">folder</span> <span class="nl">file:</span><span class="c1">//tmp/hudi-ingestion-config \</span>
  <span class="o">--</span><span class="n">schemaprovider</span><span class="o">-</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">schema</span><span class="o">.</span><span class="na">SchemaRegistryProvider</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="kd">class</span> <span class="nc">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">utilities</span><span class="o">.</span><span class="na">sources</span><span class="o">.</span><span class="na">AvroKafkaSource</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">ordering</span><span class="o">-</span><span class="n">field</span> <span class="n">impresssiontime</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">base</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">prefix</span> <span class="nl">file:</span><span class="err">\</span><span class="o">/</span><span class="err">\</span><span class="o">/</span><span class="err">\</span><span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">hudi</span><span class="o">-</span><span class="n">deltastreamer</span><span class="o">-</span><span class="n">op</span> <span class="err">\</span> 
  <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">table</span> <span class="n">uber</span><span class="o">.</span><span class="na">impressions</span> <span class="err">\</span>
  <span class="o">--</span><span class="n">op</span> <span class="no">BULK_INSERT</span>
</code></pre></div></div>

<p>For detailed information on how to configure and use <code class="highlighter-rouge">HoodieMultiTableDeltaStreamer</code>, please refer <a href="/blog/ingest-multiple-tables-using-hudi">blog section</a>.</p>

<h2 id="datasource-writer">Datasource Writer</h2>

<p>The <code class="highlighter-rouge">hudi-spark</code> module offers the DataSource API to write (and read) a Spark DataFrame into a Hudi table. There are a number of options available:</p>

<p><strong><code class="highlighter-rouge">HoodieWriteConfig</code></strong>:</p>

<p><strong>TABLE_NAME</strong> (Required)<br /></p>

<p><strong><code class="highlighter-rouge">DataSourceWriteOptions</code></strong>:</p>

<p><strong>RECORDKEY_FIELD_OPT_KEY</strong> (Required): Primary key field(s). Record keys uniquely identify a record/row within each partition. If one wants to have a global uniqueness, there are two options. You could either make the dataset non-partitioned, or, you can leverage Global indexes to ensure record keys are unique irrespective of the partition path. Record keys can either be a single column or refer to multiple columns. <code class="highlighter-rouge">KEYGENERATOR_CLASS_OPT_KEY</code> property should be set accordingly based on whether it is a simple or complex key. For eg: <code class="highlighter-rouge">"col1"</code> for simple field, <code class="highlighter-rouge">"col1,col2,col3,etc"</code> for complex field. Nested fields can be specified using the dot notation eg: <code class="highlighter-rouge">a.b.c</code>. <br />
Default value: <code class="highlighter-rouge">"uuid"</code><br /></p>

<p><strong>PARTITIONPATH_FIELD_OPT_KEY</strong> (Required): Columns to be used for partitioning the table. To prevent partitioning, provide empty string as value eg: <code class="highlighter-rouge">""</code>. Specify partitioning/no partitioning using <code class="highlighter-rouge">KEYGENERATOR_CLASS_OPT_KEY</code>. If partition path needs to be url encoded, you can set <code class="highlighter-rouge">URL_ENCODE_PARTITIONING_OPT_KEY</code>. If synchronizing to hive, also specify using <code class="highlighter-rouge">HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY.</code><br />
Default value: <code class="highlighter-rouge">"partitionpath"</code><br /></p>

<p><strong>PRECOMBINE_FIELD_OPT_KEY</strong> (Required): When two records within the same batch have the same key value, the record with the largest value from the field specified will be choosen. If you are using default payload of OverwriteWithLatestAvroPayload for HoodieRecordPayload (<code class="highlighter-rouge">WRITE_PAYLOAD_CLASS</code>), an incoming record will always takes precendence compared to the one in storage ignoring this <code class="highlighter-rouge">PRECOMBINE_FIELD_OPT_KEY</code>. <br />
Default value: <code class="highlighter-rouge">"ts"</code><br /></p>

<p><strong>OPERATION_OPT_KEY</strong>: The <a href="#write-operations">write operations</a> to use.<br />
Available values:<br />
<code class="highlighter-rouge">UPSERT_OPERATION_OPT_VAL</code> (default), <code class="highlighter-rouge">BULK_INSERT_OPERATION_OPT_VAL</code>, <code class="highlighter-rouge">INSERT_OPERATION_OPT_VAL</code>, <code class="highlighter-rouge">DELETE_OPERATION_OPT_VAL</code></p>

<p><strong>TABLE_TYPE_OPT_KEY</strong>: The <a href="/docs/concepts.html#table-types">type of table</a> to write to. Note: After the initial creation of a table, this value must stay consistent when writing to (updating) the table using the Spark <code class="highlighter-rouge">SaveMode.Append</code> mode.<br />
Available values:<br />
<a href="/docs/concepts.html#copy-on-write-table"><code class="highlighter-rouge">COW_TABLE_TYPE_OPT_VAL</code></a> (default), <a href="/docs/concepts.html#merge-on-read-table"><code class="highlighter-rouge">MOR_TABLE_TYPE_OPT_VAL</code></a></p>

<p><strong>KEYGENERATOR_CLASS_OPT_KEY</strong>: Refer to <a href="#key-generation">Key Generation</a> section below.</p>

<p><strong>HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY</strong>: If using hive, specify if the table should or should not be partitioned.<br />
Available values:<br />
<code class="highlighter-rouge">classOf[SlashEncodedDayPartitionValueExtractor].getCanonicalName</code> (default), <code class="highlighter-rouge">classOf[MultiPartKeysValueExtractor].getCanonicalName</code>, <code class="highlighter-rouge">classOf[TimestampBasedKeyGenerator].getCanonicalName</code>, <code class="highlighter-rouge">classOf[NonPartitionedExtractor].getCanonicalName</code>, <code class="highlighter-rouge">classOf[GlobalDeleteKeyGenerator].getCanonicalName</code> (to be used when <code class="highlighter-rouge">OPERATION_OPT_KEY</code> is set to <code class="highlighter-rouge">DELETE_OPERATION_OPT_VAL</code>)</p>

<p>Example:
Upsert a DataFrame, specifying the necessary field names for <code class="highlighter-rouge">recordKey =&gt; _row_key</code>, <code class="highlighter-rouge">partitionPath =&gt; partition</code>, and <code class="highlighter-rouge">precombineKey =&gt; timestamp</code></p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputDF</span><span class="o">.</span><span class="na">write</span><span class="o">()</span>
       <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"org.apache.hudi"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">options</span><span class="o">(</span><span class="n">clientOpts</span><span class="o">)</span> <span class="c1">//Where clientOpts is of type Map[String, String]. clientOpts can include any other options necessary.</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">RECORDKEY_FIELD_OPT_KEY</span><span class="o">(),</span> <span class="s">"_row_key"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">PARTITIONPATH_FIELD_OPT_KEY</span><span class="o">(),</span> <span class="s">"partition"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">PRECOMBINE_FIELD_OPT_KEY</span><span class="o">(),</span> <span class="s">"timestamp"</span><span class="o">)</span>
       <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">HoodieWriteConfig</span><span class="o">.</span><span class="na">TABLE_NAME</span><span class="o">,</span> <span class="n">tableName</span><span class="o">)</span>
       <span class="o">.</span><span class="na">mode</span><span class="o">(</span><span class="nc">SaveMode</span><span class="o">.</span><span class="na">Append</span><span class="o">)</span>
       <span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">basePath</span><span class="o">);</span>
</code></pre></div></div>

<h2 id="flink-sql-writer">Flink SQL Writer</h2>
<p>The hudi-flink module defines the Flink SQL connector for both hudi source and sink.
There are a number of options available for the sink table:</p>

<table>
  <thead>
    <tr>
      <th>Option Name</th>
      <th>Required</th>
      <th>Default</th>
      <th>Remarks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>path</td>
      <td>Y</td>
      <td>N/A</td>
      <td>Base path for the target hoodie table. The path would be created if it does not exist, otherwise a hudi table expects to be initialized successfully</td>
    </tr>
    <tr>
      <td>table.type</td>
      <td>N</td>
      <td>COPY_ON_WRITE</td>
      <td>Type of table to write. COPY_ON_WRITE (or) MERGE_ON_READ</td>
    </tr>
    <tr>
      <td>write.operation</td>
      <td>N</td>
      <td>upsert</td>
      <td>The write operation, that this write should do (insert or upsert is supported)</td>
    </tr>
    <tr>
      <td>write.precombine.field</td>
      <td>N</td>
      <td>ts</td>
      <td>Field used in preCombining before actual write. When two records have the same key value, we will pick the one with the largest value for the precombine field, determined by Object.compareTo(..)</td>
    </tr>
    <tr>
      <td>write.payload.class</td>
      <td>N</td>
      <td>OverwriteWithLatestAvroPayload.class</td>
      <td>Payload class used. Override this, if you like to roll your own merge logic, when upserting/inserting. This will render any value set for the option in-effective</td>
    </tr>
    <tr>
      <td>write.insert.drop.duplicates</td>
      <td>N</td>
      <td>false</td>
      <td>Flag to indicate whether to drop duplicates upon insert. By default insert will accept duplicates, to gain extra performance</td>
    </tr>
    <tr>
      <td>write.ignore.failed</td>
      <td>N</td>
      <td>true</td>
      <td>Flag to indicate whether to ignore any non exception error (e.g. writestatus error). within a checkpoint batch. By default true (in favor of streaming progressing over data integrity)</td>
    </tr>
    <tr>
      <td>hoodie.datasource.write.recordkey.field</td>
      <td>N</td>
      <td>uuid</td>
      <td>Record key field. Value to be used as the <code class="highlighter-rouge">recordKey</code> component of <code class="highlighter-rouge">HoodieKey</code>. Actual value will be obtained by invoking .toString() on the field value. Nested fields can be specified using the dot notation eg: <code class="highlighter-rouge">a.b.c</code></td>
    </tr>
    <tr>
      <td>hoodie.datasource.write.keygenerator.class</td>
      <td>N</td>
      <td>SimpleAvroKeyGenerator.class</td>
      <td>Key generator class, that implements will extract the key out of incoming record</td>
    </tr>
    <tr>
      <td>write.tasks</td>
      <td>N</td>
      <td>4</td>
      <td>Parallelism of tasks that do actual write, default is 4</td>
    </tr>
    <tr>
      <td>write.batch.size.MB</td>
      <td>N</td>
      <td>128</td>
      <td>Batch buffer size in MB to flush data into the underneath filesystem</td>
    </tr>
  </tbody>
</table>

<p>If the table type is MERGE_ON_READ, you can also specify the asynchronous compaction strategy through options:</p>

<table>
  <thead>
    <tr>
      <th>Option Name</th>
      <th>Required</th>
      <th>Default</th>
      <th>Remarks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>compaction.async.enabled</td>
      <td>N</td>
      <td>true</td>
      <td>Async Compaction, enabled by default for MOR</td>
    </tr>
    <tr>
      <td>compaction.trigger.strategy</td>
      <td>N</td>
      <td>num_commits</td>
      <td>Strategy to trigger compaction, options are ‘num_commits’: trigger compaction when reach N delta commits; ‘time_elapsed’: trigger compaction when time elapsed &gt; N seconds since last compaction; ‘num_and_time’: trigger compaction when both NUM_COMMITS and TIME_ELAPSED are satisfied; ‘num_or_time’: trigger compaction when NUM_COMMITS or TIME_ELAPSED is satisfied. Default is ‘num_commits’</td>
    </tr>
    <tr>
      <td>compaction.delta_commits</td>
      <td>N</td>
      <td>5</td>
      <td>Max delta commits needed to trigger compaction, default 5 commits</td>
    </tr>
    <tr>
      <td>compaction.delta_seconds</td>
      <td>N</td>
      <td>3600</td>
      <td>Max delta seconds time needed to trigger compaction, default 1 hour</td>
    </tr>
  </tbody>
</table>

<p>You can write the data using the SQL <code class="highlighter-rouge">INSERT INTO</code> statements:</p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">hudi_table</span> <span class="k">select</span> <span class="p">...</span> <span class="k">from</span> <span class="p">...;</span> 
</code></pre></div></div>

<p><strong>Note</strong>: INSERT OVERWRITE is not supported yet but already on the roadmap.</p>

<h2 id="key-generation">Key Generation</h2>

<p>Hudi maintains hoodie keys (record key + partition path) for uniquely identifying a particular record. Key generator class will extract these out of incoming record. Both the tools above have configs to specify the 
<code class="highlighter-rouge">hoodie.datasource.write.keygenerator.class</code> property. For DeltaStreamer this would come from the property file specified in <code class="highlighter-rouge">--props</code> and 
DataSource writer takes this config directly using <code class="highlighter-rouge">DataSourceWriteOptions.KEYGENERATOR_CLASS_OPT_KEY()</code>.
The default value for this config is <code class="highlighter-rouge">SimpleKeyGenerator</code>. Note: A custom key generator class can be written/provided here as well. Primary key columns should be provided via <code class="highlighter-rouge">RECORDKEY_FIELD_OPT_KEY</code> option.<br /></p>

<p>Hudi currently supports different combinations of record keys and partition paths as below -</p>

<ul>
  <li>Simple record key (consisting of only one field) and simple partition path (with optional hive style partitioning)</li>
  <li>Simple record key and custom timestamp based partition path (with optional hive style partitioning)</li>
  <li>Composite record keys (combination of multiple fields) and composite partition paths</li>
  <li>Composite record keys and timestamp based partition paths (composite also supported)</li>
  <li>Non partitioned table</li>
</ul>

<p><code class="highlighter-rouge">CustomKeyGenerator.java</code> (part of hudi-spark module) class provides great support for generating hoodie keys of all the above listed types. All you need to do is supply values for the following properties properly to create your desired keys -</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hoodie</span><span class="o">.</span><span class="na">datasource</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">recordkey</span><span class="o">.</span><span class="na">field</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">datasource</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">partitionpath</span><span class="o">.</span><span class="na">field</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">datasource</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">keygenerator</span><span class="o">.</span><span class="na">class</span><span class="o">=</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hudi</span><span class="o">.</span><span class="na">keygen</span><span class="o">.</span><span class="na">CustomKeyGenerator</span>
</code></pre></div></div>

<p>For having composite record keys, you need to provide comma separated fields like</p>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hoodie</span><span class="o">.</span><span class="na">datasource</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">recordkey</span><span class="o">.</span><span class="na">field</span><span class="o">=</span><span class="n">field1</span><span class="o">,</span><span class="n">field2</span>
</code></pre></div></div>

<p>This will create your record key in the format <code class="highlighter-rouge">field1:value1,field2:value2</code> and so on, otherwise you can specify only one field in case of simple record keys. <code class="highlighter-rouge">CustomKeyGenerator</code> class defines an enum <code class="highlighter-rouge">PartitionKeyType</code> for configuring partition paths. It can take two possible values - SIMPLE and TIMESTAMP. 
The value for <code class="highlighter-rouge">hoodie.datasource.write.partitionpath.field</code> property in case of partitioned tables needs to be provided in the format <code class="highlighter-rouge">field1:PartitionKeyType1,field2:PartitionKeyType2</code> and so on. For example, if you want to create partition path using 2 fields <code class="highlighter-rouge">country</code> and <code class="highlighter-rouge">date</code> where the latter has timestamp based values and needs to be customised in a given format, you can specify the following</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hoodie</span><span class="o">.</span><span class="na">datasource</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">partitionpath</span><span class="o">.</span><span class="na">field</span><span class="o">=</span><span class="nl">country:</span><span class="no">SIMPLE</span><span class="o">,</span><span class="nl">date:</span><span class="no">TIMESTAMP</span>
</code></pre></div></div>
<p>This will create the partition path in the format <code class="highlighter-rouge">&lt;country_name&gt;/&lt;date&gt;</code> or <code class="highlighter-rouge">country=&lt;country_name&gt;/date=&lt;date&gt;</code> depending on whether you want hive style partitioning or not.</p>

<p><code class="highlighter-rouge">TimestampBasedKeyGenerator</code> class defines the following properties which can be used for doing the customizations for timestamp based partition paths</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">keygen</span><span class="o">.</span><span class="na">timebased</span><span class="o">.</span><span class="na">timestamp</span><span class="o">.</span><span class="na">type</span>
  <span class="nc">This</span> <span class="n">defines</span> <span class="n">the</span> <span class="n">type</span> <span class="n">of</span> <span class="n">the</span> <span class="n">value</span> <span class="n">that</span> <span class="n">your</span> <span class="n">field</span> <span class="n">contains</span><span class="o">.</span> <span class="nc">It</span> <span class="n">can</span> <span class="n">be</span> <span class="n">in</span> <span class="n">string</span> <span class="n">format</span> <span class="n">or</span> <span class="n">epoch</span> <span class="n">format</span><span class="o">,</span> <span class="k">for</span> <span class="n">example</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">keygen</span><span class="o">.</span><span class="na">timebased</span><span class="o">.</span><span class="na">timestamp</span><span class="o">.</span><span class="na">scalar</span><span class="o">.</span><span class="na">time</span><span class="o">.</span><span class="na">unit</span>
  <span class="nc">This</span> <span class="n">defines</span> <span class="n">the</span> <span class="n">granularity</span> <span class="n">of</span> <span class="n">your</span> <span class="n">field</span><span class="o">,</span> <span class="n">whether</span> <span class="n">it</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">values</span> <span class="n">in</span> <span class="n">seconds</span> <span class="n">or</span> <span class="n">milliseconds</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">keygen</span><span class="o">.</span><span class="na">timebased</span><span class="o">.</span><span class="na">input</span><span class="o">.</span><span class="na">dateformat</span>
  <span class="nc">This</span> <span class="n">defines</span> <span class="n">the</span> <span class="n">custom</span> <span class="n">format</span> <span class="n">in</span> <span class="n">which</span> <span class="n">the</span> <span class="n">values</span> <span class="n">are</span> <span class="n">present</span> <span class="n">in</span> <span class="n">your</span> <span class="n">field</span><span class="o">,</span> <span class="k">for</span> <span class="n">example</span> <span class="n">yyyy</span><span class="o">/</span><span class="no">MM</span><span class="o">/</span><span class="n">dd</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">keygen</span><span class="o">.</span><span class="na">timebased</span><span class="o">.</span><span class="na">output</span><span class="o">.</span><span class="na">dateformat</span>
  <span class="nc">This</span> <span class="n">defines</span> <span class="n">the</span> <span class="n">custom</span> <span class="n">format</span> <span class="n">in</span> <span class="n">which</span> <span class="n">you</span> <span class="n">want</span> <span class="n">the</span> <span class="n">partition</span> <span class="n">paths</span> <span class="n">to</span> <span class="n">be</span> <span class="n">created</span><span class="o">,</span> <span class="k">for</span> <span class="n">example</span> <span class="n">dt</span><span class="o">=</span><span class="n">yyyyMMdd</span>
<span class="n">hoodie</span><span class="o">.</span><span class="na">deltastreamer</span><span class="o">.</span><span class="na">keygen</span><span class="o">.</span><span class="na">timebased</span><span class="o">.</span><span class="na">timezone</span>
  <span class="nc">This</span> <span class="n">defines</span> <span class="n">the</span> <span class="n">timezone</span> <span class="n">which</span> <span class="n">the</span> <span class="n">timestamp</span> <span class="n">based</span> <span class="n">values</span> <span class="n">belong</span> <span class="n">to</span>
</code></pre></div></div>

<p>When keygenerator class is <code class="highlighter-rouge">CustomKeyGenerator</code>, non partitioned table can be handled by simply leaving the property blank like</p>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hoodie</span><span class="o">.</span><span class="na">datasource</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">partitionpath</span><span class="o">.</span><span class="na">field</span><span class="o">=</span>
</code></pre></div></div>

<p>For those on hudi versions &lt; 0.6.0, you can use the following key generator classes for fulfilling your use cases -</p>

<ul>
  <li>Simple record key (consisting of only one field) and simple partition path (with optional hive style partitioning) - <code class="highlighter-rouge">SimpleKeyGenerator.java</code></li>
  <li>Simple record key and custom timestamp based partition path (with optional hive style partitioning) - <code class="highlighter-rouge">TimestampBasedKeyGenerator.java</code></li>
  <li>Composite record keys (combination of multiple fields) and composite partition paths - <code class="highlighter-rouge">ComplexKeyGenerator.java</code></li>
  <li>Composite record keys and timestamp based partition paths (composite also supported) - You might need to move to 0.6.0 and use <code class="highlighter-rouge">CustomKeyGenerator.java</code> class</li>
  <li>Non partitioned table - <code class="highlighter-rouge">NonpartitionedKeyGenerator.java</code>. Non-partitioned tables can currently only have a single key column, <a href="https://issues.apache.org/jira/browse/HUDI-1053">HUDI-1053</a></li>
</ul>

<h2 id="syncing-to-hive">Syncing to Hive</h2>

<p>Both tools above support syncing of the table’s latest schema to Hive metastore, such that queries can pick up new columns and partitions.
In case, its preferable to run this from commandline or in an independent jvm, Hudi provides a <code class="highlighter-rouge">HiveSyncTool</code>, which can be invoked as below, 
once you have built the hudi-hive module. Following is how we sync the above Datasource Writer written table to Hive metastore.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cd</span> <span class="n">hudi</span><span class="o">-</span><span class="n">hive</span>
<span class="o">./</span><span class="n">run_sync_tool</span><span class="o">.</span><span class="na">sh</span>  <span class="o">--</span><span class="n">jdbc</span><span class="o">-</span><span class="n">url</span> <span class="nl">jdbc:hive2:</span><span class="err">\</span><span class="o">/</span><span class="err">\</span><span class="o">/</span><span class="nl">hiveserver:</span><span class="mi">10000</span> <span class="o">--</span><span class="n">user</span> <span class="n">hive</span> <span class="o">--</span><span class="n">pass</span> <span class="n">hive</span> <span class="o">--</span><span class="n">partitioned</span><span class="o">-</span><span class="n">by</span> <span class="n">partition</span> <span class="o">--</span><span class="n">base</span><span class="o">-</span><span class="n">path</span> <span class="o">&lt;</span><span class="n">basePath</span><span class="o">&gt;</span> <span class="o">--</span><span class="n">database</span> <span class="k">default</span> <span class="o">--</span><span class="n">table</span> <span class="o">&lt;</span><span class="n">tableName</span><span class="o">&gt;</span>
</code></pre></div></div>

<p>Starting with Hudi 0.5.1 version read optimized version of merge-on-read tables are suffixed ‘_ro’ by default. For backwards compatibility with older Hudi versions, an optional HiveSyncConfig - <code class="highlighter-rouge">--skip-ro-suffix</code>, has been provided to turn off ‘_ro’ suffixing if desired. Explore other hive sync options using the following command:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cd</span> <span class="n">hudi</span><span class="o">-</span><span class="n">hive</span>
<span class="o">./</span><span class="n">run_sync_tool</span><span class="o">.</span><span class="na">sh</span>
 <span class="o">[</span><span class="n">hudi</span><span class="o">-</span><span class="n">hive</span><span class="o">]</span><span class="err">$</span> <span class="o">./</span><span class="n">run_sync_tool</span><span class="o">.</span><span class="na">sh</span> <span class="o">--</span><span class="n">help</span>
</code></pre></div></div>

<h2 id="deletes">Deletes</h2>

<p>Hudi supports implementing two types of deletes on data stored in Hudi tables, by enabling the user to specify a different record payload implementation. 
For more info refer to <a href="https://cwiki.apache.org/confluence/x/6IqvC">Delete support in Hudi</a>.</p>

<ul>
  <li>
    <p><strong>Soft Deletes</strong> : Retain the record key and just null out the values for all the other fields. 
 This can be achieved by ensuring the appropriate fields are nullable in the table schema and simply upserting the table after setting these fields to null.</p>
  </li>
  <li>
    <p><strong>Hard Deletes</strong> : A stronger form of deletion is to physically remove any trace of the record from the table. This can be achieved in 3 different ways.</p>

    <p>1) Using DataSource, set <code class="highlighter-rouge">OPERATION_OPT_KEY</code> to <code class="highlighter-rouge">DELETE_OPERATION_OPT_VAL</code>. This will remove all the records in the DataSet being submitted.</p>

    <p>2) Using DataSource, set <code class="highlighter-rouge">PAYLOAD_CLASS_OPT_KEY</code> to <code class="highlighter-rouge">"org.apache.hudi.EmptyHoodieRecordPayload"</code>. This will remove all the records in the DataSet being submitted.</p>

    <p>3) Using DataSource or DeltaStreamer, add a column named <code class="highlighter-rouge">_hoodie_is_deleted</code> to DataSet. The value of this column must be set to <code class="highlighter-rouge">true</code> for all the records to be deleted and either <code class="highlighter-rouge">false</code> or left null for any records which are to be upserted.</p>
  </li>
</ul>

<p>Example using hard delete method 2, remove all the records from the table that exist in the DataSet <code class="highlighter-rouge">deleteDF</code>:</p>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">deleteDF</span> <span class="c1">// dataframe containing just records to be deleted</span>
   <span class="o">.</span><span class="na">write</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">"org.apache.hudi"</span><span class="o">)</span>
   <span class="o">.</span><span class="na">option</span><span class="o">(...)</span> <span class="c1">// Add HUDI options like record-key, partition-path and others as needed for your setup</span>
   <span class="c1">// specify record_key, partition_key, precombine_fieldkey &amp; usual params</span>
   <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="nc">DataSourceWriteOptions</span><span class="o">.</span><span class="na">PAYLOAD_CLASS_OPT_KEY</span><span class="o">,</span> <span class="s">"org.apache.hudi.EmptyHoodieRecordPayload"</span><span class="o">)</span>
 
</code></pre></div></div>

<h2 id="optimized-dfs-access">Optimized DFS Access</h2>

<p>Hudi also performs several key storage management functions on the data stored in a Hudi table. A key aspect of storing data on DFS is managing file sizes and counts
and reclaiming storage space. For e.g HDFS is infamous for its handling of small files, which exerts memory/RPC pressure on the Name Node and can potentially destabilize
the entire cluster. In general, query engines provide much better performance on adequately sized columnar files, since they can effectively amortize cost of obtaining 
column statistics etc. Even on some cloud data stores, there is often cost to listing directories with large number of small files.</p>

<p>Here are some ways to efficiently manage the storage of your Hudi tables.</p>

<ul>
  <li>The <a href="/docs/configurations.html#compactionSmallFileSize">small file handling feature</a> in Hudi, profiles incoming workload 
and distributes inserts to existing file groups instead of creating new file groups, which can lead to small files.</li>
  <li>Cleaner can be <a href="/docs/configurations.html#retainCommits">configured</a> to clean up older file slices, more or less aggressively depending on maximum time for queries to run &amp; lookback needed for incremental pull</li>
  <li>User can also tune the size of the <a href="/docs/configurations.html#limitFileSize">base/parquet file</a>, <a href="/docs/configurations.html#logFileMaxSize">log files</a> &amp; expected <a href="/docs/configurations.html#parquetCompressionRatio">compression ratio</a>, 
such that sufficient number of inserts are grouped into the same file group, resulting in well sized base files ultimately.</li>
  <li>Intelligently tuning the <a href="/docs/configurations.html#withBulkInsertParallelism">bulk insert parallelism</a>, can again in nicely sized initial file groups. It is in fact critical to get this right, since the file groups
once created cannot be deleted, but simply expanded as explained before.</li>
  <li>For workloads with heavy updates, the <a href="/docs/concepts.html#merge-on-read-table">merge-on-read table</a> provides a nice mechanism for ingesting quickly into smaller files and then later merging them into larger base files via compaction.</li>
</ul>

<h2 id="schema-evolution">Schema Evolution</h2>

<p>Schema evolution is a very important aspect of data management. 
Hudi supports common schema evolution scenarios, such as adding a nullable field or promoting a datatype of a field, out-of-the-box.
Furthermore, the evolved schema is queryable across engines, such as Presto, Hive and Spark SQL.
The following table presents a summary of the types of schema changes compatible with different Hudi table types.</p>

<table>
  <thead>
    <tr>
      <th>Schema Change</th>
      <th>COW</th>
      <th>MOR</th>
      <th>Remarks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Add a new nullable column at root level at the end</td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code class="highlighter-rouge">Yes</code> means that a write with evolved schema succeeds and a read following the write succeeds to read entire dataset.</td>
    </tr>
    <tr>
      <td>Add a new nullable column to inner struct (at the end)</td>
      <td>Yes</td>
      <td>Yes</td>
      <td> </td>
    </tr>
    <tr>
      <td>Add a new complex type field with default (map and array)</td>
      <td>Yes</td>
      <td>Yes</td>
      <td> </td>
    </tr>
    <tr>
      <td>Add a new nullable column and change the ordering of fields</td>
      <td>No</td>
      <td>No</td>
      <td>Write succeeds but read fails if the write with evolved schema updated only some of the base files but not all. Currently, Hudi does not maintain a schema registry with history of changes across base files. Nevertheless, if the upsert touched all base files then the read will succeed.</td>
    </tr>
    <tr>
      <td>Add a custom nullable Hudi meta column, e.g. <code class="highlighter-rouge">_hoodie_meta_col</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td> </td>
    </tr>
    <tr>
      <td>Promote datatype from <code class="highlighter-rouge">int</code> to <code class="highlighter-rouge">long</code> for a field at root level</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>For other types, Hudi supports promotion as specified in <a href="http://avro.apache.org/docs/current/spec.html#Schema+Resolution">Avro schema resolution</a>.</td>
    </tr>
    <tr>
      <td>Promote datatype from <code class="highlighter-rouge">int</code> to <code class="highlighter-rouge">long</code> for a nested field</td>
      <td>Yes</td>
      <td>Yes</td>
      <td> </td>
    </tr>
    <tr>
      <td>Promote datatype from <code class="highlighter-rouge">int</code> to <code class="highlighter-rouge">long</code> for a complex type (value of map or array)</td>
      <td>Yes</td>
      <td>Yes</td>
      <td> </td>
    </tr>
    <tr>
      <td>Add a new non-nullable column at root level at the end</td>
      <td>No</td>
      <td>No</td>
      <td>In case of MOR table with Spark data source, write succeeds but read fails. As a <strong>workaround</strong>, you can make the field nullable.</td>
    </tr>
    <tr>
      <td>Add a new non-nullable column to inner struct (at the end)</td>
      <td>No</td>
      <td>No</td>
      <td> </td>
    </tr>
    <tr>
      <td>Change datatype from <code class="highlighter-rouge">long</code> to <code class="highlighter-rouge">int</code> for a nested field</td>
      <td>No</td>
      <td>No</td>
      <td> </td>
    </tr>
    <tr>
      <td>Change datatype from <code class="highlighter-rouge">long</code> to <code class="highlighter-rouge">int</code> for a complex type (value of map or array)</td>
      <td>No</td>
      <td>No</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>Let us walk through an example to demonstrate the schema evolution support in Hudi. 
In the below example, we are going to add a new string field and change the datatype of a field from int to long.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">Welcome</span> <span class="n">to</span>
    <span class="n">____</span>              <span class="n">__</span>
    <span class="o">/</span> <span class="n">__</span><span class="o">/</span><span class="n">__</span>  <span class="n">___</span> <span class="n">_____</span><span class="o">/</span> <span class="o">/</span><span class="n">__</span>
    <span class="n">_</span><span class="err">\</span> <span class="err">\</span><span class="o">/</span> <span class="n">_</span> <span class="err">\</span><span class="o">/</span> <span class="n">_</span> <span class="err">`</span><span class="o">/</span> <span class="n">__</span><span class="o">/</span>  <span class="err">'</span><span class="n">_</span><span class="o">/</span>
    <span class="o">/</span><span class="n">___</span><span class="o">/</span> <span class="o">.</span><span class="na">__</span><span class="o">/</span><span class="err">\</span><span class="n">_</span><span class="o">,</span><span class="n">_</span><span class="o">/</span><span class="n">_</span><span class="o">/</span> <span class="o">/</span><span class="n">_</span><span class="o">/</span><span class="err">\</span><span class="n">_</span><span class="err">\</span>   <span class="n">version</span> <span class="mf">3.1</span><span class="o">.</span><span class="mi">2</span>
    <span class="o">/</span><span class="n">_</span><span class="o">/</span>

    <span class="nc">Using</span> <span class="nc">Scala</span> <span class="n">version</span> <span class="mf">2.12</span><span class="o">.</span><span class="mi">10</span> <span class="o">(</span><span class="nc">OpenJDK</span> <span class="mi">64</span><span class="o">-</span><span class="nc">Bit</span> <span class="nc">Server</span> <span class="no">VM</span><span class="o">,</span> <span class="nc">Java</span> <span class="mf">1.8</span><span class="o">.</span><span class="mi">0_292</span><span class="o">)</span>
    <span class="nc">Type</span> <span class="n">in</span> <span class="n">expressions</span> <span class="n">to</span> <span class="n">have</span> <span class="n">them</span> <span class="n">evaluated</span><span class="o">.</span>
    <span class="nc">Type</span> <span class="o">:</span><span class="n">help</span> <span class="k">for</span> <span class="n">more</span> <span class="n">information</span><span class="o">.</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.hudi.QuickstartUtils._</span>
<span class="kn">import</span> <span class="nn">org.apache.hudi.QuickstartUtils._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">scala.collection.JavaConversions._</span>
<span class="kn">import</span> <span class="nn">scala.collection.JavaConversions._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.spark.sql.SaveMode._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SaveMode._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.hudi.DataSourceReadOptions._</span>
<span class="kn">import</span> <span class="nn">org.apache.hudi.DataSourceReadOptions._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.hudi.DataSourceWriteOptions._</span>
<span class="kn">import</span> <span class="nn">org.apache.hudi.DataSourceWriteOptions._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.hudi.config.HoodieWriteConfig._</span>
<span class="kn">import</span> <span class="nn">org.apache.hudi.config.HoodieWriteConfig._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.spark.sql.types._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">val</span> <span class="n">tableName</span> <span class="o">=</span> <span class="s">"hudi_trips_cow"</span>
    <span class="nl">tableName:</span> <span class="nc">String</span> <span class="o">=</span> <span class="n">hudi_trips_cow</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">val</span> <span class="n">basePath</span> <span class="o">=</span> <span class="s">"file:///tmp/hudi_trips_cow"</span>
    <span class="nl">basePath:</span> <span class="nc">String</span> <span class="o">=</span> <span class="nl">file:</span><span class="c1">///tmp/hudi_trips_cow</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">val</span> <span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="o">(</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"rowId"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"partitionId"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"preComb"</span><span class="o">,</span> <span class="nc">LongType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"name"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"versionId"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"intToLong"</span><span class="o">,</span> <span class="nc">IntegerType</span><span class="o">,</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">|</span> <span class="o">))</span>
    <span class="nl">schema:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">types</span><span class="o">.</span><span class="na">StructType</span> <span class="o">=</span> <span class="nc">StructType</span><span class="o">(</span><span class="nc">StructField</span><span class="o">(</span><span class="n">rowId</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">partitionId</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">preComb</span><span class="o">,</span><span class="nc">LongType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">name</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">versionId</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">intToLong</span><span class="o">,</span><span class="nc">IntegerType</span><span class="o">,</span><span class="kc">true</span><span class="o">))</span>
    
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">val</span> <span class="n">data1</span> <span class="o">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Row</span><span class="o">(</span><span class="s">"row_1"</span><span class="o">,</span> <span class="s">"part_0"</span><span class="o">,</span> <span class="mi">0L</span><span class="o">,</span> <span class="s">"bob"</span><span class="o">,</span> <span class="s">"v_0"</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span>
    <span class="o">|</span>                <span class="nc">Row</span><span class="o">(</span><span class="s">"row_2"</span><span class="o">,</span> <span class="s">"part_0"</span><span class="o">,</span> <span class="mi">0L</span><span class="o">,</span> <span class="s">"john"</span><span class="o">,</span> <span class="s">"v_0"</span><span class="o">,</span> <span class="mi">0</span><span class="o">),</span>
    <span class="o">|</span>                <span class="nc">Row</span><span class="o">(</span><span class="s">"row_3"</span><span class="o">,</span> <span class="s">"part_0"</span><span class="o">,</span> <span class="mi">0L</span><span class="o">,</span> <span class="s">"tom"</span><span class="o">,</span> <span class="s">"v_0"</span><span class="o">,</span> <span class="mi">0</span><span class="o">))</span>
    <span class="nl">data1:</span> <span class="nc">Seq</span><span class="o">[</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">Row</span><span class="o">]</span> <span class="o">=</span> <span class="nc">List</span><span class="o">([</span><span class="n">row_1</span><span class="o">,</span><span class="n">part_0</span><span class="o">,</span><span class="mi">0</span><span class="o">,</span><span class="n">bob</span><span class="o">,</span><span class="n">v_0</span><span class="o">,</span><span class="mi">0</span><span class="o">],</span> <span class="o">[</span><span class="n">row_2</span><span class="o">,</span><span class="n">part_0</span><span class="o">,</span><span class="mi">0</span><span class="o">,</span><span class="n">john</span><span class="o">,</span><span class="n">v_0</span><span class="o">,</span><span class="mi">0</span><span class="o">],</span> <span class="o">[</span><span class="n">row_3</span><span class="o">,</span><span class="n">part_0</span><span class="o">,</span><span class="mi">0</span><span class="o">,</span><span class="n">tom</span><span class="o">,</span><span class="n">v_0</span><span class="o">,</span><span class="mi">0</span><span class="o">])</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kt">var</span> <span class="n">dfFromData1</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data1</span><span class="o">,</span> <span class="n">schema</span><span class="o">)</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">dfFromData1</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"hudi"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">options</span><span class="o">(</span><span class="n">getQuickstartWriteConfigs</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">PRECOMBINE_FIELD_OPT_KEY</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="s">"preComb"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">RECORDKEY_FIELD_OPT_KEY</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="s">"rowId"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">PARTITIONPATH_FIELD_OPT_KEY</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="s">"partitionId"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="s">"hoodie.index.type"</span><span class="o">,</span><span class="s">"SIMPLE"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">TABLE_NAME</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="n">tableName</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">mode</span><span class="o">(</span><span class="nc">Overwrite</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">save</span><span class="o">(</span><span class="n">basePath</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kt">var</span> <span class="n">tripsSnapshotDF1</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"hudi"</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="n">basePath</span> <span class="o">+</span> <span class="s">"/*/*"</span><span class="o">)</span>
    <span class="nl">tripsSnapshotDF1:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">DataFrame</span> <span class="o">=</span> <span class="o">[</span><span class="nl">_hoodie_commit_time:</span> <span class="n">string</span><span class="o">,</span> <span class="nl">_hoodie_commit_seqno:</span> <span class="n">string</span> <span class="o">...</span> <span class="mi">9</span> <span class="n">more</span> <span class="n">fields</span><span class="o">]</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">tripsSnapshotDF1</span><span class="o">.</span><span class="na">createOrReplaceTempView</span><span class="o">(</span><span class="s">"hudi_trips_snapshot"</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">"desc hudi_trips_snapshot"</span><span class="o">).</span><span class="na">show</span><span class="o">()</span>
    <span class="o">+--------------------+---------+-------+</span>
    <span class="o">|</span>            <span class="n">col_name</span><span class="o">|</span><span class="n">data_type</span><span class="o">|</span><span class="n">comment</span><span class="o">|</span>
    <span class="o">+--------------------+---------+-------+</span>
    <span class="o">|</span> <span class="n">_hoodie_commit_time</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span><span class="n">_hoodie_commit_seqno</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>  <span class="n">_hoodie_record_key</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span><span class="n">_hoodie_partition</span><span class="o">...|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>   <span class="n">_hoodie_file_name</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>               <span class="n">rowId</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>         <span class="n">partitionId</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>             <span class="n">preComb</span><span class="o">|</span>   <span class="n">bigint</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>                <span class="n">name</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>           <span class="n">versionId</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>           <span class="n">intToLong</span><span class="o">|</span>      <span class="kt">int</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">+--------------------+---------+-------+</span>
    
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">"select rowId, partitionId, preComb, name, versionId, intToLong from hudi_trips_snapshot"</span><span class="o">).</span><span class="na">show</span><span class="o">()</span>
    <span class="o">+-----+-----------+-------+----+---------+---------+</span>
    <span class="o">|</span><span class="n">rowId</span><span class="o">|</span><span class="n">partitionId</span><span class="o">|</span><span class="n">preComb</span><span class="o">|</span><span class="n">name</span><span class="o">|</span><span class="n">versionId</span><span class="o">|</span><span class="n">intToLong</span><span class="o">|</span>
    <span class="o">+-----+-----------+-------+----+---------+---------+</span>
    <span class="o">|</span><span class="n">row_3</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">0</span><span class="o">|</span> <span class="n">tom</span><span class="o">|</span>      <span class="n">v_0</span><span class="o">|</span>        <span class="mi">0</span><span class="o">|</span>
    <span class="o">|</span><span class="n">row_2</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">0</span><span class="o">|</span><span class="n">john</span><span class="o">|</span>      <span class="n">v_0</span><span class="o">|</span>        <span class="mi">0</span><span class="o">|</span>
    <span class="o">|</span><span class="n">row_1</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">0</span><span class="o">|</span> <span class="n">bob</span><span class="o">|</span>      <span class="n">v_0</span><span class="o">|</span>        <span class="mi">0</span><span class="o">|</span>
    <span class="o">+-----+-----------+-------+----+---------+---------+</span>

<span class="c1">// In the new schema, we are going to add a String field and </span>
<span class="c1">// change the datatype `intToLong` field from  int to long.</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">val</span> <span class="n">newSchema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="o">(</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"rowId"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"partitionId"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"preComb"</span><span class="o">,</span> <span class="nc">LongType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"name"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"versionId"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"intToLong"</span><span class="o">,</span> <span class="nc">LongType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span>
    <span class="o">|</span> <span class="nc">StructField</span><span class="o">(</span><span class="s">"newField"</span><span class="o">,</span> <span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">|</span> <span class="o">))</span>
    <span class="nl">newSchema:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">types</span><span class="o">.</span><span class="na">StructType</span> <span class="o">=</span> <span class="nc">StructType</span><span class="o">(</span><span class="nc">StructField</span><span class="o">(</span><span class="n">rowId</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">partitionId</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">preComb</span><span class="o">,</span><span class="nc">LongType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">name</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">versionId</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">intToLong</span><span class="o">,</span><span class="nc">LongType</span><span class="o">,</span><span class="kc">true</span><span class="o">),</span> <span class="nc">StructField</span><span class="o">(</span><span class="n">newField</span><span class="o">,</span><span class="nc">StringType</span><span class="o">,</span><span class="kc">true</span><span class="o">))</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">val</span> <span class="n">data2</span> <span class="o">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Row</span><span class="o">(</span><span class="s">"row_2"</span><span class="o">,</span> <span class="s">"part_0"</span><span class="o">,</span> <span class="mi">5L</span><span class="o">,</span> <span class="s">"john"</span><span class="o">,</span> <span class="s">"v_3"</span><span class="o">,</span> <span class="mi">3L</span><span class="o">,</span> <span class="s">"newField_1"</span><span class="o">),</span>
    <span class="o">|</span>                <span class="nc">Row</span><span class="o">(</span><span class="s">"row_5"</span><span class="o">,</span> <span class="s">"part_0"</span><span class="o">,</span> <span class="mi">5L</span><span class="o">,</span> <span class="s">"maroon"</span><span class="o">,</span> <span class="s">"v_2"</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="s">"newField_1"</span><span class="o">),</span>
    <span class="o">|</span>                <span class="nc">Row</span><span class="o">(</span><span class="s">"row_9"</span><span class="o">,</span> <span class="s">"part_0"</span><span class="o">,</span> <span class="mi">5L</span><span class="o">,</span> <span class="s">"michael"</span><span class="o">,</span> <span class="s">"v_2"</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="s">"newField_1"</span><span class="o">))</span>
    <span class="nl">data2:</span> <span class="nc">Seq</span><span class="o">[</span><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">Row</span><span class="o">]</span> <span class="o">=</span> <span class="nc">List</span><span class="o">([</span><span class="n">row_2</span><span class="o">,</span><span class="n">part_0</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="n">john</span><span class="o">,</span><span class="n">v_3</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="n">newField_1</span><span class="o">],</span> <span class="o">[</span><span class="n">row_5</span><span class="o">,</span><span class="n">part_0</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="n">maroon</span><span class="o">,</span><span class="n">v_2</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="n">newField_1</span><span class="o">],</span> <span class="o">[</span><span class="n">row_9</span><span class="o">,</span><span class="n">part_0</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="n">michael</span><span class="o">,</span><span class="n">v_2</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="n">newField_1</span><span class="o">])</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kt">var</span> <span class="n">dfFromData2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data2</span><span class="o">,</span> <span class="n">newSchema</span><span class="o">)</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="n">dfFromData2</span><span class="o">.</span><span class="na">write</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"hudi"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">options</span><span class="o">(</span><span class="n">getQuickstartWriteConfigs</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">PRECOMBINE_FIELD_OPT_KEY</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="s">"preComb"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">RECORDKEY_FIELD_OPT_KEY</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="s">"rowId"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">PARTITIONPATH_FIELD_OPT_KEY</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="s">"partitionId"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="s">"hoodie.index.type"</span><span class="o">,</span><span class="s">"SIMPLE"</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">option</span><span class="o">(</span><span class="no">TABLE_NAME</span><span class="o">.</span><span class="na">key</span><span class="o">,</span> <span class="n">tableName</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">mode</span><span class="o">(</span><span class="nc">Append</span><span class="o">).</span>
    <span class="o">|</span>   <span class="n">save</span><span class="o">(</span><span class="n">basePath</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="kt">var</span> <span class="n">tripsSnapshotDF2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"hudi"</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="n">basePath</span> <span class="o">+</span> <span class="s">"/*/*"</span><span class="o">)</span>
    <span class="nl">tripsSnapshotDF2:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">DataFrame</span> <span class="o">=</span> <span class="o">[</span><span class="nl">_hoodie_commit_time:</span> <span class="n">string</span><span class="o">,</span> <span class="nl">_hoodie_commit_seqno:</span> <span class="n">string</span> <span class="o">...</span> <span class="mi">10</span> <span class="n">more</span> <span class="n">fields</span><span class="o">]</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">tripsSnapshotDF2</span><span class="o">.</span><span class="na">createOrReplaceTempView</span><span class="o">(</span><span class="s">"hudi_trips_snapshot"</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">"desc hudi_trips_snapshot"</span><span class="o">).</span><span class="na">show</span><span class="o">()</span>
    <span class="o">+--------------------+---------+-------+</span>
    <span class="o">|</span>            <span class="n">col_name</span><span class="o">|</span><span class="n">data_type</span><span class="o">|</span><span class="n">comment</span><span class="o">|</span>
    <span class="o">+--------------------+---------+-------+</span>
    <span class="o">|</span> <span class="n">_hoodie_commit_time</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span><span class="n">_hoodie_commit_seqno</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>  <span class="n">_hoodie_record_key</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span><span class="n">_hoodie_partition</span><span class="o">...|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>   <span class="n">_hoodie_file_name</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>               <span class="n">rowId</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>         <span class="n">partitionId</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>             <span class="n">preComb</span><span class="o">|</span>   <span class="n">bigint</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>                <span class="n">name</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>           <span class="n">versionId</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>           <span class="n">intToLong</span><span class="o">|</span>   <span class="n">bigint</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span>            <span class="n">newField</span><span class="o">|</span>   <span class="n">string</span><span class="o">|</span>   <span class="kc">null</span><span class="o">|</span>
    <span class="o">+--------------------+---------+-------+</span>


<span class="n">scala</span><span class="o">&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">"select rowId, partitionId, preComb, name, versionId, intToLong, newField from hudi_trips_snapshot"</span><span class="o">).</span><span class="na">show</span><span class="o">()</span>
    <span class="o">+-----+-----------+-------+-------+---------+---------+----------+</span>
    <span class="o">|</span><span class="n">rowId</span><span class="o">|</span><span class="n">partitionId</span><span class="o">|</span><span class="n">preComb</span><span class="o">|</span>   <span class="n">name</span><span class="o">|</span><span class="n">versionId</span><span class="o">|</span><span class="n">intToLong</span><span class="o">|</span>  <span class="n">newField</span><span class="o">|</span>
    <span class="o">+-----+-----------+-------+-------+---------+---------+----------+</span>
    <span class="o">|</span><span class="n">row_3</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">0</span><span class="o">|</span>    <span class="n">tom</span><span class="o">|</span>      <span class="n">v_0</span><span class="o">|</span>        <span class="mi">0</span><span class="o">|</span>      <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span><span class="n">row_2</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">5</span><span class="o">|</span>   <span class="n">john</span><span class="o">|</span>      <span class="n">v_3</span><span class="o">|</span>        <span class="mi">3</span><span class="o">|</span><span class="n">newField_1</span><span class="o">|</span>
    <span class="o">|</span><span class="n">row_1</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">0</span><span class="o">|</span>    <span class="n">bob</span><span class="o">|</span>      <span class="n">v_0</span><span class="o">|</span>        <span class="mi">0</span><span class="o">|</span>      <span class="kc">null</span><span class="o">|</span>
    <span class="o">|</span><span class="n">row_5</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">5</span><span class="o">|</span> <span class="n">maroon</span><span class="o">|</span>      <span class="n">v_2</span><span class="o">|</span>        <span class="mi">2</span><span class="o">|</span><span class="n">newField_1</span><span class="o">|</span>
    <span class="o">|</span><span class="n">row_9</span><span class="o">|</span>     <span class="n">part_0</span><span class="o">|</span>      <span class="mi">5</span><span class="o">|</span><span class="n">michael</span><span class="o">|</span>      <span class="n">v_2</span><span class="o">|</span>        <span class="mi">2</span><span class="o">|</span><span class="n">newField_1</span><span class="o">|</span>
    <span class="o">+-----+-----------+-------+-------+---------+---------+----------+</span>

</code></pre></div></div>

      </section>

      <a href="#masthead__inner-wrap" class="back-to-top">Back to top &uarr;</a>


      

    </div>

  </article>

</div>

    </div>

    <div class="page__footer">
      <footer>
        
<div class="row">
  <div class="col-lg-12 footer">
    <p>
      <table class="table-apache-info">
        <tr>
          <td>
            <a class="footer-link-img" href="https://apache.org">
              <img width="250px" src="/assets/images/asf_logo.svg" alt="The Apache Software Foundation">
            </a>
          </td>
          <td>
            <a style="float: right" href="https://www.apache.org/events/current-event.html">
              <img src="https://www.apache.org/events/current-event-234x60.png" />
            </a>
          </td>
        </tr>
      </table>
    </p>
    <p>
      <a href="https://www.apache.org/licenses/">License</a> | <a href="https://www.apache.org/security/">Security</a> | <a href="https://www.apache.org/foundation/thanks.html">Thanks</a> | <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
    </p>
    <p>
      Copyright &copy; <span id="copyright-year">2019</span> <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0"> Apache License, Version 2.0</a>.
      Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation. <a href="/docs/privacy">Privacy Policy</a>
    </p>
  </div>
</div>
      </footer>
    </div>


  </body>
</html>
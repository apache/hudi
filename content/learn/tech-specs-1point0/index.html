<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-learn docs-version-current docs-doc-page docs-doc-id-tech-specs-1point0" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Apache Hudi Technical Specification 1.0 | Apache Hudi</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://hudi.apache.org/learn/tech-specs-1point0"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="apache hudi, data lake, lakehouse, big data, apache spark, apache flink, presto, trino, analytics, data engineering"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-learn-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-learn-current"><meta data-rh="true" property="og:title" content="Apache Hudi Technical Specification 1.0 | Apache Hudi"><meta data-rh="true" name="description" content="| Syntax | Description |"><meta data-rh="true" property="og:description" content="| Syntax | Description |"><link data-rh="true" rel="icon" href="/assets/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://hudi.apache.org/learn/tech-specs-1point0"><link data-rh="true" rel="alternate" href="https://hudi.apache.org/learn/tech-specs-1point0" hreflang="en"><link data-rh="true" rel="alternate" href="https://hudi.apache.org/learn/tech-specs-1point0" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Tech Specs 1.0","item":"https://hudi.apache.org/learn/tech-specs-1point0"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Hudi: User-Facing Analytics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Hudi: User-Facing Analytics Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Apache Hudi: User-Facing Analytics JSON Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Apache Hudi" href="/opensearch.xml">
<link rel="alternate" type="application/rss+xml" href="/videos/rss.xml" title="Apache Hudi RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/videos/atom.xml" title="Apache Hudi Atom Feed">





<script src="https://widget.kapa.ai/kapa-widget.bundle.js" data-website-id="9e4444ba-93cc-45ea-b143-783ae0fbeb6f" data-project-name="Apache Hudi" data-project-color="#FFFFFF" data-project-logo="https://hudi.apache.org/assets/images/logo-big.png" data-modal-disclaimer="This AI assistant answers Apache Hudi questions using your [documentation](https://hudi.apache.org/docs/quick-start-guide/), [dev setup](https://hudi.apache.org/contribute/developer-setup/), the [tech specs](https://hudi.apache.org/tech-specs-1point0/) and open GitHub Issues from the last year." data-modal-title="Apache Hudi AI Assistant" data-modal-example-questions-title="Try asking me..." data-modal-example-questions="How can I convert an existing COW table to MOR?,How do I set up incremental queries with Hudi tables?" data-modal-image="https://hudi.apache.org/assets/images/logo-big-2.png" data-modal-image-ask-ai="https://hudi.apache.org/assets/images/logo-big-2.png" data-modal-header-min-height="64px" data-modal-image-height="40" data-modal-image-width="40" data-modal-header-bg-color="#f8f9fa" data-modal-title-color="#0db1f9" data-button-text-color="#29557a" data-button-text="Ask AI" data-consent-required="true" data-consent-screen-title="Help us improve our AI assistant" data-consent-screen-disclaimer="By clicking &amp;quot;Allow tracking&amp;quot;, you consent to the use of the AI assistant in accordance with kapa.ai&#39;s [Privacy Policy](https://www.kapa.ai/content/privacy-policy). This service uses reCAPTCHA, which requires your consent to Google&#39;s [Privacy Policy](https://policies.google.com/privacy) and [Terms of Service](https://policies.google.com/terms). By proceeding, you explicitly agree to both kapa.ai&#39;s and Google&#39;s privacy policies." data-consent-screen-accept-button-text="Allow tracking" data-modal-disclaimer-font-size="0.80rem" data-query-input-placeholder-text-color="#29557a" data-submit-query-button-bg-color="#0db1f9" data-query-input-text-color="#29557a" data-user-analytics-cookie-enabled="false" data-query-input-border-color="#211b0e" data-question-text-color="#0db1f9" data-answer-text-color="#000" data-thread-clear-button-bg-color="#000000" data-thread-clear-button-text-color="#FFFFFF" data-answer-feedback-button-bg-color="#000000" data-answer-feedback-button-text-color="#FFFFFF" data-answer-feedback-button-active-bg-color="#000000" data-answer-feedback-button-active-text-color="#FFFFFF" data-answer-copy-button-bg-color="#000000" data-answer-copy-button-text-color="#FFFFFF" data-example-question-button-text-color="#29557a" data-modal-disclaimer-bg-color="#f8f9fa" data-modal-disclaimer-text-color="#0db1f9" data-deep-thinking-button-bg-color="#0db1f9" data-deep-thinking-button-text-color="#FFFFFF" data-deep-thinking-button-active-bg-color="#0db1f9" data-deep-thinking-button-hover-bg-color="#FFFFFF" data-deep-thinking-button-active-hover-bg-color="#29557a" data-deep-thinking-button-active-text-color="#FFFFFF" async></script><link rel="stylesheet" href="/assets/css/styles.8d703ffa.css">
<script src="/assets/js/runtime~main.a2084ffa.js" defer="defer"></script>
<script src="/assets/js/main.0e95c305.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="theme-announcement-bar announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">⭐️ If you like <b>Apache Hudi</b>, give it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/apache/hudi"><b>GitHub!<svg xmlns="http://www.w3.org/2000/svg\" width="16" height="16" fill="currentColor" class="bi bi-github" viewBox="0 -2 16 16"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg></b></a> ⭐</div></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarWrapper_j_uY"><div class="navbar__inner navbarInnerStyle_KoMw"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo navbarLogo_aghy"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/docs/overview">Docs</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Learn</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/learn/tutorial-series">Tutorial Series</a></li><li><a class="dropdown__link" href="/learn/blog">Blogs</a></li><li><a class="dropdown__link" href="/learn/talks">Talks</a></li><li><a class="dropdown__link" href="/learn/videos">Video Guides</a></li><li><a class="dropdown__link" href="/learn/faq">FAQ</a></li><li><a class="dropdown__link" href="/learn/tech-specs">Tech Specs</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/learn/tech-specs-1point0">Tech Specs 1.0</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Contribute</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/contribute/developer-sync-call">Developer Sync Call</a></li><li><a class="dropdown__link" href="/contribute/how-to-contribute">How to Contribute</a></li><li><a class="dropdown__link" href="/contribute/developer-setup">Developer Setup</a></li><li><a class="dropdown__link" href="/contribute/rfc-process">RFC Process</a></li><li><a class="dropdown__link" href="/contribute/report-security-issues">Report Issues</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/community/get-involved">Get Involved</a></li><li><a class="dropdown__link" href="/community/syncs">Community Syncs</a></li><li><a class="dropdown__link" href="/community/office_hours">Office Hours</a></li><li><a class="dropdown__link" href="/community/team">Team</a></li><li><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="dropdown__link">Github<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA" target="_blank" rel="noopener noreferrer" class="dropdown__link">Slack<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://www.linkedin.com/company/apache-hudi/" target="_blank" rel="noopener noreferrer" class="dropdown__link">LinkedIn<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://www.youtube.com/@apachehudi" target="_blank" rel="noopener noreferrer" class="dropdown__link">YouTube<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://x.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="dropdown__link">X<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Ecosystem</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/powered-by">Adopters</a></li><li><a class="dropdown__link" href="/roadmap">Roadmap</a></li><li><a class="dropdown__link" href="/ecosystem">Integrations</a></li></ul></div><a class="navbar__item navbar__link" href="/releases/download">Download</a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><div><div role="button" class="searchButton_o6KI" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="none" viewBox="0 0 14 14"><circle cx="6.864" cy="6.864" r="5.243" stroke="#15467D" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5"></circle><path stroke="#15467D" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m10.51 10.783 2.056 2.05"></path></svg></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar navbarSideMenu_TODO"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><div class="navbar__logo navbarLogo_aghy"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/assets/images/hudi.png" alt="Apache Hudi" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><button type="button" aria-label="Close navigation bar" class="clean-btn navbar-sidebar__close"><svg viewBox="0 0 15 15" width="21" height="21"><g stroke="var(--ifm-color-emphasis-600)" stroke-width="1.2"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><div class="navbar-sidebar__items"><div class="navbar-sidebar__item menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/docs/overview">Docs</a></li><li class="menu__list-item"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Learn</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/learn/tutorial-series">Tutorial Series</a></li><li class="menu__list-item"><a class="menu__link" href="/learn/blog">Blogs</a></li><li class="menu__list-item"><a class="menu__link" href="/learn/talks">Talks</a></li><li class="menu__list-item"><a class="menu__link" href="/learn/videos">Video Guides</a></li><li class="menu__list-item"><a class="menu__link" href="/learn/faq">FAQ</a></li><li class="menu__list-item"><a class="menu__link" href="/learn/tech-specs">Tech Specs</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active" href="/learn/tech-specs-1point0">Tech Specs 1.0</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Contribute</a></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Community</a></li><li class="menu__list-item menu__list-item--collapsed"><a role="button" class="dropdownNavbarItemMobile_JUhd menu__link menu__link--sublist menu__link--sublist-caret navbarFontSize_pR5Q">Ecosystem</a></li><li class="menu__list-item"><a class="menu__link navbarFontSize_pR5Q" href="/releases/download">Download</a></li></ul></div><div class="navbar-sidebar__item menu"><button type="button" class="clean-btn navbar-sidebar__back">← Back to main menu</button></div></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_bSxm"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_cWv0"><aside class="theme-doc-sidebar-container docSidebarContainer_RSuS"><div class="sidebarViewport_pYEE"><div class="sidebar_mhZE"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_Y1UP menuWithAnnouncementBar_fPny"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/learn/tutorial-series"><span title="Tutorial Series" class="linkLabel_WmDU">Tutorial Series</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/learn/blog"><span title="Blogs" class="linkLabel_WmDU">Blogs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/learn/talks"><span title="Talks" class="linkLabel_WmDU">Talks</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/learn/videos"><span title="Video Guides" class="linkLabel_WmDU">Video Guides</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/learn/faq"><span title="FAQ" class="linkLabel_WmDU">FAQ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/learn/tech-specs"><span title="Tech Specs" class="linkLabel_WmDU">Tech Specs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/learn/tech-specs-1point0"><span title="Tech Specs 1.0" class="linkLabel_WmDU">Tech Specs 1.0</span></a></li><li class="menu__list-item" style="margin-top:8px"></li></ul></nav></div></div></aside><main class="docMainContainer_hjYf"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Tech Specs 1.0</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Apache Hudi Technical Specification 1.0</h1></header>
<table><thead><tr><th><strong>Syntax</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>Last Updated</td><td>Dec 2024</td></tr><tr><td><a href="https://github.com/apache/hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/common/table/HoodieTableVersion.java#L29" target="_blank" rel="noopener noreferrer" class="">Table Version</a></td><td>8</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Please check the specification for versions prior to 1.0 <a class="" href="/learn/tech-specs">here</a>.</p></div></div>
<p>Hudi brings database capabilities (tables, transactions, mutability, indexes, storage layouts) along with an incremental stream processing model (incremental merges, change streams, out-of-order data)
over very large collections of files/objects, turning immutable cloud/file storage systems into transactional data lakes.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>This document is a specification for the Hudi&#x27;s storage format along with protocols for correctly implementing readers and writers to accomplish the following goals.</p>
<ul>
<li class=""><strong>Unified Computation Model</strong> - a unified way to combine large batch style operations and frequent near real time incremental operations over large datasets.</li>
<li class=""><strong>Self-Optimizing Storage</strong> - automatically handle all the table maintenance and optimizations such as compaction, clustering, cleaning asynchronously and in most cases non-blocking to actual data changes.</li>
<li class=""><strong>Cloud Native Database</strong> - abstracts Table/Schema from actual storage and ensures up-to-date metadata and indexes unlocking multi-fold read and write performance optimizations.</li>
<li class=""><strong>Cross-Engine Compatibility</strong> - designed to be neutral and compatible with different computation engines. Hudi will manage metadata, and provide common abstractions and
pluggable interfaces to most/all common compute/query engines.</li>
</ul>
<p>This document is intended as reference guide for any compute engines, that aim to write/read Hudi tables, by interacting with the storage format directly.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="storage-layout">Storage Layout<a href="#storage-layout" class="hash-link" aria-label="Direct link to Storage Layout" title="Direct link to Storage Layout" translate="no">​</a></h2>
<p>Hudi organizes a table as a collection of files (objects in cloud storage) that can be spread across different paths on <strong><em>storage</em></strong> which can be local filesystem, distributed filesystem or object storage.
These different paths that contain a table&#x27;s files are called <strong><em>partitions</em></strong>. Some common ways of organizing files can be as follows</p>
<ul>
<li class="">
<p><strong>Hierarchical folder tree:</strong> files are organized under a folder path structure like conventional filesystems, for ease of access and navigation. Hive-style partitioning is a special case of
this organization, where the folder path names indicate the field values that partition the data. However, note that, unlike Hive style partitioning, partition columns are not removed from
data files and partitioning is a mere organizational construct.</p>
</li>
<li class="">
<p><strong>Cloud-optimized with random-prefixes</strong>: files are distributed across different paths (of even varying depth) across cloud storage, to circumvent scaling/throttling issues that plague
cloud storage systems, at the cost of losing easy navigation of storage folder tree using standard UI/CLI tools.</p>
</li>
<li class="">
<p><strong>Unpartitioned flat structure</strong>: tables can also be totally unpartitioned, where a single folder contains all the files that constitute a table.</p>
</li>
</ul>
<p>Metadata about the table is stored at a location on storage, referred to as <strong><em>basepath</em></strong>, which contains a special reserved <em>.hoodie</em> directory under the base path
is used to store transaction logs, metadata and indexes. A special file <a href="http://hoodie.properties/" target="_blank" rel="noopener noreferrer" class=""><code>hoodie.properties</code></a> under basepath persists table level configurations, shared by writers
and readers of the table. These configurations are explained <a href="https://github.com/apache/hudi/blob/master/hudi-common/src/main/java/org/apache/hudi/common/table/HoodieTableConfig.java" target="_blank" rel="noopener noreferrer" class="">here</a>, and any config without a default value needs to be specified during table creation.</p>
<div class="language-plain codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-plain codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">/data/hudi_trips/                         &lt;-- Base Path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── .hoodie/                              &lt;-- Meta Path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|   └── hoodie.properties                 &lt;-- Table Configs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── metadata/                         &lt;-- Metadata</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|       └── files/                        &lt;-- Files that make up the table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|       └── col_stats/                    &lt;-- Statistics on columns for each file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|       └── record_index/                 &lt;-- Unique index on record key</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|       └── [index_type]_[index_name]/    &lt;-- secondary indexes of different types</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|   └── .index_defs/index.json            &lt;-- index definitions </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── timeline/                   &lt;-- active timeline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|       └── history/                &lt;-- timeline history</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── americas/                       &lt;-- Data stored as folder tree</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   ├── brazil/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   │   └── sao_paulo               &lt;-- Partition Path </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   │       ├── [data_files]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── united_states/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│       └── san_francisco/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│           ├── [data_files]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── asia/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    └── india/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        └── chennai/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ├── [data_files]</span><br></span></code></pre></div></div>
<p>Data files can be either <strong><em>base files</em></strong> or <strong><em>log files</em></strong>. Base files contain records stored in columnar or SST table like file formats depending on use-cases.
Log files store deltas (partial or complete), deletes, change logs and other record level operations performed on the records in the base file. Data files are organized
into logical concepts called <strong><em>file groups</em></strong>, uniquely identified by a <strong><em>file id</em></strong>. Each record in the table is identified by an unique key and mapped to a single file group
at any given time. Within a file group, data files are further split into <strong><em>file slices</em></strong>, where each file slice contains an optional base file and a list of log files, that
constitute the state of all records in the file group at a given time. These constructs allows Hudi to efficiently support incremental operations, as will be evident later.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="timeline">Timeline<a href="#timeline" class="hash-link" aria-label="Direct link to Timeline" title="Direct link to Timeline" translate="no">​</a></h2>
<p>Hudi stores all actions performed on a table into a Log Structured Merge (<a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree" target="_blank" rel="noopener noreferrer" class="">LSM</a>) tree structure called the <strong><em>Timeline</em></strong>.
Unlike typical LSM implementations, the memory component and the write-ahead-log are at once replaced by <a href="https://avro.apache.org/" target="_blank" rel="noopener noreferrer" class="">avro</a> serialized files containing individual
actions (<strong><em>active timeline</em></strong>) for high durability and inter-process co-ordination. Every action on the Hudi table creates a new entry (<strong><em>instant</em></strong>) in the active timeline and periodically,
actions move from the active timeline to the LSM structure. Each new actions and state changes need to be atomically published to the timeline (see Appendix for storage specific guidelines to achieve that).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="time">Time<a href="#time" class="hash-link" aria-label="Direct link to Time" title="Direct link to Time" translate="no">​</a></h3>
<p>Each action on the timeline is stamped with a time at which it began and completed. The notion of time can be logical or physical timestamps, but it&#x27;s required that each timestamp
generated by a process is monotonically increasing with respect to the previous time generated by the same or another process. This requirement can be satisfied by implementing
a <a href="https://research.google/pubs/pub45855/" target="_blank" rel="noopener noreferrer" class="">TrueTime</a> generator with an external time generator or rely on system epoch times with assumed bounds on clock skews. See appendix for more.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="actions">Actions<a href="#actions" class="hash-link" aria-label="Direct link to Actions" title="Direct link to Actions" translate="no">​</a></h3>
<p>Actions have a plan (optional) and completion metadata associated with them that capture how the action alters the table state. The metadata is serialized as Avro, and the schema for
each of these actions is described in avro <a href="https://github.com/apache/hudi/tree/master/hudi-common/src/main/avro" target="_blank" rel="noopener noreferrer" class="">here</a>. The following are the key actions on the Hudi timeline.</p>
<table><thead><tr><th><strong>Action type</strong></th><th><strong>Description</strong></th><th><strong>Action Metadata</strong></th></tr></thead><tbody><tr><td>commit</td><td>A write operation that produces new base files containing either new records or modified values of existing records.</td><td>HoodieCommitMetadata</td></tr><tr><td>deltacommit</td><td>A write operation that produces new log files contains either new records or deltas/deletes for existing records. Optionally, it can also produce new log files.</td><td>HoodieCommitMetadata</td></tr><tr><td>replacecommit</td><td>A write operation that replaces a set of file groups with another atomically. It can be used to cluster the data for better query performance or rewrite files to enforce time-to-live. The requirement for this action is that the table state before and after are logically equivalent.</td><td>HoodieRequestedReplaceMetadata  HoodieReplaceCommitMetadata</td></tr><tr><td>clean</td><td>Management activity that cleans up older versions of data files that no longer will be accessed, to keep the storage size of the table in check.</td><td>HoodieCleanerPlan  HoodieCleanMetadata</td></tr><tr><td>compaction</td><td>Management activity that applies deltas/deletes from a set of log files to records on a base file and produces new base files. This amortizes the update costs, re-optimizes the file group to ultimately improve query performance.</td><td>HoodieCompactionOperation  HoodieCompactionMetadata</td></tr><tr><td>logcompaction</td><td>Management activity that consolidates a set of (typically smaller) log files into another log file within the same file group, to improve query performance between compaction actions.</td><td>HoodieCompactionOperation  HoodieCompactionMetadata</td></tr><tr><td>indexing</td><td>Management activity to build a new index from the table state. This action is used to update/build the index asynchronously even as write actions above happen on the table.</td><td>HoodieIndexPlan  HoodieIndexCommitMetadata</td></tr><tr><td>rollback</td><td>Denotes that the changes made by the corresponding commit/delta commit were unsuccessful &amp; hence rolled back, removing any partial files produced during such a write.</td><td>HoodieRollbackPlan  HoodieRollbackMetadata</td></tr><tr><td>savepoint</td><td>Savepoint is a special marker action to ensure a particular commit is not automatically cleaned. It helps restore the table to a point on the timeline, in case of disaster/data recovery scenarios</td><td>HoodieSavepointMetadata</td></tr><tr><td>restore</td><td>Restore denotes that the table was restored to a particular savepoint, physically removing data written after that savepoint.</td><td>HoodieRestorePlan  HoodieRestoreMetadata</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="states">States<a href="#states" class="hash-link" aria-label="Direct link to States" title="Direct link to States" translate="no">​</a></h3>
<p>An action can be in any one of the following states on the active timeline.</p>
<table><thead><tr><th><strong>State</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>requested</td><td>begin time for the action is generated and the action is requested along with any metadata to &quot;plan&quot; the action.  Stored in the active timeline as  <strong><em>[begin_instant_time].[action_type].[state]</em></strong></td></tr><tr><td>inflight</td><td>A process has attempted to execute a requested action. Note that this process could be still executing or failed midway. Actions are idempotent, and could fail many times in this state.  Stored in the active timeline as  <strong><em>[begin_instant_time].[action_type].[state]</em></strong></td></tr><tr><td>completed</td><td>completion time is generated and the action has completed successfully by publishing a file with both begin and completion time on the timeline.</td></tr></tbody></table>
<p>All the actions in requested/inflight states are stored in the active timeline as files named [<strong><em>begin_instant_time].[action_type].[requested|inflight]</em></strong>. Completed actions are stored along
with a time that denotes when the action was completed, in a file named [<strong><em>begin_instant_time]_[completion_instant_time].[action_type].</em></strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="lsm-timeline">LSM Timeline<a href="#lsm-timeline" class="hash-link" aria-label="Direct link to LSM Timeline" title="Direct link to LSM Timeline" translate="no">​</a></h3>
<p>Completed actions, their plans and completion metadata are stored in a more scalable LSM tree based timeline organized in an <strong><em>timeline/history</em></strong> storage location under the .hoodie metadata path.
It consists of Apache Parquet files with action instant data and bookkeeping metadata files, in the following manner.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">/.hoodie/timeline/history 					</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── _version_                               &lt;-- stores the manifest version that is current</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── manifest_1                              &lt;-- manifests store list of files in timeline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── manifest_2                              &lt;-- compactions, cleaning, writes produce new manifest files</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── ...                                      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── manifest_[N]                            &lt;-- there can be many manifest files at any given time</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── [min_time]_[max_time]_[level].parquet   &lt;-- files storing actual action details</span><br></span></code></pre></div></div>
<p>The schema of the individual files are as follows.</p>
<table><thead><tr><th><strong>File type</strong></th><th><strong>File naming</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>version</td><td>_version_</td><td>UTF-8 encoded string representing the manifest version to read. Version file should be atomically updated on storage when new manifests are created.</td></tr><tr><td>manifests</td><td>manifest_[N]</td><td>Contains a json string, with a list of file name and file length for all LSM files part of the timeline.</td></tr><tr><td>LSM files</td><td>[min_time]_[max_time]_[level].parquet</td><td>where :  <strong><em>min_time</em></strong> is the minimum begin time of all actions in the file  <strong><em>max_time</em></strong> is the maximum completion time of all actions in the file.  <strong><em>level</em></strong> is an integer starting from 0, indicating the level in the LSM tree.</td></tr></tbody></table>
<p>The actual parquet file <a href="https://github.com/apache/hudi/blob/master/hudi-common/src/main/avro/HoodieLSMTimelineInstant.avsc" target="_blank" rel="noopener noreferrer" class="">schema</a> is:</p>
<table><thead><tr><th><strong>Field name</strong></th><th><strong>Type</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>instantTime</td><td>string</td><td>the begin time of the action</td></tr><tr><td>completionTime</td><td>string</td><td>the completion time of the action</td></tr><tr><td>action</td><td>string</td><td>the action type</td></tr><tr><td>metadata</td><td>bytes</td><td>json string representing the completed metadata of the action</td></tr><tr><td>plan</td><td>bytes</td><td>Optional, avro serialized plan for the action, same as its requested/plan metadata</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-types">Table Types<a href="#table-types" class="hash-link" aria-label="Direct link to Table Types" title="Direct link to Table Types" translate="no">​</a></h2>
<p>Hudi storage format supports two table types offering different trade-offs between write and query performance (see appendix for more details) and records are stored differently based on the chosen table type.</p>
<table><thead><tr><th><strong>Table Type</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>Copy-on-Write (CoW)</td><td>Data is stored entirely in base files, optimized for read performance and ideal for slow changing datasets. Any updates, inserts, deletes accordingly produce new base files for each write operation. Change data is still stored as log files associated with the base files.</td></tr><tr><td>Merge-on-Read (MoR)</td><td>Data is stored in a combination of base and log files, optimized to <a href="#balancing-write-and-read-performance" class="">Balancing Write and Read Performance</a> and ideal for frequently changing datasets</td></tr></tbody></table>
<p>Readers need to then satisfy different query types on these tables.</p>
<ul>
<li class=""><strong>Snapshot queries</strong> - query the table for latest committed state of each record.</li>
<li class=""><strong>Time-Travel queries</strong> - snapshot query performed as of a point in timeline or equivalent on an older snapshot of the table.</li>
<li class=""><strong>Incremental queries</strong> - obtain the latest merged state of all records that have been updated/inserted between two points in the timeline.</li>
<li class=""><strong>Change Data Capture</strong> - obtain a change log of all modifications (updates, inserts, deletes) with before/after images for each record, between two points in the timeline.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-files">Data Files<a href="#data-files" class="hash-link" aria-label="Direct link to Data Files" title="Direct link to Data Files" translate="no">​</a></h2>
<p>Data Files have naming conventions that allows to easily track history of files with respect to the timeline as well as serving practical operational needs.
For e.g it&#x27;s quite possible to recover the table to a known good state, when operational accidents cause the timeline and other metadata are deleted.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="base-files">Base Files<a href="#base-files" class="hash-link" aria-label="Direct link to Base Files" title="Direct link to Base Files" translate="no">​</a></h3>
<p>Base files are standard well-known file formats like Apache Parquet, Apache Orc and Apache HBase&#x27;s HFile, named as [<strong><em>file_id]_[write_token]_[begin_time].[extension].</em></strong></p>
<p>where,</p>
<ul>
<li class=""><strong>file_id</strong> - Id of the file group that the base file belong to.</li>
<li class=""><strong>write_token</strong> - Monotonically increasing token for every attempt to write the base file within a given transaction. This should help uniquely identifying the base file when there are
failures and retries. Cleaning can remove partial/uncommitted base files by comparing with the successful write token.</li>
<li class=""><strong>requested_time</strong> - Time when this action was requested on the timeline.</li>
<li class=""><strong>extension</strong> - base file extension matching the file format such as .parquet, .orc.</li>
</ul>
<p>Note that a single file group can contain base files with different extensions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="log-files">Log Files<a href="#log-files" class="hash-link" aria-label="Direct link to Log Files" title="Direct link to Log Files" translate="no">​</a></h3>
<p>The log files contain different type of blocks, that encode delta updates, deletes or change logs against the base file. They are named with the convention</p>
<p><strong><em>.[file_id]_[requested_instant_time].log.[version]_[write_token]</em></strong>.</p>
<ul>
<li class=""><strong>file_id</strong> - File Id of the base file in the slice</li>
<li class=""><strong>requested_instant_time</strong> - Time at which the write operation that produced this log file was requested.</li>
<li class=""><strong>version</strong> - Current version of the log file format, to order deltas against the base file.</li>
<li class=""><strong>write_token</strong> - Monotonically increasing token for every attempt to write the log file. This should help uniquely identifying the log file when there are failures and retries.
Cleaner can clean-up partial log files if the write token is not the latest in the file slice.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="log-format">Log Format<a href="#log-format" class="hash-link" aria-label="Direct link to Log Format" title="Direct link to Log Format" translate="no">​</a></h3>
<p>The Log file format structure is a Hudi native format. The actual content bytes are serialized into one of Apache Avro, Apache Parquet or Apache HFile file formats based
on configuration and the other metadata in the block is serialized using primitive types and byte arrays.</p>
<p>Hudi Log format specification is as follows.</p>
<table><thead><tr><th>Section</th><th>#Bytes</th><th>Description</th></tr></thead><tbody><tr><td><strong>magic</strong></td><td>6</td><td>6 Characters &#x27;#HUDI#&#x27; stored as a byte array. Sanity check for block corruption to assert start 6 bytes matches the magic byte[].</td></tr><tr><td><strong>LogBlock length</strong></td><td>8</td><td>Length of the block excluding the magic.</td></tr><tr><td><strong>version</strong></td><td>4</td><td>Version of the Log file format, monotonically increasing to support backwards compatibility</td></tr><tr><td><strong>type</strong></td><td>4</td><td>Represents the type of the log block. Id of the type is serialized as an Integer.</td></tr><tr><td><strong>header length</strong></td><td>8</td><td>Length of the header section to follow</td></tr><tr><td><strong>header</strong></td><td>variable</td><td>Custom serialized map of header metadata entries. 4 bytes of map size that denotes number of entries, then for each entry 4 bytes of metadata type, followed by length/bytearray of variable length utf-8 string.</td></tr><tr><td><strong>content length</strong></td><td>8</td><td>Length of the actual content serialized</td></tr><tr><td><strong>content</strong></td><td>variable</td><td>The content contains the serialized records in one of the supported file formats (Apache Avro, Apache Parquet or Apache HFile)</td></tr><tr><td><strong>footer length</strong></td><td>8</td><td>Length of the footer section to follow</td></tr><tr><td><strong>footer</strong></td><td>variable</td><td>Similar to Header. Map of footer metadata entries.</td></tr><tr><td><strong>total block length</strong></td><td>8</td><td>Total size of the block including the magic bytes. This is used to determine if a block is corrupt by comparing to the block size in the header. Each log block assumes that the block size will be last data written in a block. Any data if written after is just ignored.</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="versioning">Versioning<a href="#versioning" class="hash-link" aria-label="Direct link to Versioning" title="Direct link to Versioning" translate="no">​</a></h3>
<p>Log file format versioning refers to a set of feature flags associated with a log format. The current version is <code>1</code>. Versions are changed when the log format changes.
The feature flags determine the behavior of the log file reader. The following are the feature flags associated with the log file format.</p>
<table><thead><tr><th>Flag</th><th>Version 0</th><th>Version 1</th><th>Default</th></tr></thead><tbody><tr><td>hasMagicHeader</td><td>True</td><td>True</td><td>True</td></tr><tr><td>hasContent</td><td>True</td><td>True</td><td>True</td></tr><tr><td>hasContentLength</td><td>True</td><td>True</td><td>True</td></tr><tr><td>hasOrdinal</td><td>True</td><td>True</td><td>True</td></tr><tr><td>hasHeader</td><td>False</td><td>True</td><td>True</td></tr><tr><td>hasFooter</td><td>False</td><td>True</td><td>False</td></tr><tr><td>hasLogBlockLength</td><td>False</td><td>True</td><td>False</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="headers">Headers<a href="#headers" class="hash-link" aria-label="Direct link to Headers" title="Direct link to Headers" translate="no">​</a></h3>
<p>Metadata key mapping from Integer to actual metadata is as follows:</p>
<table><thead><tr><th>Header Metadata</th><th>Encoding ID</th><th>Description</th></tr></thead><tbody><tr><td>INSTANT_TIME</td><td>1</td><td>Instant time corresponding to commit when the log block is added.</td></tr><tr><td>TARGET_INSTANT_TIME</td><td>2</td><td>Target instant to rollback, used in rollback command log block.</td></tr><tr><td>SCHEMA</td><td>3</td><td>Schema corresponding to data in the data block.</td></tr><tr><td>COMMAND_BLOCK_TYPE</td><td>4</td><td>Command block type for the command block. Currently, `ROLLBACK_BLOCK` is the only command block type.</td></tr><tr><td>COMPACTED_BLOCK_TIMES</td><td>5</td><td>Instant times corresponding to log blocks compacted due to minor log compaction.</td></tr><tr><td>RECORD_POSITIONS</td><td>6</td><td>Record positions of the records in base file that were updated (data block) or deleted (delete block). Record position is a long type, however, the list of record positions is Base64-encoded bytes of serialized `Roaring64NavigableMap` bitmap.</td></tr><tr><td>BLOCK_IDENTIFIER</td><td>7</td><td>Block sequence number used to detect duplicate log blocks due to task retries for instance.</td></tr><tr><td>IS_PARTIAL</td><td>8</td><td>Boolean indicating whether the data block is created with partial updates enabled.</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="block-types">Block types<a href="#block-types" class="hash-link" aria-label="Direct link to Block types" title="Direct link to Block types" translate="no">​</a></h3>
<p>The following are the possible block types used in Hudi Log Format:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="command-block-id-1">Command Block (Id: 1)<a href="#command-block-id-1" class="hash-link" aria-label="Direct link to Command Block (Id: 1)" title="Direct link to Command Block (Id: 1)" translate="no">​</a></h3>
<p>Encodes a command to the log reader. The Command block must be 0 byte content block which only populates the metadata Command Block Type.
Only possible values in the current version of the log format is ROLLBACK_PREVIOUS_BLOCK, which lets the reader to undo the previous block written in the log file.
This denotes that the previous action that wrote the log block was unsuccessful.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="delete-block-id-2">Delete Block (Id: 2)<a href="#delete-block-id-2" class="hash-link" aria-label="Direct link to Delete Block (Id: 2)" title="Direct link to Delete Block (Id: 2)" translate="no">​</a></h3>
<table><thead><tr><th>Section</th><th>#bytes</th><th>Description</th></tr></thead><tbody><tr><td>format version</td><td>4</td><td>version of the log file format</td></tr><tr><td>length</td><td>8</td><td>length of the deleted keys section to follow</td></tr><tr><td>deleted keys</td><td>variable</td><td>Tombstone of the record to encode a delete. The following 3 fields are serialized using the KryoSerializer. <strong>Record Key</strong> - Unique record key within the partition to deleted <strong>Partition Path</strong> - Partition path of the record deleted <strong>Ordering Value</strong> - In a particular batch of updates, the delete block is always written after the data (Avro/HFile/Parquet) block. This field would preserve the ordering of deletes and inserts within the same batch.</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="corrupted-block-id-3">Corrupted Block (Id: 3)<a href="#corrupted-block-id-3" class="hash-link" aria-label="Direct link to Corrupted Block (Id: 3)" title="Direct link to Corrupted Block (Id: 3)" translate="no">​</a></h3>
<p>This block type is never written to persistent storage. While reading a log block, if the block is corrupted, then the reader gets an instance of the
Corrupted Block instead of a Data block. It is a reserved ID for handling cases of corrupt or partially written blocks, for example on HDFS.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="avro-block-id-4">Avro Block (Id: 4)<a href="#avro-block-id-4" class="hash-link" aria-label="Direct link to Avro Block (Id: 4)" title="Direct link to Avro Block (Id: 4)" translate="no">​</a></h3>
<p>Data block serializes the actual records written into the log file</p>
<table><thead><tr><th>Section</th><th>#bytes</th><th>Description</th></tr></thead><tbody><tr><td>format version</td><td>4</td><td>version of the log file format</td></tr><tr><td>record count</td><td>4</td><td>total number of records in this block</td></tr><tr><td>record length</td><td>8</td><td>length of the record content to follow</td></tr><tr><td>record content</td><td>variable</td><td>Record represented as an Avro record serialized using BinaryEncoder</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hfile-block-id-5">HFile Block (Id: 5)<a href="#hfile-block-id-5" class="hash-link" aria-label="Direct link to HFile Block (Id: 5)" title="Direct link to HFile Block (Id: 5)" translate="no">​</a></h3>
<p>The HFile data block serializes the records using the HFile file format. HFile data model is a key value pair and both are encoded as byte arrays. Hudi record key is encoded
as Avro string and the Avro record serialized using BinaryEncoder is stored as the value. HFile file format stores the records in sorted order and with index to enable quick point reads and range scans.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="parquet-block-id-6">Parquet Block (Id: 6)<a href="#parquet-block-id-6" class="hash-link" aria-label="Direct link to Parquet Block (Id: 6)" title="Direct link to Parquet Block (Id: 6)" translate="no">​</a></h3>
<p>The Parquet Block serializes the records using the Apache Parquet file format. The serialization layout is similar to the Avro block except for the byte array content encoded in
columnar Parquet format. This log block type enables efficient columnar scans and better compression. Different data block types offers different trade-offs and picking the right block is based on the workload requirements and is critical for merge and read performance.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cdc-block-id-7">CDC Block (Id: 7)<a href="#cdc-block-id-7" class="hash-link" aria-label="Direct link to CDC Block (Id: 7)" title="Direct link to CDC Block (Id: 7)" translate="no">​</a></h3>
<p>The CDC block is used for change data capture and it encodes the before and after image of the record as an Avro data block as follows:</p>
<table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>HoodieCDCOperation</td><td>Type of the CDC operation. Can be INSERT, UPSERT, DELETE</td></tr><tr><td>recordKey</td><td>Key of the record being changed</td></tr><tr><td>oldRecord</td><td>This is the before image</td></tr><tr><td>newRecord</td><td>This is the after image</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-properties">Table Properties<a href="#table-properties" class="hash-link" aria-label="Direct link to Table Properties" title="Direct link to Table Properties" translate="no">​</a></h2>
<p>As mentioned in the <a href="#storage-layout" class="">storage layout</a> section, the table properties are stored in the <code>hoodie.properties</code> file under the <code>.hoodie</code> directory in the table base path.
Below is the list of properties that are stored in this file.</p>
<table><thead><tr><th>Table Config</th><th>Description</th></tr></thead><tbody><tr><td>hoodie.database.name</td><td>Database name under which tables will be created</td></tr><tr><td>hoodie.table.name</td><td>Table name</td></tr><tr><td>hoodie.table.type</td><td>Table type - COPY_ON_WRITE or MERGE_ON_READ</td></tr><tr><td>hoodie.table.version</td><td>Table format version</td></tr><tr><td>hoodie.table.recordkey.fields</td><td>Comma-separated list of fields used for record keys. This property is optional.</td></tr><tr><td>hoodie.table.partition.fields</td><td>Comma-separated list of fields used for partitioning the table. This property is optional.</td></tr><tr><td>hoodie.table.precombine.field</td><td>Field used to break ties when two records have same value for the record key. This property is optional.</td></tr><tr><td>hoodie.timeline.layout.version</td><td>Version of timeline used by the table.</td></tr><tr><td>hoodie.table.checksum</td><td>Table checksum used to guard against partial writes on HDFS. The value is auto-generated.</td></tr><tr><td>hoodie.table.metadata.partitions</td><td>Comma-separated list of metadata partitions that can be used by reader, e.g. <em>files</em>, <em>column_stats</em></td></tr><tr><td>hoodie.table.index.defs.path</td><td>Absolute path where the index definitions are stored for various indexes created by the users. This property is optional.</td></tr></tbody></table>
<p>The record key, precombine and partition fields are optional but play an important role in modeling data stored in Hudi
table.</p>
<table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>Partitioning key(s)</td><td>Value of this field defines the directory hierarchy within the table base path. This essentially provides an hierarchy isolation for managing data and related metadata</td></tr><tr><td>Record key(s)</td><td>Record keys uniquely identify a record within each partition.</td></tr><tr><td>Ordering field(s)</td><td>Hudi guarantees the uniqueness constraint of record key and the conflict resolution configuration manages strategies on how to disambiguate when multiple records with the same keys are to be merged into the table. The resolution logic can be based on an ordering field or can be custom, specific to the table. To ensure consistent behaviour dealing with duplicate records, the resolution logic should be commutative, associative and idempotent. This is also referred to as ‘precombine field’.</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="metadata">Metadata<a href="#metadata" class="hash-link" aria-label="Direct link to Metadata" title="Direct link to Metadata" translate="no">​</a></h2>
<p>Hudi automatically extracts the physical data statistics and stores the metadata along with the data to improve write and query performance. Hudi Metadata is an internally-managed
table which organizes the table metadata under the base path <em>.hoodie/metadata.</em> The metadata is in itself a Hudi table, organized with the Hudi merge-on-read storage format.
Every record stored in the metadata table is a Hudi record and hence has partitioning key and record key specified. Following metadata is stored in the metadata table.</p>
<ul>
<li class=""><strong>files</strong> - Partition path to file name index. Key for the Hudi record is the partition path and the actual record is a map of file name to an instance of <code>HoodieMetadataFileInfo</code>.
Additionally, a special key <code>__all_partitions__</code> holds the list of all partitions. The files index can be used to do file listing and do filter based pruning of the scanset during query</li>
<li class=""><strong>column_stats</strong> - contains statistics of columns for all the records in the table. This enables fine-grained file pruning for filters and join conditions in the query.
The actual payload is an instance of <code>HoodieMetadataColumnStats</code>.</li>
</ul>
<p>Apache Hudi platform employs HFile format, to store metadata and indexes, to ensure high performance, though different implementations are free to choose their own.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="file-listings">File Listings<a href="#file-listings" class="hash-link" aria-label="Direct link to File Listings" title="Direct link to File Listings" translate="no">​</a></h3>
<p>File listing is an index of partition path to file name stored under the partition <code>files</code> in the metadata table.
The files index can be used to do file listing and do filter based pruning of the scanset during query.
Key for the Hudi record is the partition path and the actual record is a map of file name to an instance of <code>HoodieMetadataFileInfo</code> that encodes file group ID and instant time along with file metadata.
Additionally, a special key <code>__all_partitions__</code> holds the list of all partitions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="column-statistics">Column Statistics<a href="#column-statistics" class="hash-link" aria-label="Direct link to Column Statistics" title="Direct link to Column Statistics" translate="no">​</a></h3>
<p>Column statistics is stored under the partition <code>column_stats</code> in the metadata table. The actual payload is an instance of <code>HoodieMetadataColumnStats</code>.
It contains statistics (min/max/nullCount) of columns for all the records in the table. This enables fine-grained file pruning for filters and join conditions in the query.
The Hudi key is <code>str_concat(hash(column name), str_concat(hash(partition name), hash(file name)))</code> and the actual payload is an instance of <code>HoodieMetadataColumnStats</code>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="meta-fields">Meta Fields<a href="#meta-fields" class="hash-link" aria-label="Direct link to Meta Fields" title="Direct link to Meta Fields" translate="no">​</a></h3>
<p>In addition to the fields specified by the table&#x27;s schema, the following meta fields are added to each record, to unlock incremental processing and ease of debugging. These meta fields are part of the table schema and
stored with the actual record to avoid re-computation.</p>
<table><thead><tr><th>Hudi meta-fields</th><th>Description</th></tr></thead><tbody><tr><td>_hoodie_commit_time</td><td>This field contains the commit timestamp in the timeline that created this record. This enables granular, record-level history tracking on the table, much like database change-data-capture.</td></tr><tr><td>_hoodie_commit_seqno</td><td>This field contains a unique sequence number for each record within each transaction. This serves much like offsets in Apache Kafka topics, to enable generating streams out of tables.</td></tr><tr><td>_hoodie_record_key</td><td>Unique record key identifying the record within the partition. Key is materialized to avoid changes to key field(s) resulting in violating unique constraints maintained within a table.</td></tr><tr><td>_hoodie_partition_path</td><td>Partition path under which the record is organized into.</td></tr><tr><td>_hoodie_file_name</td><td>The data file name this record belongs to.</td></tr></tbody></table>
<p>Within a given file, all records share the same values for <code>_hoodie_partition_path</code> and <code>_hoodie_file_name</code>, thus easily compressed away without any overheads with columnar file formats.
The other fields can also be optional for writers depending on whether protection against key field changes or incremental processing is desired. More on how to populate these fields in the sections below.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="indexes">Indexes<a href="#indexes" class="hash-link" aria-label="Direct link to Indexes" title="Direct link to Indexes" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="naming">Naming<a href="#naming" class="hash-link" aria-label="Direct link to Naming" title="Direct link to Naming" translate="no">​</a></h3>
<p>Indexes are stored under <code>.hoodie/metadata</code> storage path, with separate partitions of the  form <code>&lt;index_type&gt;_&lt;index_name&gt;</code>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bloom-filter-index">Bloom Filter Index<a href="#bloom-filter-index" class="hash-link" aria-label="Direct link to Bloom Filter Index" title="Direct link to Bloom Filter Index" translate="no">​</a></h3>
<p>Bloom filter index is used to accelerate &#x27;presence checks&#x27; validating whether particular record is present in the file, which is used during merging, hash-based joins, point-lookup queries, etc.
The bloom filter index is stored in Hudi metadata table under the partition <code>bloom_filters</code>.
The Hudi key is <code>str_concat(hash(partition name), hash(file name))</code> and the actual payload is an instance of <code>HudiMetadataBloomFilter</code> with the following schema:</p>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td>type</td><td>A string that refers to the bloom filter type. Bloom filter type can be simple or dynamic depending on whether the filter is based on a configured size or auto-sized based on number of keys.</td></tr><tr><td>bloomFilter</td><td>Serialized byte array of the bloom filter content.</td></tr><tr><td>timestamp</td><td>A string that refers to instant timestamp when this bloom filter metadata record was created/updated.</td></tr><tr><td>isDeleted</td><td>A boolean that represents Bboom filter entry valid/deleted flag.</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="record-index">Record Index<a href="#record-index" class="hash-link" aria-label="Direct link to Record Index" title="Direct link to Record Index" translate="no">​</a></h3>
<p>Record index contains mappings of individual record key and the corresponding file group id.
The record index not only dramatically boosts write efficiency but also improves read efficiency for keyed lookups.
The record index is stored in Hudi metadata table under the partition <code>record_index</code>. The Hudi key is the value of record key and the actual payload is an instance of <code>HoodieRecordIndexInfo</code> with the following schema:</p>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td>partitionName</td><td>A string that refers to the partition name the record belongs to.</td></tr><tr><td>fileIdHighBits</td><td>A long that refers to high 64 bits if the fileId is based on UUID format. A UUID based fileId is stored as 3 pieces in RLI (fileIdHighBits, fileIdLowBits and fileIndex). FileID format is {UUID}-{fileIndex}.</td></tr><tr><td>fileIdLowBits</td><td>A long that refers to low 64 bits if the fileId is based on UUID format.</td></tr><tr><td>fileIndex</td><td>An integer that refers to index representing file index which is used to reconstruct UUID based fileID. Applicable when the fileId is based on UUID format.</td></tr><tr><td>fileIdEncoding</td><td>An integer that represents fileId encoding. Possible values are 0 and 1. O represents UUID based fileID, and 1 represents raw string format of the fileId. When the encoding is 0, reader can deduce fileID from fileIdLowBits, fileIdLowBits and fileIndex.</td></tr><tr><td>fileId</td><td>A string that represents fileId of the location where record belongs to. When the encoding is 1, fileID is stored in raw string format.</td></tr><tr><td>instantTime</td><td>A long that represents epoch time in millisecond representing the commit time at which record was added.</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="secondary-index">Secondary Index<a href="#secondary-index" class="hash-link" aria-label="Direct link to Secondary Index" title="Direct link to Secondary Index" translate="no">​</a></h3>
<p>Just like databases, secondary index is a way to accelerate the queries by columns other than the record (primary) keys.
Hudi supports near-standard <a class="" href="/docs/sql_ddl#create-index">SQL syntax</a> for creating/dropping indexes on different columns
via Spark SQL, along with an asynchronous indexing table service to build indexes without interrupting the writers.</p>
<p>Secondary index definition is serialized to JSON format and saved at a path specified by <code>hoodie.table.index.defs.path</code>.
The index itself is stored in Hudi metadata table under the partition <code>secondary_index_&lt;index_name&gt;</code>. As usual the index
record is a key-value, however the encoding is slightly more nuanced.</p>
<p><strong>Key</strong> is constructed by combining the values of <strong>secondary column</strong> and <strong>primary key column</strong> separated by a delimiter.
The key is encoded in a format that ensures:</p>
<ol>
<li class=""><strong>Uniqueness</strong>: Each key is distinct.</li>
<li class=""><strong>Safety</strong>: Any occurrences of the delimiter or escape character within the data itself are handled correctly to avoid ambiguity.</li>
<li class=""><strong>Efficiency</strong>: The encoding and decoding processes are optimized for performance while ensuring data integrity.</li>
</ol>
<p>The key format is:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">&lt;escaped-secondary-key&gt;$&lt;escaped-primary-key&gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Where:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  - `$` is the delimiter separating the secondary key and primary key.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  - Special characters in the secondary or primary key (`$` and `\`) are escaped to avoid conflicts.</span><br></span></code></pre></div></div>
<p><strong>Value</strong> contains metadata about the record, specifically an <code>isDeleted</code> flag indicating whether the record is valid or has been logically deleted.</p>
<p>For example, consider a secondary index on the <code>city</code> column. The key-value pair for a record with <code>city</code> as <code>Chennai</code> and <code>id</code> as <code>id1</code> would look like:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">chennai$id1 -&gt; {&quot;isDeleted&quot;: false}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="expression-indexes">Expression Indexes<a href="#expression-indexes" class="hash-link" aria-label="Direct link to Expression Indexes" title="Direct link to Expression Indexes" translate="no">​</a></h3>
<p>A <a href="https://github.com/apache/hudi/blob/00ece7bce0a4a8d0019721a28049723821e01842/rfc/rfc-63/rfc-63.md" target="_blank" rel="noopener noreferrer" class="">expression index</a> is an index on a function of a column.
Hudi supports creating expression indexes for certain unary string and timestamp functions supported.
The index definition specified by the user is serialized to JSON format and saved at a path specified by <code>hoodie.table.index.defs.path</code> in <a href="#table-properties" class="">table properties</a>.
Index itself is stored in Hudi metadata table under the partition <code>expr_index_&lt;user_specified_index_name&gt;</code>.</p>
<p>We covered different <a href="#storage-layout" class="">storage layouts</a> earlier. Functional index aggregates stats by storage partitions and, as such, partitioning can be absorbed into functional indexes.
From that perspective, some useful functions that can also be applied as transforms on a field to extract and index partitions are listed below.</p>
<table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>identity</code></td><td>Identity function, unmodified value</td></tr><tr><td><code>year</code></td><td>Year of the timestamp</td></tr><tr><td><code>month</code></td><td>Month of the timestamp</td></tr><tr><td><code>day</code></td><td>Day of the timestamp</td></tr><tr><td><code>hour</code></td><td>Hour of the timestamp</td></tr><tr><td><code>lower</code></td><td>Lower case of the string</td></tr><tr><td><code>from_unixtime</code></td><td>Convert unix epoch to a string representing the timestamp in the specified format</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="relational-model">Relational Model<a href="#relational-model" class="hash-link" aria-label="Direct link to Relational Model" title="Direct link to Relational Model" translate="no">​</a></h2>
<p>This section describes how to implement a traditional relational model, with concurrent writers on top of the storage format described so far.
Specifically, it aims to employ optimistic concurrency control between writers to guarantee serializable execution of write operations. To achieve this,
Hudi assumes the availability of a distributed lock service (see appendix for lock provider implementations) to acquire an exclusive table level lock.</p>
<p>There are three types of processes at play at any given time :</p>
<ul>
<li class="">Writers that are modifying the state of the table, with updates, deletes and inserts.</li>
<li class="">Table services which do not logically change the state of the table.</li>
<li class="">Readers that are querying the state of the table.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="writer-expectations">Writer Expectations<a href="#writer-expectations" class="hash-link" aria-label="Direct link to Writer Expectations" title="Direct link to Writer Expectations" translate="no">​</a></h3>
<p>Writers generate a begin time for their actions, proceed to create new base and log files and will finally transition the action state to completed atomically on the timeline as follows.</p>
<ol>
<li class="">Writer requests a begin time for the write action as defined in the Timeline section above (this may involve a lock, depending on TrueTime generation mechanism used).
Writer also records the latest completion time on the timeline (let&#x27;s call this <strong><em>snapshot write time</em></strong>).</li>
<li class="">Writer produces new base and log files with updated, deleted, inserted records, while ensuring updates/deletes reach the correct file group by looking up an index as
of the snapshot write time (see appendix for an alternative way to encode updates as deletes to an existing file group and inserts into a new file group, along with performance tradeoffs).</li>
<li class="">Writer then grabs a distributed lock and proceeds to perform the following steps within the critical section of the lock to finalize the write or fail/abort.<!-- -->
<ol>
<li class="">Obtain metadata about all actions that have completed with completion time greater than base snapshot time. This defines the <strong><em>concurrent set</em></strong> of
actions against which the writer needs to checks if any concurrent write operations or table service actions conflict with it.</li>
<li class="">Writer checks for any overlapping file groups that have been written to in the concurrent set and decides to abort if so.</li>
<li class="">Writer checks for any compactions planned or clustering actions completed on overlapping file groups and decides to abort if so.</li>
<li class="">Writer reads out all record keys written by the concurrent set and compares it against keys from files it is about to commit. If there are any overlaps,
the writer decides to abort (implementations could omit this check for performance reasons with the ensuing tradeoffs/limitations, if deemed acceptable)</li>
<li class="">Writer checks</li>
<li class="">If any of the checks above are true, writer releases the lock and aborts the write.</li>
</ol>
</li>
<li class="">If checks in (3) pass, the writer proceeds to finalizing the write, while holding the lock.<!-- -->
<ol>
<li class="">Writer updates the metadata and index based on the new files/records added to the table, and commits it to the metadata table timeline.</li>
<li class="">Writer generates a completion time for the write and records it to the timeline atomically, along with necessary metadata</li>
<li class="">Optionally, writer plans any table services or even runs them. This is again an implementation choice.</li>
<li class="">Writer releases the lock.</li>
</ol>
</li>
</ol>
<p>Note that specific writer implementations can choose to even abort early to improve efficiency and reduce resource wastage,
if they can detect conflicts using mechanisms like marker files described in the appendix.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-servicewriter-concurrency">Table Service/Writer Concurrency<a href="#table-servicewriter-concurrency" class="hash-link" aria-label="Direct link to Table Service/Writer Concurrency" title="Direct link to Table Service/Writer Concurrency" translate="no">​</a></h3>
<p>All table services acquire the same exclusive lock as writers above to plan and finalize action, including updating the metadata/indexes.
Table services plans are serialized within the lock and once requested on the timeline are idempotent and expected to complete eventually with
potential retries on failures. External table service management and built-in optional table services within writer processes can seamlessly co-exist and merely a deployment convenience.</p>
<p>Table services should follow these expectations to ensure they don&#x27;t block each other.</p>
<table><thead><tr><th><strong>Table Service</strong></th><th><strong>Expectation</strong></th></tr></thead><tbody><tr><td>Cleaning</td><td>planning or finalizing does not conflict with any table service by definition.</td></tr><tr><td>Clustering</td><td>Should abort if it concurrent updates to same file groups being clustered are detected when finalizing.</td></tr><tr><td>Compaction</td><td>Should exclude file groups already planned for clustering, from its plan.  Could abort if it file groups being compacted have been since replaced/clustered (correctness is not affected if either way)</td></tr><tr><td>Indexing</td><td>Indexing can plan and finalize asynchronously with any table service or writer, once planed as above within the lock.</td></tr></tbody></table>
<p>Thus, Hudi does not treat table service actions as opaque modifications to the table and thus supports running compaction without blocking writers helpful for high update/concurrency workloads.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="concurrent-readers">Concurrent readers<a href="#concurrent-readers" class="hash-link" aria-label="Direct link to Concurrent readers" title="Direct link to Concurrent readers" translate="no">​</a></h3>
<p>The model supports snapshot isolation for concurrent readers. A reader constructs the state of the table based on the action with the greatest completion time and proceeds
to construct file slices out of file groups that are of interest to the read, based on the type of query. Two concurrent readers are never in contention even in the presence of concurrent writes happening.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="reader-expectations">Reader Expectations<a href="#reader-expectations" class="hash-link" aria-label="Direct link to Reader Expectations" title="Direct link to Reader Expectations" translate="no">​</a></h3>
<p>Readers further need to determine the correct file slice (an optional base file plus an ordered list of log files) to read in order to construct the snapshot state using the following steps</p>
<ol>
<li class="">Reader picks an instant in the timeline - latest completion time on the timeline or a specific time explicitly specified. Let&#x27;s call this <strong><em>snapshot read time</em></strong>.</li>
<li class="">Reader computes all file groups in the table, by first all files part of the table, grouping them by file_id and then eliminating files that don&#x27;t belong to any completed write action on the timeline</li>
<li class="">Reader then further eliminates replaced file groups, by removing any file groups that are part of any <strong><em>replacecommit</em></strong> actions completed on the timeline.</li>
<li class="">For each remaining file group, the reader proceeds to determine the correct file slice as follows.<!-- -->
<ol>
<li class="">find the base file with greatest begin time less than snapshot read time.</li>
<li class="">obtain all log files with completion time less than or equal to snapshot read time, sorted by completion time.</li>
</ol>
</li>
<li class="">For each file slice obtained, the reader proceeds to merge the base and log files as follows.<!-- -->
<ol>
<li class="">When the base file is scanned, for every record block, the reader has to lookup if there is a newer version of the record available in the log blocks and merge them into the record iterator.</li>
</ol>
</li>
</ol>
<p>Obtaining the listings from storage could be slow or inefficient. It can be further optimized by caching in memory or using the files metadata or with the support of an external timeline serving system.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="incremental-streaming-model">Incremental Streaming Model<a href="#incremental-streaming-model" class="hash-link" aria-label="Direct link to Incremental Streaming Model" title="Direct link to Incremental Streaming Model" translate="no">​</a></h2>
<p>Optimistic concurrency control yields poor performance with long running transactions and even moderate levels of writer contention. While the relation model is well-understood,
serializability based on arbitrary system time (e.g completion times in Hudi or SCNs in databases) may be an overkill and even inadequate for many scenarios. Hudi storage also supports
an alternative model based on stream processing techniques, with the following changes.</p>
<ol>
<li class=""><strong>Event-time based ordering</strong>: Instead of merging base and log files based on completion times, latest value for a record is picked based on
a user-specified event field that denotes the latest version of the record.</li>
<li class=""><strong>Relaxed expectations to block/abort</strong>: By tracking the span of actions using both begin and completion times on the timeline, processes can
detect conflicting actions and adjust file slicing accordingly. For e.g this model allows compaction to be even planned without blocking writer processes.</li>
<li class=""><strong>Custom merging</strong> : Support implementation of custom merges using RecordPayload and RecordMerger APIs.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="non-blocking-concurrency-control">Non-blocking Concurrency Control<a href="#non-blocking-concurrency-control" class="hash-link" aria-label="Direct link to Non-blocking Concurrency Control" title="Direct link to Non-blocking Concurrency Control" translate="no">​</a></h3>
<p>Please refer to <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-66/rfc-66.md" target="_blank" rel="noopener noreferrer" class="">RFC-66</a> for more and a proof of correctness.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-management">Table Management<a href="#table-management" class="hash-link" aria-label="Direct link to Table Management" title="Direct link to Table Management" translate="no">​</a></h2>
<p>All table services can be run synchronous with the Table client that merges modifications to the data or can be run asynchronously to the table client.
Asynchronous is default mode in the Apache Hudi platform. Any client can trigger table management by registering a &#x27;requested&#x27; state action in the Hudi timeline.
Process in charge of running the table management tasks asynchronously looks for the presence of this trigger in the timeline.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="compaction">Compaction<a href="#compaction" class="hash-link" aria-label="Direct link to Compaction" title="Direct link to Compaction" translate="no">​</a></h3>
<p>Compaction is the process that efficiently updates a file slice (base and log files) for efficient querying. It applies all the batched up updates
in the log files and writes a new file slice. The logic to apply the updates to the base file follows the same set of rules listed in the Reader expectations.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="log-compaction">Log Compaction<a href="#log-compaction" class="hash-link" aria-label="Direct link to Log Compaction" title="Direct link to Log Compaction" translate="no">​</a></h3>
<p>Log compaction is a minor compaction operation that stitches together log files into a single large log file, thus
reducing write amplification. This process involves introducing a new action in Hudi called <code>logcompaction</code>, on the
timeline. The log-compacted file is written to the same file group as the log files being compacted. Additionally, the
log-compacted log block header contains the <code>COMPACTED_BLOCK_TIMES</code> and the log file reader can skip log blocks that
have been compacted, thus reducing read amplification as well.
See <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-48/rfc-48.md" target="_blank" rel="noopener noreferrer" class="">RFC-48</a> for more details.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="re-writing">Re-writing<a href="#re-writing" class="hash-link" aria-label="Direct link to Re-writing" title="Direct link to Re-writing" translate="no">​</a></h3>
<p>If the natural ingestion ordering does not match the query patterns, then data skipping does not work efficiently. It is important for query efficiency
to be able to skip as much data on filter and join predicates with column level statistics. Clustering columns need to be specified on the Hudi table.
The goal of the clustering table service, is to group data often accessed together and consolidate small files to the optimum target file size for the table.</p>
<ol>
<li class="">Identify file groups that are eligible for clustering - this is chosen based on the clustering strategy (file size based, time based etc)</li>
<li class="">Identify clustering groups (file groups that should be clustered together) and each group should expect data sizes in multiples of the target file size.</li>
<li class="">Persist the clustering plan in the Hudi timeline as a replacecommit, when clustering is requested.</li>
<li class="">Clustering execution can then read the individual clustering groups, write back new file groups with target size with base files sorted by the specified clustering columns.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cleaning">Cleaning<a href="#cleaning" class="hash-link" aria-label="Direct link to Cleaning" title="Direct link to Cleaning" translate="no">​</a></h3>
<p>Cleaning is a process to free up storage space. Apache Hudi maintains a timeline and multiple versions of the files written as file slices.
It is important to specify a cleaning protocol which deletes older versions and reclaims the storage space. Cleaner cannot delete versions that
are currently in use or will be required in future. Snapshot reconstruction on a commit instant which has been cleaned is not possible.</p>
<p>For e.g, there are a couple of retention policies supported in Apache Hudi platform</p>
<ul>
<li class=""><strong>keep_latest_commits</strong>: This is a temporal cleaning policy that ensures the effect of having look-back into all the changes that happened in the last X commits.</li>
<li class=""><strong>keep_latest_file_versions</strong>: This policy has the effect of keeping a maximum of N number of file versions irrespective of time.</li>
</ul>
<p>Apache Hudi provides snapshot isolation between writers and readers by managing multiple files with MVCC concurrency. These file versions provide history
and enable time travel and rollbacks, but it is important to manage how much history you keep to balance your storage costs.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="indexing">Indexing<a href="#indexing" class="hash-link" aria-label="Direct link to Indexing" title="Direct link to Indexing" translate="no">​</a></h3>
<p>Indexing is an asynchronous process to create indexes on the table without blocking ingestion writers. The indexing is
divided into two phases: scheduling and execution. During scheduling, the indexer takes a lock for a short duration and
generates an indexing plan for data files based off of a snapshot. Index plan is serialized as avro bytes and stored in <code>[instant].indexing.requested</code> file in the timeline.
Here&#x27;s the schema for index plan</p>
<table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td>version</td><td>Index plan version. Current version is 1. It is updated whenever the index plan format changes</td></tr><tr><td>indexPartitionInfos</td><td>An array of <code>HoodieIndexPartitionInfo</code>s. Each array element consists of metadata partition path, base instant off of which indexer started and an optional map of extra metadata</td></tr></tbody></table>
<p>During execution, the indexer executes the plan, writing the index base file in the metadata table. Any ongoing commit
update the index in log files under the same filegroup. After writing the base file, the indexer checks for all
completed commit instants after <code>t</code> to ensure each of them added entries per its indexing plan, otherwise simply abort
gracefully. Finally, when the indexing is complete, the indexer writes the <code>[instant].indexing</code> to the timeline. Indexer
only takes a lock while adding events to the timeline and not while writing index files.
See <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-45/rfc-45.md" target="_blank" rel="noopener noreferrer" class="">RFC-45</a> for now.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="compatibility">Compatibility<a href="#compatibility" class="hash-link" aria-label="Direct link to Compatibility" title="Direct link to Compatibility" translate="no">​</a></h2>
<p>Compatibility between different readers and writers is enforced through the <code>hoodie.table.version</code> table config. Hudi storage format evolves in a backwards
compatible way for readers, where newer readers can read older table versions correctly. However older readers may be required to upgrade in order to read higher table versions.
Hence, we recommend upgrading readers first, before upgrading writers when the table version evolves.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="change-log">Change Log<a href="#change-log" class="hash-link" aria-label="Direct link to Change Log" title="Direct link to Change Log" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="version-8">version 8<a href="#version-8" class="hash-link" aria-label="Direct link to version 8" title="Direct link to version 8" translate="no">​</a></h3>
<p>This is a breaking format version. Users may need to first migrate completely to the new timeline before resuming normal table operations.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="version-6--earlier">version 6 &amp; earlier<a href="#version-6--earlier" class="hash-link" aria-label="Direct link to version 6 &amp; earlier" title="Direct link to version 6 &amp; earlier" translate="no">​</a></h3>
<p>Please refer to the previous tech specs <a href="https://hudi.apache.org/tech-specs" target="_blank" rel="noopener noreferrer" class="">document</a>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="apis">APIs<a href="#apis" class="hash-link" aria-label="Direct link to APIs" title="Direct link to APIs" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="recordmerger-api">RecordMerger API<a href="#recordmerger-api" class="hash-link" aria-label="Direct link to RecordMerger API" title="Direct link to RecordMerger API" translate="no">​</a></h3>
<p>Hudi data model ensures record key uniqueness constraint, to maintain this constraint every single record merged into the table needs to be checked if the
same record key already exists in the table. If it does exist, the conflict resolution strategy is applied to create a new merged record to be persisted.
This check is done at the file group level and every record merged needs to be tagged to a single file group. By default, record merging is done during the merge which
makes it efficient for queries but for certain real-time streaming requirements, it can also be deferred to the query as long as there is a consistent way to mapping
the record key to a certain file group using consistent hashing techniques.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="indexing-functions">Indexing Functions<a href="#indexing-functions" class="hash-link" aria-label="Direct link to Indexing Functions" title="Direct link to Indexing Functions" translate="no">​</a></h3>
<p>See <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-63/rfc-63.md" target="_blank" rel="noopener noreferrer" class="">RFC-63</a> for design and direction.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="appendix">Appendix<a href="#appendix" class="hash-link" aria-label="Direct link to Appendix" title="Direct link to Appendix" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="lock-provider-implementations">Lock Provider Implementations<a href="#lock-provider-implementations" class="hash-link" aria-label="Direct link to Lock Provider Implementations" title="Direct link to Lock Provider Implementations" translate="no">​</a></h3>
<p>Apache Hudi platform uses optimistic locking and provides a pluggable LockProvider interface and multiple implementations are available out of the box (Apache Zookeeper, DynamoDB, Apache Hive
and JVM Level in-process lock). It is also worth noting that, if multiple writers originate from the same JVM client, a simple locking at the client level would serialize the writes
and no external locking needs to be configured.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="balancing-write-and-read-performance">Balancing write and read performance<a href="#balancing-write-and-read-performance" class="hash-link" aria-label="Direct link to Balancing write and read performance" title="Direct link to Balancing write and read performance" translate="no">​</a></h3>
<p>A critical design choice for any table is to pick the right trade-offs in the data freshness and query performance spectrum. Hudi storage format lets the users decide
on this trade-off by picking the table type, record merging and file sizing.</p>
<table><thead><tr><th></th><th>Merge Efficiency</th><th>Query Efficiency</th></tr></thead><tbody><tr><td>Copy on Write (COW)</td><td><strong>Tunable:</strong> COW table type creates a new File slice in the file-group for every batch of updates. Write amplification can be quite high <br>when the update is spread across multiple file groups. <br>The cost involved can be high over a time period especially on tables with low data latency requirements.</td><td><strong>Optimal:</strong> COW table types create whole readable data files in open source columnar file formats on each merge batch, there is minimal overhead per record in the query engine. Query engines are fairly optimized for accessing files directly in cloud storage.</td></tr><tr><td>Merge on Read (MOR)</td><td><strong>Optimal:</strong> MOR table type batches the updates to the file slice in a separate optimized Log file, write amplification is amortized over time <br>when sufficient updates are batched. The merge cost involved will be lower than COW since the churn on the records re-written for every update is much lower.</td><td><strong>Tunable:</strong> MOR Table type required record level merging during query. Although there are techniques to make this merge as efficient as possible, there is still a record level overhead to apply the updates batched up for the file slice. The merge cost applies on every query until the compaction applies the updates and creates a new file slice.</td></tr></tbody></table>
<blockquote>
<p>Interesting observation on the MOR table format is that, by providing a special view of the table which only serves the base files in the file slice (read optimized query of MOR table), query can pick between query efficiency and data freshness dynamically during query time. Compaction frequency determines the data freshness of the read optimized view. With this, the MOR has all the levers required to balance the merge and query performance dynamically.</p>
</blockquote>
<p>Sizing the file group is extremely critical to balance the merge and query performance. Larger the file size, the more the write amplification when new file slices are being created. So to balance the merge cost, compaction or merge frequency should be tuned accordingly and this has an impact on the query performance or data freshness.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="optimistic-concurrency-efficiency">Optimistic concurrency efficiency<a href="#optimistic-concurrency-efficiency" class="hash-link" aria-label="Direct link to Optimistic concurrency efficiency" title="Direct link to Optimistic concurrency efficiency" translate="no">​</a></h3>
<p>The efficiency of Optimistic concurrency is inversely proportional to the possibility of a conflict, which in turn depends on the running time and the files overlapping between the concurrent writers.
Apache Hudi storage format makes design choices that make it possible to configure the system to have a low possibility of conflict with regular workloads</p>
<ul>
<li class="">All records with the same record key are present in a single file group. In other words, there is a 1-1 mapping between a record key and a file group id, at all times.</li>
<li class="">Unit of concurrency is a single file group and this file group size is configurable. If the table needs to be optimized for concurrent updates, the file group size can be
smaller than default which could mean lower collision rates.</li>
<li class="">Merge-on-read storage engine has the option to store the contents in record oriented file formats which reduces write latencies (often up to 10 times compared to columnar storage)
which results in less collision with other concurrent writers</li>
<li class="">Merge-on-read storage engine combined with scalable metadata table ensures that the system can handle frequent updates efficiently which means ingest jobs can be frequent and quick, reducing the chance of conflicts</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="marker-mechanism-to-remove-uncommitted-data">Marker mechanism to remove uncommitted data<a href="#marker-mechanism-to-remove-uncommitted-data" class="hash-link" aria-label="Direct link to Marker mechanism to remove uncommitted data" title="Direct link to Marker mechanism to remove uncommitted data" translate="no">​</a></h3>
<p>See <a href="https://hudi.apache.org/blog/2021/08/18/improving-marker-mechanism/" target="_blank" rel="noopener noreferrer" class="">this</a> and <a href="https://github.com/apache/hudi/blob/master/rfc/rfc-56/rfc-56.md" target="_blank" rel="noopener noreferrer" class="">RFC-56</a>.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/learn/tech-specs"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Tech Specs</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#storage-layout" class="table-of-contents__link toc-highlight">Storage Layout</a></li><li><a href="#timeline" class="table-of-contents__link toc-highlight">Timeline</a><ul><li><a href="#time" class="table-of-contents__link toc-highlight">Time</a></li><li><a href="#actions" class="table-of-contents__link toc-highlight">Actions</a></li><li><a href="#states" class="table-of-contents__link toc-highlight">States</a></li><li><a href="#lsm-timeline" class="table-of-contents__link toc-highlight">LSM Timeline</a></li></ul></li><li><a href="#table-types" class="table-of-contents__link toc-highlight">Table Types</a></li><li><a href="#data-files" class="table-of-contents__link toc-highlight">Data Files</a><ul><li><a href="#base-files" class="table-of-contents__link toc-highlight">Base Files</a></li><li><a href="#log-files" class="table-of-contents__link toc-highlight">Log Files</a></li><li><a href="#log-format" class="table-of-contents__link toc-highlight">Log Format</a></li><li><a href="#versioning" class="table-of-contents__link toc-highlight">Versioning</a></li><li><a href="#headers" class="table-of-contents__link toc-highlight">Headers</a></li><li><a href="#block-types" class="table-of-contents__link toc-highlight">Block types</a></li><li><a href="#command-block-id-1" class="table-of-contents__link toc-highlight">Command Block (Id: 1)</a></li><li><a href="#delete-block-id-2" class="table-of-contents__link toc-highlight">Delete Block (Id: 2)</a></li><li><a href="#corrupted-block-id-3" class="table-of-contents__link toc-highlight">Corrupted Block (Id: 3)</a></li><li><a href="#avro-block-id-4" class="table-of-contents__link toc-highlight">Avro Block (Id: 4)</a></li><li><a href="#hfile-block-id-5" class="table-of-contents__link toc-highlight">HFile Block (Id: 5)</a></li><li><a href="#parquet-block-id-6" class="table-of-contents__link toc-highlight">Parquet Block (Id: 6)</a></li><li><a href="#cdc-block-id-7" class="table-of-contents__link toc-highlight">CDC Block (Id: 7)</a></li></ul></li><li><a href="#table-properties" class="table-of-contents__link toc-highlight">Table Properties</a></li><li><a href="#metadata" class="table-of-contents__link toc-highlight">Metadata</a><ul><li><a href="#file-listings" class="table-of-contents__link toc-highlight">File Listings</a></li><li><a href="#column-statistics" class="table-of-contents__link toc-highlight">Column Statistics</a></li><li><a href="#meta-fields" class="table-of-contents__link toc-highlight">Meta Fields</a></li></ul></li><li><a href="#indexes" class="table-of-contents__link toc-highlight">Indexes</a><ul><li><a href="#naming" class="table-of-contents__link toc-highlight">Naming</a></li><li><a href="#bloom-filter-index" class="table-of-contents__link toc-highlight">Bloom Filter Index</a></li><li><a href="#record-index" class="table-of-contents__link toc-highlight">Record Index</a></li><li><a href="#secondary-index" class="table-of-contents__link toc-highlight">Secondary Index</a></li><li><a href="#expression-indexes" class="table-of-contents__link toc-highlight">Expression Indexes</a></li></ul></li><li><a href="#relational-model" class="table-of-contents__link toc-highlight">Relational Model</a><ul><li><a href="#writer-expectations" class="table-of-contents__link toc-highlight">Writer Expectations</a></li><li><a href="#table-servicewriter-concurrency" class="table-of-contents__link toc-highlight">Table Service/Writer Concurrency</a></li><li><a href="#concurrent-readers" class="table-of-contents__link toc-highlight">Concurrent readers</a></li><li><a href="#reader-expectations" class="table-of-contents__link toc-highlight">Reader Expectations</a></li></ul></li><li><a href="#incremental-streaming-model" class="table-of-contents__link toc-highlight">Incremental Streaming Model</a><ul><li><a href="#non-blocking-concurrency-control" class="table-of-contents__link toc-highlight">Non-blocking Concurrency Control</a></li></ul></li><li><a href="#table-management" class="table-of-contents__link toc-highlight">Table Management</a><ul><li><a href="#compaction" class="table-of-contents__link toc-highlight">Compaction</a></li><li><a href="#log-compaction" class="table-of-contents__link toc-highlight">Log Compaction</a></li><li><a href="#re-writing" class="table-of-contents__link toc-highlight">Re-writing</a></li><li><a href="#cleaning" class="table-of-contents__link toc-highlight">Cleaning</a></li><li><a href="#indexing" class="table-of-contents__link toc-highlight">Indexing</a></li></ul></li><li><a href="#compatibility" class="table-of-contents__link toc-highlight">Compatibility</a></li><li><a href="#change-log" class="table-of-contents__link toc-highlight">Change Log</a><ul><li><a href="#version-8" class="table-of-contents__link toc-highlight">version 8</a></li><li><a href="#version-6--earlier" class="table-of-contents__link toc-highlight">version 6 &amp; earlier</a></li></ul></li><li><a href="#apis" class="table-of-contents__link toc-highlight">APIs</a><ul><li><a href="#recordmerger-api" class="table-of-contents__link toc-highlight">RecordMerger API</a></li><li><a href="#indexing-functions" class="table-of-contents__link toc-highlight">Indexing Functions</a></li></ul></li><li><a href="#appendix" class="table-of-contents__link toc-highlight">Appendix</a><ul><li><a href="#lock-provider-implementations" class="table-of-contents__link toc-highlight">Lock Provider Implementations</a></li><li><a href="#balancing-write-and-read-performance" class="table-of-contents__link toc-highlight">Balancing write and read performance</a></li><li><a href="#optimistic-concurrency-efficiency" class="table-of-contents__link toc-highlight">Optimistic concurrency efficiency</a></li><li><a href="#marker-mechanism-to-remove-uncommitted-data" class="table-of-contents__link toc-highlight">Marker mechanism to remove uncommitted data</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footerCustom_j_zv"><div class="container container-fluid container_y1z5"><div class="brand_kMBW"><a href="https://hudi.apache.org/" rel="noopener noreferrer" class="footerLogoLink_DDai"><img src="/assets/images/hudi.png" alt="Apache Hudi™" class="footer__logo themedComponent_mlkZ themedComponent--light_NVdE"><img src="/assets/images/hudi.png" alt="Apache Hudi™" class="footer__logo themedComponent_mlkZ themedComponent--dark_xIcU"></a></div><div class="links_AXCu"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">About</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog/2021/07/21/streaming-data-lake-platform">Our Vision</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/concepts">Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/community/team">Team</a></li><li class="footer__item"><a class="footer__link-item" href="/releases/release-1.1.0">Releases</a></li><li class="footer__item"><a class="footer__link-item" href="/releases/download">Download</a></li><li class="footer__item"><a class="footer__link-item" href="/powered-by">Adopters</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/quick-start-guide">Quick Start</a></li><li class="footer__item"><a class="footer__link-item" href="/learn/tutorial-series">Tutorial Series</a></li><li class="footer__item"><a class="footer__link-item" href="/learn/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/learn/talks">Talks</a></li><li class="footer__item"><a class="footer__link-item" href="/learn/videos">Video Guides</a></li><li class="footer__item"><a class="footer__link-item" href="/learn/faq">FAQ</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Hudi On Cloud</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/s3_hoodie">AWS</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/gcs_hoodie">Google Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/oss_hoodie">Alibaba Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/azure_hoodie">Microsoft Azure</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cos_hoodie">Tencent Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/ibm_cos_hoodie">IBM Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/oci_hoodie">Oracle Cloud</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/community/get-involved">Get Involved</a></li><li class="footer__item"><a href="https://join.slack.com/t/apache-hudi/shared_invite/zt-33fabmxb7-Q7QSUtNOHYCwUdYM8LbauA" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/apache/hudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/ApacheHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/channel/UCs7AhE0BWaEPZSChrBR-Muw" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/apache-hudi/?viewAsMember=true" target="_blank" rel="noopener noreferrer" class="footer__link-item">Linkedin<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="mailto:dev-subscribe@hudi.apache.org?Subject=SubscribeToHudi" target="_blank" rel="noopener noreferrer" class="footer__link-item">Mailing List</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Apache</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="footer__link-item">Events</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Thanks</a></li><li class="footer__item"><a href="https://www.apache.org/licenses" target="_blank" rel="noopener noreferrer" class="footer__link-item">License</a></li><li class="footer__item"><a href="https://www.apache.org/security" target="_blank" rel="noopener noreferrer" class="footer__link-item">Security</a></li><li class="footer__item"><a class="footer__link-item" href="/asf/privacy">Privacy</a></li><li class="footer__item"><a class="footer__link-item" href="/asf/telemetry">Telemetry</a></li><li class="footer__item"><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Sponsorship</a></li><li class="footer__item"><a href="https://www.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Foundation</a></li></ul></div></div></div><div class="legal_MFbX"><div class="footer__copyright">Copyright © 2021 <a href="https://apache.org">The Apache Software Foundation</a>, Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0"> Apache License, Version 2.0</a>. Hudi, Apache and the Apache feather logo are trademarks of The Apache Software Foundation.<img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=8f594acf-9b77-44fb-9475-3e82ead1910c"><img referrerpolicy="no-referrer-when-downgrade" src="https://analytics.apache.org/matomo.php?idsite=47&amp;rec=1"></div></div></div></footer></div>
</body>
</html>
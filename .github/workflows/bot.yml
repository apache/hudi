name: Java CI

on:
  push:
    branches:
      - master
      - 'release-*'
  pull_request:
    branches:
      - master
      - 'release-*'
env:
  MVN_ARGS: -ntp -B -V -Pci-log -Pwarn-log -Dorg.slf4j.simpleLogger.log.org.apache.maven.plugins.shade=warn -Dorg.slf4j.simpleLogger.log.org.apache.maven.plugins.dependency=warn
  UTILITIES_MODULE: "hudi-utilities,hudi-examples/hudi-examples-spark"
  UTILITIES_BUNDLE_MODULE: "packaging/hudi-utilities-bundle"
  SPARK_COMMON_MODULE: "hudi-spark-datasource/hudi-spark-common"
  SPARK3_COMMON_MODULE: "hudi-spark-datasource/hudi-spark3-common"
  SPARK3PLUS_COMMON_MODULE: "hudi-spark-datasource/hudi-spark3.2plus-common"
  SPARK_MODULE: "hudi-spark-datasource/hudi-spark"
  SPARK3_MODULE: "hudi-spark-datasource/hudi-spark3.2.x"
  HUDI_COMMON_MODULE: "hudi-common"
  CLIENT_COMMON_MODULE: "hudi-client/hudi-client-common"
  SPARK_CLIENT_MODULE: "hudi-client/hudi-spark-client"
  JAVA_CLIENT_MODULE: "hudi-client/hudi-java-client"
  DATAHUB_SYNC_MODULE: "hudi-sync/hudi-datahub-sync"

concurrency:
  group: ${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'master' }}

jobs:
  utilities:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
            - scalaProfile: "scala-2.12"
              sparkProfile: "spark3.2"
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 8
        uses: actions/setup-java@v3
        with:
          java-version: |
            17
            8
          distribution: 'adopt'
          architecture: x64
      - name: Build
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run:
          mvn -am -pl $UTILITIES_MODULE clean install -T 2 -Pintegration-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true $MVN_ARGS
      - name: Quickstart Test
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run: |
          mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DfailIfNoTests=false -pl hudi-examples/hudi-examples-spark $MVN_ARGS
      - name: Hudi Utilties Unit Test
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run: |
          mvn test -Punit-tests -DskipSparkClientUTs=true -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -pl $UTILITIES_MODULE $MVN_ARGS
          export JAVA_HOME="${{env.JAVA_HOME_17_X64}}"
          WORKING_DIR="/home/runner/work/hudi-internal/hudi-internal"
          jacoco_xml_report_files=$(find ${WORKING_DIR} -name 'jacoco.xml' | awk '{printf "%s%s",sep,$0; sep=","} END{print ""}')
          echo "Jacoco xml reports: ${jacoco_xml_report_files}"
          if [ ${{ github.event_name }} == 'pull_request' ]; then
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-utilities" -Dsonar.projectKey=onehouseinc_hudi-internal_utilities \
              -Dsonar.exclusions="hudi-aws/**/*,hudi-cli/**/*,hudi-client/**/*,hudi-common/**/*,hudi-examples/**/*,hudi-flink-datasource/**/*,hudi-gcp/**/*,hudi-hadoop-mr/**/*,hudi-kafka-connect/**/*,hudi-spark-datasource/**/*,hudi-sync/**/*,hudi-tests-common/**/*,hudi-timeline-service/**/*,packaging/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.pullrequest.key=${{ github.event.number }} \
              -Dsonar.pullrequest.branch=${{ github.HEAD_REF }} \
              -Dsonar.pullrequest.base=${{ github.BASE_REF }} \
              -Dsonar.pullrequest.github.repository=https://github.com/onehouseinc/hudi-internal
          else
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-utilities" -Dsonar.projectKey=onehouseinc_hudi-internal_utilities \
              -Dsonar.exclusions="hudi-aws/**/*,hudi-cli/**/*,hudi-client/**/*,hudi-common/**/*,hudi-examples/**/*,hudi-flink-datasource/**/*,hudi-gcp/**/*,hudi-hadoop-mr/**/*,hudi-kafka-connect/**/*,hudi-spark-datasource/**/*,hudi-sync/**/*,hudi-tests-common/**/*,hudi-timeline-service/**/*,packaging/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.branch.name=${{ github.HEAD_REF }}
          fi
  utilities_bundle_misc:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - scalaProfile: "scala-2.12"
            sparkProfile: "spark3.2"
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 8
        uses: actions/setup-java@v3
        with:
          java-version: |
            17
            8
          distribution: 'adopt'
          architecture: x64
      - name: Build
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run:
          mvn -am -pl "$DATAHUB_SYNC_MODULE,$UTILITIES_BUNDLE_MODULE" clean install -T 2 -Pintegration-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true $MVN_ARGS
      - name: Hudi Utilties Bundle Unit Test
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run: |
          mvn test -Punit-tests -DskipSparkClientUTs=true -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -am -pl "$DATAHUB_SYNC_MODULE,$UTILITIES_BUNDLE_MODULE,!$UTILITIES_MODULE,!$SPARK_COMMON_MODULE,!$SPARK3_COMMON_MODULE,!$SPARK3PLUS_COMMON_MODULE,!$SPARK_MODULE,!$SPARK3_MODULE,!$HUDI_COMMON_MODULE,!$CLIENT_COMMON_MODULE,!$SPARK_CLIENT_MODULE,!$JAVA_CLIENT_MODULE" $MVN_ARGS
          export JAVA_HOME="${{env.JAVA_HOME_17_X64}}"
          WORKING_DIR="/home/runner/work/hudi-internal/hudi-internal"
          jacoco_xml_report_files=$(find ${WORKING_DIR} -name 'jacoco.xml' | awk '{printf "%s%s",sep,$0; sep=","} END{print ""}')
          echo "Jacoco xml reports: ${jacoco_xml_report_files}"
          if [ ${{ github.event_name }} == 'pull_request' ]; then
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-utilities-bundle-misc" -Dsonar.projectKey=onehouseinc_hudi-internal_utilities-bundle-misc \
              -Dsonar.exclusions="hudi-cli/**/*,hudi-client/**/*,hudi-common/**/*,hudi-flink-datasource/**/*,hudi-kafka-connect/**/*,hudi-spark-datasource/**/*,hudi-tests-common/**/*,hudi-utilities/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.pullrequest.key=${{ github.event.number }} \
              -Dsonar.pullrequest.branch=${{ github.HEAD_REF }} \
              -Dsonar.pullrequest.base=${{ github.BASE_REF }} \
              -Dsonar.pullrequest.github.repository=https://github.com/onehouseinc/hudi-internal
          else
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-utilities-bundle-misc" -Dsonar.projectKey=onehouseinc_hudi-internal_utilities-bundle-misc \
              -Dsonar.exclusions="hudi-cli/**/*,hudi-client/**/*,hudi-common/**/*,hudi-flink-datasource/**/*,hudi-kafka-connect/**/*,hudi-spark-datasource/**/*,hudi-tests-common/**/*,hudi-utilities/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.branch.name=${{ github.HEAD_REF }}
          fi
  hudi-client-and-common:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - scalaProfile: "scala-2.12"
            sparkProfile: "spark3.2"
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 8
        uses: actions/setup-java@v3
        with:
          java-version: |
            17
            8
          distribution: 'adopt'
          architecture: x64
      - name: Build
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run:
          mvn clean install -T 2 -DskipTests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -am -pl "$CLIENT_COMMON_MODULE,$SPARK_CLIENT_MODULE,$JAVA_CLIENT_MODULE,$HUDI_COMMON_MODULE" $MVN_ARGS
      - name: Hudi Client Unit Tests
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run: |
          mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -pl "$CLIENT_COMMON_MODULE,$SPARK_CLIENT_MODULE,$JAVA_CLIENT_MODULE,$HUDI_COMMON_MODULE" $MVN_ARGS
          export JAVA_HOME="${{env.JAVA_HOME_17_X64}}"
          WORKING_DIR="/home/runner/work/hudi-internal/hudi-internal"
          jacoco_xml_report_files=$(find ${WORKING_DIR} -name 'jacoco.xml' | awk '{printf "%s%s",sep,$0; sep=","} END{print ""}')
          echo "Jacoco xml reports: ${jacoco_xml_report_files}"
          if [ ${{ github.event_name }} == 'pull_request' ]; then
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-hudi-client-and-common" -Dsonar.projectKey=onehouseinc_hudi-internal_hudi-client-and-common \
              -Dsonar.exclusions="hudi-aws/**/*,hudi-cli/**/*,hudi-examples/**/*,hudi-flink-datasource/**/*,hudi-gcp/**/*,hudi-hadoop-mr/**/*,hudi-kafka-connect/**/*,hudi-spark-datasource/**/*,hudi-sync/**/*,hudi-tests-common/**/*,hudi-timeline-service/**/*,hudi-utilities/**/*,packaging/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.pullrequest.key=${{ github.event.number }} \
              -Dsonar.pullrequest.branch=${{ github.HEAD_REF }} \
              -Dsonar.pullrequest.base=${{ github.BASE_REF }} \
              -Dsonar.pullrequest.github.repository=https://github.com/onehouseinc/hudi-internal
          else
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-hudi-client-and-common" -Dsonar.projectKey=onehouseinc_hudi-internal_hudi-client-and-common \
              -Dsonar.exclusions="hudi-aws/**/*,hudi-cli/**/*,hudi-examples/**/*,hudi-flink-datasource/**/*,hudi-gcp/**/*,hudi-hadoop-mr/**/*,hudi-kafka-connect/**/*,hudi-spark-datasource/**/*,hudi-sync/**/*,hudi-tests-common/**/*,hudi-timeline-service/**/*,hudi-utilities/**/*,packaging/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.branch.name=${{ github.HEAD_REF }}
          fi
  spark-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - scalaProfile: "scala-2.12"
            sparkProfile: "spark3.2"
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 8
        uses: actions/setup-java@v3
        with:
          java-version: |
            17
            8
          distribution: 'adopt'
          architecture: x64
      - name: Build
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run:
          mvn clean install -T 2 -DskipTests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -am -pl "$SPARK_COMMON_MODULE,$SPARK3_COMMON_MODULE,$SPARK3PLUS_COMMON_MODULE,$SPARK_MODULE,$SPARK3_MODULE " $MVN_ARGS
      - name: Spark Datasource Unit Tests
        env:
          SCALA_PROFILE: ${{ matrix.scalaProfile }}
          SPARK_PROFILE: ${{ matrix.sparkProfile }}
        run: |
          mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -pl "$SPARK_COMMON_MODULE,$SPARK3_COMMON_MODULE,$SPARK3PLUS_COMMON_MODULE,$SPARK_MODULE,$SPARK3_MODULE " $MVN_ARGS
          export JAVA_HOME="${{env.JAVA_HOME_17_X64}}"
          WORKING_DIR="/home/runner/work/hudi-internal/hudi-internal"
          jacoco_xml_report_files=$(find ${WORKING_DIR} -name 'jacoco.xml' | awk '{printf "%s%s",sep,$0; sep=","} END{print ""}')
          echo "Jacoco xml reports: ${jacoco_xml_report_files}"
          if [ ${{ github.event_name }} == 'pull_request' ]; then
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-spark-tests" -Dsonar.projectKey=onehouseinc_hudi-internal_spark-tests \
              -Dsonar.exclusions="hudi-aws/**/*,hudi-cli/**/*,hudi-client/**/*,hudi-common/**/*,hudi-examples/**/*,hudi-flink-datasource/**/*,hudi-gcp/**/*,hudi-hadoop-mr/**/*,hudi-kafka-connect/**/*,hudi-sync/**/*,hudi-tests-common/**/*,hudi-timeline-service/**/*,hudi-utilities/**/*,packaging/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.pullrequest.key=${{ github.event.number }} \
              -Dsonar.pullrequest.branch=${{ github.HEAD_REF }} \
              -Dsonar.pullrequest.base=${{ github.BASE_REF }} \
              -Dsonar.pullrequest.github.repository=https://github.com/onehouseinc/hudi-internal
          else
            mvn sonar:sonar -Dsonar.projectName="hudi-internal-spark-tests" -Dsonar.projectKey=onehouseinc_hudi-internal_spark-tests \
              -Dsonar.exclusions="hudi-aws/**/*,hudi-cli/**/*,hudi-client/**/*,hudi-common/**/*,hudi-examples/**/*,hudi-flink-datasource/**/*,hudi-gcp/**/*,hudi-hadoop-mr/**/*,hudi-kafka-connect/**/*,hudi-sync/**/*,hudi-tests-common/**/*,hudi-timeline-service/**/*,hudi-utilities/**/*,packaging/**/*" \
              -Dsonar.token=${{ secrets.SONAR_CLOUD_TOKEN }} \
              -Dsonar.coverage.jacoco.xmlReportPaths="${jacoco_xml_report_files}" \
              -Dsonar.branch.name=${{ github.HEAD_REF }}
          fi



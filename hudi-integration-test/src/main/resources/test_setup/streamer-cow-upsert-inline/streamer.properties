
# Key fields, for kafka example
hoodie.datasource.write.recordkey.field=key
hoodie.datasource.write.partitionpath.field=partition
# Schema provider props (change to absolute path based on your installation)
hoodie.deltastreamer.schemaprovider.source.schema.file=file:/Users/nsb/Documents/personal/datasets/hudi_benchmarks_schema/dataset.schema 
hoodie.deltastreamer.schemaprovider.target.schema.file=file:/Users/nsb/Documents/personal/datasets/hudi_benchmarks_schema/dataset.schema 
# DFS Source
hoodie.deltastreamer.source.dfs.root=file:/Users/nsb/Documents/personal/datasets/small_20r_10p_80perc_updates
benchmark.input.source.path=file:/Users/nsb/Documents/personal/datasets/small_20r_10p_80perc_updates
# Clustering
#hoodie.clustering.inline=true
#hoodie.clustering.async.enabled=false
#hoodie.clustering.async.max.commits=6
#hoodie.clustering.inline.max.commits=6
# Clean and archive
hoodie.clean.async=false
hoodie.keep.max.commits=7
hoodie.keep.min.commits=5
hoodie.cleaner.commits.retained=4
# Metadata table
hoodie.metadata.compact.max.delta.commits=5
hoodie.metadata.keep.min.commits=8
hoodie.metadata.keep.max.commits=12
